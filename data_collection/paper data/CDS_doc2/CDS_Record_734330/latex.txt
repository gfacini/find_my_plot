# Beam test of the ATLAS End-cap Muon Level 1 Trigger System

K.Nagano, M.Ikeno, K.Nakayoshi, O.Sasaki,

KEK, 305-0801 Tsukuba, Japan

C. Fukunaga, Y.Ishida, S.Komatsu, K.Tanaka, K.Toshima

Tokyo Metropolitan University, 192-0397, Tokyo, Japan

Y.Fujii, K.Hasuko, M.Ishino, H.Kano, Y.Kataoka, Y.Nakamura, H.Sakamoto, K.Shibuya, T.Takemoto

ICEPP. University of Tokyo, 113-0033 Tokyo, Japan

Y.Hasegawa, N.Takada, M.Totsuka

Shinshu University, 390-8621 Matsumoto, Japan

T.Sakuma

Tokyo University of Agriculture and Technology, Tokyo, Japan

K.Mizouchi

Kyoto University, 606-8502, Kyoto, Japan

Y.Arataki, R.Ichimiya, H.Kurashige, S.Tsuji

Kobe University, 657-8501 Kobe, Japan

T.Maeno

CERN, 1211 Geneva 23, Switzerland

A.Harel. R.Lifshitz, N.Lupu, S.Schwarzmann, S.Tarem

Technion, Haifa, Israel

Y.Benhamou, E.Etzion

Tel-Aviv University, Tel-Aviv, Israel

D.Lellouch, L.Levinson and A.Roich

The Weizemann Institute of Science, Rehovot, Israel

###### Abstract

A prototype of the ATLAS End-cap Muon Level 1 Trigger system has been constructed and mounted on thin gap chambers, which are used for muon trigger chambers for the ATLAS endcap region. We have tested the system with the chambers using 100 GeV muon beams at CERN SPS H8 beam line. The performance of both the trigger signalgeneration and the chamber data readout has been evaluated in this configuration. In the beam test, the system has been integrated with the muon central trigger processor interface as well as the ATLAS standard central data acquisition system and detector control system. We present the evaluation results of the system and discuss validity as a level 1 trigger generator system for ATLAS.

## I Introduction

The ATLAS muon level 1(LVL1) trigger system is comprised with two different chamber systems [1]. The thin gap chamber (TGC) is used to trigger muons in the end-cap region while the resistive plate chamber (RPC) is used for muons in the barrel. The triggered data from the both chamber systems are fed into the Muon Central Trigger Processor Interface (MUCTPI) in which signal overlaps for both chamber systems are resolved and the muon candidate multiplicity in an event is optimized before the muon LVL1 trigger signals are going into the central trigger processor.

We are constructing the TGC electronics system, which contains three ASICs [2], and completed the construction of the prototype for the evaluation of the signal flow from end to end. In 2002, we have tested the system by inputting electronically emulated signals. We have checked the results with ones predicted by the simulation and found no unexpected evidence in the system for the trigger. The system serves also as a usual readout system for data outputted by the chambers. We have tested this aspect of the system and improved its performance [3].

As a natural consequence of the system development before moving into the production phase of the electronics components, we have checked the system performance with chamber signals, which are actually generated by high energy muon beams. In September 2003, we brought the chambers and the present prototype electronics system into the CERN SPS H8 beam line and measured the performance for both the trigger and readout system with high energy (100 GeV) muon beam. That time the muon beams from SPS was structured as 25ns bunch mode.

In this beam test our system was integrated in the ATLAS standard trigger and data acquisition (DAQ) system. The upper stream of the trigger part is connected with the MUCTPI and the readout system is connected with the ATLAS DAQ-1 online system. The run control and configuration database were also complied with this DAQ-1 system. The ATLAS standard detector control system (DCS) was used for the chamber environmental monitor and the chamber as well as the electronics control. Based on the performance analysis of data taken in this beam test with this system configuration, we made the evaluation of various aspects of the prototype and validated the system before going into the production phase.

## II Overview of TGC Trigger System

The signals for the LVL1 endcap muon trigger come from the Thin Gap Chambers (TGC), which covers \(1.05\leq\eta\leq 2.70\), and are situated at around z=\(\pm\)14m from the interaction point (IP). The chambers give seven measurement layers on each side, grouped into three discs labeled, in order from the closest to the IP, M1 (triplet), M2 (doublet), and M3 (doublet). The configuration of TGC in ATLAS is shown in Fig. 1.

In front of TGC, there are air-core toroidal magnets that produce the magnetic fields for muon detection. By measuring the deviation of the detected points from ones to be recorded by a straight line interpolated from IP to the point detected in the outermost layer, we can estimate the curvature of a particle. Two different lever arms from M3 to M1 and M2 provide different measurements of \(\rm p_{T}\) range. Low-\(\rm p_{T}\) muon tracks (\(6\leq\rm p_{T}<20\) GeV) are identified independently using signals from M1 alone (three layers), and from M2 and M3 in combination. Then the signals identified with M2 and M3 and ones from M1 are combined to identify high-\(\rm p_{T}\) tracks (\(\rm p_{T}>20\) GeV). Results of the independent signal processes for both r and \(\phi\) are unified eventually and muon tracks identified in an r-\(\phi\) coincidence matrix will be used for the final LVL1 decision. This process is schematically shown in Fig. 2.

Figure 1: ATLAS Muon Level 1 Trigger Scheme

### _B. Electronics System_

Fig. 3 summarizes a structure of the TGC electronics system [2]. Electronics components are divided into two parts; on-detector and off-detector parts. The on-detector part is further separated into two parts, one is called Patch-panel and Slave (PS) board that is installed just behind the detector and the other one is Hi-p\({}_{\mathrm{T}}\) and Star Switch (HS) crate that is installed at the outer rim of M1.

Digitized signals from Amplifier- Shaper- Discriminator (ASD) boards [4] attached directly to TGC are inputted to Slave Board ASICs (SLB IC) after synchronized (signal output information of r, \(\phi\) and \(\Delta\)r, \(\Delta\phi\) for every muon candidate (low p\({}_{\mathrm{T}}\) coincidence with M1, or M2 and M3). The PP ASICs and SLB ICs are mounted together on a PS board. The output signals of SLB are fed into a Hi-p\({}_{\mathrm{T}}\) board, which is installed in an HS crate and is approximately 15m away from the corresponding PS board. The Hi-p\({}_{\mathrm{T}}\) board contains Hi-p\({}_{\mathrm{T}}\) ASICs (HpT IC). An HpT IC combines information from two (for doublet) to three (for triplet) SLB ICs to make a global coincidence to find muon tracks with p\({}_{\mathrm{T}}\)\(\geq\) 20 GeV/c (Hi-p\({}_{\mathrm{T}}\) coincidence). HpT IC also makes data compression to send its output over about 90m distance with serial data transmission.

Signals for r (wire hit information of TGC) and ones for \(\phi\) (strip) are independently processed in two streams up to hi-p\({}_{\mathrm{T}}\) coincidence operation, and the sector logic (SL) installed in the off-detector part combines these two streams and makes r\(\phi\)-coincidence to identify muon signals in two dimensional space. At maximum two highest p\({}_{\mathrm{T}}\) muon candidates per trigger sector (72 sectors/side) are selected after successful r\(\phi\)-coincidence, and the information is sent to the MUCTPI. Functionalities and design concept of the three main ASICs (PP, SLB and HpT) have been discussed in detail in [5].

Since hit information for both coordinates will be used not only for the trigger decision logic but also for the second coordinate information for the ATLAS muon reconstruction in offline analyses, a readout system must be implemented. Readout data are processed also in SLB ICs, each of which implements pipeline buffers during the LVL1 processing time and FIFO for selected events (de-randomizer). At every LVL1 accept (L1A) signal, data are serialized in SLB ICs and sent to a data distributor/concentrator, which is so called Star Switch (SSW). One SSW has 18 SLB IC inputs and one output. A sequential process of receiving data from SLB, storing in FIFO, format analysis and output to Readout Driver will be done for all used channels in turn under the VME control.

Readout Driver (ROD) receives data from about ten SSWs. Data received are stored in FIFO, which is prepared for every input channel. All the data stored in FIFOs are merged if these data have an identical L1A identification number. ROD sends data to the ATLAS central DAQ facility in the end.

## III Test Beam Setup

We have used the CERN H8 beam line twice in May and September 2003. The chambers were installed at the end of the H8 and exposed to 100 GeV muon beam. The beam was structured with 25ns bunch. The TGC triplet plane (three chambers) (M1) are installed in front of the monitoring drift tubes (MDT), which will be used to detect and measure muon tracks precisely in the ATLAS detector. Two doublet planes (four chambers) (M2 and M3) are mounted behind MDT. Thus the chamber layout was the same as in the final ATLAS setup.

For this beam test setup, we have used 32 wire channels and also 32 strip channels to investigate performance of the

Figure 1: Figure 3: Overview of TGC electronics

Figure 2: ATLAS end-cap muon level 1 trigger scheme with TGCsystem. Total numbers of channels are 256 and 192 for wire and setup respectively. Two PS boards and the service patch panel; SPP, used for fan-out of Timing, Trigger and Control (TTC) signals are put in front of the triplet plane while the Hi-pT and SSW modules are installed in a VME 9Ucrate (HS crate) and these are put in the vicinity of the triplet. The PS boards and the HS crate are connected with 10m cables. The ROD, SL and CCI are put in the electronics hut for the H8 beam line together with the common electronic facilities (MUCTPI and Read out system; ROS). Figure 4 shows the triplet setup with the PS board and HSC crate.

A crate which contains the ROD has own PC running LINUX system. The PC controls and monitors modules in the crate and also controls remotely modules in the HS crate by our own HSC-CCI system.

## IV Test Results

We have measured chamber efficiencies by changing the synchronization condition, namely changing the delay values in PP ASICs. We have also measured them by modifying the gate width for the front end input signals. In Fig. 5, the efficiencies of the first chamber of the triplet for both wire and strip are shown.

In Fig.6, we plot the muon beam profile measured by two chambers of the triplet (The middle chamber in the triplet has only wires and no strips). Beam profile is measured in two dimensional space arranged with wire and strip information. Both chambers give the root mean square of about three channels for both wire and strip. Data are taken under the condition of 15ns delay of the triplet PP ASIC and 30ns gate width.

The trigger efficiency has been also measured at the end of the TGC trigger system, namely at the output of the SL after the wire and strip coincidence matching. The trigger signals generated by the SL are inputted to MUCTPI.

Figure 4: On detector electronics setup around the triplet

Figure 5: Chamber efficiency for the 1\({}^{\mathrm{st}}\) one of the triplet versus PP ASIC delay adjustment with three different gate widths (25,30 and 35ns). Triangle shows data recognized as the right bunch, and the circle (star) represents data in the previous (next) bunch.

We have measured the efficiency by changing the triplet PP ASIC delay value. In Fig.7, we show the trigger efficiency at the SL output as a function of the PP ASIC delay value. The gate width for the ASD was set to 30ns. Although the highest trigger efficiency was calculated as about 97%, 2.7% of it is owing to the dead space for the chamber support and less than 1% will be coming from some spurious beam triggers. Trigger efficiency was then estimated as 99.7% maximum after the corrections.

## V Conclusion

Functionality of the full chain of the TGC electronics system has been tested with 100GeV muon at H8 beam line of CERN SPS. TGC has been in reality used to detect muons. Generated signals have been processed (amplified, shaped and discriminated) by our own ASD board.

Seven layers of TGC have been setup to make a triplet and two doublets. We have put the triplet in front of MDT and two doublets behind it. The chamber configuration was, therefore, almost the same as the final one for the ATLAS endcap muon detection system while the number of channels was limited to minimum (but enough) to validate various functionalities of the system itself.

The main purpose of this beam test is to check the validity of the logic and performance of the system with actual chambers and actual high energy muons with 25ns bunch mode in detail. The system uses three different kind of large scale ASICs (PP, SLB and Hi-p\({}_{\rm{T}}\)). The production of PP and Hi-p\({}_{\rm{T}}\) ASIC is being or has been done. Although the design of the most complicated SLB ASIC, which contains both facilities of trigger signal generation and readout buffers) has been finished, the production is not yet started. In this beam time we intended to check the consistency of the final design of this chip in the most realistic working condition.

As we have seen and discussed in the last section, the performance of the system and data produced by it indicate the system has worked fine in an environment of not only the actual detector configuration but also the ATLAS common signal distribution scheme of timing and trigger (TTC system). The trigger output signals have been successfully accepted to MUCTPI as level 1 muon end-cap trigger ones. The read out data have been successfully merged in the ATLAS common readout chain together with ones from other sub-detector (MDT and MUCTPI). Figure 8 shows the consequence of the combined running. We have analyzed trigger data recorded in the readout buffer of both TGC and MUCTPI in a run and checked the p\({}_{\rm{T}}\) values from both streams. The consistency can be observed clearly from the graph.

## VI Acknowledgement

First of all we would like to acknowledge the CERN SPS and H8 beam line crew for giving us 25ns structured beam constantly during the test. We are grateful to ATLAS TGC construction group and in particular M. Ishino and Y. Arataki for their advice and support for the TGC operation in the beam time. We would like to express our gratitude to G. Mikenberg, N. Ellis, T. Kondo and T. Kobayashi for their support and encouragement throughout the test. We are grateful to T. Wengler, Ph. Farthouat and P. Gallno for their MUCTPI and TTC system integration and F.Ceruti for his beam time management.

Figure 6: Two dimensional Beam profile measured by the first and third chambers of the triplet.

Figure 7: Trigger efficiency versus delay value set of PPASIC

## VII References

* [1] ATLAS First Level Trigger Technical Design Report CERN/LHCC/98-14 (1998) and TDR homepage: [http://atlasinfo.cern.ch/Atlas/GROUPS/DAOTRG/TDR/tdr.html](http://atlasinfo.cern.ch/Atlas/GROUPS/DAOTRG/TDR/tdr.html)
* [2] K.Hasuko, C.Fukunaga, Y.Hasegawa, R.Ichimiya, M.Ikeno, H.Iwasaki et al., "First-Level End cap Muon Trigger System for ATLAS", in _Proc. the 6\({}^{\mathrm{th}}\) Electronics for LHC Experiments_, 2000, pp.328-332.
* [3] K. Hasuko, H.Kano. Y. Matsumoto, Y. Nakamura et al., "The First Integration Test of the ATLAS End-cap Muon Level 1 Trigger System", _IEEE Trans. Nucl. Sci.,_ vol.50 (2003) 864-868
* [4] O.Sasaki and M.Yoshida, "ASD IC for the thin gap chamber in the ATLAS experiment", _IEEE Trans. Nucl. Sci._, vol. 46 (1999) 1871-1875.
* [5] H.Kano, C.Fukunaga, M.Ikeno, O.Sasaki, R.Ichimiya, H.Kurashige et al., "Custom chips developed for trigger/ readout system of the ATLAS end-cap muon chambers", in _Proc. the 6\({}^{\mathrm{th}}\) Electronics for LHC Experiments_, 2000, pp. 486-490.

Figure 8: Comparison of trigger P\({}_{\mathrm{T}}\) values stored in the output data banks given of TGC and MUONCTPI