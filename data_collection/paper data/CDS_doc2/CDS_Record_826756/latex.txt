# A full simulation analysis of the graviscalar discovery potential in ATLAS

Ola Kristoffer Oye

###### Abstract

We explore the discovery potential for a graviscalar in ATLAS, using full detector simulation. The graviscalar is an extra dimensional supersymmetric partner to the graviton, arising in the bulk in the ADD scenario. The signal from such a particle will be observed as \(E_{T}^{miss}\) accompanied by a high \(p_{T}\) jet. The study is based on a previous study [1] performed with ATLFAST.

_Institute for Physics and Technology, University of Bergen, Norway_

## 1 Introduction

Recent models, [2, 3], suggest that there may exist large extra dimensions in addition to our 4-dimensional Standard Model world. In these models, our world resides on a 4-dimensional brane in a higher dimensional space known as the bulk, where the extra dimensions are said to be compactified, explaining the fact that we have not yet observed any effects related to the extra dimensions.

The experimental bounds from direct tests of gravitation are currently \(R<200\mu m\) for any largest extra dimension, and \(R<150\mu m\) for two equally sized extra dimensions [4]. In addition, there exist limits from astrophysics observations. These are model dependent, and apply to models with flat extra dimensions and a universally coupling graviton as the only particle present in the bulk. The bounds are \(R<90-660\) nm, depending on the assumptions made [5].

Models with large extra dimensions provide us with a possible solution to the hierarchy problem: why the scales of the different basic interactions are of so different magnitudes. The mass scale of the weak force, \(M_{W}\sim 80\) GeV, is much smaller than the mass scale of gravity, given by the Planck mass \(M_{D(4)}\sim 10^{19}\) GeV. However, if we introduce the concept of extra dimensions, \(M_{D}\) is given as

\[M_{D(4)}^{2}=M_{D(4+n)}^{n+2}R^{n} \tag{1}\]

where \(n\) is the number of extra dimensions and \(R\) is the size of these dimensions. This allows to have the Planck mass as small as \(\sim\)TeV, and gives experimentally testable predictions for the LHC.

## 2 Graviscalar model

In the following section we summarize the most important features of the model in [1], on which this analysis is based. See the reference for more detailed information.

Many of the extra-dimensional models are inspired by string theory, which incorporates also supersymmetry. In this model, only the bulk is supersymmetric, and not the brane to which the SM particles are confined. Since only gravity propagates in the bulk, the graviton obtains supersymmetric partners, while the SM particles remain without partners.

The model also requires two supersymmetry generators (extended supersymmetry) in the extra dimensional bulk. These two generators will look like four on our 4-dim brane, giving rise to four supersymmetric graviton partners with spins 3/2, 1, 1/2 and 0. The graviscalar that is the subject of this analysis, is such a supersymmetric partner, and similar studies for the graviton and other partners exist [6], [7]. It should be emphasised that the graviscalar in this case is not a scalar arising from the metric itself, as seen in [8].

Since the goal of this study is to evaluate the discovery potential and effects of such a particle in ATLAS, the couplings to SM particles must be identified. The simplest such couplings are tri-linear, and involve the graviscalar and two SM particles. They can be described by the following lagrangian:

\[{\cal L}_{EFF} = \partial_{M}\phi(x,y)\partial^{M}\phi(x,y)\] \[-\delta^{n}(y)\Bigg{[}\sum_{Q}\tilde{\Psi}^{i}_{Q}(x)(\tilde{g}+i \tilde{g}_{5}\gamma_{5})_{ij}\Psi^{j}_{Q}(x)\phi(x)\] \[+\tilde{c}_{g}G^{\mu\nu}_{a}(x)G^{a}_{\mu\nu}(x)\phi(x)+\tilde{b}_ {g}\epsilon^{\mu\nu\lambda\rho}G^{a}_{\mu\nu}(x)G^{a}_{\lambda\rho}(x)\phi(x)\] \[+\tilde{c}_{\gamma}F^{\mu\nu}(x)F_{\mu\nu}(x)\phi(x)+\tilde{b}_{ \gamma}\epsilon^{\mu\nu\lambda\rho}F_{\mu\nu}(x)F_{\lambda\rho}(x)\phi(x) \Bigg{]}\]

The couplings are :

* quarks : \(\tilde{g}\), \(\tilde{g}_{5}\)
* gluons : \(\tilde{c}_{g}\), \(\tilde{b}_{g}\)
* photons : \(\tilde{c}_{\gamma}\), \(\tilde{b}_{\gamma}\)

The coordinates \((x,y)\) refer to the 4 SM dimensions and the extra dimensions respectively. The couplings in the effective lagrangian have dimensions, so in order to create dimensionless couplings, they are multiplied with the proper power of the reduced Planck Mass \(\tilde{M}_{D}\). The reduced Planck mass is denoted by a bar and given as:

\[\tilde{M}_{D}^{n+2}=(2\pi)^{-n}M_{D}^{n+2} \tag{2}\]

Our dimensionless couplings are defined as:

\[g_{ij}=\tilde{g}_{ij}\tilde{M}_{D}^{n/2} \tag{3}\]

and

\[c_{g}=\tilde{c}_{g}\tilde{M}_{D}^{1+n/2} \tag{4}\]

When calculating the cross sections in [1], it is found that the couplings \(g_{5}\) and \(b_{g}\) can both be set to 0 without loss of generality. This comes from the fact that the cross-sections only depend on the combination of \(g+g_{5}\) and \(b_{g}+c_{g}\). Therefore, from now on, only \(g\) and \(c\) will be used for couplings to quarks and gluons respectively.

## 3 Processes

The couplings between the graviscalar and the quarks/gluons give us three possible production channels at the LHC (see figure 1 for Feynman diagrams describing the production channels) :

* \(q+\bar{q}\to\phi+g\)
* \(q+g\to\phi+q\)
* \(g+g\to\phi+g\)

As the graviscalar does not interact with the detector, its signature will be \(E_{T}^{miss}+\) jet.

To claim a discovery, we require the signal significance to be larger than 5:

\[\frac{S}{\sqrt{S+B}}>5 \tag{5}\]

where \(S\) is the number of signal events and \(B\) the number of background events after all cuts are applied.

### Assumptions and requirements of model

For the model to be valid, certain assumptions and requirements are imposed:

* Since this is an effective theory, it is only valid for energies below the basic interaction scale, in this case the Planck mass \(M_{D}\). For this reason, a cutoff in the centre of mass energy \(\sqrt{s}\) is required, to reject events with CM-energies larger than \(M_{D}\). This is defined to be the point at which the cross section with cutoff deviates from the total cross section by 10%, and thus puts a limitation on the minimum \(M_{D}\) for which the model is valid. These limits are given in table 1, taken from [1].
* It is assumed that the size of the compactified dimensions is much larger than the wavelength of the graviscalar, so that level spacings of the Kaluza-Klein states are small compared to the graviscalar momentum. The spectrum can thus be taken to be continuous, and the level spacings are given in table 1. This allows for integration over the states, instead of summing over a discrete spectrum. However, doing so limit us to consider non-warped models only, namely the ADD. The model is for this reason not applicable to the RS-scenario.

Notice in table 1 that for \(n=2\), \(M_{D}=3.6\) TeV we are outside the limits from both astrophysics and from direct tests of gravitation, since \(R=190\mu m\). The astrophysics limit are however model dependent, and need not necessarily apply to this model, since it puts bounds on the extra dimensions based on graviton couplings to \(e\) and \(\gamma\) only [1, 5]. For the bounds from direct tests, we have to require \(M_{D}>4\) TeV to get below the experimental bound of \(R<150\mu m\).

\begin{table}
\begin{tabular}{|l|l|l|l|} \hline n extra dim & \(M_{D}^{min}\) [TeV] & \(R\) [\(\mu m\)] & KK level spacing [eV] \\ \hline \hline
2 & 3.60 TeV & \(1.9\times 10^{2}\) & \(1.0\times 10^{-3}\) \\ \hline
3 & 4.30 TeV & \(9.2\times 10^{-4}\) & \(2.1\times 10^{2}\) \\ \hline
4 & 4.85 TeV & \(2.1\times 10^{-6}\) & \(9.4\times 10^{4}\) \\ \hline
6 & 5.70 TeV & \(4.5\times 10^{-9}\) & \(4.4\times 10^{7}\) \\ \hline \end{tabular}
\end{table}
Table 1: Lowest Planck mass allowed for validity of model. The radii of the extra dimensions corresponding to the given \(M_{D}\) are found using eq. 1. The KK tower spacings are calculated as \(\hbar c/R\).

Generation, Simulation and Reconstruction

For simulation and reconstruction of signal and backgrounds, AtlasRelease 7.0.2 [10] was used. The generator for the graviscalar was obtained from the authors of [1], and integrated as a user process in Athena-Pythia, using Pythia 6.221 [11], [12]. In [1], the generation was run as standalone Pythia, which has not the same default settings as set in Pythia_i. Most notably, PYPARS3 MSTP(128) is by default 1 in Pythia_i. In this case, the events with a graviscalar turned out to have no final state radiation from the gluon in the final state. Setting it to 0 fixed this.

For simulating the events, the GEANT3-based atlasim[10] was used. The events were simulated using Nordugrid [9] (mainly Parallab and Kofusy dusters), where the computation time was \(\sim\) 3-5 minutes event. Approximately 120k events of signal and background were simulated and reconstructed.

The default algorithms and parameters were used, with one exception; the Cone algorithm with \(\mathbf{R}=0.4\) was used for reconstructing jets instead of Ktjet. The reason for this choice was that the Cone algorithm gave jet distributions similar to those of ATLFAST, making the two analyses more comparable. In retrospect, we realize it would have been better to run both algorithms in parallel, being able to compare the two systematically. However, this was not done when simulating the events, and due to limited disk space, the majority of simulation files were not kept on disk, making a new reconstruction not practical.

No pile-up was included in the simulations, so the study effectively applies to a low luminosity scenario.

At generator level, a cut of \(p_{T}>500\) GeV was imposed, setting PYSUBS CKIN(3)=500 in Pythia. This unfortunately introduces a generation bias in our analysis, but helps to keep the number of needed simulated events at a manageable level.

For all the following plots involving the graviscalar, a reference graviscalar signal was used with parameters n=2, \(M_{D}\)=5.0 TeV, g=0.7, c=0.41. This is the same as used in [1].

### Standard Model Background

As the graviscalar signature is \(E_{T}^{miss}\) + jet, the SM background consists of processes having missing energy in the final state: events with neutrinos. These processes can be found in table 2. In practice, all events with poorly reconstructed energy could contribute to the background, but since we are looking at events with \(E_{T}^{miss}>500\) GeV, the effect of this is taken to be negligible.

### Cross sections

Both background and signal events were initially generated using the Pythia 6.221 default PDF, CTEQ5L [13]. Comparing with other PDFs, quite large discrepancies were found, so we decided to check the cross sections using CTEQ6 [13] PDFs, which includes fits to more recent data as well as uncertainties. Also adding to CTEQ6 improved reliability is the included running of \(\alpha_{s}\).

#### 4.2.1 PDF uncertainties

With the introduction of uncertainties in the PDFs, we can study the impact this has on our analysis, looking at a worst-case scenario. This is especially important for extra dimensional studies, where the continuous KK-state distribution makes the signal quite sensitive to fluctuations in the background. This has been found to be a significant effect in other studies [15].

However, in the CTEQ6 PDF set, only 6M, which is based on NLO calculations, includes these uncertainties. As Pythia is a LO generator, we should rather use the LO PDF, CTEQ6.1L, for computing the central cross section. We therefore use 6.1L for the central value of the cross sections, while using 6M for computing the error. We then scale the errors from 6M to 6.1L, simply by using the ratio between the cross sections from the two PDFs.

The way the 6M cross section error is calculated is the following:

* The 6M PDF is a global fit to data, using 20 free parameters. 20 eigenvectors are then obtained from the corresponding diagonalized error matrix. For each eigenvector, up and down excursions are performed in the tolerance gap, leaving us with 40 parameter sets. This translates into 40 new fits, named error PDFs.
* For each error PDF, we calculate \[\Delta\sigma_{i}^{+} =\sigma_{i}-\sigma_{0} \text{if }\sigma_{i}>\sigma_{0}\] \[\Delta\sigma_{i}^{-} =\sigma_{0}-\sigma_{i} \text{if }\sigma_{0}>\sigma_{i}\] where \(\sigma_{0}\) comes from the 6M fit, and \(\sigma_{i}\) from the \(i\)th error PDF. We then calculate the total error as \[\Delta\sigma^{\pm}=\sqrt{\sum_{i}(\Delta\sigma_{i}^{\pm})^{2}}\] (6)

\begin{table}
\begin{tabular}{|l|c|c|c|} \hline  & CTEQ5L & CTEQ6M & CTEQ6.1L \\ \hline \hline Background processes: & & & \\ \hline \(p+p\to jet+W\to jet+e+\nu_{e}\) & 313.4 fb & 424.3\({}^{+14.1}_{-12.7}\) fb & 390.4\({}^{+13.0}_{-11.7}\) fb \\ \hline \(p+p\to jet+W\to jet+\mu+\nu_{\mu}\) & 314.0 fb & 424.9\({}^{+11.5}_{-11.0}\) fb & 389.8\({}^{+16.0}_{-10.1}\) fb \\ \hline \(p+p\to jet+W\to jet+\tau+\nu_{\tau}\) & 313.4 fb & 424.1\({}^{+15.2}_{-12.3}\) fb & 388.5\({}^{+14.0}_{-11.7}\) fb \\ \hline \(p+p\to jet+Z\to jet+\nu+\nu\) & 241.0 fb & 350.1\({}^{+14.0}_{-11.0}\) fb & 318.6\({}^{+12.4}_{-10.0}\) fb \\ \hline \end{tabular} 
\begin{tabular}{|l|c|c|c|} \hline Graviscalar (g=0.7, c=0.41, \(M_{D}\)= 5 TeV, n=2) & & \\ \hline \(p+p\to jet+\phi\) & 157.2 fb & 30.1\({}^{+45.8}_{-73.1}\) fb & 233.1\({}^{+33.9}_{-50.4}\) fb \\ \hline Graviscalar subprocesses: & & & \\ \hline \(q+\bar{q}\to\phi+g\) & 32.0 fb & 40.7\({}^{+3.0}_{-2.8}\) fb & 41.1\({}^{+3.1}_{-2.9}\) fb \\ \hline \(q+g\to\phi+q\) & 85.1 fb & 150.9\({}^{+13.4}_{-23.6}\) fb & 127.0\({}^{+13.3}_{-19.8}\) fb \\ \hline \(g+g\to\phi+g\) & 40.1 fb & 109.5\({}^{+29.4}_{-49.7}\) fb & 65.0\({}^{+17.5}_{-27.7}\) fb \\ \hline \end{tabular}
\end{table}
Table 2: Cross sections for graviscalar and SM background processes. Due to the shift towards higher \(x\) for gluons in CTEQ6, the production channels involving gluon increases significantly compared to that of CTEQ5.

Notice that this results in two separate values, one for the positive and one for the negative component of the error.

The resulting cross sections for background and signal for each PDF are given in table 2. The higher cross sections given by the CTEQ6 PDFs is mainly due to a shift towards higher \(x\) in the gluon distributions. This can be seen in the gluon fusion graviscalar subprocess where the effect is quite significant.

For the rest of our analysis, we will use the numbers from CTEQ6.1L.

## 5 Analysis

The analysis was performed with ROOT 3.10/02 and 4.02/00 [14] on the combined ntuple (CBNT) output from the reconstruction in Athena.

The following sections show the results of cuts on signal and background.

### Precut on \(E_{t}^{miss}\)

On generator level, a requirement \(p_{T}>500\) GeV of was applied. For a graviscalar event this should result in \(E_{t}^{miss}>\sim 500\) GeV. A precut on \(E_{t}^{miss}>500\) GeV is for this reason applied to the reconstructed data. The distribution of \(E_{t}^{miss}\) for the background and signal can be seen in figures 2 and 3. We have calculated the missing energy in the recommended way, using H1 calibration:

\((E_{t}^{miss})^{2}=\)

\((\)EXmiss_H1_calib+EXmiss_Truth_eta5_full-EXmiss_Truth_muons\()^{2}+\)

\((\)EYmiss_H1_calib+EXmiss_Truth_eta5_full-EYmiss_Truth_muons\()^{2}\)

The reason for calculating \(E_{t}^{miss}\) in this way is that we do not simulate physics over the full eta range, only for \(|\eta|<3.2\). To obtain \(E_{t}^{miss}\) for the non-simulated region, we add the information from MC truth. Also, since \(E_{t}^{miss}\) is calculated from calorimetric information, we will have a contribution from muons. To correct for this, we subtract the MC truth muon energies, assuming this is taken care of in a more mature \(E_{t}^{miss}\) algorithm.

The efficiency of the precut can be found in tables 6 and 7 together with all other cuts. Notice especially the higher precut efficiency for the subprocess with a quark in the final state 72.8 % vs 63.5 % and 59.8 % for the two with gluons. Looking at the \(E_{t}^{miss}\) truth, we indeed see a shift towards higher values for the \(q+g\) process, indicating that this is a physical effect. It could be explained by the fact that \(q\) is shifted towards higher \(x\) in the PDFs compared to \(\tilde{q}\) and \(g\). In addition, \(g\) also seems to be higher in \(x\) than \(\tilde{q}\), comparing the \(q+\tilde{q}\) and \(g+g\) distributions. This then agrees with the fact that \(q+\tilde{q}\) gives a lower \(E_{t}^{miss}\) than \(q+g\).

#### 5.1.1 Generation bias

We see from the plots that \(E_{t}^{miss}\) is underestimated for both background and signal, this has also been reported by other studies [16]. This means that our generation bias \(p_{T}>500\) GeV becomes negligible; it is unlikely that an event with less than 500 GeV missing energy should be reconstructed with \(E_{t}^{miss}>500\) GeV.

Figure 3: Reconstructed and truth \(E_{T}^{miss}\) distributions for background processes.

Figure 2: Reconstructed and truth \(E_{T}^{miss}\) for reference graviscalar signal. We see individual plots for the three sub processes, and for the total signal.

### No isolated lepton in the event.

Three of the four background processes in table 2 have \(E_{T}^{miss}\) + lepton + jet in the final state. By looking for an isolated electron or muon, two of the background processes can be effectively rejected. The tau will however decay, and can thus not be detected directly.

### Electrons

The egamma algorithm, which performs clustering in the EM calorimeter, assigns to each cluster an IsEM parameter, telling us whether the cluster is isolated or not. The requirements for this is a combination of shower shape and energy deposited behind the EM cluster in the hadronic calorimeter. If IsEM==0, the cluster is counted as isolated. The procedure for identifying an electron:

* Find EM cluster with IsEM==0 and \(E_{T}>8\) GeV.
* In a cone \(R=0.08\) around the cluster, collect all tracks satisfying \(\chi^{2}<4\) and with hits in more than 5 silicon layers in inner detector. R is defined as \(R=\sqrt{\Delta\phi^{2}+\Delta\eta^{2}}\).
* Reject event if one of the tracks satisfies \(0.5\!<E_{T}/p_{T}<5\).

The reconstructed \(p_{T}\) distribution together with the distribution from Spcl_MC can be seen for electron background and signal in figure 4. Figure 5 shows the electron resolution by matching each reconstructed electron to its closest truth electron. Table 3 gives the electron efficiency in numbers.

The cut values are fairly loose, and are the result of an optimisation with respect to signal significance, see figure 6. The rejection rate is not very high, mainly due to many events having a low \(p_{T}\) electron from the W, as this is favoured by our precut, selecting events where the neutrino carries most of the energy.

Figure 4: Left: \(p_{T}\) for reconstructed and truth electrons for \(W\to e+\nu_{e}\) background. Right: Same plot for reference signal.

\begin{table}
\begin{tabular}{|l|l|l|} \hline Process & \(W\to e+\nu\) & Graviscalar ref. \\ \hline \hline Number of events after precut & 4153 & 6015 \\ \hline Number of events with lsEM==0 & 3437 & 267 \\ \hline Number of true electrons (Spcl\_MC) & 4693 & 1092 \\ \hline Number of reconstructed electrons & 3253 & 81 \\ \hline Number of rejected events & 3217 & 78 \\ \hline Rejection rate (\%) & \(77.5\pm 1.4\) & \(1.3\pm 0.1\) \\ \hline Rejected events with no \(e\) - truth match & 27 & 52 \\ \hline \end{tabular}
\end{table}
Table 3: Performance of electron cut on electron background and graviscalar reference signal. The last row states the number of rejected events where none of the reconstructed electrons could be matched to a truth electron in a cone \(R=0.2\).

### Muons

The MOORE algorithm performs track reconstruction in the muon spectrometer. To determine whether a muon track from this algorithm should be counted as an isolated muon or not, we use the following method:

* Select muon track with \(p_{T}>2\) GeV and \(\chi^{2}<3\).
* Sum calor energy in cone \(R=0.6\) around muon track. Reject event if \(E_{T}^{cone}<1\) GeV.

The cut efficiencies are given in table 4, and the \(p_{T}\) distribution for truth and reconstructed muons for both muon background and signal can be seen in figure 7.

In figure 8, we see \(p_{T}^{rec}/p_{T}^{truth}\), where \(p_{T}^{truth}\) is taken from the closest truth track from Spcl_MC. The event is only plotted if there exists a muon from Spcl_MC in a cone \(R=0.2\) around the track. From the right part of the figure, we can see that the shift towards values \(<1\) comes mainly from low \(p_{T}\) tracks.

The optimization of the muon cut parameters can be found in fig 9.

Figure 7: Reconstructed and truth \(p_{T}\) for muon background (left) and signal(right).

### Cut on tau background

For the tau background process, the tau will decay to electrons or muons \(\sim 35\%\) of the cases, while decaying hadronically the rest of the time. In [1], the fact that a hadronically decaying tau will recoil against a high \(p_{T}\) jet is used, cutting on high \(p_{T}\) back-to-back jets. This is however not applicable here, mainly due to the precut on \(E_{T}^{\mu\,iss}\). This removes most of the high \(p_{T}\) taus, since the W decays where the neutrino carries the larger part of the \(p_{T}\) is favoured by the precut.

In figure 10, the relative difference in \(\phi\) between the two most energetic jets in each event is shown. We see that the distribution is flat for both signal and background, and thus not possible to use for event rejection.

Another way of identifying taus, is to use the tauRec package, part of the official Atlas Release. This algorithm identifies tau candidates, built from cluster, cell and track information. Usually there are several such candidates in each event, but additional cuts are used to eliminate most of these, see the list below. If a candidate pass all the cuts, the flag tau_accept==1 is set for the candidate.

For this analysis, the algorithm was just run out of the box, leaving the cuts to their default values:

* Nbr. tracks 1 or 3
* Total charge of tracks = \(\pm\)1

\begin{table}
\begin{tabular}{|l|r|r|} \hline  & \(W\rightarrow\mu+\nu\) & Graviscalar ref. \\ \hline \hline Number of events after \(e\) cut & 3996 & 5937 \\ \hline Number of true muons (Spc1\_MC) & 4056 & 277 \\ \hline Number of rec muons & 3246 & 136 \\ \hline Number of truth matches & 3174 & 18 \\ \hline Number of rejected ev. & 3190 & 114 \\ \hline Efficiency & 79.8 \% & 1.9 \% \\ \hline \end{tabular}
\end{table}
Table 4: Data from muon cuts. By truth matches it is meant that a true muon is found for \(R<0.1\) with respect to the reconstructed muon.

Figure 9: Muon cut optimization with respect to signal significance.

* Likelihood > -6. The likelihood is calculated from the quantities EM radius, strip width, \(E_{T}^{had}/\Sigma p_{T}^{tracks}\) and \(E_{R12}^{Frac}\) (the fraction of the total EM energy deposited in a cone \(0.1<R<0.2\) around the tau candidate).
* \(E_{T}^{had}/\Sigma p_{T}^{tracks}>0.1\).

Figure 11 shows the \(p_{T}\) distribution for reconstructed taus, together with taus from truth. Also the taus from truth decaying hadronically are shown, since these are the taus taurec has the possibility of identifying.

We see from figure 12 that the reconstructed energy from tauRec is not very good, since tau neutrinos carry a substantial part of the energy from the initial tau. However, we see that the reconstructed and true taus are close in space, indicating a fairly good tagging efficiency. This is also shown in table 5, where the tau efficiency for the tau background sample and the graviscalar reference signal is compared.

Figure 11: \(p_{T}\) distributions for reconstructed taus together with true taus and true taus decaying hadronically for tau background (left) and signal (right).

\begin{table}
\begin{tabular}{|l|l|l|l|l|l|} \hline  & tau bckgr & Gsc ref & Gsc 1 & Gsc 2 & Gsc 3 \\ \hline \hline Nbr events & 4877 & 5823 & 1801 & 2178 & 1844 \\ \hline Nbr candidates & 13720 & 14346 & 3801 & 5042 & 5503 \\ \hline Nbr accept & 2110 & 237 & 41 & 99 & 97 \\ \hline Nbr truth matches & 1877 & 1 & 0 & 1 & 0 \\ \hline Nbr true taus & 4852 & 17 & 6 & 7 & 4 \\ \hline Rejected events & 2010 & 229 & 40 & 97 & 92 \\ \hline Veto efficiency & 58.8 \% & 96.1 \% & 97.8\% & 95.5 \% & 95.0 \% \\ \hline \end{tabular}
\end{table}
Table 5: Veto efficiency for tauRec. We see that the effect of the more ’tau-like’ likelihood distribution of the \(q+g\rightarrow\phi+q\) (Gsc 2) turns out to be not very significant, since the number of candidates also varies for the three sub processes.

Figure 12: Matching of reconstructed taus to closest true tau. Left: Correlation \(p_{T}^{rec}\) and \(p_{T}^{truth}\). Right: Distance between \(\tau^{rec}\) and \(\tau^{truth}\).

It was noticed that the likelihood distribution was quite different for the different graviscalar sub processes. In figure 13 the likelihood for each of these is shown as well as the tau background. All tau candidates are included, so no other cuts are applied.

We find that the likelihood distribution of the sub process with a quark jet in the final state is much closer to the distribution of the tau background than those from the two processes with a gluon. The explanation to this could be that the quark jets are more narrow than gluon jets, being more 'tau like' with respect to the likelihood computation.

This could have an impact on the tau rejection rate. However, the effect turns out to be negligible, as the number of candidates per event is higher for \(g+g\to\phi+g\), giving the two processes approximately the same overall efficiency.

## 6 Results

The distributions of \(E_{T}^{miss}\) for signal and background after all cuts are applied are shown in figure 14.

Having applied all cuts, we are now able to determine the parameters for which parameters a \(5\sigma\) discovery of a graviscalar is possible.

### Cut efficiencies

The cut efficiencies for each data set are shown in figure 15, table 6 and 7. We see from table 7 that the cut efficiencies are similar for the three production channels, as should be expected from the similarity of the three final states. Although we have seen that the tau cut treats the three processes differently,

Figure 13: Likelihood of tau candidates for the three signal subprocesses (upper row) and the tau background (lower plot). No cuts are applied at this stage. Notice the similarity between the \(q+g\to\phi+q\) and the tau background.

this has a rather small impact on the final efficiency. We will therefore, regardless of the subprocess cross-sections, use the overall cut efficiency obtained from the reference signal when considering different parameter sets for the discovery limits.

We can now, based on our cut efficiencies, calculate the number of graviscalar events needed to claim a \(5\sigma\) discovery, and with that the cross section. For this, we use equation 5. Also taking into account the uncertainties, we calculate the number of signal events needed in a worst-case scenario. By this we mean a scenario where the background cross sections turns out to be at the upper limit of the uncertainties in table 2.

The resulting number of events needed for \(5\sigma\) can be found in table 8. We find that the cross section required for a discovery at 100 fb\({}^{-1}\) is \(\sigma_{lim}=9.9\) fb for CTEQ6.1L central value, and 10.5 fb if we take the PDF error into account.

### Parameter scan

Performing a scan over the parameter space \((g,c,n)\), we determine for which parameters we obtain the cross section \(\sigma_{lim}\), given in the previous paragraph.

As stated earlier, the cross sections are mainly determined by the dimensionful couplings \(\tilde{g}\) and \(\tilde{c}\), apart from the small cutoff imposed by \(\sqrt{s}<M_{D}\). This means that for the required cross-section \(\sigma_{lim}\), a scenario with a high \(M_{D}\) compared to one with a low \(M_{D}\) would require higher dimensionless couplings \(g\) and \(c\). This can be seen from equations 3 and 4.

Following this argument, the smallest dimensionless couplings (allowed by the model) that could give us \(\sigma_{lim}\) would be those of the scenario \(M_{D}=M_{D}^{\mbox{\scriptsize\it m}}\), see table 1. This lower limit on the coupling constants is illustrated in figure 16. The region of parameter space below this would require more data to be reachable.

Figure 14: Stacked plot showing \(E_{T}^{miss}\) for background and signal after all cuts applied.

\begin{table}
\begin{tabular}{|l|l|l|l|l|l|} \hline Process & \# ev. & \(E_{T}^{miss}\) precut & \(e\) cut & \(\mu\) cut & \(\tau\) cut \\ \hline \hline \(W\to e\) + \(\nu\) & 32800 & 4153 (12.7\(\pm\)0.2\%) & 22.5\(\pm\)0.7\% & 22.3\(\pm\)0.7\% & 17.4\(\pm\)0.6\% \\ \hline \(W\to\mu+\nu\) & 32698 & 4107 (12.6\(\pm\)0.2\%) & 95.1\(\pm\)1.5\% & 19.6\(\pm\)0.7\% & 18.5\(\pm\)0.7\% \\ \hline \(W\to\tau+\nu\) & 32020 & 7599 (23.7\(\pm\)0.3\%) & 81.6\(\pm\)1.0\% & 64.2\(\pm\)0.9\% & 37.7\(\pm\)0.7\% \\ \hline \(Z\to\nu+\nu\) & 25856 & 15087 (58.4\(\pm\)0.5\%) & 98.9\(\pm\)0.8\% & 97.3\(\pm\)0.8\% & 95.3\(\pm\)0.8\% \\ \hline \hline Total & & 25.3 \% & 73.3 \% & 48.1 \% & 39.7 \% \\ \hline \end{tabular}
\end{table}
Table 6: Cut efficiencies for backgrounds. The precut efficiency is given with respect to the initial number of events, while the rest of the efficiencies are given with respect to the sample after precut, as this is the sample one would work with when performing a real analysis. The efficiencies of the lepton cuts are given cumulatively, so the \(\tau\) cut is the efficiency of all three cuts with respect to the sample after precut. The total efficiency are weighted with cross sections from table 2.

\begin{table}
\begin{tabular}{|l|l|l|l|l|l|} \hline Process & \# ev. & \(E_{T}^{miss}\) precut & \(e\) cut & \(\mu\) cut & \(\tau\) cut \\ \hline \hline \(q+\bar{q}\to\phi+g\) & 3099 & 1852 (59.8\(\pm\)1.4\%) & 98.9\(\pm\)2.3\% & 96.8\(\pm\)2.3\% & 95.2\(\pm\)2.3\% \\ \hline \(q+g\to\phi+q\) & 3099 & 2257 (72.8\(\pm\)1.5\%) & 98.7\(\pm\)2.1\% & 96.9\(\pm\)2.1\% & 92.9\(\pm\)2.0\% \\ \hline \(g+g\to\phi+g\) & 3000 & 1906 (63.5\(\pm\)1.5\%) & 98.5\(\pm\)2.3\% & 96.5\(\pm\)2.3\% & 92.0\(\pm\)2.2\% \\ \hline \hline Total & & 67.9\% & 98.7 \% & 96.8 \% & 93.1 \% \\ \hline \end{tabular}
\end{table}
Table 7: Cut efficiencies for the three production channels. The total efficiency are weighted with cross sections from table 2.

Figure 15: Left: Cut efficiencies for background processes. Right: Cut efficiencies for signal and total background.

Looking at scenarios with larger \(M_{D},\) thus increasing the dimensionless couplings required for reaching \(\sigma_{lim},\) we have to take into account that \(g\) and \(c\) are limited from above by the requirement

\[c\lesssim 1,g\lesssim 1 \tag{7}\]

for perturbative reasons1. The shaded region in figure 16 indicates this.

Footnote 1: Dimensionless couplings\(<1\) could also give us large perturbative corrections, making a leading order approximation highly unreliable. Keeping \(g\) and \(c\) below \(1\) is however more of a basic requirement, preventing the model from diverging in a higher order expansion.

We set \(g=0,\)\(c=1\) (and opposite) and require \(\sigma_{lim}.\) This then gives us the maximum Planck mass \(M_{D}^{max}\) for which we could have a large enough cross-section at the two extremes no gluon (c=0) and no quark (g=0) couplings. The resulting values for \(M_{D}^{max}\) can be found in table 9.

By identifying these values, we determine for which range of Planck masses a discovery of the graviscalar is probable. For the case \(M_{D}^{max}<M_{D}^{min},\) as is the case for parts of \(n=6\) parameter space, we conclude that the model is unable to give a reliable prediction.

## 7 Conclusion

From the results obtained, we conclude that within this model, the discovery of a graviscalar is possible for n = 2, 3, 4 and 6 (for certain parameters). The

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{2}{|c|}{\#events before cuts} & \multicolumn{2}{|c|}{\#events after cut} \\ \hline \hline  & Centr. & Centr + Err. & Centr. & Centr + Err. \\ \hline Background & 148730 & 169216 & 14997 & 17063 \\ \hline \# sig events for \(5\sigma\) discvr & 989 & 1052 & 625 & 665 \\ \hline \end{tabular}
\end{table}
Table 8: Total number of events for background, shown both for central value (Centr.) and worst case (Centr + Err) cross-sections. The corresponding number of signal events required for a \(5\sigma\) discovery is shown in the lower row, corresponding to a cross section of 9.9 fb for central value and 10.5 fb for central value + error (worst case).

\begin{table}
\begin{tabular}{|l|l|l|l|} \hline n & \(M_{D}^{min}\) (TeV) & \(M_{D}^{max}\) (TeV) \\ \hline \hline  & & \(g=0\) & \(c=0\) \\ \hline
2 & 3.6 & 15.9 & 17.1 \\ \hline
3 & 4.3 & 10.8 & 7.4 \\ \hline
4 & 4.85 & 8.5 & 5.2 \\ \hline
6 & 5.7 & 6.6 & 4.1 \\ \hline \end{tabular}
\end{table}
Table 9: Ranges of \(M_{D}\) for which the model allows a discovery. The two limits \(c=0\) or \(g=0\) are evaluated. We see that for n=4, the difference between min and max is small for the case \(c=0\). For \(n=6\) and \(c=0\) we have \(M_{D}^{max}<M_{D}^{min}\). This puts us outside the validity region of the model, and is also expressed in fig. 16, where \(g_{min}>1\).

Figure 16: Parameter scan for graviscalar discovery limit at integrated luminosity 100 fb\({}^{-1}\). The solid areas indicates the lower limits on the parameters (g, c, n) with respect to a 5\(\sigma\) discovery, using \(M_{D}=M_{D}^{m\,in}\). The dotted lines indicate for each \(n\) the coupling limits in a ’worst case’ scenario, taking the highest values for background cross sections from the PDF uncertainties in table 2. The shaded area to the right indicates the requirement that \(g,c<1\).

model is however limited by the ranges of \(M_{D}\) for which it is valid. This prevents a reliable prediction for \(n=6\) in the case \(c<\sim 0.55\), as this requires \(M_{D}^{max}<M_{D}^{min}\), shown in table 9. For the case of \(g=0\), \(n=6\), the model is however still able to give a valid prediction for discovery.

The case \(n=2\) is close to being constrained by experimental bounds on the inverse square law of the gravitational interaction and is ruled out by indirect astrophysical constraints. As stated earlier, the bounds from astrophysics are model dependent and need not apply to our model. To place us inside the bounds from direct tests of gravitation, we need to have \(M_{D}>4\) TeV. Since this is well below \(M_{D}^{max}=15.9\) TeV, we still have good sensitivity in a \(n=2\) scenario.

Comparing with the ATLFAST study in [1], we see similar results for the discovery potential. We find a difference for the scenario \(n=4\) and \(c=0\); a discovery is not within reach in [1], while it is in this study. There are two main reasons for this:

* The change to CTEQ6 gives us overall higher cross sections, increasing the cross sections for sub processes involving gluons in particular. This clearly improves the discovery potential.
* The simulation were run without pileup. This effectively puts us in a low luminosity scenario, while [1] studies a high luminosity scenario. Running high luminosity would certainly impair the performance of the cuts, reducing the overall discovery potential.

The inclusion of the \(E_{T}^{miss}\) precut could possibly also have an effect, although this reduces the efficiency of the leptonic cuts, since we after the precut are left with a majority of low energetic leptons.

It also turns out that the inclusion of PDF uncertainties does not have a large impact on our results, as the uncertainty for our backgrounds in this energy range is small.

There is at the time no good way of distinguishing the signal from a graviscalar from that of a graviton or one of the other supersymmetric partners, since the cross sections for these turn out to have the same energy dependencies [1]. Since it is also not possible to determine the CM energy for the incoming partons at the LHC, CM angular distributions can not be used for distinguishing the different kinds of particles. This means that all the members of the multiplet will all add to the total \(E_{T}^{miss}\) signal, making it difficult to identify the individual couplings.

The results nevertheless gives an indication of what the signal from an extra-dimensional scalar would look like in ATLAS, showing that the possibility of detecting such a signal, provided the right parameters, is definitely present.

## 8 Acknowledgements

Thanks to Anna Lipniacka, Bjarne Stugu, Georges Azuelos and Pierre-Hugues Beauchemin for good advice and helpful discussions. Thanks to Samir Ferrag for valuable help with including PDF errors in the analysis.

## References

* [1] G. Azuelos, P.H. Beauchemin, C.P. Burgess, 2005 J. Phys. G: Nud. Part. Phys. 31 1-19, (hep-ph/0401125)
* [2] N. Arkani-Hamed, S. Dimopoulos and G. Dvali, Phys. Lett. **B429**(1998) 263 (hep-ph/9803315);Phys. Rev. **D59**(1999) (hep-ph/9807344).
* [3] L. Randall, R. Sundrum, Phys. Rev. Lett. **83** (1999) 3370 hep-ph/9905221; Phys. Rev. Lett. **83** (1999) 4690 hep-th/9906064.
* [4] C.D. Doyle et al., Phys.Rev. **D70** (May 2004), hep-ph/0405262
* [5] S. Eidelman et al., PDG 2004 review, Phys. Lett. **B592**, 1 (2004)
* [6] D. Atwood, C.P. Burgess, E. Filotas, F. Leblond, D. London and I. Maksymyk, Physical Review **D63** (2001) 025007 [hep-ph/0007178]
* [7] L. Vacavant and I. Hinchliffe, (2000) ATL-PHYS-2000-016.
* [8] T. Han, J. D. Lykken, R. Zhang, Phys. Rev. **D59**, 105006 (1999) (hep-ph/9903294)
* [9] NorduGrid, [http://www.nordugrid.org](http://www.nordugrid.org)
* [10] Atlas Offline Software, [http://atlas.web.cern.ch/Atlas/GROUPS/SOFTWARE/OO/](http://atlas.web.cern.ch/Atlas/GROUPS/SOFTWARE/OO/)
* [11] T. Sjostrand, P. Edn, C. Friberg, L. Lonnblad, G. Miu, S. Mrenna and E. Norrbin, Computer Phys. Commun. 135 (2001) 238 (LU TP 00-30, hep-ph/0010017)
* [12] I. Hinchliffe, G. Stavropoulos, Pythia_i, [http://www-theory.lbl.gov/](http://www-theory.lbl.gov/) ianh/monte/Generators/Pythia/
* [13] J. Pumplin, D.R. Stump, J. Huston, H.L. Lai, P. Nadolsky, W.K. Tung JHEP **0207** (2002) 012, (hep-ph/0201195)
* [14] R. Brun, F. Rademakers, Nucl. Inst. & Meth. in Phys. Res. A 389 (1997) 81-86. [http://root.cern.ch/](http://root.cern.ch/).
* [15] S. Ferrag, 2004, hep-ph/0407303
* [16] M. Biglietti et al.; ATL-PHYS-2004-011; 2003