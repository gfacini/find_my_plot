# Optimal Filtering in the ATLAS Hadronic

Tile Calorimeter

Fullana, E

Castelo, J

Castillo, V

Cuenca, C

Ferrer, A

Higon, E

Iglesias, C

Munar, A

Poveda, J

Ruiz-Martinez, A

Salvachua, B

Solans, C

Teuscher, R

Valls, J

Departamento de Fisica Atomica, Molecular y Nuclear and IFIC,

CSIC-Universidad de Valencia. Edificio Institutos de Investigacion. Apartado de Correos 22085 E-46071 Valencia - Espana University of Chicago, Chicago, Illinois, USA

###### Abstract

In this paper we present an Optimal Filtering algorithm to reconstruct the energy, time and pedestal of a photomultiplier signal from its digital samples. The optimal filter method is applied in multiply-sampled signals and improves the energy reconstruction by minimizing the impact on resolution of both electronic noise, intrinsic to the calorimeter, and the pile-up which depends on the luminosity. The OF implementation and performance have been studied for the hadronic Tile Calorimeter (TileCal) of the ATLAS detector. The algorithm is tested and compared with other reconstruction algorithms from two different types of data: calibration runs coming from the TileCal Charge Injection System and physics events - pions, electrons and muons - acquired during the testbeam program of the TileCal detector. The results are promising specially in the regions where the electronic noise contributes significantly to the resolution.

###### Contents

* 1 Introduction
* 2 Signal reconstruction with OF
* 3 Calculation of OF weights in the TileCal environment
	* 3.1 Pedestal
	* 3.2 The \(\boldsymbol{R}\) matrix
	* 3.3 The shape form function
	* 3.4 Calculation of weights
* 4 Implementation
	* 4.1 CIS events
	* 4.2 Physics events
	* 4.3 Iteration procedure
	* 4.4 Flat filtering
	* 4.5 Fit method
* 5 Results
	* 5.1 CIS: Calibration constants
	* 5.2 CIS: Charge reconstruction
	* 5.3 CIS: Phase reconstruction
	* 5.4 CIS: Quality factor
	* 5.5 Physics: Noise
	* 5.6 Physics: Pions
	* 5.7 Physics: Electrons
	* 5.8 Physics: Muons
* 6 Conclusions
* 7 Acknowledgments

[MISSING_PAGE_EMPTY:3]

List of Figures
* 1 Top: pedestal and RMS values (in ADC counts) as a function of the channel number for a typical TileCal electronics drawer. Bottom: Pedestal (left) and RMS (right) distributions of the same drawer.
* 2 Left: signal shape form reconstructed with CIS data for a fixed amount of injected charge. Right: resulting function of the CIS data fit.
* 3 Distribution of amplitude weights for 171 working channels of 4 electronic drawers.
* 4 Distribution of time weights for 171 working channels of 4 electronic drawers.
* 5 Left: amplitude weights versus the reference time (weights of the central sample \(a_{5}\)). Right: time weights versus the reference time (weights of the central sample \(b_{5}\)). All results are shown for high gain (HG) and low gain (LG) events
* 6 Left: the testbeam setup in August 2003. Right: testbeam setup for all the other testbeam periods.
* 7 Left: beam direction for pions. Right: beam direction for muons and electrons.
* 8 CIS calibration factors (ADC counts/pC) for high gain (HG, bottom) and low gain (LG, top) and for both algorithms: flat filtering (FF, left) and optimal filtering (OF, right). All data correspond to all working channels of three CB modules.
* 9 CIS amplitude reconstruction (high gain). Top: reconstructed vs injected charge (both in pC). Middle: residual distribution vs injected charge (in pC). Bottom: reconstructed charge resolution vs injected charge (in pC). In all cases dots correspond to FF results and triangles to OF.
* 10 CIS amplitude reconstruction (low gain). Top: reconstructed vs injected charge (in pC). Middle: residual distribution vs injected charge (in pC). Bottom: reconstructed charge resolution vs injected charge (in pC). In all cases dots correspond to FF results and triangles to OF.

CIS phase reconstruction (top, in ns) and its RMS (bottom) as a function of the injected charge (pC). Left: high gain. Right: low gain. The 3-in-1 phase shift value is fixed to 35.
* 12 CIS phase reconstruction (top, in ns) and its RMS (bottom) as a function of the injected charge (pC). Left: high gain. Right: low gain. The 3-in-1 phase shift value is fixed to 84.
* 13 CIS quality factor distributions (\(\chi\), top) and their RMS (bottom) as a function of the injected charge (in pC). Left: high gain. Right: low gain.
* 14 Energy reconstruction (in pC) in a cell with no deposited energy obtained with the four algorithms.
* 15 Energy distribution of pions at 350 GeV (top left), 180 GeV (top right), 20 GeV (bottom left) and 9 GeV (bottom right) impinging into a CB module at \(\eta=0.35\). Results are shown for the four algorithms, FF, FM, OF1 and OF2.
* 16 Energy resolution (in %) vs. beam energy (GeV) for pions impinging a CB module at \(\eta=0.35\). The results are shown for the four different algorithms, FF, FM, OF1 and OF2.
* 17 Conversion factors (pC/GeV) for pions impinging a CB module at \(\eta=0.35\). The results are shown for the four different algorithms, FF, FM, OF1 and OF2.
* 18 Energy distribution of electrons at 180 GeV (top left), 100 GeV (top right), 20 GeV (bottom left) and 9 GeV (bottom right) impinging a CB module at tile 5. The distributions of all the algorithms, FF, FM, OF1 and OF2 are included.
* 19 Energy resolution (in %) vs. beam energy (GeV) for electrons impinging a CB module at tile 5. The results are shown for the four different algorithms, FF, FM, OF1 and OF2.
* 20 Conversion factors (pC/GeV) for electrons impinging a CB module at tile 5. The results are shown for the four different algorithms, FF, FM, OF1 and OF2.
* 21 Distributions of energy deposited by muons at 180 GeV in the three modules of the TileCal testbeam. Results are shown for the different reconstruction algorithms, FF, FM, OF1 and OF2.

List of Tables
* 1 Summary of applied cuts for the pion analysis.
* 2 Energy resolution of pions with an incident angle of \(\eta=0.35\).
* 3 Parameters of the fit for pions with an incident angle of \(\eta=0.35\).
* 4 Energy calibration factors pC/GeV of pions with an incident angle of \(\eta=0.35\).
* 5 Summary of applied cuts for the electron analysis.
* 6 Energy resolution of electrons with an incident angle of \(90^{\circ}\) at tile 5.
* 7 Energy calibration factors pC/GeV of electrons with an incident angle of \(90^{\circ}\) at tile 5.
* 8 Parameters of the fit for muons with an incident angle of \(90^{\circ}\) at tile 5.

Introduction

Optimal Filtering (OF) is an algorithm which reconstructs the amplitude of an analog signal from its digital samples. In the ATLAS hadronic Tile Calorimeter (TileCal) the amplitude of the signal is proportional to the energy deposited in the readout cell, therefore OF can be used as an energy reconstruction algorithm. In addition it also reconstructs the time information of the signal and provides a way to calculate the quality of the reconstructions.

The implementation of OF in calorimetry was originally proposed as a solution to the problem of noise optimization in liquid ionization calorimeters working in a high luminosity environment [1]. In this kind of calorimeters the signal is of the order of hundreds of nanoseconds due to the drift velocity of the charges in the active medium. In high luminosity accelerators (as the LHC) the bunch crossing period is much shorter (25 ns for the LHC) than the signal time domain. As a consequence the amount of pile up noise in the signal forces the introduction of a cut on the recolection time of the charges, which is hardwired in the front end electronics of the detector. However this time must not be too short because the thermal noise to signal ratio increases as the recolection time of the charges decreases. There is an optimal recolection time which minimizes the contribution of both sources of noise. The problem arises when this optimal time cannot be constant during the lifetime of the detector due to updates in the luminosity or ageing in the electronic components. The OF algorithm reduces the noise to the level of the optimal recolection time in the cases where this time is not optimal in the hardware.

In TileCal, the readout is based on photomultipliers whose fast signal (\(\sim 20\) ns) avoids this problem [2]. However, after the shaper, the signal has also contributions from the two noise sources considered in [1], pile up and electronic noise. Therefore this algorithm is still useful in this type of calorimeters.

OF is envisaged to be implemented in the Read Out Driver (ROD) cards which are part of the ATLAS DAQ electronics [3]. A ROD module reads optical fibers from the front-end electronics. The fibers transmit all the information of an event selected by the first level trigger in digital format. The ROD motherboard is designed to hold mezzanine cards which are equipped with last generation Digital Signal Processors (DSP). These DSPs can be programmed to implement energy reconstruction algorithms. Once the energy is calculated the information is sent to the second level trigger, the next step of the data acquisition chain. The maximum allowed rate of the ATLAS first level trigger (\(\sim 100\) kHz) and the computing power limitations of the DSPs impose severe constraints to the complexity of the algorithms which may be implemented on them. However a good performance of the second level trigger requires high accuracy of the energy reconstruction. Therefore any algorithm implementedin the DSPs should reach a compromise between simplicity and accuracy [4].

This note explains several aspects of the OF implementation in the TileCal environment. The theoretical aspects of the algorithm are exposed in Sec. 2 and Appendix A. The calculation of the OF parameters is explained in Sec. 3. The algorithm implementation in calibration runs and with real physics data is shown in Sec 4. The results are given in Sec. 5 and finally the conclusions are summarized in Sec. 6.

## 2 Signal reconstruction with OF

OF consists in a weighted sum of the signal samples to recover its parameters (amplitude and time) while minimizing the noise impact. The method yields the amplitude and time of a signal pulse given a finite number of sampled signal values. The theoretical development described here is taken from [1].

Let's define \(g(t)\) as the shape form function of the signal (noise free) normalized in amplitude. The samples can thus be expressed as:

\[S(t)=Ag(t)\,, \tag{1}\]

where \(S(t)\) represents the time sampling function and \(A\) is the true amplitude of the signal. The set of samples are taken from \(S(t)\) at regular time intervals \(t_{i}\) and are given by:

\[S_{i}=Ag(t_{i})=Ag_{i}\,. \tag{2}\]

If we introduce imperfections due to real electronics the samples now become:

\[S_{i}=Ag(t_{i}-\tau)+n_{i}\,, \tag{3}\]

where \(\tau\) is the phase between the digitizer output and the \(g\) and \(n_{i}\) is the noise term. We want \(A\) and \(\tau\) to be output parameters of the algorithm. Therefore, in order to linearize the dependence of \(S\) with those parameters, we make a Taylor's expansion at first order:

\[S_{i}\simeq Ag(t_{i})-A\tau g^{\prime}(t_{i})+n_{i}=Ag_{i}-A\tau g_{i}^{\prime }+n_{i}\,. \tag{4}\]

This aproximation introduces a dependence on the quality of the reconstructions with \(\tau\). If \(\tau\) is equal to zero the Taylor's expansion is exact but with increasing \(\tau\) the quality of the reconstruction decreases.

Let's define now two quantities:

\[u =\sum_{i=1}^{n}a_{i}S_{i}\,. \tag{5}\] \[v =\sum_{i=1}^{n}b_{i}S_{i}\,, \tag{6}\]

where \(n\) is the number of samples and \(a\) and \(b\) are free parameters of the algorithm called OF weights.

We require now the expected values of \(u\) and \(v\) (\(\langle u\rangle\) and \(\langle v\rangle\)) for \(m\) events of equal amplitude and time to be equal to \(A\) and \(A\tau\) respectively:

\[A=\langle u\rangle=\langle\sum_{i=1}^{n}a_{i}S_{i}\rangle=\sum_{i=1}^{n}a_{i} \langle S_{i}\rangle\;, \tag{7}\] \[A\tau=\langle v\rangle=\langle\sum_{i=1}^{n}b_{i}S_{i}\rangle= \sum_{i=1}^{n}b_{i}\langle S_{i}\rangle\;. \tag{8}\]

If we substitute \(S_{i}\) by (4) in equations (7) and (8) and assume all parameters to be constant except the noise, \(n\), we get:

\[A=\langle u\rangle=\sum_{i=1}^{n}(Aa_{i}g_{i}-A\tau a_{i}g_{i}^{\prime}+a_{i} \langle n_{i}\rangle)\,, \tag{9}\]

\[A\tau=\langle v\rangle=\sum_{i=1}^{n}(Ab_{i}g_{i}-A\tau b_{i}g_{i}^{\prime}+b_ {i}\langle n_{i}\rangle)\,. \tag{10}\]

We take the expected value of \(n_{i}\), \(\langle n_{i}\rangle\), as zero. This is the case for a Gaussian distribution which is the aproximation of a model for thermal noise and used also for pile up noise. Note that if this value is different from zero it can be absorbed into a pedestal. Therefore if we subtract this pedestal from the samples or we introduce a third parameter defined as the pedestal (see Appendix A) the algorithm is still valid. The important point is that the noise has to be stationary, i.e., the statistical averages must be time independent [5]. With this assumption equations (9) and (10) become:

\[A=\langle u\rangle=A\sum_{i=1}^{n}a_{i}g_{i}-A\tau\sum_{i=1}^{n}a_{i}g_{i}^{ \prime}\,, \tag{11}\]

\[A\tau=\langle v\rangle=A\sum_{i=1}^{n}b_{i}g_{i}-A\tau\sum_{i=1}^{n}b_{i}g_{i} ^{\prime}\,. \tag{12}\]From (11) and (12) we set now the following four constraints for the weights:

\[\begin{array}{l}\sum\limits_{i=1}^{n}a_{i}g_{i}=1\,,\qquad\sum\limits_{i=1}^{n}b _{i}g_{i}=0\,,\\ \sum\limits_{i=1}^{n}a_{i}g_{i}^{\prime}=0\,,\qquad\sum\limits_{i=1}^{n}b_{i}g_ {i}^{\prime}=-1\,.\end{array} \tag{13}\]

Note that we have defined \(m\) events with equal amplitude and time to calculate \(\langle u\rangle\) and \(\langle v\rangle\). However the distribution of \(u\) and \(v\) values is broaded by the noise contribution. In order to minimize this effect we require the parameters \(\mathbf{a}\) and \(\mathbf{b}\) to be calculated such that they minimize the \(u\) and \(v\) variances.

The variances of \(u\) and \(v\) are given by:

\[\text{Var}(u) =\text{Var}(\sum\limits_{i=1}^{n}a_{i}S_{i})\,, \tag{14}\] \[\text{Var}(v) =\text{Var}(\sum\limits_{i=1}^{n}b_{i}S_{i})\,. \tag{15}\]

If we develop again equations (14) and (15) using (4) we have:

\[\text{Var}(u) =\text{Var}(A\sum\limits_{i=1}^{n}a_{i}g_{i}-A\tau\sum\limits_{i=1 }^{n}a_{i}g_{i}^{\prime}+\sum\limits_{i=1}^{n}a_{i}n_{i})\,, \tag{16}\] \[\text{Var}(v) =\text{Var}(A\sum\limits_{i=1}^{n}b_{i}g_{i}-A\tau\sum\limits_{i =1}^{n}b_{i}g_{i}^{\prime}+\sum\limits_{i=1}^{n}b_{i}n_{i})\,, \tag{17}\]

where again all the parameters are constant except \(\mathbf{n}\).

Note that \(\text{Var}(a+x)=\text{Var}(x)\) if \(a\) is constant. With this, equations (16) and (17) can be reduced to:

\[\text{Var}(u) =\text{Var}(\sum\limits_{i=1}^{n}a_{i}n_{i})\,, \tag{18}\] \[\text{Var}(v) =\text{Var}(\sum\limits_{i=1}^{n}b_{i}n_{i})\,. \tag{19}\]

If we develop them we obtain:

\[\text{Var}(u) =\sum\limits_{i=1}^{n}a_{i}^{2}\text{Var}(n_{i})+\frac{2}{m}\sum \limits_{i=1}^{n}\sum\limits_{j=i+1}^{n}a_{i}a_{j}\sum\limits_{i=1}^{m}(n_{i}- \langle n_{i}\rangle)(n_{j}-\langle n_{j}\rangle)\,, \tag{20}\]\[\mbox{Var}(v)=\sum_{i=1}^{n}b_{i}^{2}\mbox{Var}(n_{i})+\frac{2}{m}\sum_{i=1}^{n} \sum_{j=i+1}^{n}b_{i}b_{j}\sum_{j}^{m}(n_{i}-\langle n_{i}\rangle)(n_{j}- \langle n_{j}\rangle)\,, \tag{21}\]

which can be expressed in a more compact way as:

\[\mbox{Var}(u) = \frac{1}{m}\sum_{i,j=1}^{n}a_{i}a_{j}\sum(n_{i}-\langle n_{j} \rangle)(n_{j}-\langle n_{j}\rangle)\,, \tag{22}\] \[\mbox{Var}(v) = \frac{1}{m}\sum_{i,j=1}^{n}b_{i}b_{j}\sum_{j}^{m}(n_{i}-\langle n _{i}\rangle)(n_{j}-\langle n_{j}\rangle)\,. \tag{23}\]

Again we suppose that \(\langle n_{i}\rangle=0\) and then:

\[\mbox{Var}(u) = \frac{1}{m}\sum_{i,j=1}^{n}a_{i}a_{j}\sum(n_{i}n_{j})=\sum_{i,j=1} ^{n}a_{i}a_{j}\langle n_{i}n_{j}\rangle\,, \tag{24}\] \[\mbox{Var}(v) = \frac{1}{m}\sum_{i,j=1}^{n}b_{i}b_{j}\sum(n_{i}n_{j})=\sum_{i,j=1 }^{n}b_{i}b_{j}\langle n_{i}n_{j}\rangle\,. \tag{25}\]

Our goal is to find expresions for \(\boldsymbol{a}\) and \(\boldsymbol{b}\) which minimize the variance and fulfill the constraints of (13). We use thus the Lagrange multipliers method by constructing the following two functions:

\[I_{u} = \sum_{i,j=1}^{n}a_{i}a_{j}\langle n_{i}n_{j}\rangle-\lambda(\sum_ {i=1}^{n}a_{i}g_{i}-1)-\kappa\sum_{i=1}^{n}a_{i}g_{i}^{\prime}\,, \tag{26}\] \[I_{v} = \sum_{i,j=1}^{n}b_{i}b_{j}\langle n_{i}n_{j}\rangle-\mu(\sum_{i=1 }^{n}b_{i}g_{i})-\rho(\sum_{i=1}^{n}b_{i}g_{i}^{\prime}+1)\,, \tag{27}\]

where \(\lambda\), \(\kappa\), \(\mu\) and \(\rho\) are the Lagrange multipliers.

Next we partial derivate \(I_{u}\) and \(I_{v}\) with respect to \(a_{i}\) and \(b_{i}\) and equal them to zero:

\[\frac{\partial I_{u}}{\partial a_{i}} = 2\sum_{j=1}^{n}a_{j}\langle n_{i}n_{j}\rangle-\lambda g_{i}- \kappa g_{i}^{\prime}=0\,, \tag{28}\] \[\frac{\partial I_{v}}{\partial b_{i}} = 2\sum_{j=1}^{n}b_{j}\langle n_{i}n_{j}\rangle-\mu g_{i}-\rho g_{i }^{\prime}=0\,. \tag{29}\]

Equations (28) and (29) define two sets of \(n\) equations. Together with the two sets of two equations in (13) we have now two systems of \(n+2\) equations and \(n+2\) unknowns.

We can substitute \(\langle n_{i}n_{j}\rangle\) by \(R_{ij}\) in (28) and (29) which represents an element of the noise autocorrelation matrix defined as:

\[R_{ij}=\frac{\sum(n_{i}-\langle n_{i}\rangle)(n_{j}-\langle n_{j}\rangle)}{\sqrt {\sum(n_{i}-\langle n_{i}\rangle)^{2}\sum(n_{j}-\langle n_{j}\rangle)^{2}}}= \frac{\langle(n_{i}-\langle n_{j}\rangle)(n_{j}-\langle n_{j}\rangle)\rangle}{ \sqrt{\mbox{Var}(n_{i})\mbox{Var}(n_{j})}}\,. \tag{30}\]

By hypotheses \(\langle n_{i}\rangle=0\) and \(\mbox{Var}(n_{i})=\mbox{Var}(n_{j})\) as \(n_{i}\) and \(n_{j}\) are samples of the same noise distribution. Therefore the denominator in (30) is absorbed in the Lagrange multipliers of (28) and (29).

The \(n+2\) equations for \(a\) are given by:

\[\begin{array}{l}\sum\limits_{i=1}^{n}a_{i}g_{i}=1\,,\\ \sum\limits_{i=1}^{n}a_{i}g_{i}^{\prime}=0\,,\\ \sum\limits_{j=1}^{n}a_{j}R_{ij}-\lambda g_{i}-\kappa g_{i}^{\prime}=0\,\,\,\, \,\,\,\forall\,i\,,\end{array} \tag{31}\]

which can be written in matrix format as:

\[\left(\begin{array}{ccccc}R_{11}&R_{12}&\ldots&R_{1n}&g_{1}&g_{1}^{\prime} \\ R_{21}&R_{22}&\ldots&R_{2n}&g_{2}&g_{2}^{\prime}\\ \vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\ R_{n1}&R_{n2}&\ldots&R_{nn}&g_{n}&g_{n}^{\prime}\\ g_{1}&g_{2}&\ldots&g_{n}&0&0\\ g_{1}^{\prime}&g_{2}^{\prime}&\ldots&g_{n}^{\prime}&0&0\end{array}\right)\, \left(\begin{array}{c}a_{1}\\ a_{2}\\ \vdots\\ a_{n}\end{array}\right)=\left(\begin{array}{c}0\\ 0\\ \vdots\\ 0\\ 1\\ 0\end{array}\right)\,. \tag{32}\]

The \(n+2\) equations for \(b\) are given by:

\[\begin{array}{l}\sum\limits_{i=1}^{n}b_{i}g_{i}=0\,,\\ \sum\limits_{i=1}^{n}b_{i}g_{i}^{\prime}=-1\,,\\ \sum\limits_{j=1}^{n}b_{j}R_{ij}-\mu g_{i}-\rho g_{i}^{\prime}=0\,\,\,\,\,\, \forall\,i\,.\end{array} \tag{33}\]In matrix format (33) reads:

\[\left(\begin{array}{cccccc}R_{11}&R_{12}&\ldots&R_{1n}&g_{1}&g_{1}^{\prime}\\ R_{21}&R_{22}&\ldots&R_{2n}&g_{2}&g_{2}^{\prime}\\ \vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\ R_{n1}&R_{n2}&\ldots&R_{nn}&g_{n}&g_{n}^{\prime}\\ g_{1}&g_{2}&\ldots&g_{n}&0&0\\ g_{1}^{\prime}&g_{2}^{\prime}&\ldots&g_{n}^{\prime}&0&0\end{array}\right)\left( \begin{array}{c}b_{1}\\ b_{2}\\ \vdots\\ b_{n}\\ \mu\\ \rho\end{array}\right)=\left(\begin{array}{c}0\\ 0\\ \vdots\\ 0\\ -1\end{array}\right). \tag{34}\]

Equations (32) and (34) are used to calculate \(\boldsymbol{a}\) and \(\boldsymbol{b}\). In the next sections the calculation of \(\boldsymbol{R}\), \(\boldsymbol{g}\) and \(\boldsymbol{g}^{\prime}\) for the TileCal environment will be shown as well as the effect of the amplitude/energy and time reconstruction in calibration and physics data.

## 3 Calculation of OF weights in the TileCal enviroment

### Pedestal

Note that equation (3) assumes that the signal lays in a zero baseline. This is not the case for the TileCal electronics where the baseline of the signal (pedestal) is above zero. Fig. 1 shows the average and standard deviation of the pedestal (in ADC counts) versus the channel number for a standard TileCal electronics drawer (45 channels). The pedestal average varies between 35 and 65 counts whereas the standard deviation remains constant to about 1count.

One solution to this problem, studied in Appendix A, is to modify the algorithm by defining a new set of weights which calculate the pedestal as another parameter in addition to amplitude and time. This solution has an important advantage as it avoids the necessity of pedestal treatment in the samples. However it introduces one additional constraint in the calculation of the \(\boldsymbol{a}\) and \(\boldsymbol{b}\) components which makes the weights less optimal than in the case considered here.

The solution taken here consists in subtracting the pedestal event by event from the samples. The pedestal is calculated in two different ways: if it is a pedestal event (only used in the \(\boldsymbol{R}\) calculation) the pedestal is calculated as the average of all the samples; if it is a signal event the pedestal is defined as the average of the first and last samples. This approach is valid as the time domain of the signal is smaller than the number of samples times the period between samples (25 ns) and then the first and last samples contain no signal. However when the event comes in advance or delayed, the first or last samples could contain signal and this method would overestimate the pedestal. Furthermore pedestal calculation and later subtraction from the samples increases the computing time of the algorithm which would limit the performance of the DSPs at the ROD level.

The optimal solution to the pedestal problem requires a detailed study including the performance at the DSP level as computing time or number of bits in the operations and external factors as number of samples or beam synchronyzation would affect the results.

### The \(\boldsymbol{R}\) matrix

The noise autocorrelation matrix, \(\boldsymbol{R}\), can be calculated in three different ways:

1. Considering the only source of noise as thermal and using the thermal noise autocorrelation matrix.
2. Computed from pedestal data using equation (30).
3. Assuming that there is no correlation and then \(\boldsymbol{R}\) is equal to the identity matrix.

The OF weights related to \(\boldsymbol{R}\) calculated from type B or type C above are very similar whereas those calculated from type A are different [6]. Option A is ruled out as it ignores the presence of any other source of noise appart from thermal. We chose option C as it is simpler and sets a lower limit for OF improvement. In this case the vector \(\boldsymbol{a}\) is just proportional to \(\boldsymbol{g}\) and the vector \(\boldsymbol{b}\) is essentially \(\boldsymbol{g}^{\prime}\). Any other proper determination of \(\boldsymbol{R}\) would improve noise reduction. In anycase the present studies of noise correlation in the TileCal electronics do not show a strong correlation between samples [7, 8]. This situation could change when noise coming from minimum bias events is included in the samples. In this case the noise autocorrelation function can be calculated from the waveform and its derivative. Note that, the noise has two components, one due to thermal noise and the other to pileup noise and, both would have to be weighted according to the luminosity but otherwise totally determined from the waveform [1]. Another way to obtain the matrix is from special runs with random triggers from LHC data [9] although one would have to be sure that there are not real events mixed in with the samples which would distort the average values. The OF results are not very sensitive to the exact value of that matrix and then an analytical approach is perfectly adequate [5].

Figure 1: Top: pedestal and RMS values (in ADC counts) as a function of the channel number for a typical TileCa1 electronics drawer. Bottom: Pedestal (left) and RMS (right) distributions of the same drawer.

### The shape form function

In order to calculate the \(g\) and \(g^{\prime}\) components defined in (4) it is necessary to determine the Shape Form Function (SFF) of the signal.

The TileCal electronics has a Charge Injection calibration System (CIS) which tests the performance of each readout channel over its full dynamic range [10]. The system is able to inject charge at all time phases relative to the digitizer clock in steps of 0.728 ns. Therefore we fix the injected charge and sweep all phases in order to reconstruct the shape form of all channels of each drawer. The reconstructed shape form for a typical channel is shown in Fig. 2 left.

The calibration shape form is later fit by the following analytical function [11]:

\[\mathrm{SF}(t)=p+A\left(\frac{t-\lambda}{\tau}\right)^{\mu}\exp\left(-\mu\frac {t-\lambda}{\tau}\right)\,. \tag{35}\]

The variables \(p\), \(A\), \(\lambda\), \(\tau\), and \(\mu\) are parameters of the fit. The presence of \(\mu\) in the exponent makes the fit highly non linear. In order to simplify the fit we fix the coordinates of the maximum in the fit. The maximum of the shape form and its time position are related to the parameters \(\tau\), \(\lambda\), \(A\) and \(\mu\) by the expressions:

\[t_{\mathrm{max}}=\tau+\lambda\,, \tag{36}\] \[\mathrm{SF}(t_{\mathrm{max}})=A\exp\left(-\mu\right)\,. \tag{37}\]

We set the position of the maximum to zero (\(t_{\mathrm{max}}=0\) ns) and we make \(\mathrm{SF}(t_{\mathrm{max}})\) equal to the maximum value of the reconstructed shape form. These

Figure 2: Left: signal shape form reconstructed with CIS data for a fixed amount of injected charge. Right: resulting function of the CIS data fit.

two settings establish two bounds in the parameters, one between \(\tau\) and \(\lambda\) in (36) and the other between \(A\) and \(\mu\) in (37), which simplifies the fit. The result of the fit with these two bounds is shown in Fig. 2 right. Note that we must subtract the pedestal in the function SF(t) and normalize it in amplitude to one in order to calculate \(g\) and \(g^{\prime}\):

\[\mathrm{SF}_{\mathrm{g}}(t)=\frac{\mathrm{SF}(t)-p}{\mathrm{SF}(t_{\mathrm{ max}})}\,. \tag{38}\]

The components of \(g\) are then calculated from \(\mathrm{SF}_{\mathrm{g}}(t)\) in (38). The times at which the elements of \(g\) are calculated are free parameters, however as the time distance of two consecutive elements of \(g\) must be the sampling period it remains only one free parameter which sets the reference in the time reconstruction. Moreover the position of the \(g\) elements in the shape form should be as close as possible as the samples position as, due to (4), the algorithm is able to reconstruct the time distance between the \(g\) elements and the samples. This is only the case as a first order approximation and the closer this distance the more accurate the reconstruction. This time distance is provided by the algorithm from equation (8) as \(\tau\). The \(g^{\prime}\) components are calculated from the derivative of \(\mathrm{SF}_{\mathrm{g}}(t)\) at the same time position as the \(g\) components.

This procedure of shape form reconstruction assumes that the shape form in physics events is the same as in CIS events. This is not strictly true as the shape form area in physics events is 10% larger than in CIS data [12]. The effect of this difference in the reconstructions is difficult to evaluate. The solution is to calculate the \(g\) and \(g^{\prime}\) parameters from a fit to a physics shape form. A new method of physics shape form reconstruction was developed within the TileCal group [12]. This method reconstructs the shape form from physics events using the data obtained in the Test Beam setup of the TileCal detector. However the computing time for the reconstruction is longer, which is not a serious problem as in principle it is steady and it has not to be calculated very often.

As a consequence different OF weights have been calculated for physics events. For CIS events the OF weights are calculated from the CIS shape form reconstruction whereas in physics events the OF weights are calculated from the physics shape form reconstruction.

### Calculation of weights

The OF weights depend on the noise and shape forms of each particular channel. In principle each channel needs a different set of OF weights as both the noise and the shape form is different from channel to channel. In addition each channel has two readout gains (high and low gain) and the shape form from each one is slightly different. Therefore every channel needs two sets of weights, one for low gain and the other for high gain. In order to fulfill this requirement the CIS shape form is reconstructed and fitted for every channel and for the two gains. For the physics one only two averaged shape forms were available (one for high and one for low gain) and then only two sets of weights were calculated to reconstruct physics events. The noise variations from channel to channel are not reflected in the calculation of weights as in the present study we equal the \(\boldsymbol{R}\) matrix to the identity matrix. We calculate all the weights for 25 reference times between \(-12\,\mathrm{ns}\) to \(12\,\mathrm{ns}\) in steps of \(1\,\mathrm{ns}\), as explained in the next section.

Fig. 3 shows the distribution of the amplitude weights, \(\boldsymbol{a}\), for 9 samples and for 171 channels corresponding to four electronic drawers of TileCal. All weights are calculated for a fixed reference time corresponding to a central weight set at the peak of the shape form. In our time convention this corresponds to time equal to \(0\,\mathrm{ns}\). For the most significative weights (\(a_{4}\), \(a_{5}\), \(a_{6}\)) the variations are of the order of 1% which would be within the error of the shape form fit. Fig. 4 shows the same distribution for the time weights \(\boldsymbol{b}\). The most significative weights in this case (\(b_{4}\), \(b_{6}\)) do not show variations greater than 1%.

Fig. 5 shows the weights corresponding to the central sample (\(a_{5}\) and \(b_{5}\)) versus the reference time. In both plots \(0\,\mathrm{ns}\) means the weight is calculated for a sample in the peak of the shape form. The amplitude weight plot shows how the weight follows the shape form function. This means that equation (5) is a weighted sum where the weights reflect the position of the sample in the shape form. This is more remarkable in our case as we neglect the noise correlation although even when it is included this point should not change significantly. Fig. 5 shows also this dependency for high and low gain weights. The difference is of the order of 1% which is a lower limit regarding that only variations in the shape form are included. Recently new results point out to differences in the noise correlation for high and low gain noise samples [7]. By including these correlations in the calculation of weights the difference between high and low gain weights would be larger.

Therefore if we take into account only the shape form, the weights do not have significant variations from channel to channel and for the two gains. This situation would change if we include the noise correlation in the calculation of weights. In this way the thermal noise correlation would increase the difference of high and low gain weights within the same channel. On the other hand the dependence of minimum bias energy deposition with pseudorapidity and distance to the interaction point would also introduce variations of weights from channel to channel.

## 4 Implementation

In this study we apply the OF algorithm to two types of events. The first type are calibration events coming from the CIS system. The second type are real physics events from the TileCal testbeam setup data corresponding to the years 2002 and 2003.

Figure 3: Distribution of amplitude weights for 171 working channels of 4 electronic drawers.

### CIS events

The CIS system in TileCal is designed to emulate the photomultiplier current released by a capacitor discharge. Its electronics is placed with in the front-end electronics of the TileCal detector. It has two capacitors, one of 5.1 pF and the other of 100 pF. Both capacitors are charged with a 10-bit DAC system. The 5 pF capacitor discharges from 0 pC to 40 pC in steps of 0.64 pC and the 100 pF discharges from 0 pC to 800 pC in steps of 12.8 pC. This allows to fully test the high gain range, from 0 pC to 12.5 pC, and the low gain range, from 12.5 pC to 800 pC. As said before, the CIS system discharges the current within

Figure 4: Distribution of time weights for 171 working channels of 4 electronic drawers.

a configurable phase range which goes from \(-12\,\mathrm{ns}\) to \(12\,\mathrm{ns}\) with respect to the digitizer clock. Both characteristics make the CIS system perfectly suitable to test ROD algorithms for different charge ranges and for signals coming with all the possible phases.

### Physics events

The TileCal group started a testbeam program in 1993. Prototypes and final modules have been tested and calibrated in the H8 beam line at the SPS at

Figure 5: Left: amplitude weights versus the reference time (weights of the central sample \(a_{5}\)). Right: time weights versus the reference time (weights of the central sample \(b_{5}\)). All results are shown for high gain (HG) and low gain (LG) events

Figure 6: Left: the testbeam setup in August 2003. Right: testbeam setup for all the other testbeam periods.

CERN. Data were taken with muons, pions and electrons between 10 and 400 GeV. In August 2003, a very low energy beam was also set up to cover energies down to 1 GeV. To test the performance of the OF algorithm under physics events we use pions and electrons of several energies and a single run of muons. The data correspond mainly to the summer 2003 test beam period with two different geometrical setups. These are shown in Fig. 6 right (two Central Barrels CB and two Extended Barrels EB) and left (three CBs). The modules are placed in a movable table which allows the beam to impinge the detector at any point and incident angle. This allows to perform different types of scans along the modules, like cell scans by redirecting the beam at the centers of the front face cells at a fixed angle of \(20^{\circ}\), \(\eta\) scans and tilerow scans where the beam impinges perpendicular to the lateral side of the module.

As we are interested in the performance of the energy reconstruction algorithms as a function of energy more than its uniformity response, we choose data from tilerow scans (corresponding to the tilerow 5 scan point) for electrons and muons (Fig. 7 right) and \(\eta=0.35\) for pions (Fig. 7 left). In all cases the beam impinges in the middle central module as shown in Fig. 7. These configurations correspond to those for which most of the energies were available. All data shown in this paper correspond to the CB modules JINR12, JINR55, JINR27 and JINR63.

Due to the importance of the performance under physics events two different OF algorithms are applied. OF1 is the same algorithm as in CIS events with the only difference being the use of a physics shape form for the weights calculation. Therefore the same weights are used for all the channels. The OF2 algorithm is shown in Appendix A. It avoids the pedestal calculation by the introduction of a new output parameter, the pedestal itself. This fact is important as the available computing time for the online reconstruction at the ROD level is only 10 \(\mu\)s. This new implementation of the algorithm saves the time of the pedestal calculation and its substraction from the samples.

Figure 7: Left: beam direction for pions. Right: beam direction for muons and electrons.

### Iteration procedure

The OF algorithm needs the samples to come within a narrow time interval from the OF weights reference time. The time distance between the samples and the reference time of the weights (called phase) should be thus as small as possible in order to maximize the precision on the reconstructed energy and time. This is the case for CIS events where all the phases are available and one can always choose events with the proper phase.

However this is not the case for physics events at the testbeam where most of them are taken with an asynchronous beam. For this type of data the position of the samples along the SFF change event by event following a uniform distribution. The solution to the problem is to apply the proper weights for each event according to the position of the samples in the SFF. In order to do that we calculate 25 sets of weights, one for each reference time between \(-25\) and \(25\) ns in steps of \(1\) ns sweeping all the SFF. The problem becomes thus to find out the position of the samples in the SFF in order to choose the appropriate weights. We use the phase information provided by the OF algorithm and design an iteration process which is described below.

The first step of the iteration process is to check the position of the maximum sample and to detect if there is signal in the samples or, on the contrary, they belong to a pedestal event. This last case is important as pedestal events do not converge in an iteration process. The algorithm flags an event as pedestal if neither the maximum sample is the central sample nor the two samples next to it (one \(25\) ns before and the other \(25\) ns after). The algorithm also flags a pedestal event if the difference of the maximum sample with the first or the last samples is smaller than \(4\) counts. When the event is flag as pedestal the equations applied to the samples are:

\[E=\sum_{i=1}^{n}a_{i}S_{i}\,, \tag{39}\]

\[E\tau=\sum_{i=1}^{n}b_{i}S_{i}\,, \tag{40}\]

where the \(\boldsymbol{a}\) and \(\boldsymbol{b}\) weights are taken from a reference time equal to zero, i.e., the weights are calculated to have a central sample in the peak of the SFF.

If the event is not flag as pedestal the iteration process starts. If the maximum sample is not placed in the central sample the samples are shifted a proper number of positions to set it in the middle. This last point is a requirement of the algorithm to work due to the range of calculated OF weights, from \(-12\) ns to \(12\) ns. It could be avoided by increasing this range, e.g., from \(-37\) ns to37 ns, although there are just few events whose maximum sample is not in the middle, and this solution increases the total number of weights by a factor of three.

Once the maximum sample is in the middle, equations (39) and (40) are applied in order to reconstruct the energy and the phase. This is iteration number zero. The weights of this iteration are the weights corresponding to 0 ns reference time. If the reconstructed phase in this iteration is within \(-0.5\) ns and 0.5 ns the process stops and these are considered the final values of energy and time. If this is not the case the process is repeated with the weights of the closest reference time to the reconstructed phase in the previous iteration. If the reconstructed phase in each iteration is within \(-0.5\) ns and 0.5 ns the process stops. The phase is always reconstructed relative to the reference time of the weights. This is a correct convergence criteria but in order to choose the weights for the next iteration, or to give a final reconstruction phase, this phase must be converted in a total phase by adding the reference time of the weights used.

Once the iterations are finished the total phase should be adjusted again to take into account the shift of the samples. The number of shifts, with the corresponding sign times 25 ns should added to the total reconstructed phase in order to have the final phase. The energy does not need any adjustment and the reconstructed one in the last iteration is the final energy.

### Flat filtering

The TileCal testbeam program uses a different algorithm to reconstruct the energy, the so called Flat Filtering (FF) method. This algorithm consists of a plain sum of the samples once the pedestal, defined as the signal at the first sample, has been subtracted from all other samples. The FF algorithm of the testbeam program does not include all samples in the sum but only the five consecutive samples which maximize the signal out of the total 9 available samples. The reconstructed energy given by the FF method is thus given by:

\[E=\mbox{max}\,\left[\sum_{i=j}^{j+4}\left(S_{i}-S_{1}\right)\right]\,\,j=1, \ldots,5\,. \tag{41}\]

### Fit method

Two years ago a new method was developed to reconstruct the energy and time information from the samples, the so called Fit Method (FM) [12]. The FM develops linear equations for the calculation of energy, time and pedestal by the minimization of the \(\chi^{2}\). Those reconstructions are available as part of the testbeam data. We use this algorithm to compare its energy resolution with that obtained from the OF method in physics events. However the differences should not be significant as this method and the OF technique are equivalent to first order [1].

## 5 Results

### CIS: Calibration constants

The FF and OF algorithms provide both an output energy although they quite differ in the way this energy is reconstructed. While the OF algorithm reconstructs the amplitude of the signal, the FF method computes a magnitude which is proportional to its area. Both magnitudes are though proportional to the deposited energy in the module cell. In order to perform a consistent comparison between both algorithms we calibrate its output (ADC counts) to provide the same physical magnitude, i.e., the charge released by the capacitor in CIS events (in pc), and the photomultiplier current in physics events (also in pc). Each channel is calibrated independently by computing calibration factors for the two gains. The data to calibrate the algorithms is taken from CIS runs. The injected charge (in pc) is given by:

\[Q=2C\frac{4.096N_{\mathrm{DAC}}}{1023}\,, \tag{42}\]

where \(C\) is the capacitor value (5 or 100 pF) and \(N_{\mathrm{DAC}}\) is the DAC value. The capacitor is charged at a voltage set by this DAC which has a high precision reference voltage of 2 times 4.096 V [13]. We use only runs which involve the 100 pF capacitor as it reaches both the high and the low gain scale and its nominal value is more precise [14]. Charges between 0 and 12 pC are used for the high gain calibration and charges between 13 and 800 pC for the low gain one.

The CIS data also includes a variable with the phase between the start time of the discharge and the digitizer. This phase ranges from \(-12\) ns to 12 ns. We use phases within the whole range in the calibration in order to reproduce the physics data conditions which come within the whole range of phases. Only few phases are eliminated from the calibration as they produce double peaks in the amplitude reconstruction. For each charge we average the output (in ADC counts) of the algorithms for all the phases and make a linear fit of the Figure 8: CIS calibration factors (ADC counts/pC) for high gain (HG, bottom) and low gain (LG, top) and for both algorithms: flat filtering (FF, left) and optimal filtering (OF, right). All data correspond to all working channels of three CB modules.

injected charge versus the averaged output:

\[O_{\rm FF/OF}=mQ\,, \tag{43}\]

where \(Q\) represents the injected charge in pC, \(m\) the calibration factor and \(O_{\rm FF/OF}\) the averaged output of the algorithms in ADC counts. Fig. 8 shows the distribution of the calibration factors for all the channels of the 3 modules used at the August 2003 testbeam period. The slope, \(m\), has a relative variation of about 2% in both gains and both algorithms, which agrees with [14]. The averaged ratio between high and low gain calibrations is 61 for OF and 62 for FF with a RMS of 3 for both algorithms. The nominal value between the high gain and the low gain is 64 [15] which lays whitin the error of our result. The intercept is forced to be zero but if set free the variation in the slope value is of the order of few per mil. This result also agrees with [14].

### CIS: Charge reconstruction

By reconstructing the injected charge with the CIS system one can check whether the calibration factors are properly calculated and the effect of the algorithms in the resolution. Fig. 9 shows the amplitude reconstruction distributions for high gain data. The top plot shows the injected charge versus the reconstructed charge (\(Q_{\rm REC}\)), where the diagonal corresponds to \(Q_{\rm REC}=Q_{\rm INJ}\). All points lay over the line, which proves the correct calculation of the calibration factors. The middle plot shows the residual versus the injected charge. The residual is calculated as the difference between the injected charge and the reconstructed charge divided by the injected charge. This plot corroborates the calibration factors and shows a good linearity of both the electronics and the algorithms. The bottom plot shows the resolution versus the injected charge. For each injected charge there are 34 phases and for each phase there are 8 events; therefore there are a total of 272 events for each injected charge. We define the resolution as the RMS divided by the mean of the reconstructed charge for a particular injected charge. The OF resolution is better than the FF one by a factor which increases as the charge decreases. This is the expected result as the OF algorithm is designed to minimize the noise impact in the resolution, which increases as the charge decreases. This result is confirmed in Fig. 10 which shows the same plots for the low gain range. The only difference is a small non linearity in the low charge region, which agrees with [16]. As the non linearity is shared by both algorithms its origin must be in the electronics.

### CIS: Phase reconstruction

The OF algorithm reconstructs the phase of the event. This phase is defined as the difference in time between the event samples and the reference time of the OF weights. The CIS system is able to discharge the capacitor within the whole phase range with respect to the digitizer clock. This phase is externaly configurable through the standard online DAQ software. In a CIS run every charge is discharged in 34 phases sweeping all the phase range, and each phase is repeated during 8 events. The phase information is available in the CIS data which allows to select only events with a fixed phase. Figs. 11 and 12 show the reconstructed phase of the OF algorithm versus the injected charge for a fixed phase according to the CIS information, (the 3-in-1 phase shift value equal to 35 and 84 respectively). The dependence is strong for low charges and becomes smaller, but not negligible, as the charge increases. The low gain distributions follow the same behaviour as the high gain ones with no shift in the reconstructed time (apart from that due to the loss of algorithm resolution). The information of the CIS data is thus not exactly our phase definition but instead a magnitude which is related with it. This relation depends on the charge but is constant for a fixed charge. Figs. 11 and 12 show also the RMS of the reconstructed time distributions versus the injected charge. There are only 8 events per charge and phase and the RMS of them gives an idea of the error in the time reconstruction which should be taken merely as an estimation due to the lack of statistics. The RMS increases strongly as the charge decreases for both high and low gain data. This is due as the time reconstruction involves a division by the amplitude (see equation (40)) which emphasizes the loss of phase resolution as the amplitude decreases.

### CIS: Quality factor

We define a quality factor, \(\chi\), as:

\[\chi E=\sum_{i=1}^{n}\mathrm{ABS}((S_{i}-p)-Eg_{i}(\tau))\;, \tag{44}\]

where \(n\) is the number of samples, \(S_{i}\) are the different samples of the event, \(E\) is the reconstructed amplitude in (39) and the \(g_{i}\) correspond to the shape form factors defined in (2). We choose an absolute value instead of a square in the \(\chi\) definition as it is envisaged to be implemented in the DSPs where an absolute value calculation is faster than a square function. The \(\chi\) is an indicator of the quality of both time and energy reconstructions. It helps to flag events whose shape form does not fit the shape form defined by \(\mathbf{g}\). This is the case of events with pile up or saturated samples which would have a bad \(\chi\)and the ROD could take specific actions for a detailed offline reconstruction.

Fig. 13 shows the \(\chi\) versus the injected charge in CIS runs. The quality factor increases smoothly as the charge decreases until it reaches the low charge region where the increase in \(\chi\) is boosted. This result reproduces the increase of the \(RMS\) of the time reconstruction and the loss of resolution in the energy reconstruction as the charge decreases.

Figure 9: CIS amplitude reconstruction (high gain). Top: reconstructed vs injected charge (both in pC). Middle: residual distribution vs injected charge (in pC). Bottom: reconstructed charge resolution vs injected charge (in pC). In all cases dots correspond to FF results and triangles to OF.

Figure 10: CIS amplitude reconstruction (low gain). Top: reconstructed vs injected charge (in pC). Middle: residual distribution vs injected charge (in pC). Bottom: reconstructed charge resolution vs injected charge (in pC). In all cases dots correspond to FF results and triangles to OF.

Figure 11: CIS phase reconstruction (top, in ns) and its RMS (bottom) as a function of the injected charge (pC). Left: high gain. Right: low gain. The 3-in-1 phase shift value is fixed to 35.

Figure 12: CIS phase reconstruction (top, in ns) and its RMS (bottom) as a function of the injected charge (pC). Left: high gain. Right: low gain. The 3-in-1 phase shift value is fixed to 84.

Figure 13: CIS quality factor distributions (\(\chi\), top) and their RMS (bottom) as a function of the injected charge (in pC). Left: high gain. Right: low gain.

### Physics: Noise

The energy reconstruction in pedestal events sets the accuracy of the calorimeter to measure non energy depositions. Fig. 14 shows the reconstructed energy for pedestal events and for the four algorithms discussed in this paper. Each distribution corresponds to a particular cell of a calorimeter module. All distributions are Gaussian and centered in zero which proves the correct pedestal subtraction for all the algorithms.

The sigma of the fit sets the precision for the measurement of non energy depositions. The FF distribution is characterized by the largest sigma around 0.054 pC while the lowest sigma is obtained by the OF2 and FM algorithms which correspond to \(\sim 0.022\) pC and \(\sim 0.023\) pC respectively, which are compatible within the errors. If we apply the overall pC to GeV calibration factor of 1.1 GeV/pC, the sigma noise are of the order of 59 MeV, 25 MeV, 32 MeV and 24 MeV corresponding to the FF, FM, OF1 and OF2 algorithms respectively.

Notice that the sigma of the OF1 distribution is larger than the sigma of OF2 and FM. As OF1 only outputs two parameters the level of noise minimization is larger than the OF2 which outputs three parameters. This proofs the importance of a proper determination of the pedestal - as an output parameter of the algorithm - which could be as relevant as the noise minimization. However the difference is not very large and this situation could change in a more noisy environment.

Figure 14: Energy reconstruction (in pC) in a cell with no deposited energy obtained with the four algorithms.

### Physics: Pions

The energies used for the pion analysis correspond to 350, 180, 100, 20 and 9 GeV. The signal for pions is defined by the function \(\mathrm{S_{PI}}(E_{\mathrm{thr}})\). This function returns the sum of the energy of all the channels of all the drawers at the testbeam setup. Only those channels whose energy is greater than a particular threshold \(E_{\mathrm{thr}}\) (in GeV) are included in the sum.

The pion beam is contaminated with muons (from pion decays) and electrons, being the muons the dominant contamination component. We have defined several cuts in order to select good events of pions:

**cur1:**: The X and Y coordinates of beam chambers 1 and 2 must be between \(-25\) mm and \(25\) mm [17]. This cut selects only those events where the particle impinges in the proper detector position by the use of the beam chambers at the testbeam setup.
**cur2:**: The trigger value must be equal to 1 (i.e., physics events) and \(\mathrm{S_{PI}}(1.)\) must be greater than 1 pC [17]. This cut selects only those events which are flagged as physics events by the DAQ software.
**cur31:**: The Cherenkov1 signal must be lower than 150 ADC counts [17]. This first Cherenkov detector flags electron contamination in the beam at 100 GeV.
**cur32:**: The Cherenkov2 signal must be lower than 450 ADC counts. This second Cherenkov detector flags electron contamination in the beam at very low energies.
**cur4:**: The muon wall signal must be lower than 2 ADC counts. This signal comes from a muon wall which is a layer of scintillators read by several PMs placed at around one meter distance from the back of the detector. It flags muons which go through the whole module.

All above cuts are energy dependent and are summarized in Table 1.

The pion signal is defined as \(\mathrm{S_{PI}}(0.2)\) for the FF algorithm and as \(\mathrm{S_{PI}}(0.07)\) for the FM and OF algorithms. The distribution of this function over 40 000 events is then fitted by a Gaussian distribution along the whole energy range. The output parameters of this fit define the range of a second fit to be two times the sigma around the mean. This process is iterated until the sigma and the mean convergence.

The resolution is defined as the ratio between the sigma and the mean. Theerror on the resolution is calculated from the errors of the fit parameters as:

\[\epsilon\left(\mathbb{R}\right) =\frac{1}{\mu}\sqrt{\epsilon^{2}\left(\sigma\right)+\mathbb{R}^{2} \epsilon^{2}\left(\mu\right)}\,, \tag{45}\]

where \(\mathbb{R}\) is the resolution, \(\mu\) is the mean, \(\epsilon\left(\mu\right)\) is the error on the mean and \(\epsilon\left(\sigma\right)\) is the error on the sigma.

Fig. 15 shows the energy distribution of pions at 350 (top left), 180 (top right), 20 (bottom left) and 9 GeV (bottom left). The 350 GeV distribution shows a low energy tail due to pion shower leakage in the modules. This tail is also seen for the 180 GeV beam although here it is less remarkable as at this energy the pions are almost fully contained in the modules. The 9 GeV distribution shows a high energy tail produced by the muon contamination in the beam. In all these plots, specially at high energies where the resolution is better, the detector response is higher for the FF algorithm with respect to the others. This is due to a miscalibration in the ADC to pC factors produced by a \(\sim\) 10% difference in the shape form area for CIS events with respect to physics events. As FF is an area calculation algorithm - a plain sum of the samples - this difference is translated to the calibration constants.

The resolutions of the four algorithms for all the energies are summarized in Table 2. Fig. 16 shows the resolutions versus the beam energy. At high energies the resolution is relatively similar for all the algorithms while at low energies the resolution varies for the different algorithms. The OF algorithm improves the resolution at all the energies but specially at low energies due to the minimization of the electronic noise contribution. At high energies the signal to noise ratio is high and therefore the resolution is dominated by sampling and physics fluctuations. At low energies the signal to noise ratio is low and thus there is a non negligible contribution in the resolution due to electronic noise. As OF minimizes the electronic noise the effect is remarkable in this region. For the TileCal case this region corresponds to low ADC count signals, lower than 1 pC in the high gain region and higher than 12.5 pC which is the gain transition region. This result is compatible with the energy resolution versus injected charge plots at the bottom of Figs. 9 and 10. In the physics case the differences are not as remarkable as in the CIS case as they are masked by the physics fluctuations.

The resolution data shown in Table 2 is fit over the whole energy range to the functions \(\frac{\sigma}{E}=\frac{a}{\sqrt{E}}+b\) and \(\frac{\sigma}{E}=\frac{a}{\sqrt{E}}\oplus b\). The parameter \(a\), the stochastic term, reflects statistical fluctuations in the shower development, while \(b\), the constant term, reflects uncertainties in the energy measurements due to miscalibration, cracks in the detector, dead material, etc. [10]. These formulas show the typical energy behaviour of the resolution in calorimetry which scales as \(E^{-1/2}\). Table 3 shows the results of the fits. The first parameterization provides an slope between 40% and 50% while the constant term is between 2.0% and 2.5% which agree with [10]. The second parameterization provides an slope between 50% and 55% while the constant term is between 3.8% and 4.2%. These results are compatible with the requirements of ATLAS calorimetry where a jet energy resolution of \(\frac{\sigma}{E}=\frac{50\%}{\sqrt{E}}\oplus 3\%\) is expected. The combination of the TileCal and the electromagnetic calorimeter improves the resolution fulfilling the requirement [18].

We conclude from the fit data that the election of the energy reconstruction algorithm does not have an strong impact on the determination of the \(a\) and \(b\) parameters. This result is expected as the parameters depend on the intrinsic calorimeter construction. The energy reconstruction algorithm only minimizes the noise contribution to the resolution which is rather small at the testbeam setup. In a more noisy environment, which can be artificially produced if we sum all the channels in the pion signal, the resolution and then the \(a\) and \(b\) parameters show a stronger dependence on the energy reconstruction algorithm [19].

Fig. 17 shows the reconstructed energy in pC divided by the beam energy versus the energy of the beam. This corresponds to the conversion factors (pC/GeV) for pions impinging a CB module at \(\eta=0.35\). If we ignore the point at 9 GeV the figure shows an upward tendency of the relative response of the calorimeter with the energy. This non linearity is expected as a consequence of the non compensation of the calorimeter and the increase of the electromagnetic component within the hadronic shower as a function of the energy. We have to be carefull with the point at 9 GeV as at this energy the reconstructed pion energy is contaminated with muons and therefore no conclusions should be derived from this point.

\begin{table}
\begin{tabular}{c c c c c c} E(GeV) & FT & FM & OF1 & OF2 \\ \hline
350 & (4.99 \(\pm\) 0.04)\% & (5.01 \(\pm\) 0.04)\% & (4.83 \(\pm\) 0.03)\% & (4.76 \(\pm\) 0.03)\% \\
180 & (5.73 \(\pm\) 0.04)\% & (5.57 \(\pm\) 0.04)\% & (5.58 \(\pm\) 0.04)\% & (5.51 \(\pm\) 0.04)\% \\
100 & (6.68 \(\pm\) 0.11)\% & (6.29 \(\pm\) 0.10)\% & (6.44 \(\pm\) 0.10)\% & (6.33 \(\pm\) 0.10)\% \\
20 & (13.1 \(\pm\) 0.2)\% & (12.4 \(\pm\) 0.2)\% & (12.7 \(\pm\) 0.2)\% & (12.8 \(\pm\) 0.2)\% \\
9 & (18.9 \(\pm\) 0.2)\% & (17.2 \(\pm\) 0.2)\% & (17.17 \(\pm\) 0.19)\% & (17.9 \(\pm\) 0.2)\% \\ \end{tabular}
\end{table}
Table 2: Energy resolution of pions with an incident angle of \(\eta\) = 0.35.

\begin{table}
\begin{tabular}{c c c c c} E(GeV) & ntuple & TESTbeam & module & \(\eta\) & CUTS \\  & code & period & code & & \\ \hline
350 & 340698 & July 2003 & JINR27 & 0.35 & cut1\&cut2 \\
180 & 340427 & July 2003 & JINR27 & 0.35 & cut1\&cut2 \\
100 & 340487 & July 2003 & JINR27 & 0.35 & cut1\&cut2\&cut31 \\
20 & 330362 & June 2003 & JINR12 & 0.35 & cut1\&cut2 \\
9 & 360188 & August 2003 & JINR63 & -0.35 & cut1\&cut2\&cut32 \&cut4 \\ \end{tabular}
\end{table}
Table 1: Summary of applied cuts for the pion analysis.

\begin{table}
\begin{tabular}{c c c c c}  & \(\frac{\sigma}{E}=\frac{a}{\sqrt{E}}+b\) & \(\frac{\sigma}{E}=\frac{a}{\sqrt{E}}\oplus b\) \\ \hline  & a & b & a & b \\ FF & 48.6 \(\pm\) 0.6 & 2.23 \(\pm\) 0.05 & 55.3 \(\pm\) 0.5 & 4.00 \(\pm\) 0.05 \\ FM & 42.7 \(\pm\) 0.6 & 2.53 \(\pm\) 0.05 & 50.2 \(

\begin{table}
\begin{tabular}{c c c c c} E(GeV) & FF & FM & OF1 & OF2 \\
350 & 0.9844 \(\pm\) 0.0003 & 0.8720 \(\pm\) 0.0003 & 0.8879 \(\pm\) 0.0003 & 0.8858 \(\pm\) 0.0003 \\
180 & 0.9716 \(\pm\) 0.0004 & 0.8593 \(\pm\) 0.0003 & 0.8731 \(\pm\) 0.0003 & 0.8716 \(\pm\) 0.0003 \\
100 & 0.9490 \(\pm\) 0.0010 & 0.8443 \(\pm\) 0.0008 & 0.8564 \(\pm\) 0.0009 & 0.8547 \(\pm\) 0.0008 \\
20 & 0.928 \(\pm\) 0.002 & 0.873 \(\pm\) 0.002 & 0.886 \(\pm\) 0.002 & 0.872 \(\pm\) 0.002 \\
9 & 0.961 \(\pm\) 0.002 & 0.979 \(\pm\) 0.002 & 0.9263 \(\pm\) 0.0018 & 0.8851 \(\pm\) 0.0018 \\ \hline \end{tabular}
\end{table}
Table 4: Energy calibration factors pC/GeV of pions with an incident angle of \(\eta\) = 0.35.

Figure 15: Energy distribution of pions at 350 GeV (top left), 180 GeV (top right), 20 GeV (bottom left) and 9 GeV (bottom right) impinging into a CB module at \(\eta=0.35\). Results are shown for the four algorithms, FF, FM, OF1 and OF2.

Figure 16: Energy resolution (in %) vs. beam energy (GeV) for pions impinging a CB module at \(\eta=0.35\). The results are shown for the four different algorithms, FF, FM, OF1 and OF2.

Figure 17: Conversion factors (pC/GeV) for pions impinging a CB module at \(\eta\) = 0.35. The results are shown for the four different algorithms, FF, FM, OF1 and OF2.

### Physics: Electrons

The energies used for the electron analysis correspond to 180, 100, 20 and 9 GeV. The signal for electrons is also defined by the function \(\mathrm{S_{e}}(E_{\mathrm{thr}})\). This function returns the sum of the energy of all channels of all the drawers at the testbeam setup. As for the pions case only those channels whose energy is greater than a particular threshold \(E_{\mathrm{thr}}\) are included in the sum.

The pion contamination in the electron beam is much greater than the electron contamination in the pion beam. Therefore we have defined additional cuts in order to suppress pions in the energy distribution and select good events of electrons. These new cuts are:

**cut5:**: \(\mathrm{L_{cut}(B9)}\) greater than 0.5 where the function \(\mathrm{L_{cut}(cell)}\) returns the ratio between the energy deposited in the cell divided by the total energy. Only those events which deposit more than 50% of the energy in the first cell (B9) are included in the analysis. This cut uses the longitudinal profile of the energy deposition to select electrons from pions and muons.
**cut6:**: \(\mathrm{T_{cut}()}\) must be lower than 0.03 where the function \(\mathrm{T_{cut}()}\) returns the ratio between the energy deposited in the upper and lower module and the total energy. This cuts selects only those events which deposit more than 97% of the energy in the central modules. The cut uses the lateral profile of the hadronic shower to remove pion events from the energy reconstruction.

All above cuts are energy dependent and are summarized in Table 5.

As for the pion case the signal for electrons is defined as \(\mathrm{S_{e}(0.2)}\) for the FF algorithm and as \(\mathrm{S_{ee}(0.07)}\) for the FM and OF algorithms. The energy resolution and its error are obtained as in the pion case by an iteration procedure.

Fig. 18 shows the energy distribution of electrons at 180 (top left), 100 (top right), 20 (bottom left) and 9 GeV (bottom left). The 180 and 100 GeV distributions show a low energy tail due to the pion contamination in the beam. Although several cuts have been set in order to select good events of electrons there is still pion contamination in those distributions. It is difficult to get a good selection criteria as the energy of the beam decreases and this explains the low and high energy tails of the distributions at 20 and 9 GeV. As for the pion case the detector response is higher for the FF algorithm with respect to the others. Again here the miscalibration in the ADC to pC factors due to the differences in the shape forms explains this higher response for the FF algorithm.

The resolutions of the four algorithms for all energies are summarized in Table 6. Fig. 19 shows the resolutions versus the beam energy. The electrons deposit the energy within the first cell of the detector. Each cell is read out by two photomultipliers which receive approximately the same amount of light. Therefore both photomultipliers are read out by the same gain. As the electron signal is concentrated in a single cell the effect of the two read out gains on the resolution is remarkable with these type of particles. The two highest energies are read out by the low gain while the two lowest energies are read out by the high gain. At 180 GeV the signal to noise ratio is large and the four algorithms give approximately the same resolution. At 100 GeV this ratio is not as large as for high energies and the differences on the resolution are slightly higher. At 20 GeV the gain changes, the signal to noise ratio becomes large and the four resolutions are approximately equal again. At 9 GeV the signal compared to the noise is low and now the effect of the algorithms on the resolution is remarkable as in the low gain case.

Fig. 20 shows the reconstructed energy in pC divided by the beam energy versus the energy of the beam. As for the pion case the point at 9 GeV is not reliable due to the difficulty in selecting good electron events. The other points do not show the upward tendency as for the pions case as here now all the shower is purely electromagnetic.

\begin{table}
\begin{tabular}{c c c c c} E(GeV) & FF & FM & OF1 & OF2 \\ \hline
180 & \((2.12\pm 0.04)\)\% & \((1.82\pm 0.03)\)\% & \((2.01\pm 0.04)\)\% & \((1.82\pm 0.03)\)\% \\
100 & \((3.64\pm 0.06)\)\% & \((3.16\pm 0.06)\)\% & \((3.44\pm 0.06)\)\% & \((3.21\pm 0.06)\)\% \\
20 & \((6.0\pm 0.2)\)\% & \((5.8\pm 0.2)\)\% & \((5.99\pm 0.17)\)\% & \((5.85\pm 0.18)\)\% \\
9 & \((8.3\pm 0.2)\)\% & \((7.5\pm 0.2)\)\% & \((7.6\pm 0.2)\)\% & \((7.1\pm 0.2)\)\% \\ \hline \end{tabular}
\end{table}
Table 6: Energy resolution of electrons with an incident angle of 90\({}^{\circ}\) at tile 5.

\begin{table}
\begin{tabular}{c c c c c} E(GeV) & rtuple & TESTbeam & module & Tile & CUTS \\  & code & period & code & & \\ \hline
180 & 360483 & August 2003 & JINR63 & 5 & cut1\&cut2\&cut5\&cut6\&cut31 \\
100 & 340534 & July 2003 & JINR27 & 5 & cut1\&cut2\&cut5\&cut6\&cut31 \\
20 & 330368 & June 2003 & JINR12 & 5 & cut1\&cut2\&cut5\&cut6\&cut31 \\
9 & 360301 & August 2003 & JINR63 & 5 & cut1\&cut2\&cut5\&cut6\&cut31 &cut32 \\ \hline \end{tabular}
\end{table}
Table 5: Summary of applied cuts for the electron analysis.

Figure 18: Energy distribution of electrons at 180 GeV (top left), 100 GeV (top right), 20 GeV (bottom left) and 9 GeV (bottom right) impinging a CB module at tile 5. The distributions of all the algorithms, FF, FM, OF1 and OF2 are included.

Figure 19: Energy resolution (in %) vs. beam energy (GeV) for electrons impinging a CB module at tile 5. The results are shown for the four different algorithms, FF, FM, OF1 and OF2.

Figure 20: Conversion factors (pC/GeV) for electrons impinging a CB module at tile 5. The results are shown for the four different algorithms, FF, FM, OF1 and OF2.

### Physics: Muons

For the muon analysis only one energy run is used corresponding to muons at 180 GeV. The muons behave as MIPs and impinge the detector at tile 5 (Fig. 7 right). The signal for muons is defined as the sum of all cells which contain tile 5 of the CB module impinged by the beam. The muon beam is not contaminated by any other particle and thus only cut1 is applied. As for the pion and electron cases this cut selects only muons which impinge the detector at the proper position.

The distribution of the energy deposited by muons is fitted by a Landau convoluted with a Gaussian function:

\[S_{i}\left(x|p_{1},p_{2},p_{3},p_{4}\right)=p_{1}\times\int_{-\infty}^{\infty }\mathcal{L}\left(\frac{y-p_{2}}{0.5860p_{3}}\right)\exp\left(-\frac{\left(x-y \right)^{2}}{2p_{4}^{2}}\right)\mathrm{d}y\,. \tag{46}\]

The function \(\mathcal{L}(x)\) is the Landau probability density function. The \(p_{1}\), \(p_{2}\) and \(p_{3}\) parameters characterize the Landau distribution while \(p_{4}\) describes the Gaussian smearing term.

The distribution of energy deposited by muons is characterized by two important magnitudes: the most probable value (\(\mathrm{MOP}\)) which is defined as the peak position and the full width at half maximum (FWHM). Equation (46) has no analytic solution and therefore it has to be calculated numerically. The same applies to the MOP and FWHM values with their errors. Equation (46) is taken from [20] and it is the standard function to fit the energy deposited by muons in the TileCal detector.

The distribution of the energy deposited by muons of 180 GeV in the TileCal detector is shown in Fig. 21 for the FF, FM and OF algorithms. The results of the fit are summarized in Table 8.

The MOP differences between the different algorithms correspond to the same miscalibrations seen for electrons and pions. The FWHM values show also differences between the algorithms. This result should in principle not occur as the Landau distribution depends only on the detector geometry and not on the energy reconstruction algorithm. However the fit procedure does not distinguish between the Gaussian sigma and the Landau FWHM and thus both quantities can be algorithm dependent [21]. The \(p_{4}\) value of the FF algorithm in Table 8 is the largest of the four algorithms which confirms the result of Section 5.5 about the pedestal sigma. The unexpected large value of the FWHM for this algorithm also confirms the difficulty of the fit process to distinguish between both distributions. For the other three algorithms the FWHM and \(p_{4}\) parameters are very similar which also agrees with the noiseresults from Section 5.5 except for the FM which shows a \(p_{4}\) value slightly higher than expected when it should be closer to the OF2 value according to Section 5.5. However it is compensated by a slightly lower value of the FWHM value.

Table 8 Parameters of the fit for muons with an incident angle of 90\({}^{\circ}\) at tile 5.

Figure 21: Distributions of energy deposited by muons at 180 GeV in the three modules of the TileCal testbeam. Results are shown for the different reconstruction algorithms, FF, FM, OF1 and OF2.

Conclusions

In this note the basis of the Optimal Filtering algorithm has been shown in two different ways:

* The two parameters approach, where the energy and time are given as output parameters of the algorithm while the pedestal is calculated directly from the samples.
* The three parameters approach, where the energy, time and pedestal are all output parameters of the algorithm.

The OF algorithm requires information about the noise of the specific channel and a very good characterization of its shape form. The noise treatment has been neglected in this paper due to the difficulties to extract noise information from the digital samples. The introduction of a proper noise treatment in the algorithm would otherwise improve the results shown in this paper. Thus these results should be interpreted as a low limit of the goodness of OF performance. The shape form is characterized differently according to the type of data where the OF is applied. For charge injection events the shape form is reconstructed with the charge injection data itself while for physics events it is reconstructed with a shape form given directly from physics data. This avoids systematics due to different shape forms in the two types of data. The OF parameters distribution due to differences in the CIS shape form correspond to differences of the order of one per cent.

The OF algorithm applied to CIS data reconstructs the injected charge for the whole range for both high and low gain data. The resolution of the reconstructed charge is better than the one reconstructed with the Flat Filtering algorithm. This improvement is more evident as the signal to noise ratio decreases for both gains. The time reconstruction is also satisfactory in CIS events where the reconstructed RMS is lower than 0.3 ns for the whole range of injected charges getting worse for very low charges. The worsening of both energy and time reconstructions is monitored by the variable \(\chi\) which could be used to flag those events online at the ROD DSP level.

The reconstruction of physics events is also promising. The OF algorithm has been tested with pions, electrons and muons at the testbeam. In general the OF algorithm equals or improves the resolution of the detector with the current algorithms for all data types. As for the CIS case this improvement is more remarkable in regions where the signal to noise ratio is low.

The OF algorithm fulfills also several aspects needed at the ROD level. It is versatile, it reconstructs energy, time, pedestal and monitors the quality of all the reconstructions. It is accurate, it outputs the energy with a resolution which is equal or better than the present energy reconstruction algorithms. Itis simple and fast, it is based in a weighted sum of samples which combines sums and multiplications. These are operations which consume few clock cycles in a DSP minimizing the computing time of all the reconstructions. All these characteristics make OF a good candidate for the online reconstruction at the ROD level.

Finally we note that the OF is expected to further improve the energy and time reconstruction in the presence of minimum bias noise, consider as an additional noise source together with the intrinsic noise from the front-end electronics [22].

## 7 Acknowledgments

We gratefully recognize all of our many colleagues in the TileCal subsystem of the ATLAS collaboration, specially all the people involved in the testbeam data taking periods: shifters, experts, etc.

Within this group we would like to mention Richard Teucher and Tomas Davidek for providing the physics shape form reconstruction. Richard again for the development of the FM algorithm and the information about the CIS system. Tomas again for the discussion about pions and muons analysis. Tibor Zenis for his contribution in the pion analysis. Robert Stanek for his outstanding knowledge of calorimetry and his unlimited capacity of motivation as testbeam coordinator. Alexander Solodkov for his help in the technical details of the data management. And finally Rupert Leitner for his help, guide - specially in the low energy analysis - and support during all his period as TileCal team leader.

It is a pleasure to acknowledge also the contribution of Bill Cleland, his deep knowledge of signal processing and his help in understanding the algorithm of Optimal Filtering which guided us at the beginning in the periods of uncertainty and still helps us at the present in its final implementation.

Finally we thank the IFIC computing services, specially Javier Sanchez, for his help in the problem of data storage.

Signal reconstruction with OF (ii)

One of the problems of OF as developed in Section 2 is the non zero pedestal treatment of the Tilecal electronics signal. In this section we show how OF can be redeveloped in order to have into account this pedestal as another parameter appart from the amplitude and time.

Let's define again \(g(t)\) as the shape form function of the signal (noise free) normalized in amplitude and resting at a zero baseline. The samples can thus be expressed as:

\[S(t)=p+Ag(t)\,,\] (A.1)

where \(S(t)\) represents the time sampling function, \(p\) the pedestal and \(A\) the true amplitude of the signal. The set of samples are taken from \(S(t)\) at regular time intervals \(t_{i}\) and are given by:

\[S_{i}=p+Ag(t_{i})=p+Ag_{i}\,.\] (A.2)

If we introduce imperfections due to real electronics the samples now become:

\[S_{i}=p+Ag(t_{i}-\tau)+n_{i}\,,\] (A.3)

where \(\tau\) is the phase between the digitizer output and the \(g\) and \(n_{i}\) is the noise term. In order to linearize the dependence with \(\tau\), we make a Taylor's expansion at first order:

\[S_{i}\simeq p+Ag(t_{i})-A\tau g^{\prime}(t_{i})+n_{i}=p+Ag_{i}-A\tau g^{\prime }_{i}+n_{i}\,.\] (A.4)

This aproximation introduces a dependence on the quality of the reconstructions with \(\tau\). If \(\tau\) is equal to zero the Taylor's expansion is exact but with increasing \(\tau\) the quality of the reconstruction decreases.

Let's define now three quantities:

\[u =\sum_{i=1}^{n}a_{i}S_{i}\,,\] (A.5) \[v =\sum_{i=1}^{n}b_{i}S_{i}\,,\] (A.6) \[w =\sum_{i=1}^{n}c_{i}S_{i}\,,\] (A.7)

[MISSING_PAGE_EMPTY:56]

for the weights:

\[\begin{array}{l}\sum\limits_{i=1}^{n}a_{i}=0\,,\qquad\sum\limits_{i=1}^{n}a_{i} g_{i}=1\,,\qquad\sum\limits_{i=1}^{n}a_{i}g_{i}^{\prime}=0\,;\\ \sum\limits_{i=1}^{n}b_{i}=0\,,\qquad\sum\limits_{i=1}^{n}b_{i}g_{i}=0\,, \qquad\sum\limits_{i=1}^{n}b_{i}g_{i}^{\prime}=-1\,;\\ \sum\limits_{i=1}^{n}c_{i}=1\,,\qquad\sum\limits_{i=1}^{n}c_{i}g_{i}=0\,, \qquad\sum\limits_{i=1}^{n}c_{i}g_{i}^{\prime}=0\,.\end{array}\] (A.17)

Note that \(\sum\limits_{i=1}^{n}a_{i}=0\) and \(\sum\limits_{i=1}^{n}b_{i}=0\) guarantees that any constant term added to \(S_{i}\) will make no contribution to neither the amplitue \(A\) nor the phase \(\tau\). Also note that we have defined \(m\) events with equal amplitude, time and pedestal to calculate \(\langle u\rangle\), \(\langle v\rangle\) and \(\langle w\rangle\). However the distribution of \(u\), \(v\) and \(w\) values is broaded by the noise contribution. In order to minimize this effect we require the parameters \(a\), \(b\) and \(c\) to be calculated such that they minimize the \(u\), \(v\) and \(w\) variances.

These variances are given by:

\[\text{Var}(u)=\text{Var}(\sum\limits_{i=1}^{n}a_{i}S_{i})\,,\] (A.18)

\[\text{Var}(v)=\text{Var}(\sum\limits_{i=1}^{n}b_{i}S_{i})\,,\] (A.19)

\[\text{Var}(w)=\text{Var}(\sum\limits_{i=1}^{n}c_{i}S_{i})\,.\] (A.20)

If we develop again equations (A.18), (A.19) and (A.20) using (A.4) we have:

\[\text{Var}(u)=\text{Var}(p\sum\limits_{i=1}^{n}a_{i}+A\sum\limits_{i=1}^{n}a_{ i}g_{i}-A\tau\sum\limits_{i=1}^{n}a_{i}g_{i}^{\prime}+\sum\limits_{i=1}^{n}a_{ i}n_{i})\,,\] (A.21)

\[\text{Var}(v)=\text{Var}(p\sum\limits_{i=1}^{n}b_{i}+A\sum\limits_{i=1}^{n}b_ {i}g_{i}-A\tau\sum\limits_{i=1}^{n}b_{i}g_{i}^{\prime}+\sum\limits_{i=1}^{n}b _{i}n_{i})\,,\] (A.22)

\[\text{Var}(w)=\text{Var}(p\sum\limits_{i=1}^{n}c_{i}+A\sum\limits_{i=1}^{n}c_ {i}g_{i}-A\tau\sum\limits_{i=1}^{n}c_{i}g_{i}^{\prime}+\sum\limits_{i=1}^{n}c_ {i}n_{i})\,,\] (A.23)

where again all the parameters are constant except \(n\).

Note that \(\text{Var}(a+x)=\text{Var}(x)\) if \(a\) is constant. With this, equations (A.21),(A.22) and (A.23) can be reduced to:

\[\text{Var}(u) = \text{Var}(\sum_{i=1}^{n}a_{i}n_{i})\;,\] (A.24) \[\text{Var}(v) = \text{Var}(\sum_{i=1}^{n}b_{i}n_{i})\;,\] (A.25) \[\text{Var}(w) = \text{Var}(\sum_{i=1}^{n}c_{i}n_{i})\,.\] (A.26)

If we develop them we obtain:

\[\text{Var}(u) = \sum_{i=1}^{n}a_{i}^{2}\text{Var}(n_{i})+\frac{2}{m}\sum_{i=1}^{n }\sum_{j=i+1}^{n}a_{i}a_{j}\sum^{m}(n_{i}-\langle n_{i}\rangle)(n_{j}-\langle n _{j}\rangle)\;,\] (A.27) \[\text{Var}(v) = \sum_{i=1}^{n}b_{i}^{2}\text{Var}(n_{i})+\frac{2}{m}\sum_{i=1}^{n }\sum_{j=i+1}^{n}b_{i}b_{j}\sum^{m}(n_{i}-\langle n_{i}\rangle)(n_{j}-\langle n _{j}\rangle)\,,\] (A.28) \[\text{Var}(w) = \sum_{i=1}^{n}c_{i}^{2}\text{Var}(n_{i})+\frac{2}{m}\sum_{i=1}^{n }\sum_{j=i+1}^{n}c_{i}c_{j}\sum^{m}(n_{i}-\langle n_{i}\rangle)(n_{j}-\langle n _{j}\rangle)\,,\] (A.29)

which can be expressed in a more compact way as:

\[\text{Var}(u) = \frac{1}{m}\sum_{i,j=1}^{n}a_{i}a_{j}\sum^{m}(n_{i}-\langle n_{j }\rangle)(n_{j}-\langle n_{j}\rangle)\;,\] (A.30) \[\text{Var}(v) = \frac{1}{m}\sum_{i,j=1}^{n}b_{i}b_{j}\sum^{m}(n_{i}-\langle n_{i }\rangle)(n_{j}-\langle n_{j}\rangle)\,.\] (A.31) \[\text{Var}(w) = \frac{1}{m}\sum_{i,j=1}^{n}c_{i}c_{j}\sum^{m}(n_{i}-\langle n_{i }\rangle)(n_{j}-\langle n_{j}\rangle)\,.\] (A.32)

Again we suppose that \(\langle n_{i}\rangle=0\) and then:

\[\text{Var}(u) = \frac{1}{m}\sum_{i,j=1}^{n}a_{i}a_{j}\sum^{m}(n_{i}n_{j})=\sum_{ i,j=1}^{n}a_{i}a_{j}\langle n_{i}n_{j}\rangle\;,\] (A.33) \[\text{Var}(v) = \frac{1}{m}\sum_{i,j=1}^{n}b_{i}b_{j}\sum^{m}(n_{i}n_{j})=\sum_{ i,j=1}^{n}b_{i}b_{j}\langle n_{i}n_{j}\rangle\;,\] (A.34) \[\text{Var}(w) = \frac{1}{m}\sum_{i,j=1}^{n}c_{i}c_{j}\sum^{m}(n_{i}n_{j})=\sum_{ i,j=1}^{n}c_{i}c_{j}\langle n_{i}n_{j}\rangle\;.\] (A.35)Our goal is to find expressions for \(\mathbf{a}\), \(\mathbf{b}\) and \(\mathbf{c}\) which minimize the variance and fulfill the constraints of (A.17). We use thus the Lagrange multipliers method by constructing the following three functions:

\[I_{u}=\sum_{i,j=1}^{n}a_{i}a_{j}\langle n_{i}n_{j}\rangle-\lambda(\sum_{i=1}^{n}a _{i}g_{i}-1)-\kappa\sum_{i=1}^{n}a_{i}g_{i}^{\prime}-\nu\sum_{i=1}^{n}a_{i}\,,\] (A.36)

\[I_{v}=\sum_{i,j=1}^{n}b_{i}b_{j}\langle n_{i}n_{j}\rangle-\mu\sum_{i=1}^{n}b_{ i}g_{i}-\rho(\sum_{i=1}^{n}b_{i}g_{i}^{\prime}+1)-\phi\sum_{i=1}^{n}b_{i}\,,\] (A.37)

\[I_{w}=\sum_{i,j=1}^{n}c_{i}c_{j}\langle n_{i}n_{j}\rangle-\alpha\sum_{i=1}^{n} c_{i}g_{i}-\beta\sum_{i=1}^{n}c_{i}g_{i}^{\prime}-\gamma(\sum_{i=1}^{n}c_{i}-1)\,,\] (A.38)

where \(\lambda\), \(\kappa\), \(\nu\), \(\mu\), \(\rho\)\(\phi\), \(\alpha\), \(\beta\), and \(\gamma\) are the Lagrange multipliers.

Next we partial derivate \(I_{u}\), \(I_{v}\) and \(I_{w}\) with respect to \(a_{i}\), \(b_{i}\) and \(c_{i}\) and equal them to zero:

\[\frac{\partial I_{u}}{\partial a_{i}}=2\sum_{j=1}^{n}a_{j}\langle n_{i}n_{j} \rangle-\lambda g_{i}-\kappa g_{i}^{\prime}-\nu=0\,,\] (A.39)

\[\frac{\partial I_{v}}{\partial b_{i}}=2\sum_{j=1}^{n}b_{j}\langle n_{i}n_{j} \rangle-\mu g_{i}-\rho g_{i}^{\prime}-\phi=0\,,\] (A.40)

\[\frac{\partial I_{w}}{\partial c_{i}}=2\sum_{j=1}^{n}c_{j}\langle n_{i}n_{j} \rangle-\alpha g_{i}-\beta g_{i}^{\prime}-\gamma=0\,.\] (A.41)

Equations (A.39), (A.40) and (A.41) define three sets of \(n\) equations. Together with the three sets of three equations in (A.17) we have now three systems of \(n+3\) equations and \(n+3\) unknowns.

We can substitute \(\langle n_{i}n_{j}\rangle\) by \(R_{ij}\) in (A.39), (A.40) and (A.41) which represents an element of the noise autocorrelation matrix defined as:

\[R_{ij}=\frac{\sum(n_{i}-\langle n_{i}\rangle)(n_{j}-\langle n_{j}\rangle)}{ \sqrt{\sum(n_{i}-\langle n_{i}\rangle)^{2}\sum(n_{j}-\langle n_{j}\rangle)^{2} }}=\frac{\langle(n_{i}-\langle n_{j}\rangle)(n_{j}-\langle n_{j}\rangle)\rangle }{\sqrt{\text{Var}(n_{i})\text{Var}(n_{j})}}\,.\] (A.42)

By hypotheses \(\langle n_{i}\rangle=0\) and \(\text{Var}(n_{i})=\text{Var}(n_{j})\) as \(n_{i}\) and \(n_{j}\) are samples of the same noise distribution. Therefore the denominator in (A.42) is absorbed in the Lagrange multipliers.

The \(n+3\) equations for \(\boldsymbol{a}\) are given by:

\[\begin{array}{l}\sum\limits_{i=1}^{n}a_{i}g_{i}=1\,,\\ \sum\limits_{i=1}^{n}a_{i}g^{\prime}_{i}=0\,,\\ \sum\limits_{i=1}^{n}a_{i}=0\,,\\ \sum\limits_{j=1}^{n}a_{j}R_{ij}-\lambda g_{i}-\kappa g^{\prime}_{i}-\nu=0 \quad\forall\,i\,,\end{array}\] (A.43)

which can be written in matrix format as:

\[\left(\begin{array}{cccccc}R_{11}&R_{12}&\ldots&R_{1n}&g_{1}&g^{\prime}_{1} &1\\ R_{21}&R_{22}&\ldots&R_{2n}&g_{2}&g^{\prime}_{2}&1\\ \vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\ R_{n1}&R_{n2}&\ldots&R_{nn}&g_{n}&g^{\prime}_{n}&1\\ g_{1}&g_{2}&\ldots&g_{n}&0&0&0\\ g^{\prime}_{1}&g^{\prime}_{2}&\ldots&g^{\prime}_{n}&0&0&0\\ 1&1&\ldots&1&0&0&0\end{array}\right)\left(\begin{array}{c}a_{1}\\ a_{2}\\ \vdots\\ a_{n}\\ \lambda\\ \kappa\\ \nu\end{array}\right)=\left(\begin{array}{c}0\\ 0\\ 0\\ 0\\ 1\\ 0\end{array}\right)\,.\] (A.44)

The \(n+3\) equations for \(\boldsymbol{b}\) are given by:

\[\begin{array}{l}\sum\limits_{i=1}^{n}b_{i}g_{i}=0\,,\\ \sum\limits_{i=1}^{n}b_{i}g^{\prime}_{i}=-1\,,\\ \sum\limits_{i=1}^{n}b_{i}=0\,,\\ \sum\limits_{j=1}^{n}b_{j}R_{ij}-\mu g_{i}-\rho g^{\prime}_{i}-\phi=0\quad \forall\,i\,.\end{array}\] (A.45)In matrix format (A.45) reads:

\[\left(\begin{array}{cccccc}R_{11}&R_{12}&\ldots&R_{1n}&g_{1}&g^{\prime}_{1}&1\\ R_{21}&R_{22}&\ldots&R_{2n}&g_{2}&g^{\prime}_{2}&1\\ \vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\ R_{n1}&R_{n2}&\ldots&R_{nn}&g_{n}&g^{\prime}_{n}&1\\ g_{1}&g_{2}&\ldots&g_{n}&0&0&0\\ g^{\prime}_{1}&g^{\prime}_{2}&\ldots&g^{\prime}_{n}&0&0&0\\ 1&1&\ldots&1&0&0&0\end{array}\right)\left(\begin{array}{c}b_{1}\\ b_{2}\\ \vdots\\ b_{n}\\ \mu\\ \rho\\ \phi\end{array}\right)=\left(\begin{array}{c}0\\ 0\\ 0\\ -1\\ 0\end{array}\right)\,.\] (A.46)

The \(n+3\) equations for \(c\) are given by:

\[\begin{array}{l}\sum\limits_{i=1}^{n}c_{i}g_{i}=0\,,\\ \sum\limits_{i=1}^{n}c_{i}g^{\prime}_{i}=0\,,\\ \sum\limits_{i=1}^{n}c_{i}=1\,,\\ \sum\limits_{j=1}^{n}c_{j}R_{ij}-\alpha g_{i}-\beta g^{\prime}_{i}-\gamma=0 \quad\forall\,i\,.\end{array}\] (A.47)

In matrix format (A.47) reads:

\[\left(\begin{array}{cccccc}R_{11}&R_{12}&\ldots&R_{1n}&g_{1}&g^{\prime}_{1}&1 \\ R_{21}&R_{22}&\ldots&R_{2n}&g_{2}&g^{\prime}_{2}&1\\ \vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\vdots\\ R_{n1}&R_{n2}&\ldots&R_{nn}&g_{n}&g^{\prime}_{n}&1\\ g_{1}&g_{2}&\ldots&g_{n}&0&0&0\\ g^{\prime}_{1}&g^{\prime}_{2}&\ldots&g^{\prime}_{n}&0&0&0\\ 1&1&\ldots&1&0&0&0\end{array}\right)\left(\begin{array}{c}c_{1}\\ c_{2}\\ \vdots\\ c_{n}\\ \alpha\\ \beta\\ \gamma\end{array}\right)=\left(\begin{array}{c}0\\ 0\\ 0\\ \vdots\\ 0\\ 0\\ 1\end{array}\right)\,.\] (A.48)

Equations (A.44), (A.46) and (A.48) are used to calculate \(a\), \(b\) and \(c\).

Notice that now the equations for amplitude, time and pedestal reconstruction are given by:

\[A=\sum\limits_{i=1}^{n}a_{i}S_{i}\,,\] (A.49)\[A\tau=\sum_{i=1}^{n}b_{i}S_{i}\,,\] (A.50) \[p=\sum_{i=1}^{n}c_{i}S_{i}\,,\] (A.51)

and it is not necessary to substract the pedestal from the samples before applying the above equations. The pedestal calculation (equation (A.51)) could be implemented in the DSPs according to the needs. The quality factor defined in (44) is now given by:

\[\chi A=\sum_{i=1}^{n}\text{ABS}(S_{i}-(Ag_{i}+p))\,.\] (A.52)

This factor should be interpreted only as an online variable to be eventually implemented at the DSP level of the RODs and which flags events whose shape form does not fit with the values of \(\boldsymbol{g}\) (pile-up, saturation). Thus, the definition of \(p\) as the signal from the first sample would be enough for this purpose and would save time in an online implementation.

The most important consequence of the introduction of the pedestal as an additional parameter in the output of the algorithm is the variance minimization. One additional constraint is added per parameter in the Lagrange multipliers method. As a consequence the variances \((\text{Var}(u),\,\text{Var}(v),\,\text{Var}(w))\) are equal or greater than in the two parameter case and then the minimization could be less optimal. In the ATLAS enviroment the beam is synchronous, therefore the phase distribution of the events could be narrow enough to neglect the first order aproximation in (4) without including the time reconstruction. Therefore the output parameters would only be the energy and pedestal going back to the minimization levels of Section 2.

The final decision of which algorithm to implement at the ROD is not straightforward, and a further study including pileup and minimum bias final ATLAS conditions is needed in order to give a final answer to this problem.

## References

* [1] E. G. Cleland, W. E. Stern. Signal processing considerations for liquid ionization calorimeters in a high rate environment. _Nucl. Instr. Meth._, 338:467, 1994.
* [2] Richard Wigmans. _Calorimetry_. Oxford University Press, 2000.
* [3] J. Torres, J. Castelo, and E. Fullana. ROD general requirements and present hardware solution for the ATLAS Tile calorimeter. Proceedings of the 8th Workshop on Electronics for LHC Experiments, Colmar, France, 9-13 Sep 2002.
* Universitat de Valencia. ATLAS note in preparation.
* [5] Bill Cleland private comunication.
* [6] F. Camarena, J. Castelo, and E. Fullana. Optimal filtering applied to 1998 test beam of module 0. _ATLAS internal note, ATL-TILECAL-2002-015_, 2002.
* [7] C. Cuenca. Pedestal noise and autocorrelation. _Presentation at TileCal Commissioning meeting_, 28th July, 2004.
* Universitat de Valencia. ATLAS note in preparation.
* LAPP Annecy-le-Vieux_, 14-15th November, 2002.
* [10] ATLAS Collaboration. Tile Calorimeter Technical Design Report. Technical Report CERN/LHCC 96-42, CERN, 1996.
* [11] Rupert Leitner private comunication.
* [12] R. Teuscher. Energy and time reconstruction for CIS and Physics. _Presentation at TileCal Analysis meeting_, 7th October, 2002.
* [13] K. Anderson et al. Front-end electronics for the ATLAS tile calorimeter. Proceedings of the 4th Workshop on Electronics for LHC Experiments (LEB 98), Rome, Italy, 21-25 Sep 1998.
* [14] R. Teuscher. Performance of the Charge Injection System (CIS). _Presentation at TileCal Calibration Workshop_, 20th November, 2003.
* [15] S. Berglund et al. The ATLAS Tile Calorimeter digitizer. Proceedings of the 5th Workshop on Electronics for the LHC Experiments (LEB 99), Snowmass, Colorado, 20-24 Sep 1999.
* [16] R. Teuscher. CIS calibration and pulse shapes. _Presentation at TileCal Analysis meeting_, 25th February, 2002.

* [17] T. Zenis and S. Tokar. Flat Filter vs. Fit Method for projective pions. _Presentation at TileCal MC+TOOLS+ANALYSIS meeting_, 23rd February, 2004.
* [18] ATLAS Collaboration. Calorimeter Performance Technical Design Report. Technical Report CERN/LHCC 96-40, CERN, 1996.
* [19] E. Fullana. Energy reconstruction algorithms and their influence on the ATLAS Tile Calorimeter. In _Proceedings of the XI International Conference on Calorimetry in High Energy Physics_, Perugia, 2004.
* [20] T. Davidek and R. Leitner. Parametrization of the muon response in the Tile Calorimeter. _ATLAS internal note, ATL-TILECAL-97-114_, 1997.
* [21] Tomas Davidek private comunication.
* [22] R. Teuscher. OF strategies for Minimum Bias events in the TileCal. _Presentation at TileCal Analysis meeting_, 2nd October, 2000.