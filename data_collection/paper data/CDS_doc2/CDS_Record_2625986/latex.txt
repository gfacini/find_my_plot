# Trigger Menu in 2017

The ATLAS Collaboration

###### Abstract

This document summarises the trigger menu deployed by the ATLAS experiment during 2017 data taking at proton-proton collision centre-of-mass energies of \(\sqrt{s}=13\) TeV and \(\sqrt{s}=5\) TeV at the LHC and describes the improvements with respect to the trigger system and menu used in 2016 data taking.

ATLAS PUB Note ATL-DAQ-PUB-2018-002

24th June 2018

## 1 Introduction

The trigger system is an essential component of any hadron collider experiment as it is responsible for deciding whether or not to record a given beam crossing for later study. During the first operational years of the Large Hadron Collider's (LHC) second experimental running period, the ATLAS trigger system [1] operated efficiently at collision centre-of-mass energies of \(\sqrt{s}=13\) TeV and \(\sqrt{s}=5\) TeV, and instantaneous luminosities of up to \(0.5\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) during 2015, and up to \(1.4\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) during 2016. A detailed description of the initial performance of the trigger system during 2015 is summarised in Ref. [2]. This document summarises the trigger menu utilised for the data taking of proton-proton (\(pp\)) collision data taking in 2017 up to a peak luminosity of \(1.7\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) and describes the improvements of the trigger system and algorithms with respect to the previously described performance in 2016 [3].

## 2 The ATLAS detector and trigger system

The ATLAS detector is a multipurpose particle physics detector with nearly \(4\pi\) coverage in solid angle around the collision point,1 and is described in detail in Ref. [1].

Footnote 1: ATLAS uses a right-handed coordinate system with its origin at the nominal interaction point (IP) in the centre of the detector and the \(z\)-axis along the beam pipe. The \(x\)-axis points from the IP to the centre of the LHC ring, and the \(y\)-axis points upwards. Cylindrical coordinates (\(r,\phi\)) are used in the transverse plane, \(\phi\) being the azimuthal angle around the \(z\)-axis. The pseudorapidity is defined in terms of the polar angle \(\theta\) as \(\eta=-\ln\tan(\theta/2)\). Transverse momentum and energy are defined as \(p_{\rm T}=p\sin\theta\) and \(E_{\rm T}=E\sin\theta\), respectively. Angular distance is measured in units of \(\Delta R\equiv\sqrt{(\Delta\eta)^{2}+(\Delta\phi)^{2}}\).

In Run 2 the ATLAS detector has a two-level trigger system. The first-level trigger (Level-1 trigger, L1) is implemented in hardware and uses a subset of the detector information to reduce the rate of accepted events from an input rate of up to 40 MHz to maximally 100 kHz. This is followed by a software-based trigger (high-level trigger, HLT) that reduces the rate of recorded events to 1 kHz on average. The event reconstruction at the HLT of objects such as leptons or jets happens only to the extent required by the executed trigger algorithms. It is referred to as online reconstruction. Events which are accepted by the HLT are transferred to CERN's Tier-0 computing centre for offline reconstruction. Event selections in the HLT are referred to simply as triggers and the collection of all triggers is called the trigger menu. Triggers are comprised of steps, where a step is a sequence of algorithms. A typical step will execute multiple feature-extraction algorithms requesting event-data fragments from within a rectangular (in \(\eta\times\phi\)) Region of Interest (RoI) defined by the L1 output, and run reconstruction algorithms over this sub-set of the event data. Each step terminates on a hypothesis algorithm which uses the reconstructed features to form a boolean decision whether the trigger condition is satisfied. The output of single algorithms and entire steps is cached, the partial-event data requested by feature extraction algorithms is also cached and any subsequent requests for the same algorithm/step (within the same RoI) or data fragment(s) within the event processing returns the local cached version.

An additional component of the ATLAS detector that is being commissioned during Run 2 is the ATLAS Forward Proton (AFP) project [4]. This new subdetector extends the physics reach of ATLAS, by enabling the identification of protons that emerge intact from the LHC proton-proton collisions at very low angles. Two detectors with tracking and timing capabilities are placed 2-3 mm from the beam, 210 m away to each side of the ATLAS interaction point. This enables the observation and measurement of a range ofprocesses where one or both protons remain intact, which otherwise would be difficult or impossible to study.

## 3 Trigger menu in 2017

During the 2017 proton-proton run, the LHC delivered a peak luminosity close to \(L=1.7\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) during most of the year, and briefly exceeded \(L=2.0\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) towards the end of the year. Given the expected luminosity increase with respect to the 2016 running conditions, \(L=1.4\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\), changes to the trigger menu utilised previously became necessary.

The trigger menu strategy is based on the following building blocks:

* Primary triggers, which are used for physics measurements, and typically run unprescaled.
* Support triggers, which are used for efficiency and performance measurements, background estimates or monitoring, and typically run at a small rate (of the order of 0.5 Hz each). About 15% of the HLT bandwidth is dedicated to support triggers.
* Alternative triggers, which run alternative online reconstruction algorithms complementary to primary and/or support triggers. For example as part of the commissioning of future primaries.
* Backup triggers, with tighter selections and lower expected rate, in case the rate of the primary trigger becomes too high.
* Calibration triggers, which are used for detector calibrations and often run at high rate but store very small events with only the relevant information from the detector needed for the calibrations.

The primary triggers that comprise the 2017 standard physics trigger menu (aiming to cover the 1.4 - \(1.7\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) luminosity regime) and their measured rates are shown in Table 1. The different identification and isolation definitions per object can be found in Ref. [2]. With respect to the trigger menu utilised during 2016 [3] several changes were implemented. The online \(p_{\mathrm{T}}\) requirements, also referred to as thresholds, are only slightly higher. Despite the increase in luminosity, single electron and muon HLT thresholds remain at 26 GeV. Dielectron trigger thresholds remain at 17 GeV and 15 GeV at HLT and L1 level respectively, but isolation was introduced at L1. A significant change is seen in the L1 seed for single tau triggers which was increased from 60 GeV to 100 GeV. For the default missing transverse energy (\(E_{\mathrm{T}}^{\mathrm{miss}}\)) trigger which is used in many searches for physics beyond the Standard Model, an improved reconstruction algorithm at the HLT is introduced with a more robust performance in high pile-up conditions, which allows analyses to keep the offline \(E_{\mathrm{T}}^{\mathrm{miss}}\) thresholds unchanged. Several improvements, described in Section 4, were introduced for jet triggers and \(B\)-physics triggers which allowed to retain low thresholds despite the increase in luminosity. The \(b\)-jet triggers in 2017 use a reoptimised multivariate identification algorithms as used offline with six different operating points. Several combined trigger were added to the menu in order to efficiently select events for analyses with complex event topologies. These triggers typically do not significantly increase the overall trigger rate. In addition, various improvements to the online reconstruction algorithms were deployed by incorporating offline reconstruction algorithms and calibrations as much as possible to the HLT.

The complete trigger menu has to respect all technical limitations at Level-1 and the HLT, which makes the alignment of the physics goals of the menu with the available resources in terms of bandwidth and CPU a challenging task. Recorded events are gathered in data streams, depending on their primary use case and 

[MISSING_PAGE_EMPTY:4]

their specific offline reconstruction needs. Figure 1 shows the average recording rate of the physics data stream of all ATLAS \(pp\) runs taken in 2017. Events for physics analyses are recorded at an average rate of approximately 1 kHz.2

Footnote 2: Due to decreasing luminosity during the run, the average rate is about two thirds of the peak rate for runs in which no levelling (see Section 3.1) is applied.

The main physics stream contains data from the full detector when a trigger is activated. However other streams, such as calibration streams, only record partial information, a strategy called partial event building (PEB). In PEB, only specific parts of the detector are stored, reducing the event size by a large factor. An alternative approach to reduce the event size is followed by the trigger-level-analysis [5], where only the objects reconstructed by the HLT are stored. By reducing the size of the event-data, the triggers can operate at much higher rates, without saturation of the output bandwidth. Figure 2 shows the HLT rates and output bandwidth as a function of time. The apparent mismatch between rate and output bandwidth in some streams is due to the use of partial event building.

### Luminosity levelling

In August 2017 a problem was identified in sector 16L2 of the LHC that prevented operating with as many number of bunches. An alternative filling scheme was introduced, named _8b4e_ (eight filled, four empty), that circumvented the problem, but reduced the number of colliding bunches by 30%. In order to compensate for the loss in luminosity, the beam intensity was increased and the emittance reduced, allowing the LHC to reach a record luminosity of \(L=2.08\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\). However, the increase in luminosity with the _8b4e_ filling scheme also resulted in unprecedented levels of pile-up, with up to a mean of 80 interactions per bunch-crossing, compared to an expectation of a mean of 60 interactions with the nominal filling scheme. The resulting rates from such high luminosity together with the unforeseen level of pile-up, resulted in an excessive strain of the CPU resources of the HLT farm. The resulting trigger

Figure 1: The average recording rate of the main physics data stream and the \(B\)-physics and light states data stream for each ATLAS \(pp\) run taken in 2017. The total average of all runs is indicated as a red dotted line, and the total average of the main physics stream is indicated as a blue dotted line.

menu, adjusted to this higher luminosity and pile-up environment, would have led to a reduced efficiency for many analyses. In order to avoid this efficiency loss, ATLAS decided to request luminosity-levelling at a luminosity of \(1.56\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) (implying a \(\langle\mu\rangle\) of about 60 during the levelling period), until the luminosity had naturally fallen below this threshold.

After the introduction of luminosity levelling, small adjustments had to be introduced in the menu, particularly for triggers with a non-linear rate dependence on the level of pile-up. The Level-1 threshold for the lowest unprescaled \(E_{\mathrm{T}}^{\mathrm{miss}}\) trigger had to be increased from 50 GeV to 55 GeV for a brief period until the L1 \(E_{\mathrm{T}}^{\mathrm{miss}}\) trigger rate was reduced with an update of the L1Calo noise filters (see Section 4.1.2). In addition, many HLT triggers that were running \(b\)-tagging on low-\(p_{\mathrm{T}}\) jets had to be disabled due to the excessive CPU consumption.

### Trigger menu for special \(pp\) runs

Additional trigger menus were designed to be used during special runs. These menus are adapted to the particular data-taking conditions and physics purpose of each run.

**Start-up menu:**: During the first months of 2017 data-taking the LHC operated initially with many fewer bunches than nominal and hence at much lower instantaneous luminosities, increasing progressively up to the nominal run conditions. This period is referred to as start-up, and a dedicated menu was deployed with the main focus being the commissioning and validation of new triggers, algorithms and improvements introduced during the end-of-year shutdown. Dedicated triggers are also included for detector, calibration and performance studies.
**Van-der-Meer scan menu:**: The absolute luminosity calibration of the ATLAS detector is performed via a Van-der-Meer (VdM) scan [6]. During this special run events are recorded based on activity in the MBTS (Minimum Bias Trigger Scintillator) system and LUCID (LUminosity measurement using a Cherenkov Integrating Detector). The events are recorded to a dedicated stream with partial event building at a rate of approximately 20 kHz.
**Low-mu menu:**: During 2017 a set of low pile-up runs was scheduled, with \(\langle\mu\rangle=2\) and \(\langle\mu\rangle=1\), with several groups expressing interest for such runs. For example, the measurement of \(p_{\mathrm{T}}(W)\) which is

Figure 2: Trigger stream rates (left) and output bandwidth (right) at the HLT as a function of time in a fill taken in August 2017 with a peak luminosity of \(L=1.7\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) and a peak average interactions per crossing of \(\langle\mu\rangle=49\). The monitoring stream is not reflected in the output bandwidth as the monitoring data is handled differently.

needed to reduce the error on the measurement of the \(W\) mass [7], the heavy-ion long range multi-particle correlation 'ridge' analysis [8], \(E/p\) measurements and jet calibration, axion searches, and several others. The primary triggers in the low-mu menu were:

* single lepton triggers with low-\(p_{\mathrm{T}}\) threshold, no isolation and loose identification. The HLT \(p_{\mathrm{T}}\) threshold was lowered to \(p_{\mathrm{T}}>14\) GeV for the single muon trigger and \(E_{\mathrm{T}}>15\) GeV for the single electron trigger.
* high-multiplicity-track triggers with various thresholds, seeded by total-energy L1 triggers.
* Triggers based on protons tagged with AFP [4] and jets in ATLAS.
* Very low \(E_{\mathrm{T}}\) diphoton triggers (\(E_{T}^{\gamma}>3\) GeV), requiring in addition a veto on total-energy in the detector.
* A period of data-taking at a centre-of-mass energy of 5 TeV was scheduled in November 2017. The main goal was to serve as reference for the ion-ion runs. Given the low pile-up conditions additional physics cases were identified, mostly overlapping with the 13 TeV low-mu run, but including also others such as the measurement of the inclusive \(t\bar{t}\) cross section at 5 TeV. In addition to the triggers from the low-mu menu, further dedicated triggers were deployed:
* Hard-probes triggers were included (electron, muons, photon, jets, \(b\)-jets) in order to have references for the upcoming heavy-ions runs.
* Several multijet triggers were included, requiring at least four jets with \(p_{\mathrm{T}}>45\) GeV or six jets with \(p_{\mathrm{T}}>25\) GeV, targeting the \(t\bar{t}\) process with an all-hadronic decay. The triggers for leptonic top decays were already covered by the single-lepton triggers needed for the \(W\) mass measurement.

## 4 Improvements and updates to the trigger during 2017

The increase in the instantaneous luminosity with respect to the 2016 data taking period manifested itself as a steady increase of the average number of interactions per bunch crossing. This increase was even more pronounced after the required modifications to the filling scheme (see Section 3.1). The dependence of trigger rates, signal efficiencies and the CPU consumption of HLT algorithms on the number of pile-up interactions differs for the various trigger signatures. The CPU consumption of some algorithms, such as as tracking algorithms, show a non-linear dependence on the number of pile-up interactions. The same non-linear dependence with pile-up is observed in the rate of global calorimeter-based trigger signatures like total energy and \(E_{\mathrm{T}}^{\mathrm{miss}}\).

Constant improvements of the trigger algorithms as well as of the trigger menu are necessary to cope with these changing conditions and to ensure an efficient triggering for the broad physics analysis program of the ATLAS experiment. The most recent improvements with respect to the trigger system performance in 2016 [3] are briefly described in the following subsections.

### Improvements to the Level-1 trigger

#### 4.1.1 Level-1 muon trigger

Due to the strict timing requirements on the Level-1 trigger system, the Level-1 muon trigger decision is based on hits in the Resistive Plate Chamber detectors (RPC) in the barrel region and the Thin Gap Chamber detectors (TGC) in the forward region of the detector. Muons are identified by spatial and temporal coincidence requirements on the hits provided by the RPCs or TGCs. The degree of deviation from the hit pattern expected for a muon with infinite momentum is used to estimate the \(p_{\mathrm{T}}\) of the muon candidate based on six possible thresholds.

The coincidence window used to search for spatial hit coincidence was optimised using 2016 data to determine the alignment parameters on a chamber-by-chamber basis. The improved coincidence window reduced by 12% the rate of the L1 single-muon trigger with a 20  threshold for no loss in efficiency.

To increase the L1 muon trigger coverage, additional RPC chambers were installed in 2015 in the regions close to the feet that support the ATLAS detector, which led to an increase in geometrical acceptance of about 4% [3]. In 2017, the overlaps with the newly installed RPCs in the barrel feet region were optimised using 2016 data, leading to a rate reduction of about 10%.

#### 4.1.2 Level-1 calorimeter trigger

The Level-1 Calorimeter Trigger [9] (L1Calo) uses calorimeter energy deposits to identify various types of high-\(E_{\mathrm{T}}\) objects as well as energy sums of interest, such as total energy or \(E_{\mathrm{T}}^{\mathrm{miss}}\). The calorimeter energy deposits undergo a series of calibrations and corrections to remove the average pile-up contribution. The L1Calo filter coefficients and noise cuts were updated for the high pile-up conditions that the LHC delivered after the switch to the \(8b4e\) filling scheme. The updated noise cuts reduced the rates and the non-linear dependence of the Level-1 triggers that are most sensitive to pile-up, such as \(E_{\mathrm{T}}^{\mathrm{miss}}\) and low-\(p_{\mathrm{T}}\) multijet triggers, leading to a 8% reduction on the total L1 rate. The reduced calorimeter occupancy after the noise cuts also improved the reconstruction time at the HLT level.

#### 4.1.3 Level-1 topological trigger

In order to respect the L1 rate limit of 100 kHz at the peak luminosities seen in 2017 the L1 thresholds would need to be raised, in some cases leading to a significant loss for the ATLAS physics programme. The Level-1 topological trigger processor [10] can combine information about several objects into topological information about the event. This functionality is used to greatly enhance the background rejection at Level-1 by exploiting the topological features of the targeted signal process, leading to a reduction in rate while keeping the thresholds constant.

**B-physics and light states:**: L1Topo is extensively used for B-physics triggers, where the thresholds of the non-topological L1 dimuon trigger were raised to \(p_{\mathrm{T}}>11\) (6) for the leading (sub-leading) muon. Additional cuts on the opening angle and invariant mass of the dimuon system are introduced in order to keep the dimuon trigger \(p_{\mathrm{T}}\) threshold low (\(p_{\mathrm{T}}>6\) (6)). Two examples are the new triggers that target \(B_{s}\to\mu\mu\) and \(\Upsilon\to\mu\mu\), where the rates of the corresponding L1Topo triggersat \(1.7\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) are 1.8 kHz and 1.5 kHz, to be compared with the 65 kHz that would be required to trigger with \(p_{\rm T}>6\) (6) GeV without the additional topological cuts.
**Ditau triggers:**: the use of L1Topo triggers is critical for analyses relying on ditau triggers with a need for low \(p_{\rm T}\) thresholds, such as \(H\rightarrow\tau\tau\). The large rate from QCD multijet background where a jet is misidentified as a tau can be reduced by requiring a cut on the angular separation \(\Delta R(\tau_{1},\tau_{2})\), characteristic of a ditau system recoiling against additional hadronic radiation. Dedicated L1Topo triggers are used requiring the presence of two isolated taus with a maximal \(\Delta R(\tau_{1},\tau_{2})\), one additional jet, and a disambiguation algorithm in order to exclude tau candidates from the jet candidates. Such triggers were commissioned and validated during 2016 [3, 11], showing a reduction of about a factor of two in rate with respect to their counterparts without L1Topo. Given their reliable performance all the non-topological L1 backups were decommissioned in 2017 in order to optimise the L1 bandwidth usage.
**\(J/\psi\) to electrons:**: the electron calibration at low \(p_{\rm T}\) is performed using a sample of \(J/\psi\to ee\) events. In order to record a large number of events, low \(p_{\rm T}\) thresholds are needed at the L1 trigger level, which would lead to huge rates. In order to reduce the rate new L1Topo triggers are included, introducing an additional cut on the invariant mass of the electron candidates. The new triggers allowed the recording of a ten times larger dataset while running at the same rate as the non-L1Topo triggers.

### Algorithm improvements and menu optimisation towards high pile-up running

During 2017 the LHC provided peak luminosities up to \(2.1\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\), a number which could be even higher in 2018. At such high luminosity an important limitation to the trigger is the available CPU within the HLT farm.

#### 4.2.1 Improvements in CPU consumption and rate reduction

During 2016 and beginning of 2017, the CPU requirements to run at \(\langle\mu\rangle=60\) were studied, with the conclusion that the CPU consumption was not sustainable and would prevent running at \(2.0\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\). In order to reduce the CPU needs dedicated work on three topics was performed, targeting technical improvements to the code, an optimisation of the trigger menu, and optimisation of costly algorithms.

Technical improvements to the code resulted in a reduction of 4% in computation time through the use of more efficient copy methods and magnetic field computation. The trigger menu was optimised in order to improve the sharing of common sequences, increasing the benefits of caching. An extensive clean up was also performed to decommission triggers that were no longer in use. In addition the trigger algorithms were also optimised, in some cases raising the \(p_{\rm T}\) thresholds for ID tracks to be considered by the algorithm, but ensuring that the performance of the triggers remained unaffected.
**Electrons:**: the preselection for track-cluster matching was optimised using an \(E_{\rm T}\)-dependent criteria, which reduced by a factor of four the time needed by the algorithm. The ordering of the menu sequences and cuts was optimised to reduce the rate of precision tracking and the computation of shower shapes.

**Muons:**: several improvements were introduced in the muon reconstruction, which contains the most costly algorithm in the menu, leading to a reduction of up to 50% in computation time. Among other changes, the maximum number of fit iterations was reduced, and the \(p_{\mathrm{T}}\) cut on the ID tracks used to build muons was raised to 2 GeV, with no loss in performance.
**B-physics:**: in addition to the gains in muon reconstruction, the B-physics triggers were further improved by optimising the muon-muon vertexing and rejecting events not passing simple dimuon invariant mass cuts earlier in the sequence, leading to a factor of three improvement on average in the time needed by the algorithms.
**B-jets:**: The identification of \(b\)-hadrons needed for the \(b\)-jet triggers is very CPU intensive, and a thorough optimisation of the algorithms was performed. By reducing the size of the region of interest in \(z/\eta/\phi\) for precision \(b\)-tagging tracking and raising the \(p_{\mathrm{T}}\) threshold for the tracks used in the vertexing the time performance was improved by a factor of five in the vertexing and 30% in the \(b\)-tagging, with no loss in identification performance.

#### 4.2.2 \(E_{\mathrm{T}}^{\mathrm{miss}}\) triggers at high pile-up

As \(E_{\mathrm{T}}^{\mathrm{miss}}\) is a global event level variable, the rate of \(E_{\mathrm{T}}^{\mathrm{miss}}\) triggers is strongly affected by the number of collisions per bunch crossing, since each proton-proton collision adds to the total energy deposited in the calorimeter. While complex correction techniques mitigate these effects to a large extent in the offline reconstruction, at trigger level these resolution effects lead to a strong increase of the trigger rate with rising pile-up. Several options exist to reconstruct the \(E_{\mathrm{T}}^{\mathrm{miss}}\) at the HLT. The _missing_\(H_{\mathrm{T}}\) (MHT) algorithm calculates \(E_{\mathrm{T}}^{\mathrm{miss}}\) as the negative vector sum of transverse energy of calibrated R=0.4 anti-\(k_{T}\) jets, where those jets are constructed from calibrated topological clusters of calorimeter cells. The _puffi_ algorithm is designed to disentangle calorimeter deposits from the hard-scatter from those originating from pile-up interactions by grouping towers made out of topological clusters into a pile-up and a hard-scatter category. This grouping is based on their energy, where the threshold itself is dependent on the mean energy and the variance of low-\(p_{\mathrm{T}}\) towers. Assuming that the contribution to \(E_{\mathrm{T}}^{\mathrm{miss}}\) from pile-up interactions averages to be zero, a minimisation taking into account resolution terms determines energy contributions from pile-up interaction in the hard-scatter towers. These pile-up contributions are then subtracted, and the final \(E_{\mathrm{T}}^{\mathrm{miss}}\) value is determined from the negative sum of transverse energy of those pile-up corrected hard-scatter towers.

Figure 3 shows the trigger efficiency and trigger cross section as a function of the pile-up for two \(E_{\mathrm{T}}^{\mathrm{miss}}\) triggers using the _MHT_ or _puffi_ algorithms. The _MHT_ algorithm was utilised as the baseline \(E_{\mathrm{T}}^{\mathrm{miss}}\) trigger in 2016, while the _puffi_ algorithm was used in 2017. The _puffi_ algorithm exhibits a slightly sharper efficiency turn-on, while yielding a much smaller rate and also smaller dependence on the pile-up. At a pile-up of \(\langle\mu\rangle=50\) the rate is reduced by an order of magnitude with respect to the previous _MHT_ algorithm.

### Special techniques

Constraints on the menu design become progressively tighter with increases in luminosity and pile-up. Improvements in offline reconstruction algorithms are ported to the HLT, where possible, improving the trigger efficiency turn-on and allowing for thresholds to remain constant despite the increased luminosity.

Alternative approaches are also considered in order to provide data for low-\(p_{\mathrm{T}}\) physics without the high prescales that would be needed to accommodate them.

#### 4.3.1 Dedicated B-physics streams

The B-physics and Light States (BLS) physics program in ATLAS relies primarily on dimuon triggers, and triggering low-\(p_{\mathrm{T}}\) dimuon events efficiently has been a major challenge. The limit of 1 kHz on the HLT trigger output rate due to the available CPU for event reconstruction at Tier-0 poses a strict limit on the ATLAS trigger capacities, in particular for the B-physics program.

A dedicated stream containing BLS triggers was created. This BLS stream allows for tailored reconstruction and also the possibility to delay the reconstruction of the events during periods when data were collected faster than it could be processed through Tier-0. The BLS stream has a peak rate of 160 Hz at HLT, with an average rate of 100 Hz. The additional available HLT rate was used to unprescale primary triggers for analyses that were limited by statistics.

An additional approach that was exploited to increase the recorded BLS data was PEB. A new B-physics PEB stream was introduced, that requires the presence of a muon candidate and an inner detector track, with a combined mass close to \(m(J/\psi)\). Only a small area of the detector is reconstructed, within an area of \(\Delta\eta\times\Delta\phi=1.5\times 1.5\) centred on the muon, which reduces the final event size by a factor of approximately seven. These events constitute a sample that can be used for MS tracking efficiency studies, which is a key input for the low-\(p_{\mathrm{T}}\) muon performance studies required by the B-physics program.

#### 4.3.2 End-of-fill triggers

During a regular physics fill, the instantaneous luminosity decreases exponentially, and after several hours it will have decreased by more than a factor of two with respect to the peak luminosity. The resulting

Figure 3: Trigger efficiency (left) and trigger cross section (trigger rates normalised to the instantaneous luminosity) as a function of the average number of interactions per bunch crossing (right) for \(E_{\mathrm{T}}^{\mathrm{miss}}\) trigger using the _MHT_ or _puff_ algorithms. All triggers also require the \(E_{\mathrm{T}}^{\mathrm{miss}}\) calculated at L1 to exceed 50 GeV. The efficiencies are evaluated in an event sample passing a loose \(W\rightarrow\mu\nu\) selection.

lower rate produced by the primary triggers leaves enough space to introduce dedicated end-of-fill triggers, usually low-\(p_{\rm T}\) triggers that are not possible to run at high luminosities. Triggers that target processes with very large cross sections such as QCD multijet production, B-physics processes, or searches for BSM signals with a large QCD background benefit most from the available resources at the end of the fill. One such example is the L1 single-jet trigger with \(E_{\rm T}>50\) GeV, which is activated when \(L<1.0\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\). This trigger is used to seed jet triggers for the trigger-level-analysis [5]. The prescale strategy and luminosity thresholds were reoptimised for 2017.

#### 4.3.3 Global sequential calibration

The offline calibration of jets benefits from the global sequential calibration (GSC) [12], which greatly improves the jet resolution. This additional calibration step has been ported to the algorithms running in the HLT in order to reduce the differences between online and offline reconstruction, and improve the trigger efficiency turn on. The GSC corrects jets according to their longitudinal shower shape and associated track characteristics without changing the overall energy scale.3 It can be split into parts involving calorimeter-based variables and parts involving track-based variables. Since tracking cannot be performed for all jet thresholds, options are provided with and without the track-based corrections. The tracks required for the GSC correction are already cached after the \(b\)-tagging algorithms have run, therefore the GSC correction does not require any additional tracking.

Footnote 3: An additional correction involving the number of muon segments is not ported to the HLT as it only affects very high \(p_{\rm T}\) jets leading to punch-through effects. These very high \(p_{\rm T}\) jets are always above the trigger threshold.

Figure 4 shows the efficiency turn-on curve for a single-jet trigger with three different calibrations applied to jets in the HLT. These additional corrections allow for improved agreement between the scale of trigger and offline jets as a function of both \(\eta\) and \(p_{\rm T}\), and thus the trigger efficiency rises much more rapidly.

### New triggers for challenging phase-space

In cases where an analysis is severely hindered by the trigger, new dedicated triggers are introduced in order to cover challenging phase-space. In the following several new triggers are discussed that allow for the recording of events in regions of phase-space that were previously uncovered.

#### 4.4.1 Higgs \(\to\gamma^{*}\gamma\to\ell\ell\gamma\)

The analysis of Higgs \(\to\gamma\gamma\) benefits from including events with a photon conversion, \(\gamma^{*}\to\ell\ell\). However the presence of two close-by leptons degrades significantly the efficiency of diphoton or photon+electron triggers. In order to overcome this limitation a dedicated electron identification algorithm is introduced, allowing events with two collimated electrons to pass. The performance of the trigger with respect to the distance between the electrons is shown in Figure 5, and compared with standard diphoton triggers in the menu. The efficiency is measured in a sample of simulated \(H\to\ell\ell\gamma\) events with \(m(\ell,\ell)<10\) GeV, \(p_{\rm T}^{\gamma}>35\) GeV and both leptons satisfying \(p_{\rm T}^{\ell}>15\) GeV. The new trigger recovers a significant fraction of events, especially in the regime of \(\Delta R(\ell,\ell)<0.1\). A requirement that the invariant mass of the photon and dielectron system is compatible with the Higgs mass is introduced to reduce the fake rate from \(Z\to ee\) events, with negligible impact on the signal efficiency.

#### 4.4.2 Large-R jet triggers with trimming and mass cuts

The increasingly common use of jet substructure and jet mass in analyses, particularly searches, provides an additional handle that can be exploited at the trigger level to reduce the rate of jet triggers, leading to lower jet-\(p_{\mathrm{T}}\) thresholds. Figure 6 shows the trigger efficiency for two large-R trimmed [13] single-jet triggers with same HLT rate. The inclusion of a jet-mass cut allows to place a lower jet-\(p_{\mathrm{T}}\) cut at the same trigger rate.

#### 4.4.3 Dedicated triggers for beyond Standard Model (BSM) searches

Searches for BSM physics assume the existence of new particles that are, in most cases, heavier than the particles in the SM. The decay products of heavy particles are usually energetic enough that the triggering on such high-\(p_{\mathrm{T}}\) objects does not pose a rate issue, especially in final states that are not fully hadronic. However, some BSM models predict light particles that may not have been detected yet due to their very small cross section. The efficient triggering of such low-\(p_{\mathrm{T}}\) final states is difficult due to their high rates, and dedicated triggers that exploit all the features of the signal are needed to allow for the reduction of \(p_{\mathrm{T}}\) thresholds while maintaining a reasonable rate.

**Higgsino decay to soft leptons:**: the current exclusion limits for the direct production of higgsino LSPs is about 100, with some dependence on the mass splitting between the three higgsino states [14].

Figure 4: Efficiency turn-on curve for a single-jet trigger with three different calibrations applied to jets. Offline jets are selected with \(|\eta|<2.8\). In green (open squares) the calibration applied in 2016 data, in red (closed circles) the updated calibration applied in 2017, utilising only calorimeter information, and in blue (open circles) this updated calibration additionally with track information. The extra calibration steps include the GSC and the application of _in situ_ corrections. These additional corrections allow for improved agreement between the scale of trigger and offline jets as a function of both \(\eta\) and \(p_{\mathrm{T}}\), and thus the trigger efficiency rises much more rapidly.

After production, the heavier states decay into the lightest neutralino producing soft leptons, with a \(p_{\rm T}\) dependent on the mass splitting (but usually of order a few \(\rm GeV\)), and \(E_{\rm T}^{\rm miss}\) in the final state. The amount of \(E_{\rm T}^{\rm miss}\) in the final state is too low to record these events efficiently using a pure \(E_{\rm T}^{\rm miss}\) trigger. The presence of initial state radiation can be exploited to record events where the system is moderately boosted, but requiring a large boost further suppresses the processes' already small cross section. Therefore combining the presence of soft leptons, \(E_{\rm T}^{\rm miss}\), and initial state radiation can be used to reduce the \(p_{\rm T}\) thresholds of all the involved objects and increase the trigger efficiency. Various triggers were introduced, requiring \(E_{\rm T}^{\rm miss}\) and jets as well as topological cuts on \(\Delta\phi({\rm jet}_{1,2},E_{\rm T}^{\rm miss})\) at L1, and the following requirements at the HLT:

* Two muons \(p_{\rm T}>4\)\(\rm GeV\), one jet \(p_{\rm T}>20\)\(\rm GeV\), \(E_{\rm T}^{\rm miss}>40\)\(\rm GeV\).
* One muon \(p_{\rm T}>4\)\(\rm GeV\), one jet \(p_{\rm T}>90\)\(\rm GeV\), \(E_{\rm T}^{\rm miss}>90\)\(\rm GeV\).
* One muon \(p_{\rm T}>4\)\(\rm GeV\), one electron \(E_{\rm T}>5\)\(\rm GeV\), one jet \(p_{\rm T}>30\)\(\rm GeV\), \(E_{\rm T}^{\rm miss}>40\)\(\rm GeV\).
* Two electrons \(E_{\rm T}>5\)\(\rm GeV\), one jet \(p_{\rm T}>40\)\(\rm GeV\), \(E_{\rm T}^{\rm miss}>70\)\(\rm GeV\).
* One electron \(E_{\rm T}>5\)\(\rm GeV\), one jet \(p_{\rm T}>50\)\(\rm GeV\), \(E_{\rm T}^{\rm miss}>70\)\(\rm GeV\).

All triggers require in addition a minimum angular distance between the two leading jets and \(E_{\rm T}^{\rm miss}\) at the HLT of \(\Delta\phi({\rm jet}_{1,2},E_{\rm T}^{\rm miss})>1.0\). The combinations of all these features allows the offline \(E_{\rm T}^{\rm miss}\) cut to be reduced from \(200\)\(\rm GeV\), which is necessary when using the lowest unprescaled \(E_{\rm T}^{\rm miss}\) trigger, to lower values more appropriate for the analysis.

Figure 5: Trigger efficiency in a sample of simulated Higgs \(\to\gamma^{*}\gamma\to\ell\ell\gamma\) events as a function of \(\Delta R(\ell,\ell)\). The new trigger with a dedicated identification algorithm for collinear electrons (3) increases the signal efficiency for low values of \(\Delta R(\ell,\ell)\).

**Higgsino decay to \(b\)-jets:**: in certain SUSY models such as gauge mediated SUSY breaking, the higgsino can decay to the gravitino. When the dominant decay of the higgsino is via a Higgs boson, the final state with largest branching ratio is characterised by four \(b\)-jets and \(E_{\mathrm{T}}^{\mathrm{miss}}\), since BR(\(H\to b\bar{b}\)) = 58%. When the mass of the higgsino is not much heavier than the Higgs boson, the decay products have low momentum and are difficult to trigger efficiently. In such scenarios, it is critical to exploit the high number of \(b\)-jets in the final state, and to reduce the \(E_{\mathrm{T}}^{\mathrm{miss}}\) threshold as much as possible. Four new triggers were introduced targeting such signal, leading to an increase of more than 30% in the signal trigger efficiency with respect to an offline selection with at least 3 \(b\)-jets using a 77% efficiency working point (WP), and \(E_{\mathrm{T}}^{\mathrm{miss}}\) above 100 :

* Four jets \(p_{\mathrm{T}}>35\), three of them \(b\)-tagged with a 70% WP.
* One jet \(p_{\mathrm{T}}>100\), \(b\)-tagged with a 60% WP, \(E_{\mathrm{T}}^{\mathrm{miss}}>80\).
* Three jets \(p_{\mathrm{T}}>35\), \(b\)-tagged with a 77% WP, \(E_{\mathrm{T}}^{\mathrm{miss}}>60\).
* Two jets \(p_{\mathrm{T}}>45\), \(b\)-tagged with a 70% WP, \(E_{\mathrm{T}}^{\mathrm{miss}}>80\).

Figure 6: Trigger efficiencies for HLT large-R single-jet triggers as a function of the leading offline trimmed [13] jet \(p_{\mathrm{T}}\) for jets with \(|\eta|<2.0\) and jet mass above 50. Two large-R jet triggers, from the 2017 menu, are shown. Blue circles represent a trimmed large-R jet trigger with a \(p_{\mathrm{T}}\) threshold of 420. Adding an additional 30 cut on the jet mass of the selected trimmed trigger jet is shown in green triangles. The mass cut significantly suppresses the QCD dijet background, allowing a lower \(p_{\mathrm{T}}\) threshold of 390, while retaining nearly all signal-like jets with a mass of above 50. Events used to measure the performance of each trigger are selected from fully-efficient, lower-threshold jet triggers. Only statistical uncertainties are shown.

#### AFP triggers

In order to fully exploit the capabilities of AFP, dedicated triggers were introduced requiring the presence of a proton in one or both sides, along with optional requirements on the time-of-flight or hard objects in the ATLAS detector. Such triggers were mainly used during special, low-luminosity runs dedicated for diffractive studies. 2017 was the first year with a full setup, where stations on both sides of ATLAS were equipped with both silicon tracker and time-of-flight detectors. As some of the physics goals of AFP require a high integrated luminosity, detectors were included in the ATLAS data-taking on the regular basis. Such data is useful for detector commissioning as well as physics studies (e.g. searches for anomalous couplings).

#### 4.4.5 New L1Topo triggers

The Level-1 topological trigger processor can combine information about several objects into topological information about the event. In order to access new regions of phase space, new dedicated L1Topo triggers are implemented, exploiting the features of the targeted signal for the triggering of such events.

**VBF Higgs to \(b\)-quarks:**: the measurement of the Higgs boson properties is a key part of the ATLAS physics program. The largest branching ratio of the Higgs boson is into \(b\)-quarks (58%), but due to the large backgrounds of such hadronic final state, evidence for this decay was only established recently through the associated production with a vector boson [15]. The inclusion of further production modes is therefore important to improve the measurement. A further production mode that is being studied is vector-boson fusion (VBF) with an additional radiated photon. The presence of a photon facilitates the triggering but the need to keep the photon threshold low can yield unreasonable trigger rates at L1 before the presence of the two \(b\)-jets can be exploited at HLT to reduce the trigger rate. The inclusion of a new L1Topo trigger requiring a photon candidate with \(E_{T}>18\) GeV and a dijet system with a mass above 300 GeV, exploits the VBF topology already at L1 to reduce the rate and enable a low photon threshold.
**Large-R jets with mass cuts:**: the usage of large-R jets in analyses and also at HLT level (see Subsection 4.4.2) has improved the performance of measurements and searches in boosted regimes. The computation of large-R jet properties is only feasible at the HLT level, as running the anti-\(k_{T}\) algorithm to recluster jets using L1Topo is not possible within the available resources. To overcome this and provide an efficient L1 seed for large-R HLT triggers, a new L1Topo algorithm is introduced called _Simple Cone_ (SC), which sums the energy of sliding-window jets within a cone of radius \(R=1.0\) around each jet. The energy of such SC jets has a better correspondence with the large-R anti-\(k_{T}\) jets computed offline and therefore provides better efficiency, especially when the offline large-R jets contain a large numbers of subjets since it becomes more likely that significant energy falls outside the usual sliding window algorithm of the Level-1 trigger.
**Charged long-lived particles:**: searches for long-lived particles (LLPs) have to overcome additional challenges at the trigger level. Charged LLPs may travel slowly through the detector and decay late leaving the same signature as a slow muon-like particle. For slow enough particles (\(\beta<0.6\)) the single-muon triggers have zero efficiency since the particle arrives in the MS in the next bunch-crossing (BC). Dedicated triggers were deployed to target such signatures, relying on a combination of an energetic jet or \(E_{\mathrm{T}}^{\mathrm{miss}}\) in a given BC and a muon being detected in the next BC.

**Neutral long-lived particles:**: in addition to charged LLPs, many SM extensions also include the production of neutral, weakly-coupled, LLPs that decay to SM jets, with a wide range of possible lifetimes. If the LLP decays in the hadronic calorimeter (HCal), it will produce a displaced jet. This feature can be used to design dedicated triggers with lower \(p_{\mathrm{T}}\) thresholds than the standard jet triggers [16]. In order to trigger on displaced jets, a HLT algorithm is developed requiring a jet with small electromagnetic fraction and track isolation (CalRatio trigger). This trigger is seeded at L1 by the lowest unprescaled tau trigger, with a L1 threshold of 60 GeV in 2015-2016 and 100 GeV in 2017. A L1 tau trigger is used instead of a jet trigger due to the smaller cone size of the tau algorithms, a feature which is also present in displaced jets which produce narrow showers in the calorimeter. The usage of L1Topo allows for a reduction in the threshold from 100 GeV to 30 GeV with either of the following requirements:

* LLP-NOMATCH: at least one L1 tau candidate with \(p_{\mathrm{T}}>30\) GeV, with no electromagnetic energy deposit larger than 2 GeV in front of either the leading or subleading tau candidate.
* LLP-RO: at least one L1 tau candidate matched to an electron/photon candidate, with \(\mathrm{E_{had}/E_{EM}>10}\), where \(\mathrm{E_{had}}\) and \(\mathrm{E_{EM}}\) are the energies deposited by the tau candidate in the hadronic and electromagnetic calorimeters respectively.

These two L1Topo triggers were validated during 2016 and active during the 2017 data taking, with an average rate of 400Hz (100 Hz) for LLP-NOMATCH (LLP-RO).

Figure 7 shows a comparison of the trigger efficiency as a function of the LLP decay position between the CalRatio trigger seeded by the L1 tau trigger with \(p_{\mathrm{T}}>60\) GeV, and the CalRatio trigger seeded by LLP-NOMATCH. The trigger efficiency is defined as the fraction of LLPs that fire the trigger, and is calculated as a function of the LLP transverse decay position. The selection algorithm strongly depends on the LLP decay position and is most efficient in the HCal (from 2.2 m to 4 m).

A good efficiency recovery is observed for low-\(p_{\mathrm{T}}\) jets (\(p_{\mathrm{T}}<100\) GeV), making the recovery especially noticeable for the signal samples with lower masses, more populated with low-\(p_{\mathrm{T}}\) jets as seen in Fig. 7. For higher mass samples, producing high-\(p_{\mathrm{T}}\) jets, the efficiency of LLP-NOMATCH is worse than the L1 tau trigger, but the efficiency is recovered via the LLP-RO algorithm.

## 5 Summary

The ATLAS trigger system was successfully operated during the 2017 proton-proton data-taking period. The trigger menu allowed for the collection of a balanced data set for various physics analyses as well as for detector monitoring and calibration purposes as summarised within this document. In 2017 several improvements to the trigger system and its algorithms were deployed for the first time and contributed to the ability to cope with the significant increase in instantaneous luminosity. Among them are the implementation of alternative solutions such as partial event building and delayed streams, and dedicated work in algorithm improvements and menu optimisation focused on high pile-up scenarios. In addition to improvements of existing triggers, new triggers were added to target previously uncovered phase-space. The performance of the Level-1 muon and calorimeter trigger algorithms was improved and optimised for the high pile-up conditions that LHC delivered. The Level-1 topological trigger was commissioned in 2016 and was extensively used in 2017, with many signatures relying on it for the primary triggers. The Level-1 topological trigger is a crucial part of the trigger system for maintaining the ability of the ATLAS detector to trigger on low-momentum physics signatures.

The improvements and developments to the trigger system, with the focus on high pile-up scenarios, will allow ATLAS to record data efficiently during 2018 at higher luminosities.

Figure 7: Left: trigger efficiency as a function of the LLP decay position in the transverse plane, \(\mathrm{L_{xy}}\), comparing the CalRatio trigger seeded by the L1 tau trigger with \(p_{\mathrm{T}}>60\) GeV, plotted in filled markers, and the CalRatio trigger seeded by LLP-NOMATCH, plotted in open markers. Right: LLP \(p_{\mathrm{T}}\) distribution for several signal samples.

## References

* [1] ATLAS Collaboration, _The ATLAS Experiment at the CERN Large Hadron Collider_, JINST **3** (2008) S08003.
* [2] ATLAS Collaboration, _Performance of the ATLAS Trigger System in 2015_, Eur. Phys. J. C **77** (2017) 317, arXiv: 1611.09661 [hep-ex].
* [3] ATLAS Collaboration, _Trigger Menu in 2016_, ATL-DAQ-PUB-2017-001, 2017, url: [https://cds.cern.ch/record/2242069](https://cds.cern.ch/record/2242069).
* [4] L. Adamczyk et al., _Technical Design Report for the ATLAS Forward Proton Detector_, tech. rep. CERN-LHCC-2015-009. ATLAS-TDR-024, 2015, url: [https://cds.cern.ch/record/2017378](https://cds.cern.ch/record/2017378).
* [5]_Trigger-object Level Analysis with the ATLAS detector at the Large Hadron Collider: summary and perspectives_, tech. rep. ATL-DAQ-PUB-2017-003, CERN, 2017, url: [https://cds.cern.ch/record/2295739](https://cds.cern.ch/record/2295739).
* [6] S. van der Meer, _Calibration of the effective beam height in the ISR_, tech. rep. CERN-ISR-PO-68-31. ISR-PO-68-31, CERN, 1968, url: [https://cds.cern.ch/record/296752](https://cds.cern.ch/record/296752).
* [7] ATLAS Collaboration, _Measurement of the \(W\)-boson mass in pp collisions at \(\sqrt{s}=7\) TeV with the ATLAS detector_, Eur. Phys. J. C **78** (2017), arXiv: 1701.07240 [hep-ex].
* [8] ATLAS Collaboration, _Measurement of multi-particle azimuthal correlations in pp, p+Pb and low-multiplicity Pb+Pb collisions with the ATLAS detector_, Eur. Phys. J. C**77** (2017) 428, arXiv: 1705.04176 [hep-ex].
* [9] R. Achenbach et al., _The ATLAS Level-1 Calorimeter Trigger_, Journal of Instrumentation **3** (2008) P03001, url: [http://stacks.iop.org/1748-0221/3/i=03/a=P03001](http://stacks.iop.org/1748-0221/3/i=03/a=P03001).
* [10] E. Simioni et al., _The Topological Processor for the future ATLAS Level-1 Trigger: From design to commissioning_, ATL-COM-DAQ-2014-019, arXiv: 1406.4316 [physics.ins-det].
* [11] ATLAS Collaboration, _The ATLAS Tau Trigger in Run 2_, ATLAS-CONF-2017-061, 2017, url: [https://cds.cern.ch/record/2274201](https://cds.cern.ch/record/2274201).
* [12] ATLAS Collaboration, _Jet global sequential corrections with the ATLAS detector in proton-proton collisions at \(\sqrt{s}=8\) TeV_, ATLAS-CONF-2015-002, 2015, url: [https://cds.cern.ch/record/2001682](https://cds.cern.ch/record/2001682).
* [13] D. Krohn, J. Thaler and L.-T. Wang, _Jet Trimming_, JHEP **02** (2010) 084, arXiv: 0912.1342 [hep-ph].
* [14] ATLAS Collaboration, _Search for electroweak production of supersymmetric states in scenarios with compressed mass spectra at \(\sqrt{s}=13\) TeV with the ATLAS detector_, Phys. Rev. D **97** (2017), arXiv: 1712.08119 [hep-ex].
* [15] ATLAS Collaboration, _Evidence for the \(H\to b\overline{b}\) decay with the ATLAS detector_, JHEP **12** (2017) 024, arXiv: 1708.03299 [hep-ex].