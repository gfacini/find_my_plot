ATLAS

LUM Internal Note

September 2005

**Simulation of Luminosity Monitoring**

**in ATLAS**

**S. Ask**

_CERN (Switzerland)_

A fast and flexible simulation program has been written and used to study different aspects related to the luminosity monitoring in ATLAS. This was made both in order to answer questions related to the planned luminosity monitor LUCID and to study the possibility of using the beam condition monitor and the minimum bias trigger scintillator counters as additional luminosity monitors. The study was made using Pythia v6.319 events at generator level and a simple program simulating the detector response of the luminosity monitors. Studies related to particle rates and the acceptance of inelastic events were made with respect to the different luminosity monitors and the saturation effect due to an imperfect particle counting was estimated. A detailed study of luminosity monitoring using bunch crossings which are registered in both the A and C side detector modules was made where the effects were both estimated by the simulation and explained by Poisson statistics.

Introduction

Several methods have previously been proposed to measure the luminosity in ATLAS [1, 2]. The main method uses Roman Pot stations to make a reference luminosity measurement, based on elastic scattering events, in runs with low luminosity. This measurement is then used to calibrate a _luminosity monitor_ in order to determine the luminosity in the physics runs where the Roman Pot detectors can not be operated.

As a complement to the full ATLAS simulation, a faster and more flexible simulation program using a simpler description of the detector response has been made. The program was made and set up in such a way as to make the studies as similar to the real measurement as possible and for this reason two separate scenarios were used. The first scenario was made to simulate the luminosity _calibration_ runs where the bunch crossings (BC) very rarely contain more than one interaction and the second to simulate the _measurement_ runs where the number of interactions per BC varies with the luminosity.

Three different detector systems for luminosity monitoring were studied, corresponding to the main ATLAS luminosity monitor LUCID [2] together with the beam condition monitor (BCM) [3] and the minimum bias trigger scintillator counters (MBTS) [4]. Both LUCID and the BCM will have time resolutions small enough to make bunch-by-bunch measurements possible and the ability to identify several particles entering the same detector element is planned. The possibilities of how to use the MBTS are at this time still under investigation and for this reason just some preliminary results with respect to the MBTS are presented in this note.

The mean number of inelastic interactions per BC can be expressed as

\[\mu=\sigma_{\it Inel}\cdot\frac{L}{f_{BC}}=\sigma_{\it Inel}\cdot L_{B} \tag{1}\]

where \(\sigma_{\it Inel}\) is the inelastic cross section, \(L\) is the instantaneous luminosity, \(f_{BC}\) is the bunch frequency and \(L_{B}\) is the average bunch luminosity. When studying LUCID and the BCM it is appropriate to use the bunch luminosity since these detectors are designed with the ability to measure individual bunches. The monitoring capability of these detectors is therefore not affected by a luminosity increase due to a larger number of bunches in the accelerator. The method to monitor the luminosity is primarily by measuring the mean number of particles per BC in one of the A or C side detector modules which is directly proportional to the mean number of interactions per BC

\[\langle M\rangle=\langle C\rangle\cdot\varepsilon_{\it pp}\cdot\mu=\langle C \rangle\cdot\varepsilon_{\it pp}\cdot\sigma_{\it Inel}\cdot L_{B} \tag{2}\]

Here \(\langle M\rangle\) is the measured mean number of particles per BC, \(\langle C\rangle\) is the mean number of particles obtained from the detected interactions in the calibration run (one interaction per detected BC) and \(\varepsilon_{\it pp}\) is the inelastic acceptance for one side of the detector. Hence the product \(\langle C\rangle\cdot\varepsilon_{\it pp}\) is the mean number of particles detected per interaction and in the calibration runs the luminosity monitor will be calibrated by the Roman Pot luminosity measurement, i.e. the product \(\varepsilon_{\it pp}\cdot\sigma_{\it Inel}\) will be determined at \(L=10^{27}\ cm^{-2}s^{-1}\). The total luminosity range, from the calibration to the design value, will hence be \(L=10^{27}\) to \(10^{34}\ cm^{-2}s^{-1}\) which corresponds to \(\mu\) values between \(2.5\times 10^{-6}\) and \(25\) assuming an inelastic cross section of \(79.2\ mb\).

Simulations of this method have been made [2] using the standard LUCID design, however, this has lead to new questions like:

* What effect has the removal of one Cerenkov tube layer in LUCID?
* How large is the effect of counting hits instead of each particle?
* Is it possible to use bunch crossings with no detected interactions for luminosity monitoring at high luminosity?* What is the effect of requiring a coincidence between the side A and C detector modules?

These questions are of a general nature and are more conveniently investigated with a fast simulation program with a simpler description of the detector response than was used in [2]. This motivated the work presented in this note where the simulation program was mainly used to study general behaviors and relative effects, however, quantitative results like number of detected particles are also presented. The study has a special emphasis on the last question about the use of coincidence since in addition to the interest in estimating this effect, the statistical explanation of the effect due to requiring a coincidence in bunch crossings with multiple interactions was not understood in detail. The results and the program presented in this note should be used as a complement to the continuing simulations using the full ATLAS software, where it can be used to make cross checks between the results.

## 2 Event Simulation

For the simulation minimum bias, single and double diffractive events were produced by Pythia v6.319. The events were stored in a HBOOK truple file which was later converted into an equivalent ROOT file by the h2root program.

The default event sample used in these studies was generated using the same ATLAS parameter settings as used in [2] (MSEL = 0, MSUB(92.95) = 1, MSTP(51) = 7, MSTP(81) = 1, MSTP(82) = 4, PARP(67) = 1, PARP(82) = 1.8, PARP(89) = 1000, PARP(90) = 0.16, PARP(84) = 0.5, PARP(85) = 0.33, PARP(86) = 0.66, MSTP(2) = 1, MSTP(33) = 0) and the charged particle density, shown in figure 1 agrees well with the results from earlier versions presented in [1].

An event sample of 15k events was used for all studies except for the BCM studies in the calibration scenario. Due to the small acceptance of the BCM, a biased event sample was produced where 80k events were generated but only the events with at least one particle in the

Figure 1: The inelastic charged particle density as a function of pseudorapidity from Pythia v6.319 using the standard ATLAS settings.

BCM acceptance was stored in the file. This samples was, however, not used for pile-up studies where an unbiased mix of interactions was desired.

In order to avoid problems of exceeding the memory allocated for the PYJETS common block the multiple interactions in the bunch crossings at high luminosity were not produced using the MSTP(131) = 1 switch, but was created outside Pythia. The bunch crossings with multiple interactions were made by \(n\) inelastic events where \(n\) was given for each bunch crossing by a random number according to a Poisson distribution with mean \(\mu\). Only bunch crossings with at least one interaction were kept and the number of bunch crossings with zero interactions was determined by

\[N_{0}=N_{Inel}\cdot\frac{e^{-\mu}}{(1-e^{-\mu})} \tag{3}\]

where \(N_{Inel}\) is the number of generated bunch crossings containing at least one inelastic interaction1.

Footnote 1: Hence \(N_{0}\) also contain bunch crossing with only elastic \(pp\) collisions.

## 3 Detector Simulation and Monitoring Procedure

The inelastic Pythia events were used by a simple detector simulation program for the various studies. This program use three different C++ classes which represent the detectors, one representing LUCID, one for the BCM and one more general which easily can be adapted to describe a luminosity monitor at any location, size and with variable granularity. All classes contain one A side and one C side module which are identical and implemented independent of each other. For each bunch crossing a loop over all particles is made where each particle is provided to the detector modules in order to determine if it becomes detected or not. When all the particles in the bunch crossing have been treated, the detector module return a signal value for each tube or detector element. All detector classes could be set to either count the particles entering the tube/element or give a signal when a hit occurs. In the case of particle counting the signal value of a certain detector element was increased in discrete steps for each detected particle, i.e. perfect particle counting, and in the case of hit counting the signal value can only be 0 or 1. The two methods therefore give results according to the best or worst case scenario, where either the number of particles is correctly identified every time or always equal to 0 or 1.

For each particle treated by a LUCID module the following selection criteria were used to determine if it was detected:

* The particle is charged;
* At the \(z\)-distance (i.e. along the beam) of the front of the LUCID module the particle has to be within the inner and outer radial boundary of LUCID;
* The particle has a momentum larger than its Cerenkov threshold;
* The particle is inside the circular region of a Cerenkov tube at the front of LUCID.

The selection does not take into account the fact that particles transverse different distances of the tubes since the generated particles are produced at the interaction point (IP) to which the tubes are pointing. The standard module configuration of LUCID with 5 tube layers with 40 tubes per layer and the parameter values in table 1 were used to define the LUCID characteristics.

The BCM class represent 4 detectors per side which each have an 0.8 \(\times\) 0.8 \(mm^{2}\) active detector area. The four detectors were symmetrically distributed in \(\phi\) and the particle selection was made in the same way as for the LUCID class, but only using the first two criteria. The parameters used to describe the BCM modules are shown in table 1.

The general detector class was made more flexible than the other two. The detector modules were defined by a \(z\)-distance, an inner and outer radius together with the \(x\) and \(y\) granularity. This means that a full coverage within the boundaries of the detector is assumed. The particle selection of the general detector class was made in the same way as for the BCM.

The studies were made in two separate scenarios called the _calibration_ and _measurement_ scenario. In the calibration scenario bunch crossings were produced containing only one inelastic collision as expected at the calibration runs which are planned to be made at \(L=10^{27}cm^{-2}s^{-1}\). At this luminosity the probability to have more than one interaction in a colliding BC is in the order of \(\mathcal{O}(10^{-6})\). From the simulations of the calibration scenario, the mean number of particles per detected interaction and module \(\langle C\rangle\) and the inelastic acceptance \(\varepsilon_{pp}\) were estimated. The \(\langle C\rangle\) value was determined in the calibration runs by the mean number of particles from the detected BC. In order to estimate the inelastic acceptance with high accuracy, several possibilities are foreseen. In the standard scenario the luminosity is monitored by single module measurements and the number of particles is proportional to the luminosity as given by equation 2. In this case the acceptance is included in the conversion constant (\(\varepsilon_{pp}\cdot\sigma_{Inel}\)) obtained by calibrating the measured mean number of particles of the luminosity monitor to the Roman Pot luminosity measurement at the calibration runs. It is, however, important to know the acceptance separately as well, e.g. for understanding non-linearity effects when using a coincidence between modules as will be discussed below, and it will therefore be estimated both from Monte Carlo simulations and by measurements using the luminosity monitor and a reference detector with an acceptance that is close to 100%. \(\varepsilon_{pp}\) was determined in the simulation by the fraction of detected BC. The \(\langle C\rangle\) and \(\varepsilon_{pp}\) values were estimated both by single module measurements and when coincidence was required between the A and C side luminosity monitor modules. When coincidence was used, still only one module measure the number of particles per interaction but only if at least one particle had been registered in the opposite module. The inelastic acceptance without using coincidence corresponds to

\[\varepsilon_{pp}=\frac{\varepsilon_{SDA}\cdot N_{SDA}+\varepsilon_{SDC}\cdot N _{SDC}+\varepsilon_{DD}\cdot N_{DD}+\varepsilon_{MB}\cdot N_{MB}}{N_{SDA}+N_{ SDC}+N_{DD}+N_{MB}} \tag{4}\]

\begin{table}
\begin{tabular}{|c|c|c||c|} \hline \multicolumn{4}{|c||}{LUCID} & BCM \\ \hline \hline Tube Nr. & \(r_{center}\) (\(mm\)) & \(r_{tube}\) (\(mm\)) & Misc \\ \hline
1 & 84.65 & 6.65 & \(n\) = 1.00137 \\
2 & 97.0 & 7.6 & \(z\) = 16976.0 \(mm\) \\
3 & 111.15 & 8.7 & \(\Delta\phi\) = 0.07854 \(rad\) \\
4 & 127.35 & 10.0 & \(Gran.\) = 40 \(\times\) 5 tubes \\
5 & 145.9 & 11.45 & \(Gran.\) = 4 \\ \hline \end{tabular} 
\begin{tabular}{|c|c|c||c|} \hline \multicolumn{4}{|c||}{LUCID} & BCM \\ \hline \hline Tube Nr. & \(r_{center}\) (\(mm\)) & \(r_{tube}\) (\(mm\)) & Misc \\ \hline
1 & 84.65 & 6.65 & \(n\) = 1.00137 \\
2 & 97.0 & 7.6 & \(z\) = 16976.0 \(mm\) \\
3 & 111.15 & 8.7 & \(\Delta\phi\) = 0.07854 \(rad\) \\
4 & 127.35 & 10.0 & \(Gran.\) = 40 \(\times\) 5 tubes \\
5 & 145.9 & 11.45 & \(Gran.\) = 4 \\ \hline \end{tabular}
\end{table}
Table 1: LUCID: Parameter values used to describe the LUCID modules. \(r_{center}\) and \(r_{tube}\) represents the distance from the beam to the center of the Cerenkov tube at the front of LUCID and the radius of the tube respectively. \(n\) is the refraction index of the LUCID gas, \(z\) the \(z\)-distance from the IP to the front of LUCID, \(\Delta\phi\) is half the distance in \(\phi\) between two neighboring tubes and \(Gran.\) is the number of tubes per module. BCM: Parameter used to describe the diamond BCM detector. \(R_{in}\) and \(R_{out}\) are the inner and outer radius of the detector. This corresponds to the projection on the plane in the center of the detector and perpendicular to the beam since detectors are situated in an 45\({}^{\circ}\) angle. _Acc._ is the active detector area and \(Gran.\) is the number of detectors per module.

and becomes

\[\varepsilon_{pp}^{Coin}=\frac{\varepsilon_{\mathit{SDA}}^{\mathit{C}}\cdot \varepsilon_{\mathit{SDA}}^{\mathit{C}}\cdot N_{\mathit{SDA}}+\varepsilon_{ \mathit{SDC}}^{\mathit{A}}\cdot\varepsilon_{\mathit{SDC}}^{\mathit{C}}\cdot N_{ \mathit{SDC}}+\varepsilon_{\mathit{DD}}^{\mathit{A}}\cdot\varepsilon_{\mathit{DD }}^{\mathit{C}}\cdot N_{\mathit{DD}}+\varepsilon_{\mathit{MB}}^{\mathit{A}} \cdot\varepsilon_{\mathit{MB}}^{\mathit{C}}\cdot N_{\mathit{MB}}}{N_{\mathit{ SDA}}+N_{\mathit{SDC}}+N_{\mathit{DD}}+N_{\mathit{MB}}} \tag{5}\]

when requiring coincidence, if there is no correlation between the outcome of module A and C for the individual interactions. Here \(\varepsilon_{i}^{\mathit{A}}\) and \(\varepsilon_{i}^{\mathit{C}}\) are the acceptances of module A and C for collisions of type \(i\) and \(N_{i}\) corresponds to the number of collisions of type \(i\) in the sample. The processes are divided into, single diffractive (\(SDA/SDC\)) with the diffractive proton moving toward the A and C module respectively, double diffractive (\(DD\)) and minimum bias (\(MB\)) processes in the same way as the Pythia processes 92 to 95.

For the measurement scenario, the number of interactions \(n\) in a bunch crossing is determined from a random number according to a Poisson distribution with mean \(\mu=\sigma_{Inel}\cdot L_{B}\). The inelastic cross section was computed by Pythia and the bunch luminosity is given as input to the program. Only bunch crossings with at least one interaction were generated and the number of BC with zero interactions was determined from equation 3. In this scenario the mean number of particles per BC and module \(\langle M\rangle\) is determined and the number of so called zero BC was counted, which will be discussed in section 5.2.

## 4 The Calibration Scenario

The first study of the calibration scenario was made for LUCID where some of the single module results were already known and could be used to verify the simulation results. The left plot of figure 2 shows the distribution of particles in LUCID from 15k inelastic events with a 5 layer tube structure of LUCID with 40 tubes per layer.

The distribution is quite uniform both in \(\phi\) and between the different layers. The probability to detect an inelastic interaction was estimated to be \(69.9\%\pm 0.4\) for the standard LUCID module A and \(69.4\%\pm 0.4\) for module C and the mean number of particles per detected interaction \(\langle C\rangle=3.25\pm 0.03\) and \(\langle C\rangle=3.26\pm 0.03\) was obtained from module A and C respectively. These results from the calibration scenario translates into a mean number of particles per inelastic interaction and module of \(3.25\times 0.696=2.26\) which in turn corresponds to a mean number of particles per any interaction and module of \(2.26\times 79.2/101.4=1.77\). Here 79.2 and 101.4 are the inelastic and total cross sections in _mb_ respectively and the number of particles per interaction is consistent with the number 1.7 reported in [2]. The results were also reproduced after displacing the detector module in the positive and negative transverse directions and the results were consistent with the those presented in [6]. The change of acceptance with different layer configurations of LUCID was also studied and table 2 shows the obtained acceptance when different numbers of layers were removed. In the table layer 1 refers to the most inner layer (i.e. closest to the beampipe) and layer 5 to the outer layer and one can see that the removal of a layer on the inside or the outside have about the same effect. This is in agreement with what could be expected since the particles from an inelastic collision is uniformly distributed between the LUCID layers.

The \(\langle C\rangle\) value and the acceptance was also determined when requiring a coincidence between the A and C side modules and the values \(\langle C\rangle^{Coin}=3.61\) and \(\varepsilon_{pp}^{Coin}=0.539\) were obtained. The increase of the mean number of particles per detected interaction arise since the selection constraint implied by a coincidence increase the fraction of minimum bias interactions of the selected BC sample. Roughly speaking (details can be found in appendix B) the fraction of minimum bias interactions, which have an approximate \(\langle C\rangle\) value of 3.7 compared to about 1.7 for the diffractive interactions, increase from about 84% to 94%. In the calibration scenario where not more than one interaction occurrs per BC the number of accepted BC drops significantly when the requirement of having particles registered in both modules is imposed. It should, however, be pointed out that the \(\varepsilon_{pp}^{Coin}\) acceptance is not equal to the single module acceptance squared, \(\varepsilon_{pp}^{2}\), when several processes with different acceptances contribute, which can also be seen from equation 4 and 5. The relation between the calibration values obtained with and without the coincidence requirement is therefore depending on the physics model and in order to obtain the values in both scenarios the values must either both be determined at calibration or the relation from one to the other rely on Monte Carlo simulations.

In addition the general detector class was used to simulate LUCID (where the Cerenkov constraint was added to the selection criteria) using the LUCID granularity and the inner and outer radius. This is equivalent to the LUCID class with the difference that there is full coverage of the LUCID front plane, i.e. no holes between the tubes. The full coverage increased the single module acceptance to 73% and 72% for side A and C and the coincidence acceptance was increased to 57%. The full coverage also increased the mean number of particles detected by LUCID with 13.5% which agrees with the fact that particles are to a good approximation uniformly distributed in LUCID together with that the holes would give a 14% increase of the area if they were covered.

The \(\langle C\rangle\) and \(\varepsilon_{pp}\) values were also estimated for the BCM and the MBTS. The BCM class described in section 3 was used and the general detector class was used for the MBTS. For the MBTS an inner radius of 158 \(mm\) and an outer radius of 1000 \(mm\) was used and the \(z\)-distance was set to 3490 \(mm\).

Due to the small acceptance of the BCM the biased sample of inelastic collisions was used.

Figure 2: LEFT: The particle distribution in LUCID from inelastic events. The figure shows all detected particles in module A from 15000 inelastic events. RIGHT: The number of particles per bunch crossing and module detected by LUCID as a function of the mean number of inelastic collisions per bunch crossing.

[MISSING_PAGE_FAIL:8]

the single module results obtained in the calibration scenario (\(\langle C\rangle=3.25\), \(\varepsilon_{pp}=0.696\)). Using single module measurements, the effect on the linearity was investigated when several particles entering a single tube could not be distinguished. In this case the signal value of a certain tube was only zero or one independent of the number of particles that enters and the results are shown in the left plot of figure 3. Figure 3 shows the measured \(\mu\) value (\(\langle M\rangle/(\langle C\rangle\cdot\varepsilon_{pp})\)) as a function of the input \(\mu\) value (\(\sigma_{Inel}\cdot L_{B}\)) and the line corresponds to perfect linearity. The dots following the line are the MC results with the assumption of perfect particle counting and the dots below the line corresponds to the results from only counting hits. It can be seen how the measured mean number of particles per BC, \(\langle M\rangle\), saturates with increasing luminosity when only hits are counted and this saturation effect is 13% \(\pm\) 1 at \(\mu=25\) (\(L=10^{34}\)). The LUCID detector is designed with the ability to count particles and should therefore not suffer from this effect, so this quantifies a worst case scenario.

The same kind of study was made within the BCM simulation. The right plot in figure 3 shows the mean number of particles per BC and module as a function of \(\mu\). The line represent the linear extrapolation from the values obtained at calibration (\(\langle C\rangle=1.04\), \(\varepsilon_{pp}=0.031\)) and the dots corresponds to the MC results where the four BCM detectors in a single module have only the ability to count hits. The plots shows a smaller saturation effect than for LUCID due to the lower occupancy and the difference at \(\mu=25\) is 8.5% \(\pm\) 2.9. Due to the low acceptance of the BCM the plot shows the average result of module A and C in order to lower the statistical error. The mean number of particles per BC and module is 0.033 \(\pm\) 0.001 at \(\mu=1\) (\(L=4\times 10^{32}\)) and 0.77 \(\pm\) 0.02 at \(\mu=25\) (\(L=10^{34}\)).

One of the main tasks of this study was to investigate the effect from using coincidence between the two detector modules, i.e. counting the particles in one mo

Figure 3: Saturation of the \(\mu\) measurement when counting hits only for LUCID and the BCM. The lines corresponds to perfect particle counting and the squares below to hit counting.

at least one particle is registered also in the other module. The coincidence requirement is very effective to suppress background which is not produced at the interaction point and since the machine background from the LHC is not well known this source might give rise to sever background contamination, particularly in the calibration runs where the collision rate is low. For this reason one might only be able to make accurate measurements during calibration using coincidence and one needs to understand the related effects.

The mean number of particles detected by module A per BC, when coincidence between the LUCID A and C modules is required, is shown as a function of \(\mu\) in the left plot of figure 4. The line corresponds to the linear extrapolation from the calibration values obtained using coincidence (\(\langle C\rangle^{Coin}=3.61\), \(\varepsilon_{pp}^{Coin}=0.539\)) and the dots shows the MC results. The plots shows how the MC results deviates from the line and give rise to a difference of 16% \(\pm\) 1 at \(\mu=25\).

As seen in the calibration studies, the \(\langle C\rangle\) and \(\varepsilon_{pp}\) values differs for interactions with or without a coincidence requirement. The relation between the values from the two kinds of interactions is non-trivial and rely on the physics model which implies that both have to be determined at calibration or partly determined by MC. Since the fractions in a BC of the two kinds of interactions changes with \(\mu\) when coincidence is required they have to be taken into account separately in order to describe the evolution of the mean number of particles per BC correctly. For a luminosity monitor consisting of an A and C module the expected mean number of particles per BC measured in module A requiring coincidence becomes (details are found in appendix A)

\[\langle M\rangle^{Coin}=\langle C_{3}\rangle\varepsilon_{3}\mu+\langle C_{1} \rangle\varepsilon_{1}\mu\left(1-e^{-(\varepsilon_{2}+\varepsilon_{3})\mu}\right) \tag{6}\]

Here \(\langle C_{1}\rangle\) corresponds to the mean number of particles per interaction detected in module A

Figure 4: The measured number of particles per BC in module A for LUCID and the BCM when coincidence between module A and C is required both during calibration and measurement.

but not in C and \(\langle C_{3}\rangle\) to the mean number of particles per interaction detected in both modules. \(\varepsilon_{1}\), \(\varepsilon_{2}\) and \(\varepsilon_{3}\) corresponds to the probability for an interaction to be detected in module A but not in C, in C but not in A or in both A and C. Hence the interactions which are registered in one or both modules are taken in to account separately and the needed parameters are given from the calibration data by

\[\begin{array}{l}\varepsilon_{1}=\varepsilon_{pp}^{A}-\varepsilon_{pp}^{Coin }\\ \varepsilon_{2}=\varepsilon_{pp}^{Coin}\\ \varepsilon_{3}=\varepsilon_{pp}^{Coin}\\ \langle C_{1}\rangle=\frac{\langle C\rangle^{A}\varepsilon_{pp}^{A}-\langle C \rangle^{Coin}\varepsilon_{pp}^{Coin}}{\varepsilon_{1}}\\ \langle C_{3}\rangle=\langle C\rangle^{Coin}\end{array} \tag{7}\]

It should also be pointed out that since the acceptance enters in the exponential of equation 6, a large acceptance luminosity monitor decrease the non-linear effect significantly compared to a luminosity monitor with small acceptance, as will be seen later for the BCM.

Figure 5 shows the MC results from the LUCID simulation shown in figure 4 divided by the linear extrapolation from calibration using coincidence (also shown in figure 4), which is represented by the dots, together with the results obtained by equation 6. The plot shows how the mean number of particles is consistent with linearity, using the calibration values obtained with coincidence, for small \(\mu\) values but becomes non-linear as it approaches \(\mu\sim 0.1\). At medium \(\mu\) one can see a non-linear behavior which saturates at large \(\mu\) values. Above \(\mu\sim 4\) the \(\mu\) dependence becomes linear again, however, with a different slope. This can be understood by

Figure 5: The ratio \(\langle M\rangle/(\langle C_{3}\rangle\varepsilon_{3}\mu)\) from MC when coincidence was required. The MC results are also compared to the expected results from equation 6.

studying equation 6 which have the two following limits

\[\begin{array}{ll}\langle M\rangle^{Coin}=\langle C_{3}\rangle\varepsilon_{3}\mu& \qquad(\mu\ll 1)\\ \langle M\rangle^{Coin}=\langle(C_{3})\varepsilon_{3}+\langle C_{1}\rangle \varepsilon_{1}\rangle\mu&\qquad(\mu\gg 1)\end{array} \tag{8}\]

In the case of small \(\mu\) the formula is of course equivalent to the linear function obtained from the calibration values when coincidence is required since the detected BC are dominated by single interactions. For large \(\mu\) the formula becomes linear again with a different slope which is equivalent to the linear formula using calibration values obtained without coincidence, \((\langle C_{3}\rangle\varepsilon_{3}+\langle C_{1}\rangle\varepsilon_{1})= \langle C\rangle^{A}\varepsilon_{pp}^{A}\). This means that when \(\mu\) is large enough to give coincidence hits in every BC, the coincidence criteria have no effect and the mean number of particles detected per interaction is the same as when not requiring coincidence. It is worth stressing that to describe the evolution with \(\mu\) correctly when using coincidence, requires knowing both the single module acceptance and the acceptance when using coincidence. The former can be problematic to estimate accurately due to the machine background.

The effect from different physics model assumptions on the 16% difference between the linear evolution, \(\langle M\rangle^{Coin}=\langle C_{3}\rangle\varepsilon_{3}\mu\), and the MC were studied by varying the SDA, SDC, DD and MB cross sections. Six different variations were made where one or several cross sections were changed and the others were set to the default values calculated by Pythia. The different sets of cross sections (Tot, SDA, SDC, DD, MB) together with the corresponding difference from the linear extrapolation are shown in table 4. Here the two first tests corresponds to an increase and decrease of the diffractive cross section by 12 \(mb\) in total from the default set (101.4, 7.15, 7.15, 10.2, 54.7). The third and forth test corresponds to a change of the single diffractive cross section by 10 \(mb\) and for the last two the minimum bias cross section was changed by 20 \(mb\). It is shown from the table that this difference is relatively stable with different cross sections and the statistical error on all the test results are less than 2%.

A similar study was made for the BCM and the results are shown in the right plot of figure 4. The plot present the mean number of particles per BC and module as a function of \(\mu\). The straight line represents the linear extrapolation from the values obtained at calibration using coincidence (\(\langle C\rangle^{Coin}=1.08\), \(\varepsilon_{pp}^{Coin}=0.0019\)), the dots corresponds the MC results and the solid and dashed lines following the dots corresponds to two versions of equation 6. The solid line corresponds to the formula alone and the dashed line corresponds to when the saturation effect due to hit counting, which was used in the BCM simulation, was taken into account. The saturation effect is the same when using coincidence as the one shown in figure 3 when not using

\begin{table}
\begin{tabular}{|c|c|} \hline (Tot, SDA, SDC, DD, MB) (\(mb\)) & \(\Delta\langle M\rangle/\langle C_{3}\rangle\varepsilon_{3}\mu\) \\ \hline (Default) & 16\% \(\pm\) 1 \\ ( 89.4, 3.65, 3.65, 5.2, 54.7) & 15\% \\ (113.4, 10.65, 10.65, 15.2, 54.7) & 17\% \\ ( 91.4, 2.15, 2.15, 10.2, 54.7) & 16\% \\ (111.4, 12.15, 12.15, 10.2, 54.7) & 20\% \\ ( 81.4, 7.15, 7.15, 10.2, 34.7) & 18\% \\ (121.4, 7.15, 7.15, 10.2, 74.7) & 17\% \\ \hline \end{tabular}
\end{table}
Table 4: The cross section sets (Tot, SDA, SDC, DD, MB) in \(mb\) and the corresponding difference between MC and the linear extrapolation obtained at calibration using coincidence BC.

coincidence. One can clearly see the overall stronger non-linearity due to the smaller BCM acceptance and how equation 6 follows the MC results well. However, the lack of statistics did not allow a more detailed study as for the LUCID simulation.

### The Zero Counting Method

In the measurement scenario the number of not detected BC was also counted, so called zero BC. For the single module measurement this corresponds to the number of bunch crossings with no particles registered in the luminosity monitor module. When requiring coincidence, BC where no particles are registered in any module or only one module are counted. The number of zero BC is related to the luminosity and have the advantage of not being sensitive to an imperfect ability to count particles. However, the zero counting method have the disadvantage that for high luminosities the zero BC rate can be very low if the luminosity monitor have a large acceptance. The number of expected zero BC (when not requiring coincidence) corresponds to

\[N_{zero}=N_{BC}e^{-\varepsilon_{0}p\mu} \tag{9}\]

and

\[N_{zero}=N_{BC}e^{-(1-\varepsilon_{0})\mu}\,(2e^{\varepsilon_{1}\mu}-1) \tag{10}\]

when coincidence is required (details are found in appendix A). Here \(N_{BC}\) corresponds to the total number of BC and \(\varepsilon_{0}\) and \(\varepsilon_{1}\) are the probabilities of either not detecting any particles in any module or just in one module but not in the other. The left plot of figure 6 shows the fraction \(N_{zero}/N_{BC}\) obtained from the LUCID simulation as a function of \(\mu\) both with and without requiring coincidence. The squares corresponds to the MC results without coincidence and the stars to the results where coincidence is required. The corresponding lines represents equations 9 and 10 and due to the statistical limitation of the MC the comparison could only be made for small \(\mu\) values.

For LUCID equation 10, with \(\varepsilon_{0}=1-\varepsilon_{1}-\varepsilon_{2}-\varepsilon_{3}\), gives a zero BC rate at \(\mu=25\) of \(N_{zero}/N_{BC}=2.8\times 10^{-8}\) and \(N_{zero}/N_{BC}=5.5\times 10^{-8}\) without and with the use of coincidence. With a 31.6 \(MHz\) average bunch frequency the recording time needed to get about 1% statistical error on the luminosity measurement is approximately 2h 30min and 4h 50min respectively. These periods can, however, be decreased to 15min and 30min if a 3% statistical error is sufficient. The recording time can also be decreased by only using a sub-set of the tubes in LUCID.

Figure 6 shows the same kind of results obtained from the BCM simulation and it shows how the small BCM acceptance implies a high zero BC rate both when using and not using coincidence.

## 6 Conclusions

A fast simulation of monitoring the luminosity in ATLAS has been made. This was done mainly for the luminosity monitor LUCID but also the BCM and MBTS were studied. It was shown that the removal of one LUCID layer have a relatively small effect on the inelastic acceptance and that the difference between removing the inner or outer layer is marginal. A significant difference between interactions which were detected in only one or in both modules of LUCID was observed in the simulated calibration runs. For the simulations of the measurement runs at an arbitrary luminosity the saturation effect from an imperfect particles counting was estimated in the worst case to be about 13% and 8% for LUCID and the BCM respectively and an estimation of the BCM particle rate was presented. The use of BC which are registered in both luminosity monitor modules have been investigated in detail where the non-linear behavior have been simulated and explained by Poisson statistics. It was shown that the calibration information both for interactions registered in one and both modules are needed in order to describe the evolution of the particle rate and that a large luminosity monitor acceptance minimizes the non-linearity effect implied by requiring coincidence. For LUCID, the non-linear behavior implied an effect of about 16% on the measurement. This value was shown to not depend strongly on different physics model assumptions. The main remaining question related to the use of a coincidence requirement is the accuracy to which the \(\langle C_{1}\rangle\) and \(\varepsilon_{1}\) values in equation 6 can be estimated. By using MC simulations and the calibration data, \(\langle C_{1}\rangle\) and \(\varepsilon_{1}\) can be estimated in several ways and corrections of the non-linear effect can be made. The achievable uncertainty on \(\langle C_{1}\rangle\) and \(\varepsilon_{1}\) will have to be investigated by a separate study. The results in this note should be considered as a complement to the simulations using the full ATLAS software and the program used in this study can be used for cross checks.

Figure 6: The ratio \(N_{zero}/N_{BC}\) from MC for LUCID and the BCM. The squares corresponds to results obtained without requiring coincidence and the stars to when coincidence was required. The MC results are compared with the expected results from equation 9 and 10.

Coincidence Effects

Selecting BC with coincidence between the A and C modules for the luminosity monitoring is an effective way to reduce background which is not coming from the IP. This, however, introduce potentially large non-linear effects on the measurement with increasing luminosity which have to be understood. This appendix present the calculation of the formulas used to give the expected experimental outcome of the luminosity monitor when selecting BC by requiring coincidence between module A and C.

### Particle Counting

The mean number of measured particles per BC and module is given by

\[\langle M\rangle=\ \langle C\rangle\cdot\varepsilon_{pp}\cdot\mu \tag{11}\]

when no coincidence is required. Here \(\langle C\rangle\) represent the mean number of particles per detected interaction, \(\varepsilon_{pp}\) the single module acceptance and \(\mu\) the mean number of interactions per BC. As seen when only single interactions per BC were studied the relation between the \(\langle C\rangle\) and \(\varepsilon_{pp}\) values from interactions registered in just one module or in both is non-trivial and depends on the physics model. The transition from BC where in principle only one interaction occurs to BC with multiple interactions changes the amount of impact from the different \(\langle C\rangle\) and \(\varepsilon_{pp}\) values and for this reason the calibration results from using both single modules and coincidence have to be taken into account separately in order to describe the expected particle rate correctly at a given luminosity when coincidence is required.

If only BC with coincidence between the two modules are selected, the mean number of particles measured in module A will be give by two different contributions:

* The BC contains at least one interaction which is registered in both modules together with any number of interactions that are only registered in module A;
* The BC contain no interaction that is registered in both modules but at least one that is only registered in module A and one that is only registered in module C.

The mean number of particles measured in A for a BC _with \(n\) interactions_ is given by the sum of the probability for each configuration that satisfy condition \(I\) and \(II\) times the corresponding numbers of detected interactions and their mean values of the particles per detected interaction. The two contributions then equals

\[I=\sum_{k=1}^{n}\varepsilon_{3}^{k}\left(\begin{array}{c}n\\ k\end{array}\right)\left[\sum_{l=0}^{n-k}\varepsilon_{1}^{l}(1-\varepsilon_{1}- \varepsilon_{3})^{n-k-l}\left(\begin{array}{c}n-k\\ l\end{array}\right)\right](k\langle C_{3}\rangle+l\langle C_{1}\rangle) \tag{12}\]

\[II=\sum_{k=1}^{n}\varepsilon_{1}^{k}\left(\begin{array}{c}n\\ k\end{array}\right)\left[\sum_{l=1}^{n-k}\varepsilon_{2}^{l}(1-\varepsilon_{1}- \varepsilon_{2}-\varepsilon_{3})^{n-k-l}\left(\begin{array}{c}n-k\\ l\end{array}\right)\right](k\langle C_{1}\rangle) \tag{13}\]

where \(\varepsilon_{1}\) and \(\varepsilon_{2}\) corresponds to the probability of detecting an interaction in module A or C respectively without registering anything in the opposite one and \(\varepsilon_{3}\) corresponds to the probability to detect an interaction in both modules. \(\langle C_{1}\rangle\) and \(\langle C_{3}\rangle\) corresponds to the mean number of particles detected in module A per interaction either registered by only module A or in both modules. The \(k\)-sum in contribution \(I\) runs over the number of coincidence interactions in the BC and the \(l\)-sum over all the possible configurations of the remaining \(n-k\) interactions. The probability of each configuration is then multiplied by its mean number of particles detected in module A, \(k\langle C_{3}\rangle+l\langle C_{1}\rangle\), where \(k\) and \(l\) take the \(\langle C_{i}\rangle\) values for the two different types of interactions into account correctly for each possible BC configuration. In the expression for contribution \(II\) the \(k\) and \(l\)-sums runs over the number of interactions that are detected in module A or C respectively but not in the opposite one. Here it is required that at least one interaction of each type (type 1 and 2) occurs in order to give rise to coincidence, however, only the particles registered in module A are counted.

The expressions for contribution \(I\) and \(II\) were evaluated by first calculating the \(l\)-sums

\[\begin{array}{l}i=\sum_{l=0}^{n-k}\varepsilon_{1}^{l}(1-\varepsilon_{1}- \varepsilon_{3})^{n-k-l}\left(\begin{array}{c}n-k\\ l\end{array}\right)=(1-\varepsilon_{3})^{n-k}\\ ii=\sum_{l=0}^{n-k}\varepsilon_{1}^{l}(1-\varepsilon_{1}-\varepsilon_{3})^{n-k -l}\left(\begin{array}{c}n-k\\ l\end{array}\right)=(n-k)\varepsilon_{1}(1-\varepsilon_{3})^{n-k-1}\\ iii=\sum_{l=1}^{n-k}\varepsilon_{2}^{l}(1-\varepsilon_{1}-\varepsilon_{2}- \varepsilon_{3})^{n-k-l}\left(\begin{array}{c}n-k\\ l\end{array}\right)=(\varepsilon_{0}+\varepsilon_{2})^{n-k}-\varepsilon_{0}^{ n-k}\end{array} \tag{14}\]

where \(\varepsilon_{0}=1-\varepsilon_{1}-\varepsilon_{2}-\varepsilon_{3}\).

These solutions where then used to evaluate the \(k\)-sums which when summed up give the mean number of particles detected per BC, _with n interactions_, in module A when coincidence is required.

\[\begin{array}{l}j=\sum_{k=1}^{n}k\langle C_{3}\rangle\varepsilon_{3}(1- \varepsilon_{3})^{n-k}\left(\begin{array}{c}n\\ k\end{array}\right)=\langle C_{3}\rangle\varepsilon_{3}n\\ jj=\sum_{k=1}^{n}n\langle C_{1}\rangle\varepsilon_{1}\varepsilon_{3}^{k}(1- \varepsilon_{3})^{n-k-1}\left(\begin{array}{c}n\\ k\end{array}\right)=\langle C_{1}\rangle\varepsilon_{1}n\left[\left(1+ \frac{\varepsilon_{3}}{1-\varepsilon_{3}}\right)-(1-\varepsilon_{3})^{n-1} \right]\\ jj=-\sum_{k=1}^{n}k\langle C_{1}\rangle\varepsilon_{1}\varepsilon_{3}^{k}(1- \varepsilon_{3})^{n-k-1}\left(\begin{array}{c}n\\ k\end{array}\right)=-\varepsilon_{1}\langle C_{1}\rangle n\varepsilon_{3}\left( 1+\frac{\varepsilon_{3}}{1-\varepsilon_{3}}\right)\\ jjj=\sum_{k=1}^{n}k\langle C_{1}\rangle\varepsilon_{1}^{k}(\varepsilon_{0}+ \varepsilon_{2})^{n-k}\left(\begin{array}{c}n\\ k\end{array}\right)=\langle C_{1}\rangle\varepsilon_{1}\,n(\varepsilon_{0}+ \varepsilon_{1}+\varepsilon_{2})^{n-1}\\ jjjjj=-\sum_{k=1}^{n}k\langle C_{1}\rangle\varepsilon_{1}^{k}\varepsilon_{0}^{ n-k}\left(\begin{array}{c}n\\ k\end{array}\right)=-\langle C_{1}\rangle\varepsilon_{1}n(\varepsilon_{0}+ \varepsilon_{1})^{n-1}\end{array} \tag{15}\]

In order to get an expression for the expected mean number of particles detected in module A at any given luminosity the above results were multiplied with a Poisson distribution with the mean \(\mu\) and summed over all \(n\).

\[\begin{array}{l}\langle M\rangle=\sum_{n=0}^{\infty}(j+jj+jjjj+jjjjjj)\frac{ e^{-\mu}\mu^{n}}{n!}\\ =\langle C_{3}\rangle\varepsilon_{3}\mu+\langle C_{1}\rangle\varepsilon_{1}\mu \left(1-e^{-(\varepsilon_{2}+\varepsilon_{3})\mu}\right)\end{array} \tag{16}\]

It can be noted that under the assumptions

\[\langle C\rangle=\langle C_{1}\rangle=\langle C_{3}\rangle \tag{17}\] \[\varepsilon_{pp}=\varepsilon_{1}+\varepsilon_{3}=\varepsilon_{2}+ \varepsilon_{3}\] (18) \[\varepsilon_{pp}^{2}=\varepsilon_{3} \tag{19}\]

which would be likely if all the interactions in the sample were of the same kind, the \(\langle M\rangle\) expression becomes

\[\langle M\rangle=\ \langle C\rangle\varepsilon_{pp}\ \mu\left(1-(1-\varepsilon_{pp})e^{- \varepsilon_{pp}\mu}\right) \tag{20}\]

This formula has been used before when discussing the non-linearity introduced by requiring coincidence, however the more general formula is of course preferred since the assumptions above are normally not full filled.

### Zero Counting

If only BC with a coincidence between module A and C are counted, \(\mu\) can be measured from the number of _zero BC_ where nothing is registered in one or both modules. The probability of getting a zero BC consists of four contributions:

1. The probability of not having any interactions in the BC, \(n=0\);
2. The probability of having \(n\) interactions with at least one interaction which is only registered in module A together with any number of interactions that are not registered in any module;
3. The probability of having \(n\) interactions with at least one interaction which is only registered in module C together with any number of interactions that are not registered in any module;
4. The probability of having \(n\) interactions where no interaction is registered in any module.

Since \(n\) is given by a Poisson distribution the first contribution \(I\) simply becomes

\[I=e^{-\mu} \tag{21}\]

If the probability of detecting an interaction in one module but not the other (\(\varepsilon_{1}\)) and the probability of not detecting an interaction in any module (\(\varepsilon_{0}\)) are known the equal contributions \(II\) and \(III\) can be expressed as

\[II=III=\sum_{n=1}^{\infty}\frac{e^{-\mu}\mu^{n}}{n!}\left[\sum_{k=1}^{n}\left( \begin{array}{c}n\\ k\end{array}\right)\varepsilon_{1}^{k}\varepsilon_{0}^{n-k}\right]=e^{-(1- \varepsilon_{0}-\varepsilon_{1})\mu}-e^{-(1-\varepsilon_{0})\mu} \tag{22}\]

Here the probability of having \(n\) interactions is multiplied by the the probability that these interactions appear in the allowed configurations according to \(II\) and \(III\), where the binomial factors take into account the number of permutations of each configuration. The final contribution \(IV\) is the probability of having \(n\) interactions where each escapes detection both in module A and C

\[IV=\sum_{n=1}^{\infty}\frac{e^{-\mu}\mu^{n}}{n!}\varepsilon_{0}^{n}=e^{-\mu} \left(e^{\varepsilon_{0}\mu}-1\right) \tag{23}\]

The probability of measuring a zero BC when using coincidence then becomes

\[P^{Exp}(0;\mu) =I+2\cdot II+IV=e^{-(1-\varepsilon_{0})\mu}\left(2e^{\varepsilon_{ 1}\mu}-1\right) \tag{24}\]

which decrease rapidly with increasing \(\mu\) for an luminosity monitor with large acceptance.

## Appendix B The Individual Processes

In order to better understand the difference between the acceptance value obtained by using coincidence and the square of the single module acceptance (\(\varepsilon_{pp}^{2}\neq\varepsilon_{pp}^{Coin}\)) the calibration scenario was studied using samples containing events from only one single process at the time. This made it possible to determine if the difference arise purely from the fact that the measurement is made with an event sample consisting of several processes which have different acceptances, shown by the equations 4 and 5 or if it also is due to some more intrinsic property of the interactions, e.g. if momentum conservation would increase the probability to detect something in one module if something is registered in the other. These results do not have any direct implications on theresults presented in this note, but are interesting in order to understand the physics behind the effects from using coincidence or not.

Table 5 show the \(\langle C\rangle\) and \(\varepsilon_{pp}\) values for LUCID and the BCM obtained using the individual sub-processes separately. From the table it can be seen how the product \(\varepsilon_{pp}^{A}\times\varepsilon_{pp}^{C}\) is consistent with \(\varepsilon_{pp}^{Coin}\) for the individual processes within the LUCID study. This is, however, not the case for the BCM results where both the single diffractive and minimum bias processes give statistically inconsistent results between the product \(\varepsilon_{pp}^{A}\times\varepsilon_{pp}^{C}\) and \(\varepsilon_{pp}^{Coin}\). This indicates that for LUCID the difference is only due to that several processes with different acceptances are in the sample where as for the BCM the difference is caused also by additional correlation effects.

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline \multicolumn{2}{|c|}{LUCID} & \multicolumn{2}{|c|}{A} & \multicolumn{2}{|c|}{C} & \multicolumn{2}{|c|}{A\&C} & \multicolumn{2}{|c|}{} \\ \hline Process & \(\sigma\)\((mb)\) & \(\langle C\rangle\) & \(\varepsilon_{pp}\) & \(\langle C\rangle\) & \(\varepsilon_{pp}\) & \(\langle C\rangle\) & \(\varepsilon_{pp}\) & \(N_{evt}\) \\ \hline \hline SDA & 7.15 & 1.71 & 0.49 & 1.57 & 0.12 & 1.74 & 0.077 & 5k \\ SDC & 7.15 & 1.63 & 0.13 & 1.71 & 0.49 & 1.69 & 0.080 & 5k \\ DD & 10.2 & 1.66 & 0.41 & 1.65 & 0.41 & 1.66 & 0.15 & 5k \\ MB & 54.7 & 3.59 & 0.85 & 3.68 & 0.84 & 3.78 & 0.73 & 5k \\ \hline \multicolumn{2}{|c|}{BCM} & \multicolumn{2}{|c|}{} & \multicolumn{2}{|c|}{} & \multicolumn{2}{|c|}{} & \multicolumn{2}{|c|}{} & \multicolumn{2}{|c|}{} \\ \hline SDA & & 1.006 & 0.0076 & 1.005 & 0.0034 & 1 & 0.0000 48 & 800k \\ SDC & & 1.003 & 0.0036 & 1.004 & 0.0073 & 1 & 0.0000 41 & 800k \\ DD & & 1.006 & 0.0063 & 1.005 & 0.0061 & 1 & 0.0000 41 & 800k \\ MB & & 1.035 & 0.0454 & 1.025 & 0.0459 & 1.09 & 0.0033 & 40k \\ \hline \end{tabular}
\end{table}
Table 5: The \(\langle C\rangle\) and \(\varepsilon_{pp}\) values from MC for LUCID and the BCM obtained by using the individual sub-processes separately.

## References

* [1]_ATLAS Detector and Physics Performance TDR_, CERN-LHCC/99-14, ATLAS TDR 14, Volume I, Chapter 13; _ATLAS Detector and Physics Performance TDR_, CERN-LHCC/99-15, ATLAS TDR 15, Volume II, Chapter 15.
* [2]_ATLAS Forward Detectors for Luminosity Measurement and Monitoring_, CERN-LHCC/04-10, LHCC I-014.
* [3] A. Gorisek, _Recent tests and integration plan for Beam Conditions Monitor (BCM)_, ATLAS Inner Detector Week, June 2005, CERN, Switzerland; A. Gorisek & M. Mikuz private communication.
* [4] M. Nessi, _Status of minimum-bias scintillator_, Talk ATLAS Overview Week, October 2004, Freiburg, Germany; V. Hedberg private communication.
* [5] T. Sjostrand _et al._, Comp. Phys. Comm. **135** (2001) 238; T. Sjostrand _et al._, _Pythia 6.3_, LU TP 03-38 (hep-ph/0308153).
* [6] P. Grafstrom, _LUCID Progress Report_, TMB meeting, July 2004, CERN, Switzerland.