# Strategy to Search for Single-Top Events using early Data of the ATLAS Detector at the LHC

The ATLAS Collaboration

###### Abstract

At the LHC, single top-quark events will be produced at a third of the rate of top-quark pairs. Single top-quark production proceeds through three different mechanisms, resulting in distinct final states, topologies and backgrounds. In this document we present a strategy to search for the dominant \(t\)-channel process. The analysis was developed based on simulated events that represent collision data corresponding to an integrated luminosity of a few hundred pb\({}^{-1}\) at a center-of-mass energy of 10 TeV. The analysis focuses on data-driven techniques to normalize the rates of the main backgrounds and calibrate predictions obtained from samples of simulated events. The selection of single top-quark events is optimized by the use of a likelihood method. The results show that already in the early phase of the LHC the sensitivity to the single top-quark \(t\)-channel process will be limited by systematic uncertainties, highlighting the importance of the control of the background-related uncertainties and the \(b\)-quark jet identification.

The ATLAS Collaboration

Introduction

The first observation of single top quarks has been reported recently by both the CDF [1] and D0 [2] experiments. This measurement is important since it serves as a direct probe of the \(W-t-b\) interaction and allows the direct determination of the quark mixing matrix element \(\mathrm{V_{tb}}\)[3, 4]. The present observation by the two experiments is consistent with the Standard Model expectation for the presence of two single-top production mechanisms, the \(t\)- and the \(s\)-channels, measured as a whole. However, because the single-top production signal is affected by large background processes, future measurements will still be statistically limited, and a separate observation of both \(t\)-channel and \(s\)-channel production at the \(5\sigma\) level appears difficult at the Tevatron.

At the LHC, the single top-quark production represents a third of the overall top quark production and precision measurements of the three single-top mechanisms should be achievable. This is of particular importance since single-top production is sensitive to physics beyond the Standard Model, such as extra heavy \(W^{\prime}\) bosons from GUT or extra-dimension theories, charged Higgs bosons \(H^{\pm}\) in 2HDM models, and flavor-changing neutral currents.

This document reports the results of an analysis devoted to the search for single top-quark events in the \(t\)-channel, which is the dominant source of single top-quarks at the LHC. The strategy presented in this paper emphasizes the development of techniques to normalize and constrain the main backgrounds using the data. This is the case for the dominant \(W+\)jets and top pair backgrounds, whose contributions can be fitted from background-enriched samples and propagated to the sample selected for the single-top search. The analysis has been developed in the framework of an early run with an integrated luminosity of 200 pb\({}^{-1}\) at a centre-of-mass energy of 10 TeV, which was the planned scenario when these studies started. Now the LHC is scheduled to run at a center-of-mass energy of 7 TeV in the years 2010 and 2011. The developed techniques remain applicable in the altered run scenario of the LHC and constitute an important extension of previous ATLAS studies [5] that were performed at a centre-of-mass energy of 14 TeV.

This note is organized as follows: the single top-quark phenomenology is introduced in Section 2. Section 3 describes the event preselection. Section 4 describes a neural network method used to normalize the cross section of the main backgrounds to the observed data. An estimate of the sensitivity to the single-top \(t\)-channel process using two approaches (sequential cuts and likelihood selections) is presented in Section 5. Finally, we summarize our conclusions in Section 6.

## 2 Phenomenology of Single-Top Analyses

In the Standard Model, single-top production is due to three different mechanisms (see Fig. 1): (a) \(t\)-channel \(W\) boson-gluon fusion mode, (b) associated production of a top quark and a \(W\) boson, indicated as \(Wt\)-channel, and (c) \(s\)-channel production coming from the exchange of an offshell charged boson \(W^{*}\). Among those channels, the dominant contribution comes from the \(t\)-channel processes which accounts for 124.5 pb (79.9 pb and 44.6 pb for \(tq\bar{b}\) and \(\bar{t}qb\) production, respectively); the \(Wt\)-channel contribution amounts to 32.7 pb, while the \(s\)-channel mode is expected to have a cross-section of 6.6 pb (4.2 pb and 2.4 pb for \(t\bar{b}\) and \(\bar{t}b\) production, respectively) for 10 TeV proton-proton collisions. All cross sections are calculated at next-to-leading order (NLO) using MCFM [6]. The theoretical uncertainty on the different single-top processes is about 5% [5]. The top mass used is \(m_{top}=172.5\) GeV.

In the Standard Model the top quark decays almost exclusively into a \(W\) boson and a quark. The \(W\) boson can then decay leptonically or hadronically. For the present analysis the \(t\)- and \(Wt\)- single-top channels were simulated using the AcerMC [7] event generator interfaced to Herwig[8] for parton showering and the modeling of the underlying event. Another single-top \(t\)-channel sample generated with MC@NLO[9] was used for the study of systematical uncertainties related to the generator dependence (see Section 5.3). The \(s\)-channel was not considered, since its cross section is small and the number of expected events is negligible for \(200\,\mathrm{pb}^{-1}\). Cross-sections are quoted including all \(W\) boson decays, but only leptonic states (including \(\tau\) leptons) have been simulated since we focus in this work only on lepton plus jets signatures (see Section 3).

Top-pair production constitutes a major background to single-top events. The LHC total (approximate) NNLO top-pair production cross section is 400 pb [10] with an uncertainty of about 6%, about 2.5 times larger than the corresponding summed single-top cross section, and more than three times that of the \(t\)-channel process. Given the fact that the topology of the single top-quark final state is characterized by one high-\(p_{T}\) lepton, missing transverse energy \(E_{T}^{miss}\) and jets, \(t\bar{t}\) production represents a significant background in its lepton+jets decay mode, with a final state containing two jets from the hadronization of \(b\)-quarks and two jets from light quarks, a high-\(p_{T}\) lepton and missing energy. The "dilepton" channel (\(\mathrm{t}\bar{\mathrm{t}}\to\mathrm{l}\nu\mathrm{b}\mathrm{l}\nu\mathrm{b}\)) where a lepton is lost due to the limited detector acceptance also constitutes a major background. Finally, top quark pairs with one or both \(W\)-boson(s) decaying into a \(\tau\) lepton where the \(\tau\) decays into an electron or a muon, may also survive the selection. For our analysis the top-pair Monte Carlo sample was produced with the MC@NLO generator interfaced to Herwig.

\(W\)+jets production constitutes another major source of background as the cross section is several orders of magnitude above that of the single top-quark production. The leading order (LO) Alpgen[11] generator with the Herwig parton shower algorithm was used for the generation of inclusive \(W\)+jets events in this analysis. The MLM prescription [12] was used for the matching of the parton shower and the matrix element calculations. Processes in inclusive \(W\)+jets samples include \(W\)+light-jets (\(u,d,s,g\)), \(Wc/c\bar{c}\)+jets with massless charm quarks and \(Wb\bar{b}\)+jets with \(b\bar{b}\) from parton shower only. Since \(Wb\bar{b}\)+jets events with high \(p_{T}\)\(b\)-jets are strongly suppressed by the MLM matching procedure this process needs to be added separately. Thus specific 'hard' \(W+b\bar{b}\) samples (referred to below as the "\(Wb\bar{b}\)+jets" sample) were generated with Alpgen, with the requirements \(p_{T}(b)>20\) GeV and \(\Delta R(b\bar{b})>0.7\). The LO cross-sections for inclusive \(W\to l\nu\) and \(W\to l\nu+b\bar{b}\) processes were computed for different parton multiplicities. The total cross-sections amount to 16170 pb and 18 pb respectively including a NNLO K-factor of 1.22 (calculated in [5] using FEWZ [13]). The \(W\)+\(b\)+jets process was not considered in this analysis, as this process cannot be generated by Alpgen. According to recent studies [14] this process could be of considerable size in the tagged \(W\)+2 jets data set, even larger that the \(Wb\bar{b}\)+jets contribution. In practice the contribution from \(W\)+\(b\)+jets events will have to be

Figure 1: Leading diagrams corresponding to the three production mechanisms of single-top events: (a) \(t\)-channel production, (b) \(Wt\)-channel associated production, (c) \(s\)-channel.

studied using data.

\(Z\)+jets Monte Carlo samples were simulated using the Alpgen generator combined with Herwig for the parton showering. This process has a cross section about 10 times lower (1440 pb at NNLO) than \(W\)+jets events and it can be reduced sizably (more than a factor 10) after applying a dilepton veto and requiring significant \(E_{T}^{miss}\). No specific \(Zb\bar{b}\)+jets samples were produced.

\(WW\) and \(WZ\) diboson events where at least one of the bosons decays leptonically (electron or muon channels) constitute a relatively small background, with NLO cross-sections of 23 pb and 8 pb, respectively. These processes were simulated using Herwig. NLO K-factors, calculated with MCFM for \(WW\) process and extrapolated from [15] for the \(WZ\) process, are 1.46 and 1.71 respectively.

While QCD-multijet processes do not feature the same final state as the signal they contribute to the background due to their overwhelming cross section and small but finite rate of object misidentification. QCD-multijet events are a background for \(t\bar{t}\) and single top-quark analyses if at least one of the jets in the event is misidentified as an isolated lepton or if the event produces a non-prompt lepton (from \(b\)-quark semileptonic decay for example) that is sufficiently isolated. In practice, the level of background will be derived directly from the data and will strongly depend on the lepton fake rate and the heavy flavor fraction of QCD-multijet events. In the present study we used a QCD-multijet sample, generated with Alpgen, to explore the likely background level. Requiring events with large reconstructed transverse mass of the leptonic \(W\) bosons1) was found to be effective at reducing it to a manageable level, without hampering the signal significantly.

Footnote 1): The reconstructed transverse mass of the leptonically decaying \(W\) boson is defined as \(m_{T}(W)=\sqrt{(p_{T}^{lep}+E_{T}^{miss})^{2}-(p_{X}^{lep}+E_{X}^{miss})^{2}-(p_ {Y}^{lep}+E_{Y}^{miss})^{2}}\).

## 3 Event Preselection

A set of preselection criteria was defined in previous studies [5] for all three single top-quark production modes. In this paper, slightly modified definitions are used, in order to account for the startup conditions of the detector. The selected triggers correspond to the ones that will be used for luminosities between \(10^{31}\) and \(10^{32}\,\mathrm{cm}^{-2}\mathrm{s}^{-1}\), and lepton and jet selection criteria have been loosened.

### Object Selection Criteria

Specific criteria have been defined to select the objects (leptons and jets) used in the analysis. Selected events must have at least one reconstructed high-\(p_{T}\) isolated lepton in the region with \(|\eta|<2.5\). The isolation criterion requires that the energy in a cone of \(\Delta R\)= 0.2 around the lepton direction be less than 6 GeV and is important for the rejection of QCD-multijet background. Muons and electrons are required to have \(p_{T}>20\,\mathrm{GeV}\). Electrons reconstructed in the crack region of the calorimeter (\(1.37<|\eta|<1.52\)) are not selected. Muons close to a jet (\(\Delta R<0.3\)) are removed.

Calibrated jets are reconstructed with a R=0.4 cone algorithm and are required to have \(p_{T}>30\,\mathrm{GeV}\) and \(|\eta|<5.0\). Jets within \(\Delta R<0.2\) of an electron are removed (see overlap removal procedure below).

The identification of jets containing \(b\)-quarks is one of the most important selection criteria for the analysis of events containing top quarks. For the studies described here, which are devoted to the early data period, we used a jet probability (_JetProb_) tagger [5], which is based only on the impact-parameter resolution function of prompt tracks and is expected to be commissioned first with the early data. The _JetProb_ tagger calculates a probability for each jet to originate from a light parton. We select a cut on the \(b\)-tag weight which corresponds to a 45% \(b\)-tagging efficiency and a light-jet rejection factor of about 90. The chosen working point is a compromise between the efficiency on the selection of the signal and the rejection of non-\(b\) processes (mostly \(W\)+jets). Performance of \(b\)-tagging algorithms will be derived directly from data in the future. The expected precision achievable with early data is 6% absolute uncertainty on the \(b\)-tagging efficiency and 10% relative error on the mistagging rate [5].

### Event Preselection Criteria

Once the reconstructed objects have been defined and selected we apply an event preselection which classifies the events according to exclusive electron and muon streams. This selection is aimed at reducing the rate of three of the main background processes affecting single-top analyses: the top-pair production, the \(W\)+jets and the QCD-multijet events.

Events are first required to pass either a single isolated electron or muon trigger, both with 15 GeV thresholds. The design and performance of the three levels of trigger are presented extensively elsewhere [5]. These triggers yield efficiencies of over 80% for muons and over 95% for electrons.

We define muon and electron channels according to the flavor of the highest \(p_{T}\) lepton selected in the event. Finally, electron and muon channels are made orthogonal by rejecting events which contain a second lepton with \(p_{T}\) higher than 20 GeV.

Events are then preselected if at least two jets with \(p_{T}\) above 30 GeV are reconstructed. The event jet multiplicity is required to be less than or equal to four. Among the selected jets, at least one must be identified as a \(b\)-jet using the _JetProb_ tagger.

The transverse missing energy is required to be \(E_{T}^{miss}>20\,\mathrm{GeV}\). Missing \(\mathrm{E_{T}}\) is defined by \(\vec{E}_{T}^{miss}=-\sum_{i}E_{T}^{i}\hat{n}_{i}\), where \(i\) is the calorimeter tower number for \(|\eta|<4.9\), and \(\hat{n}_{i}\) is a unit vector perpendicular to the beam axis and pointing at the \(i^{th}\) tower. We define the magnitude \(E_{T}^{miss}=|\vec{E}_{T}^{miss}|\). Corrections are made to the \(E_{T}^{miss}\) for the reconstructed objects, including electrons, muons and jets. In addition, the \(E_{T}^{miss}\) is also corrected for dead material in the cryostat. This criterion is 90% efficient for single-top \(t\)-channel signal that pass the previous selections (without the b-tagging requirement), while reducing the contamination from QCD-multijet events by a factor of approximately six.

Finally, events are selected if the transverse mass of the reconstructed \(W\) boson is greater than 30 GeV. This selection reduces the number of QCD-multijet events passing the preselection by more than a factor five while reducing the top signal acceptance by 10% at the preselection stage.

### Event Yields

We consider in the following three sub-samples, each a subset of the previous one: a _Pretag_ sample made up with preselected events before any \(b\)-tag requirement; a _Tag_ sample constituted by all preselected events for which one jet is \(b\)-tagged, and a _2-jets_ sample made up by tagged events with exactly two high \(p_{T}\) jets.

Table 1 reports the expected number of events in 200 pb\({}^{-1}\) for all three samples and Fig. 2 shows the jet multiplicity distributions for signal and background events in the _Pretag_ and _Tag_ samples. The number of W(\(\to l\nu\))+\(b\bar{b}\)+light partons and W(\(\to l\nu\))+light partons events are reported separately in Table 1. However since the fraction of \(Wb\bar{b}\)+jets events with respect to the total number of inclusive \(W\)+jets events is below 10% in any of the three samples these

two contributions will be combined throughout the rest of the note. The fraction of \(W\)+heavy-flavors tends to become dominant in the combined inclusive \(W\)+jets sample once \(b\)-tagging is required, in particular because \(W\)+light partons process also include a fraction of events with heavy flavors (see Sec. 2). In the _2-jets_\(W\)+jets sample for example, about 26% of events have at least one jet containing a \(b\)-quark (including a 7% contribution from \(W\)+\(b\bar{b}\)+light partons process) and 49% of events have at least one jet that contains a \(c\)-quark. The remaining fraction (25%) of events is composed of \(W\)+light-jets, with jets containing only light partons.

In the _Pretag_ sample, the signal-over-background ratio is about 2%, with background consisting mainly of \(W\)+jets events (75%) and top pair events (11%). In the _Tag_ sample, the S/B ratio is improved to 8% with top pair events constituting almost 60% of the background yield. In the _2-jets_ sample about 470 \(t\)-channel single-top events are expected, with a background composed mainly of \(W\)+jets (43%) and \(t\bar{t}\) (35%) events. Fig. 3 shows the leptonic reconstructed top-quark mass distribution in this sample. With a signal-over-background ratio of 13% a statistical precision better than 15% can be achieved on the signal cross section measurement. This sample will thus be used to determine the sensitivity to single-top \(t\)-channel events. The relatively low S/B ratio however makes the measurement dominated by the large systematic uncertainties affecting the background estimate. In order to improve the precision of the \(t\)-channel cross-section determination, it is thus necessary to reduce the uncertainty on the background estimates and to optimize the selection of the signal. The first requirement is fulfilled by determining the rates of the main backgrounds from the data itself, making use of a large statistics background-enriched sample in _Pretag_ events: this method is described in Section 4. The latter demand is addressed by the use of a more sophisticated method aimed at purifying further the _2-jets_ sample, and will be described in Section 5.

## 4 Background Normalization

The rates of the background processes involved in top-quark physics can be estimated from theory, but some, such as the W+jets background, have large uncertainties. It will therefore be necessary to estimate the cross section of the main background processes using data. In this section we present a method to measure the main background rates using the observed data in control regions.

The idea is to construct a discriminant that allows for a simultaneous determination of the \(W\)+jets and \(t\bar{t}\) rates which are the main background processes for single top-quark production. The method first selects a control region that is statistically independent from the signal region

\begin{table}
\begin{tabular}{l r r r} \hline  & _Pretag_ & _Tag_ & _2-jets_ \\ \hline \(t\)-channel & 1660 \(\pm\) 10 & 760 \(\pm\) 7 & 470 \(\pm\) 6 \\ \hline \(Wt\)-channel & 710 \(\pm\) 3 & 300 \(\pm\) 2 & 125 \(\pm\) 2 \\ \(t\bar{t}\) & 10850 \(\pm\) 40 & 6020 \(\pm\) 30 & 1250 \(\pm\) 20 \\ \(W(\to l\nu)\)+light partons & 73300 \(\pm\) 200 & 2180 \(\pm\) 30 & 1530 \(\pm\) 30 \\ \(W(\to l\nu)\)+\(b\bar{b}\)+light partons & 460 \(\pm\) 6 & 215 \(\pm\) 4 & 120 \(\pm\) 3 \\ Z(\(\to ll\))+jets / diboson & 3140 \(\pm\) 30 & 130 \(\pm\) 5 & 85 \(\pm\) 5 \\ QCD & 6400 \(\pm\) 400 & 600 \(\pm\) 100 & 400 \(\pm\) 90 \\ \hline Total & 96520 \(\pm\) 400 & 10205 \(\pm\) 100 & 3980 \(\pm\) 100 \\ \hline S/B & 0.02 & 0.08 & 0.13 \\ \hline \end{tabular}
\end{table}
Table 1: Expected number of events selected in 200 pb\({}^{-1}\) in the _Pretag_, _Tag_ and _2-jets_ samples (as defined in the text). Uncertainties are from finite statistics in simulation samples.

Figure 3: Reconstructed leptonic top-quark mass for events with exactly two jets that pass the event preselection.

Figure 2: Stacked jet multiplicity distributions for preselected events, without \(b\)-tagging requirement (left plot) and for events with at least one \(b\)-tagged jet (right plot).

and that is composed with events kinematically similar to the ones in the signal region, in order to allow a reliable extrapolation of the background rates. Since our final goal is the measurement of the \(t\)-channel single top-quark cross section in the _2-jets_ tagged data set, we will investigate the \(W\)+jets and \(t\bar{t}\) rates in the 3-jets _Pretag_ data set before identifying \(b\)-quark jets. A priori we expect this _Pretag_ sample to be composed of approximately 68% \(W\)+jets events and 24% \(t\bar{t}\) events, see Table 2. Thus, a sufficient rate of both processes is present, which allows for a simultaneous determination of the two rates. Therefore if we know the 2-jets/3-jets ratio we can constrain the 2-jets background using the measurement performed in the 3-jets _Pretag_ sample. We assume in our approach that Alpgen correctly predicts this ratio, however this assumption will need to be tested using data.

### Neural Network Discriminant

At the Tevatron multivariate techniques, among them artificial neural networks (NN), have been successfully used to measure the \(t\bar{t}\) cross section [16, 17]. In the analysis presented here we use a three-layer feed forward NN with a complex, robust preprocessing of the input variables provided by the NeuroBayes package [18]. Bayesian regularization techniques are used for the training process. There is one input node for each input variable plus one bias node. There are 15 nodes in the hidden layer and one output node which gives a continuous output in the interval [0,1]. In our case we consider \(t\bar{t}\) as signal and \(W\)+jets and all other processes as background. The network is trained using a sample of simulated events. The signal fraction of the training sample is chosen to be 50%. The background events in the training sample are weighted according to the expected composition. The following 11 discriminating input variables are used:

* \(H_{T}\): The scalar sum of the transverse momentum of the charged lepton, \(E_{T}^{miss}\), and the transverse energy of the three jets.
* \(m(j_{1}j_{2})\): The invariant mass of the leading and second-leading jet.
* \(m(j_{1}j_{3})\): The invariant mass of the leading and third-leading jet.
* \(m(j_{2}j_{3})\): The invariant mass of the second-leading and third-leading jet.
* \(m(j_{1}j_{2}j_{3})\): The invariant mass of the three jets.
* \(\eta(\ell)\): The pseudorapidity of the charged lepton.
* \(|\Delta\eta(\ell,j_{2})|\): The absolute value of the difference in pseudorapidity of the charged lepton and the second-leading jet.

\begin{table}
\begin{tabular}{l|r} \hline t-channel & 430\(\pm\)60 \\ \hline Wt-channel & 260\(\pm\)30 \\ \(t\bar{t}\) & 4500\(\pm\)600 \\ \(W\to l\nu\)+jets & 13000\(\pm\)3000 \\ \(Z\to ll\)+jets, diboson & 660\(\pm\) 2 \\ QCD & 1600\(\pm\)800 \\ \hline Total & 20000\(\pm\)3000 \\ \hline \end{tabular}
\end{table}
Table 2: Number of expected events in 200 pb\({}^{-1}\) in the preselected 3-jets _Pretag_ sample (uncertainties are theoretical).

* \(|\Delta\eta(\ell,j_{3})|\): The difference in pseudorapidity of the charged lepton and the third-leading jet.
* \(\Delta\eta(j_{1},j_{2})\): The difference in pseudorapidity of the leading and second-leading jet.
* \(|\Delta\eta(j_{2},j_{3})|\): The difference in pseudorapidity of the second-leading and third-leading jet.
* \(\cos\theta_{\ell\nu j_{c}}(\ell,j_{1})\): The cosine of the angle \(\theta\) between the charged lepton and the leading jet in the rest frame of the sum of the charged lepton, the neutrino and the most central jet (minimum \(|\eta|\)).

The variables were chosen in order to limit the effect of the systematic uncertainty due to the jet energy scale. As an example we show the template distributions of \(H_{T}\) and \(m_{j1j2}\), which are the two most important input variables, in Fig. 4. The expected distributions for \(200\,\mathrm{pb}^{-1}\) are given in Fig. 5.

When applying the trained NN to samples of simulated events of the different physics processes, the template distributions shown in Fig. 6 (left hand side) are obtained. Normalizing the distributions to the number of expected events as given in Table 2, yields the predicted distribution in Fig. 6 (right hand side).

### Expected Statistical and Systematic Uncertainties

We measure the rate of \(W\)+jets and \(t\bar{t}\) events using a binned maximum-likelihood fit to the neural network output distribution. Gaussian constraints are applied to the expected rates of other processes. We denote \(\beta_{j}\) the ratio of the fitted rate over the expectation, for process \(j\). The measured \(\beta_{t\bar{t}}\) and \(\beta_{\mathrm{W+jets}}\) will be used as scale factors for the expected rates of these processes in the signal region of the single top-quark analysis. The statistical sensitivity is estimated using ensemble tests, which yield a relative statistical uncertainty of 2.0% on the \(W\)+jets rate and an uncertainty of 3.5% on the \(t\bar{t}\) rate.

When exploiting the shape of a discriminant distribution, as done in this analysis, one has to account for systematic acceptance uncertainties as well as systematic shape uncertainties.

Figure 4: Examples of input variables to the NN in the 3-jets _Pretag_ data set. The right most bin indicates the overflow bin. Left side: \(H_{T}\) distribution. Right side: \(m(j_{1}j_{2})\) distribution. See text for details.

Acceptance uncertainties are a measure of how much the number of expected events changes as a result of a specific systematic shift. Shape uncertainties parameterize the change in the template distribution due to a specific source of uncertainty. The changes in the template distributions cause shifts in the estimated rates. The following sources of systematic uncertainty are considered:

1. Jet Energy Scale: we first consider the uncertainty in the jet energy scale (JES). To estimate this effect we alter the JES by \(\pm 5\%\). The associated shape uncertainties are given by modified template histograms, one for JES up, and one for JES down, see Fig. 7 and Fig. 8. As a result, we get JES uncertainties on the \(W\)+jets rate of \(\Delta\beta=^{+0.12}_{-0.13}\) and on the \(t\bar{t}\) rate of \(\Delta\beta=^{-0.04}_{+0.04}\).
2. Parton Distribution Functions: we have reevaluated the acceptances for \(t\bar{t}\) events using a re-weighting of events based on the eigenvector method applied to the CTEQ6.6 and MRST2006nnlo PDF sets. For CTEQ we found a symmetrized relative uncertainty of \(4.5\%\),

Figure 5: Examples of input variables to the NN in the 3-jets _Pretag_ data set. The distributions are normalized to an integrated luminosity of \(200\,\mathrm{pb}^{-1}\). Left side: \(H_{T}\). Right side: \(m(j_{1}j_{2})\). The right most bin in each distribution contains the overflow bin.

Figure 6: The distributions of the NN output. Left side: Template distributions normalized to unit area. Right side: Expected distribution for an integrated luminosity of \(200\,\mathrm{pb}^{-1}\).

Figure 8: Effect of JES uncertainty on rates fitted in pseudo-experiments normalized to the expectation (\(\beta\)). Left side: distribution for \(W\)+jets. Right side: distribution for \(t\bar{t}\). The black histograms centered at one show the outcome of pseudo-experiments with unaltered JES, the default setting. The median of this distribution is taken as reference. To estimate the impact of an altered JES we perform ensemble tests in which the JES is altered by \(+5\%\) or by \(-5\%\). The resulting distributions of \(\beta\) are shown: \(+5\%\) (blue) and \(-5\%\) (red). The median of these distributions is shifted by an amount \(\Delta\) which indicates that we expect to measure a higher (or lower) rate of events in the case that the JES is differing by \(\pm 5\%\), compared to the rate we expect in case of an unaltered JES. We define the shift as a measure of the systematic uncertainty on our rate measurement.

Figure 7: Shape uncertainty for a JES shift of \(\pm 5\%\) for the two most important processes, \(W\)+jets (left) and \(t\bar{t}\) (right). The lower plots show the ratios of the template histograms and thus gives the relative change in each bin.

for MRST we obtain 1.8%. Since the CTEQ uncertainty also covers the difference between the central values given by CTEQ and MRST, we do not assign a separate systematic uncertainty for the CTEQ-MRST difference.
3. Single-top contamination: a small source of uncertainty is related to the single-top contribution in the 3-jets _Pretag_ dataset. We study how the measured \(W\)+jets and \(t\bar{t}\) rates are affected when the single-top expectation value is set to 0, 1 or 2 times the Standard Model prediction in the fitted distribution. The effect of the precision of the Gaussian constraint on single-top rates is also studied by varying the theoretical constraint within 50% and 100% of its uncertainty. The impact on the uncertainty on the background rate determination was found to be small (4% for \(W\)+jets and 0.3% for \(t\bar{t}\)).

In Table 3 we summarize the expected uncertainties on the measurement of the \(W\)+jets and \(t\bar{t}\) rates in the 3-jets _Pretag_ data set.

## 5 Search for \(t\)-channel Single-Top Production

In this section we present two methods to search for single-top \(t\)-channel events in the _2-jets_ tagged sample defined in Section 3. The first method is based on the use of a set of kinematical sequential cuts. This selection uses two additional requirements on the \(b\)-tagged jet \(p_{T}\) threshold and on the \(\eta\) of the hardest untagged jet. The second approach is based on likelihood functions designed to improve signal and background separation. These functions make use of a few angular discriminant variables, which are less prone to calibration uncertainties in the early data-taking period than jet \(p_{T}\).

### Sequential Cut Analysis

The single-top \(t\)-channel process is characterized by the production of a boosted top quark and a very energetic forward light quark. The particles originating from the top quark leptonic decays (\(b\)-quark and leptons from \(W\) decay) are produced centrally and have high transverse momentum. An additional forward \(b\)-quark from initial state gluon splitting may also be produced in the event.

The _Tag_ sample, as defined in Section 3, is dominated by \(t\bar{t}\) and \(W\)+jets backgrounds. The following cuts improve the signal-over-background ratio by a factor of four. A cut on a \(b\)-tagged jet \(p_{T}>50\) GeV reduces the \(W\)+jets background significantly (-40%), since \(b\)-tagged jets from

\begin{table}
\begin{tabular}{l|c|c|c} \hline Source & & \(W\)+jets & \(t\bar{t}\) \\ \hline statistical & & \(\pm 2.0\%\) & \(\pm 3.5\%\) \\  & +5\% & +11.5\% & -3.8\% \\ JES & \(-5\%\) & -13.4\% & +3.7\% \\ PDF & & – & \(\pm 4.5\%\) \\ Single-top fraction & & \(\pm 4\%\) & \(\pm 0.3\%\) \\ \hline Total & & \(\pm 14.1\%\) & \(\pm 6.9\%\) \\ \hline \end{tabular}
\end{table}
Table 3: Expected uncertainties on the measurement of the \(W\)+jets and \(t\bar{t}\) rates in the 3-jets _Pretag_ data set. The total uncertainty is computed by adding the uncertainties due to the different sources in quadrature. We symmetrize the uncertainty in the JES by taking the largest uncertainty of the plus or minus JES variation, respectively.

\(W\) events are much softer as they primarily come from mistagged jets originating from extra gluon radiation. A cut on the pseudorapidity of the hardest untagged jet \(|\eta|>2.5\) rejects \(t\bar{t}\) because light jets from \(t\bar{t}\) events are typically initiated from hadronic \(W\) decays and thus are produced more centrally.

Table 4 reports the expected number of events of signal and background in 200 pb\({}^{-1}\) after application of the two additional cuts to the _Tag_ sample (column 2). The amount of QCD-multijet events is not considered since we expect this contribution to be low (about 60 events in the 2-4 jets bins) and because of large uncertainties (more than 50%) on the expected event yield due to the limited Monte Carlo statistics. In the 2-jets bin, where the signal cross section is determined, no QCD-multijet events survive the sequential cuts. Thus we consider the impact of QCD-multijet events to be small (the upper limit corresponding to one simulated event surviving the sequential cuts selections is 20 events or less) and we neglect it throughout the rest of the analysis. The selected sample is still background-dominated with \(t\bar{t}\) and \(W\)+jets events which represent about 65% and 30% of the total background yield, respectively. Events with exactly two jets show an improved signal-over-background ratio (column 3 in Table 4) and are used to determine the sensitivity to the single-top \(t\)-channel events. The background in these events is composed mainly of \(W\)+jets (60%) and \(t\bar{t}\) (35%) events.

### Likelihood Function Analysis

We present here a simple multivariate approach to improve the signal purity, based on few variables and a likelihood ratio method. A likelihood variable is robust from the statistical point of view and is more effective to discriminate the signal from background than the sequential cuts since a likelihood uses the entire shape of several input variables.

Only events that pass the _Tag_ preselection cuts as defined in Section 3 are considered in the following. Two likelihood ratio discriminants are constructed, one for the rejection of \(t\bar{t}\) events, \({\cal L}_{t\bar{t}}\) and another for the rejection of \(W\)+jets process, \({\cal L}_{W+jets}\). The signal considered in these likelihood definitions is the \(t\)-channel single top. The observables entering the likelihood calculations are the pseudorapidity of the highest \(p_{T}\) untagged jet, the \(\Delta R\) between the lepton and the highest \(p_{T}\)\(b\)-tagged jet, the \(\Delta R\) between the highest \(p_{T}\)\(b\)-tagged jet and the highest \(p_{T}\) untagged jet, and the centrality2). These angular variables are chosen for their discriminating

\begin{table}
\begin{tabular}{l||r|r||r|r} \hline Processes & \multicolumn{2}{c||}{Sequential cuts} & \multicolumn{2}{c}{Likelihood cuts} \\ \cline{2-5}  & 2-4 jets & 2 jets & 2-4 jets & 2 jets \\ \hline \hline \(t\)-channel & 184 \(\pm\) 4 & 118 \(\pm\) 3 & 160 \(\pm\) 3 & 112 \(\pm\) 3 \\ \hline \(Wt\)-channel & 16 \(\pm\) 1 & 6 \(\pm\) 1 & 7 \(\pm\) 1 & 2 \(\pm\) 1 \\ \(t\bar{t}\) & 361 \(\pm\) 9 & 63 \(\pm\) 4 & 154 \(\pm\) 6 & 32 \(\pm\) 3 \\ \(W\to l\nu\)+jets & 159 \(\pm\) 7 & 112 \(\pm\) 6 & 114 \(\pm\) 6 & 89 \(\pm\) 6 \\ \(Z\to ll\)+jets,diboson & 7 \(\pm\) 1 & 4 \(\pm\) 1 & 6 \(\pm\) 1 & 3 \(\pm\) 1 \\ \hline Total & 727 \(\pm\) 12 & 303 \(\pm\) 7 & 441 \(\pm\) 9 & 239 \(\pm\) 7 \\ \hline S/B & 0.34 & 0.64 & 0.57 & 0.89 \\ \hline \end{tabular}
\end{table}
Table 4: Expected number of events selected in 200 pb\({}^{-1}\) surviving the preselection criteria and either additional cuts on the \(p_{T}\) of the \(b\)-tagged jet and the pseudorapidity of the hardest untagged jet (sequential cuts) or a set of selections on the likelihood outputs (likelihood values greater than 0.9). The number of expected events with exactly two jets is given for each type of selection. Uncertainties are from finite statistics in simulation samples.

power and for their insensitivity to jet energy scale systematic uncertainties.

A reasonable discrimination between signal and the main \(t\bar{t}\) and \(W\)+jets background is achieved for all jet multiplicities. Fig. 9 shows the likelihood ratio distributions \(\mathcal{L}_{t\bar{t}}\) and \(\mathcal{L}_{W+jets}\) in the _2-jets_ sample. We improve the purity of our sample by restricting our selection to events in which both likelihood ratios exceed given thresholds. These thresholds are chosen such as to maximize the signal-over-background ratio, and thus reduce most of the source of uncertainties on the cross section measurement. Events in the preselected sample are required to have likelihood ratio values \(\mathcal{L}_{t\bar{t}}\) and \(\mathcal{L}_{W+jets}\) greater than 0.9.

The number of events of signal and background expected in 200 pb\({}^{-1}\) in the _Tag_ sample after application of the cuts on the likelihood ratio outputs is reported in Table 4 (column 4). We expect about 40 events from QCD-multijet processes in the 2-4 jets bins, with a large statistical uncertainty (70%) due to the limited simulated event samples used in this analysis. No Monte Carlo QCD-multijet events survive these cuts in the _2-jets_ sample. Therefore, as in the sequential cut-based analysis, we neglect this contribution in the following.

With respect to the sequential cut analysis described in section 5.1 the \(S/B\) is increased by almost 70%. For the two-jets sample (Table 4, column 5) the signal is then comparable to the sequential cut analysis, while the total amount of background is reduced by 30%. This reduction is realized through a 50% reduction of the \(t\bar{t}\) background and a 20% reduction of the \(W\)+jets background.

### Expected Uncertainty on the Signal Cross Section

We estimate the sensitivity to the single-top \(t\)-channel production using the selected samples in both the sequential cuts and the likelihoods cuts approaches. Only events with exactly two jets are used in the measurement. To improve the precision of the measurement, each selected sample is divided into several channels according to the reconstructed lepton flavor and charge, leading to four orthogonal samples. Due to the signal production charge asymmetry (see Section 2) we expect more single-top \(t\)-channel events in the \(e^{+}/\mu^{+}\) samples. The signal cross section is then determined using a maximum-likelihood fit of the four channels.

The impact of systematic sources of uncertainties on the cross section measurement is determined with ensemble tests. A large number of pseudo-experiments are performed where nuisance

Figure 9: Distribution of likelihood ratios discriminants in 200 pb\({}^{-1}\) in the _2-jets_ tagged sample. Two discriminants are constructed, one for the rejection of \(t\bar{t}\) events, \(\mathcal{L}_{t\bar{t}}\), (left) and another for the rejection of \(W\)+jets process, \(\mathcal{L}_{W+jets}\), (right). The cross section determination is performed with events in which both likelihood ratios exceed 0.9.

parameters (uncertainties on \(b\)-tagging, jet energy scale, etc) affecting the signal acceptance and background rates are sampled using a Gaussian distribution, and for each pseudo-experiment the signal cross section is measured with a maximum-likelihood fit. The measured distribution is used to construct an empirical likelihood of the signal cross section, \(\sigma_{t}\). A positive flat prior probability distribution function (p.d.f) is assumed such that the probability for non-physical negative values of \(\sigma_{t-ch}\) is zero. Thus the distribution of the measured cross sections given by the maximum-likelihood fits can be used to describe the posterior density function of \(\sigma_{t}\). In this procedure all nuisance parameters are implicitly integrated over assuming a flat prior. In the Bayesian approach the posterior p.d.f can be integrated to construct Bayesian intervals, set limits on the measured cross section and derive signal significances.

Two types of statistical errors affect our measurement: the uncertainty due to the Poisson error that one would expect from data statistics and the uncertainty related to the finite statistics of the simulated event samples. For both sequential cut and likelihood analyses the impact of these statistical uncertainties corresponds to an error on the measured cross section of about 15%, the dominating effect being the data statistics.

Several experimental and theoretical systematic uncertainties affect the cross-section determination: the uncertainty in the \(b\)-tagging algorithm performance, jet energy scale, luminosity and background estimate which can originate from both experimental and theoretical aspects (gluon radiation modeling and PDF). These systematic effects are detailed in the following.

1. Background normalization: in this analysis, we consider the results obtained from the data-driven technique described in Section 4. This method leads to a precision on the expected rate of 14.1% for \(W\)+jets events and 5.2% for \(t\bar{t}\) events, taking into account both statistical and systematic errors reported in Table 3 with the exception of PDF uncertainties that are considered separately. The uncertainties coming from the jet energy scale variations are assumed fully correlated in the error propagation. For the other backgrounds processes the theoretical uncertainties are assumed.
2. Uncertainty on \(W\)+heavy flavors cross sections: the leading order Alpgen generator poorly predicts the fraction of \(W+b\bar{b}\) and \(W+c\bar{c}\) events and does not generate the \(W\)+\(b\)+jets process. In addition, theoretical calculations at NLO, such as [14], give uncertainties of about 20% on the rates of \(W+b(\bar{b})\) processes. Therefore the fraction of \(W\)+heavy flavors in the tagged sample will need to be measured using data. We currently cannot estimate, in the absence of sufficient data, the uncertainty on the fraction \(W\)+heavy flavors and we decide to rely in this analysis on Alpgen predictions. We acknowledge that a systematic uncertainty related to the heavy flavor composition of the background exists and that it will need to be measured precisely in the future. However in order to have an idea of how the level of background impacts the signal cross section determination we consider below (Sec. 5.4) a scenario where the total \(W\)+jets background is doubled.
3. \(b\)-tagging: the uncertainties related to the expected performance of the \(b\)-jet tagging algorithm have been evaluated via varying separately both the \(b\)-jet tagging efficiency by \(\pm 6\%\) (absolute rate) and the relative light-jet mistagging rate by \(\pm 10\%\) with respect to their default values [5], reported in Section 3.1. The variation observed on the total number of events of background is mostly due to the effect of \(b\)-tagging efficiency uncertainty on \(t\bar{t}\) events and mistagging rate uncertainty on \(W\)+jets events. The light-jet fake rate accounts for more than one third of the total background error (38% and 46% for the cut-based and likelihood analysis, respectively).
4. Jet energy scale: a variation of \(\pm\) 5% on the jet energy scale (JES) has been propagated to the jet reconstruction and selection efficiencies were re-assessed. The uncertainty due to the JES can be greatly reduced when the rates of the two leading background processes, \(t\bar{t}\) and \(W\)+jets events which constitute more than 90% of the total background, are determined from data. Indeed the JES uncertainty on the rates of these two processes is already taken into account in the background normalization uncertainty. The JES effect on the total amount of background events is reduced below the percent level when the uncertainties on \(t\bar{t}\) and \(W\)+jets events are taken out of the calculation. The impact on the cross section error is then dominated by the JES uncertainty on the signal acceptance.
* ISR/FSR: the presence of extra jets originating from gluon radiation can affect the number of additional jets and thus the selection efficiency. To estimate the uncertainty due to initial and final state radiation specific \(t\)-channel and \(t\bar{t}\) Monte Carlo samples were produced with the AcerMC generator with variations in the ISR/FSR settings of Pythia used for parton showering. Pythia parameters are varied so that the reconstructed top mass is increased or decreased with respect to the default value. For each process we have two samples, one with high-FSR/low-ISR and another with low-FSR/high-ISR, where high/low mean double of half of the default ATLAS value 3) \(\Lambda\) value used in running \(\alpha_{s}\). We assessed the impact of such variations on the selection efficiencies entering the cross-section determination. The average uncertainty on the cross-section determination due to ISR/FSR is about 10% for both cut-based and likelihood methods. Footnote 3): 0.192 is used as a default value for the \(\Lambda\) value used in running \(\alpha_{s}\) (Pythia parameters PARP(61) and PARP(72)).
* Parton density function: the uncertainty in the PDF can affect the kinematical distributions of the final state objects, hence impacting the determination of the selection efficiency for both signal and background. PDF uncertainties were calculated for signal and \(t\bar{t}\) background using a re-weighting method together with different PDF sets. The PDF used for this study are CTEQ6m which was used for generation and two more recent PDF sets, CTEQ6.6 and MRST2006nnlo. Events are required to pass the sequential cut analysis selections. We take the largest errors as our PDF systematic uncertainty on the acceptance of signal (2.2%) and \(t\bar{t}\) background (9.7%). These errors are assumed to be the same for the likelihood analysis.
* Generator dependence: differences between Monte Carlo generators might affect the selection efficiency. We compared the default AcerMC +Herwig signal sample used in the analysis with a \(t\)-channel single-top sample produced using MC@NLO. The difference between the signal efficiencies, 11% and 16% for the cut-based and likelihood analysis respectively, is taken as a systematic uncertainty. Note that this error is likely an overestimate since we are in fact comparing LO and NLO Monte Carlo generators. We expect this error to be reduced by comparing results obtained with other NLO generators (such as POWHEG), and comparing with data.
* Luminosity: an error of 10% was considered on the integrated luminosity. This error also affects the background rates if those latter are estimated from Monte Carlo only4). Precise data-driven background rates estimates remove this dependence and are therefore important to help reduce this source of uncertainty. Footnote 4): The cross section error due to the luminosity uncertainty can be approximated to \((1+\frac{B}{S})\frac{\sigma_{F}}{L}\), where B is the amount of background determined from Monte Carlo and S the expected signal.
* Lepton: an uncertainty of 1% in both lepton identification and trigger efficiency was considered and the impact on the cross-section determination assessed.

* Charge misreconstruction: the average lepton \(p_{T}\) for the processes we consider is about 50 GeV. In this \(p_{T}\) range we expect the probability of charge misreconstruction to be below 0.1% [5], and thus negligible for this analysis.

The average uncertainty on the cross section measurement due to each source of errors was evaluated for both sequential cuts and likelihood analyses, and the results are summarized in Table 5.

The uncertainty expected for the cut-based and likelihood analyses are 45% and 40%, respectively. The largest source of error comes from the uncertainty on the \(b\)-tagging performance.

### Sensitivity to \(t\)-channel Single-Top Events

For a scenario of 200 pb\({}^{-1}\) at 10 TeV the best precision achievable on the Standard Model single-top production cross-section (125 pb) is limited to 40% with a signal-over-background ratio of 0.9 (assuming that the background composition is correctly predicted by our Monte Carlo simulations). The expected significance for the SM signal cross section, as determined through ensemble tests with pseudo-experiments, is 2.7 \(\sigma\). Conversely, in the hypothesis of the absence of signal in the data we can exclude cross sections larger than 61 pb at 95% confidence level. Given the present uncertainties on the fraction of heavy flavors in the \(W\)+jets tagged sample at LHC energies, we investigated the possibility that this background could be larger in data than in our estimates and we determined the impact on the signal significance. In a hypothetical scenario in which the total \(W\)+jets background is doubled, the best achievable precision on the single-top cross-section would then be 49%, and the expected significance for the SM signal cross section would decrease to 2.0 \(\sigma\).

\begin{table}
\begin{tabular}{l|c c} \hline Source of & \multicolumn{2}{c}{\(\Delta\sigma/\sigma(\%)\)} \\ uncertainty & Sequential cuts & Likelihood \\ \hline \hline Data statistics & 15\% & 14\% \\ \hline Monte Carlo statistics & 6\% & 6\% \\ JES & 8\% & 3\% \\ \(b\)-tagging & 26\% & 22\% \\ Background normalization & 12\% & 10\% \\ ISR/FSR & 10\% & 10\% \\ PDF & 7\% & 6\% \\ Generator & 11\% & 16\% \\ Lep. ID, trigger & 4\% & 3\% \\ \hline Luminosity & 11\% & 11\% \\ \hline \hline Total & 45\% & 40\% \\ \hline \end{tabular}
\end{table}
Table 5: Summary of all expected uncertainties that affect the measured cross section for 200 pb\({}^{-1}\) of data, in both sequential cuts and likelihood analyses. Data statistics is the Poisson error one would expect from 200 pb\({}^{-1}\) of data while Monte Carlo statistics is the uncertainty on the estimated quantities due to limited size of the simulation samples used in this study. Uncertainties on \(W\)+jets and \(t\bar{t}\) background rates are obtained from a fit to a neural network output distribution in the 3-jets bin _Pretag_ control sample.

Conclusions and Outlook

We have developed a strategy to search for \(t\)-channel single top-quark production in early ATLAS data. The primary objective of the studies was to devise data-driven techniques to normalize the rates of the main backgrounds and calibrate predictions obtained from samples of simulated events, thereby extending previous studies performed by the ATLAS collaboration [5]. The selection of single top-quark events is further optimized by the use of a likelihood method.

Our studies show that even in the early phase of the LHC the measurement of the single top-quark \(t\)-channel cross section will be limited by systematic uncertainties. The most relevant sources of uncertainty are the understanding of \(b\)-quark jet identification, the background normalization, and the simulation of the \(t\)-channel process with Monte Carlo event generators. A significant improvement could be gained by using a \(b\)-tagging algorithm with a higher rejection of light-quark jets. Such advanced algorithms are already under development in ATLAS, and this study shows the importance of commissioning them rapidly, so they can already be applied to the data sample obtained from the initial LHC run.

## References

* [1] CDF Collaboration. Observation of electroweak single top-quark production. _Phys. Rev. Lett._, **103**(092002), 2009.
* [2] D0 Collaboration. Observation of single top-quark production. _Phys. Rev. Lett._, **103**(092001), 2009.
* [3] N. Cabibbo. Unitary symmetry and leptonic decays. _Phys.Rev.Lett_, **10**, 1963.
* [4] M.Kobayashi and T.Maskawa. CP-violation in the renormalizable theory of weak interaction. _Prog. Theor.Phys._, **49**, 1973.
* [5] ATLAS Collaboration. Expected performance of the ATLAS experiment, detector, trigger and physics. CERN-OPEN(2008-020), 2008.
* Monte Carlo for FeMtobarn processes. Available from World Wide Web: [http://mcfm.fnal.gov/](http://mcfm.fnal.gov/).
* [7] B. P. Kersevan and R. W. Elzbieta. The Monte Carlo Event Generator AcerMC version 3.5 with interfaces to PYTHIA 6.4, HERWIG 6.5 and ARIADNE 4.1. _hep-ph/0405247_, 2008.
* [8] G. Corcella et al. HERWIG 6.5: an event generator for Hadron Emission Reactions With Interfering Gluons (including supersymmetric processes). _JHEP_, **01**:010, 2001.
* [9] S. Frixione, B. Weber, and P. Nason. MC@NLO generator version 3.4. _hep-ph/0204244 and hep-ph/0305252_, 2002.
* [10] S. Moch and P. Uwer. Heavy-quark pair production at two loops in QCD. _Phys. Rev._, D**78**(034003 (arXiv : 0807.2794)), 2008.
* [11] L.M. Mangano. Alpgen, a generator for hard multiparton process in hadronic collisions. _JHEP_, 0307(001), 2003. Available from World Wide Web: [http://arxiv.org/abs/hep-ph/0206293](http://arxiv.org/abs/hep-ph/0206293).