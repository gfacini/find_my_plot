# Expected performance of the ATLAS detector at the High-Luminosity LHC

The ATLAS Collaboration

The High-Luminosity LHC (HL-LHC) will deliver proton-proton collisions at a center-of-mass energy of \(\sqrt{s}=14\) TeV with a baseline instantaneous luminosity of \(5\cdot 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) and an ultimate achievable instantaneous luminosity of \(7.5\cdot 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\). The ATLAS detector is being upgraded for the HL-LHC running conditions to support a broad physics program in the presence of significantly increased pileup and more than a decade of data-taking. A comprehensive campaign to understand the physics reach of the experiment at the HL-LHC and a possible higher energy LHC (HE-LHC) is underway. This note provides a reference for the ATLAS detector performance for the physics projections that are included in the HL/HE-LHC Yellow Report, including documenting the assumptions made regarding the reconstruction and identification of physics objects and systematic uncertainties for the full anticipated dataset.

## 1 Introduction

The LHC physics program has just completed the Run 2 data-taking period and is heading, after a Phase-I upgrade, towards its Run 3 data-taking, as shown in Figure 1. A Phase-II upgrade is scheduled following Run 3 to further develop the LHC into the High-Luminosity LHC (HL-LHC). [1]

The upgraded HL-LHC will deliver proton-proton collisions at a center-of-mass energy of \(\sqrt{s}=14\) TeV with a baseline instantaneous luminosity of \(5\cdot 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) and an ultimate achievable instantaneous luminosity of \(7.5\cdot 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\). This will potentially increase the average pileup \(\langle\mu\rangle\), or the number of collisions per bunch crossing, to approximately 200. The HL-LHC will enable the ATLAS experiment to increase the collected integrated luminosity by approximately an order of magnitude throughout its operation, reaching an integrated luminosity of about 3000 fb\({}^{-1}\) (4000 fb\({}^{-1}\) in the "ultimate" scenario). This dataset holds tremendous potential for advances to precision measurements of Standard Model (SM) processes, with particular emphasis on probing the Higgs and electroweak sectors, and to searches for physics Beyond the Standard Model (BSM). Realizing this potential requires upgrades to the ATLAS experiment in the form of the Phase-II upgrade [2; 3] to enable sufficient performance in the face of the more challenging experimental conditions expected at the HL-LHC while also increasing radiation hardness and replacing aging detector components.

The planned ATLAS upgrades have been driven by the physics goals of the collaboration to optimize physics output. A comprehensive campaign to understand the physics reach of the experiment in the face of HL-LHC conditions is underway. The work began with the design of the detector upgrades, and a significant amount of performance projections can therefore be found in the various Technical Design Reports that the ATLAS Collaboration has produced to document the design and performance of upgraded components to the detector. Expected performance estimates of both the HL-LHC and, further, the hypothetical High-Energy LHC (HE-LHC) upgrade with an assumed center-of-mass energy of \(\sqrt{s}=27\) TeV and a total integrated luminosity of 15 ab\({}^{-1}\)[4] comprise the CERN HL/HE-LHC Yellow Report. While the HL-LHC was the focus of the ATLAS studies, a limited set of projections include an estimate for the HE-LHC.

The purpose of this note is to provide a reference for ATLAS physics projections that are included in

Figure 1: Timeline for the LHC accelerator operation and planned upgrades.

this Yellow Report, documenting the performance assumptions made regarding the reconstruction and identification of physics objects and systematic uncertainties.

The organization of this document is as follows:

* Section 2 includes brief descriptions of the upgrades outlined in the ATLAS Technical Design Reports that correspond to the ATLAS detector at the HL-LHC.
* Section 3 includes a description of the various strategies that are used for physics projections and the strategy employed for estimating systematic uncertainties.
* Section 4 describes the expected performance for ATLAS at the HL-LHC for various physics objects and event-level quantities that are used in analysis projections, including the assumed systematic uncertainties.

## 2 ATLAS detector upgrades

### Inner Tracker

The ATLAS Inner Tracker will be completely replaced for Phase-II operations to provide excellent tracking in the face of the high-pile environment expected at the HL-LHC. The new silicon-only design (ITk) will achieve improved momentum resolution for reconstructed tracks and extend the \(|\eta|\) coverage from \(|\eta|<2.5\) to \(|\eta|<4.0\) with a lower material budget than in Run 2. A silicon pixel detector composed of 5 barrel layers will be placed closest to the beamline. A silicon strip detector with 4 barrel layers will extend tracking out to higher radii. A series of rings will extend coverage to the forward region. These upgrades are described in detail in the Pixel Detector Technical Design Report [5] and the Silicon Strip Detector Technical Design Report [6]. The inner tracker layout named "Inclined Duals" was the baseline for the Pixel Technical Design Report and is widely used for performance studies presented in this note. The pixel pitch size was set to \(50\times 50\)\(\mu\)m\({}^{2}\).

### Calorimeters

The ATLAS Liquid Argon (LAr) Calorimeter will have entirely new frontend and readout electronics optimized to withstand radiation conditions for the duration of Phase-II running. The electronics architecture is designed to output full-granularity digitized signals at 40 MHz. These upgrades will combat Phase-II conditions with active pileup correction techniques using nearby bunch crossings to maintain an excellent energy resolution over a wide dynamic range. These upgrades are described in detail in the Liquid Argon Calorimeter Technical Design Report [7].

The ATLAS Tile Calorimeter will use new frontend and readout electronics, power supplies, and optical link interface boards to withstand increased radiation conditions for the duration of Phase-II running. These upgrades are described in detail in the Tile Calorimeter Technical Design Report [8].

### Muon Spectrometer

A large fraction of the ATLAS Muon Spectrometer frontend and on- and off-detector readout and trigger electronics will be replaced to enable higher trigger rates and longer latencies. Additional muon chambers will be installed to maintain muon identification and reconstruction performance, increase trigger acceptance, and suppress the rate of random coincidences. The possibility to extend the muon acceptance to \(|\eta|<4\) is still under study (high-\(\eta\) tagger), although most performance results presented to date for HL-LHC studies do not yet take possible improvements from this extension into account in their projections. These upgrades are described in detail in the Muon Spectrometer Technical Design Report [9].

### Trigger & Data Acquisition

The detector upgrades present new requirements and new opportunities for the Trigger and Data Acquisition (TDAQ) systems. ATLAS will use a two-level TDAQ design as a baseline; a 'Level-0' hardware trigger leads to detector readout of 1 MHz for luminosities up to \(7.5\cdot 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) and a processing farm, the 'Event filter' (EF), reduces the output data rate to 10 kHz. The design supports an evolved architecture with track-based triggers running at 4 MHz. The HL-LHC TDAQ system is described in detail in the TDAQ Technical Design Report [10].

The hardware trigger system is largely redesigned and allows for higher data granularity and enhanced flexibility beyond what will be afforded during the Run 3 data taking. Increased tracking functionality allows single object trigger thresholds to be kept low and assists pileup mitigation for the very challenging hadronic signatures at the HL-LHC. The baseline TDAQ architecture includes a Hardware Tracker (HTT) sitting in parallel to the processing farm in the EF; the HTT provides the EF with tracks that would not have been reconstructible otherwise due to the required computing resources. The HTT works in two modes: one reconstructs tracks in regions of interest and one performs full-event tracking. Both implementations use the same hardware that is customised according to the needs of each.

### High-Granularity Timing Detector

The ATLAS High-Granularity Timing Detector (HGTD), which will precisely measure the timings of charged particles, will be installed covering \(2.4<|\eta|<4.0\) in front of the LAr calorimeter to reduce background from pileup jets, as the increased pileup expected in high-luminosity running will require additional mitigation strategies. A timing resolution of 30 ps for minimum-ionizing particles is expected. These upgrades are described in detail in the HGTD Technical Proposal [11]. Most performance results presented to date for HL-LHC studies do not yet take possible improvements from the HGTD into account in their projections.

## 3 Projection strategies

Different approaches have been used to assess the sensitivity of the ATLAS experiment at the HL-LHC and HE-LHC. For some of the projections, a mix of the approaches described below is used, in order to deliver the most realistic result. The total integrated luminosity for the HL-LHC dataset is assumed to be 3000 fb\({}^{-1}\) at a center-of-mass energy of \(\sqrt{s}=14\) TeV. For HE-LHC studies the same expecteddetector performance is assumed as the Phase-II ATLAS detector, but in a hypothetical accelerator with an assumed center-of-mass energy of \(\sqrt{s}=27\) TeV and total integrated luminosity of \(15\) ab\({}^{-1}\).

The effect of systematic uncertainties is taken into account based on the studies performed for the Run 2 analyses and using common guidelines for projecting the expected improvements that are foreseen owing to the large dataset and upgraded detectors, as described in Section 3.1.

**Detailed simulations** are used to assess the performance of reconstructed objects in the upgraded detectors and HL-LHC conditions, as described in Section 2. For some of the projections, such simulations are directly interfaced to different event generators, parton showering (PS) and hadronisation generators. Monte Carlo (MC) generated events are used for SM and BSM processes, and are employed in the various projections to estimate the expected contributions of each process.

**Extrapolations** rely on existing results with event statistics scaled to the HL-LHC luminosity to estimate the expected sensitivity. The increased center-of-mass energy and the performance of the upgraded detectors are taken into account for most of the extrapolations using scale factors on the individual processes contributing to the signal regions. Such scale factors are derived from the expected cross sections and from detailed simulation studies. This technique benefits from the full complexity of the existing analysis, which often includes data-driven background methods and has been optimized for performance. However, relying on current signal and control region selections, efficiencies, acceptances, object reconstruction and identification, etc. does not fully account for possible improvements and challenges expected with an upgraded detector and HL-LHC conditions.

**Parametric simulations** are used for some of the projections to allow a full re-optimization of the analysis selections that profit from the larger available datasets without requiring all samples to be simulated in HL-LHC conditions, which is computationally expensive. Particle-level definitions are used for electrons, photons, muons, taus, jets and missing transverse momentum. These are constructed from stable particles of the MC event record with a lifetime larger than \(0.3\cdot 10^{-10}\) s within the observable pseudorapidity range. Jets are reconstructed using the anti-\(k_{t}\) algorithm [12] implemented in the FastJet[13] package, with a radius parameter of \(R=0.4\). All stable final-state particles are used to reconstruct jets except for the neutrinos, leptons and photons associated to \(W\) or \(Z\) boson or \(\tau\) lepton decays. The effects of an upgraded ATLAS detector are taken into account by applying energy smearing, efficiencies and fake rates to generator-level quantities, following parameterisations based on detector performance studies with the detailed simulations. The effect of high pileup at the HL-LHC is incorporated by overlaying minimum-bias events with \(\langle\mu\rangle=200\) onto the hard-scatter events. Jets from pileup are then randomly selected as jets to be considered for analysis.

### Systematic uncertainties

It is a significant challenge to predict the expected systematic uncertainties of physics results at the end of HL-LHC running. In almost all cases it would be pessimistic to assume a similar performance as seen in Run 2 given the very large increase in integrated luminosity, resulting in vastly larger data samples of the control processes used to measure the energy scales, resolutions and efficiencies of the different physics objects. In addition, it is reasonable to anticipate improvements to techniques of determining systematic uncertainties over an additional decade of data-taking. To estimate the expected performance, experts in the various physics objects and detector systems have studied current limitations to systematic uncertainties in detail to determine which contributions are limited by statistics and where there are more fundamental limitations. Predictions were made taking into account the increased integrated luminosity and expected potential gains in technique. These recommendations, often referred to in projections as the "baseline", were then harmonized with CMS to take advantage of a wider array of expert opinions and to allow the experiments to make sensitivity predictions on equal footing. In some cases there were additional sets of assumptions explored, referred to as "optimistic" scenarios, to reflect particular potential improvements that could be foreseen. The expected systematic uncertainties are reported along with object performance in the following sections.

Several general principles were defined for assessing the expected statistical, theoretical, and experimental uncertainties:

* Uncertainties due to statistics of available Monte Carlo simulation are set to zero for projections. As with other sources of uncertainty, the level of available Monte Carlo statistics in 2035 is difficult to predict. A clearer understanding of the fundamental potential of ATLAS in the HL-LHC can be found by de-coupling this potential source of uncertainty. In some cases, where experience from current running has shown the level of Monte Carlo simulation statistics to be a significant concern, a comparison is done between the "baseline" scenario with zero uncertainty, and a scenario assuming an effective Monte Carlo luminosity (number of events) equal to 1.5 times what will be available for the data.
* The intrinsic statistical uncertainty in measurements for extrapolated analyses scales with \(1/\sqrt{\mathrm{L}}\), where L is the projection's integrated luminosity divided by that of the reference Run 2 analysis.
* If predictions from theory do not change from current precision, systematic uncertainties from modeling would dominate for many of the HL-LHC projections. In some cases theorists have provided a detailed description of expected performance, such as for parton distribution functions. In other cases, analyses are performed making simple assumptions, with a default decision to divide the theory uncertainties, both inclusive cross-sections as well as modeling uncertainties, by a factor of two. Results are shown with theory and experimental systematic uncertainties defined so that the impact of the decisions can be clearly seen.
* Systematics driven by intrinsic detector limitations are left unchanged, or revised according to detailed simulation studies of the upgraded detector.
* Uncertainties on methods, as for instance non-statistical uncertainties on data-driven techniques, are kept at the same value as in the latest public results available, assuming that the harsher HL-LHC conditions will be compensated for by improved techniques for evaluating systematic uncertainties.
* In the case where a parametric simulation is done, only the leading sources of systematic uncertainties are often considered. For the extrapolations based on Run 2 analyses, a more complete set of nuisance parameters is available, though, again, a focus is placed on the largest sources of uncertainty.

#### 3.1.1 Parton distribution functions

For analyses where an accurate knowledge of the proton Parton Distribution Functions (PDFs) makes a significant difference in sensitivity, scale factors are used to estimate the expected HL-LHC PDF uncertainties achievable by the end of the HL-LHC physics program. The projected PDFs have been estimated from assumptions on the measurement uncertainties achievable after HL-LHC on key SM processes and re-evaluating the resulting PDFs. A set of PDFs with reduced uncertainties as well as a set of scale factors to apply as a ratio of the current uncertainties (PDF4LHC15) versus expected uncertainties are provided in Ref. [14]. There are two scenarios given: the conservative scenario assumes that there will be no reduction in the experimental systematic errors and the optimistic scenario assumes a reduction by a factor of 2.5 in the experimental systematic errors. The obtained scale factors are reported in Table 1.

## 4 Expected performance

### Luminosity

The peak instantaneous luminosity for the HL-LHC dataset is expected to be \(\approx 5\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\), with a corresponding average of approximately 140 interactions per bunch crossing [1]. The HL-LHC is expected to produce a total integrated luminosity of 250 fb\({}^{-1}\) per year and 3000 fb\({}^{-1}\) in its 12-year lifetime [1]. An ultimate instantaneous luminosity of \(\approx 7.5\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\), corresponding to approximately 200 interactions per bunch-crossing, is foreseen as ultimately achievable, which makes this higher level of pileup the appropriate target for the ATLAS upgrades.

Physics analyses would benefit from an uncertainty on the full dataset integrated luminosity as low as 1-1.5%. An ambitious goal of 1% has been assumed in the physics studies for the Yellow Report, compared with about 2% typically achieved at Run 1 or Run 2. This target uncertainty is extremely challenging, taking into account the more difficult experimental conditions (particularly the average pileup \(\langle\mu\rangle\) of 200) expected at HL-LHC. It will be pursued profiting from the experience from previous runs, hardware upgrades to the Beam Conditions Monitor (BCM) and Luminosity Cherenkov Integrating Detector (LUCID), and the new HGTD. The new BCM will be mounted on a ring within the pixel detector of the ITk and will have smaller sensor pads to accommodate higher occupancy levels at \(\langle\mu\rangle\approx 200\). The LUCID-3 detector is foreseen to use quartz fibre bundles in place of quartz counters. The HGTD will have a bunch-by-bunch luminosity capability, and should have excellent linearity owing to the relatively low occupancy. In addition to these detectors, the LAr and Tile calorimeters, and measurements based on track-counting and reconstructed Z-boson counting, will be used to monitor the long-term stability of the various luminosity measurements, and the linearity between the low-luminosity VdM scans used to establish the absolute calibration and the physics data-taking regime.

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline PDFs: HL-LHC/Current & 10 GeV \(<M_{X}<\) 40 GeV & 40 GeV \(<M_{X}<\) 1 TeV & 1 TeV \(<M_{X}<\) 6 TeV \\ \hline \hline gluon-gluon luminosity & 0.58 (0.49) & 0.41 (0.29) & 0.38 (0.24) \\ quark-gluon luminosity & 0.71 (0.65) & 0.49 (0.42) & 0.39 (0.29) \\ quark-quark luminosity & 0.78 (0.73) & 0.46 (0.37) & 0.60 (0.45) \\ quark-antiquark luminosity & 0.73 (0.70) & 0.40 (0.30) & 0.61 (0.50) \\ up-strange luminosity & 0.73 (0.67) & 0.38 (0.27) & 0.42 (0.38) \\ \hline \end{tabular}
\end{table}
Table 1: Expected scale factors for PDF uncertainties are given for two scenarios. The conservative scenario assumes that no improvements will be achieved in experimental systematic errors, and the optimistic scenario (in parentheses) assumes a reduction in experimental systematic errors by a factor of 2.5. [14]

### Trigger

An initial baseline trigger menu (see Table 2) has been developed to enable a diverse physics program at the HL-LHC that supports precision measurements at the electroweak scale and a wide array of BSM searches. The menu includes reasonably low-momentum electrons and muons, coupled with a comprehensive set of hadronically-decaying tau lepton triggers, missing-transverse-momentum (\(E_{\mathrm{T}}^{\mathrm{miss}}\)) triggers, and jet triggers, including massive large radius (large-\(R\)) jet triggers, all built into a flexible menu with contingencies to allow for new ideas. Generally, trigger selections are planned to have thresholds similar to, or below, what we have in the current data taking with a notable exception being the multi-jet and \(E_{\mathrm{T}}^{\mathrm{miss}}\) triggers, which become particularly challenging in high-pileup environments. In addition to the items listed in the menu, several dedicated selections have been explored. For example, most B-physics trigger signatures are based on 6 GeV dimuon triggers, as in Run 2, with additional mass and vertex selections.

There are a number of examples where significant improvements can be found in trigger performance due to the HL-LHC TDAQ upgrades. There are significant improvements in muon trigger efficiencies due to

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline  & Run 1 & Run 2 (2017) & Planned \\ Trigger & Offline \(p_{\mathrm{T}}\) & Offline \(p_{\mathrm{T}}\) & HL-LHC \\ Selection & Threshold & Threshold & Offline \(p_{\mathrm{T}}\) \\  & [GeV] & [GeV] & Threshold [GeV] \\ \hline \hline isolated single \(e\) & 25 & 27 & 22 \\ isolated single \(\mu\) & 25 & 27 & 20 \\ single \(\gamma\) & 120 & 145 & 120 \\ forward \(e\) & & & 35 \\ di-\(\gamma\) & 25 & 25 & 25 \\ di-\(e\) & 15 & 18 & 10 \\ di-\(\mu\) & 15 & 15 & 10 \\ \(e-\mu\) & 17,6 & 8,25 / 18,15 & 10 \\ single \(\tau\) & 100 & 170 & 150 \\ di-\(\tau\) & 40,30 & 40,30 & 40,30 \\ single \(b\)-jet & 200 & 235 & 180 \\ single jet & 370 & 460 & 400 \\ large-\(R\) jet & 470 & 500 & 300 \\ four-jet (w/ \(b\)-tags) & & 45(1-tag) & 65(2-tags) \\ four-jet & 85 & 125 & 100 \\ \(H_{\mathrm{T}}\) & 700 & 700 & 375 \\ \(E_{\mathrm{T}}^{\mathrm{miss}}\) & 150 & 200 & 210 \\ VBF inclusive & & & 2x75 w/ (\(\Delta\eta>2.5\) \\ (di-jets) & & & \& \(\Delta\phi<2.5\)) \\ \hline \end{tabular}
\end{table}
Table 2: Representative trigger menu for ATLAS operations at the HL-LHC. The offline thresholds indicate the momentum above which a typical analysis would use the data. Where multiple object triggers are described only one threshold is given if both objects are required to be at the same \(p_{\mathrm{T}}\); otherwise, each threshold is given with the two values separated by a comma. In the case of the \(e-\mu\) trigger in Run 2, two sets of thresholds were used depending on running period, and both are listed. This table is a subset of Table 6.4 from the TDAQ TDR [10].

increased resistive plate chamber coverage, with single muon trigger efficiencies going from \(\approx 70\%\) (Run 2) to \(\approx 90\%\) (HL-LHC) for \(|\eta|<1.05\). The coverage maps are shown in Figure 2 and Figure 2 for Phase-I and the HL-LHC respectively. This change brings a particularly large benefit to analyses that rely on multi-muon triggers. Additional examples of improvements include multijet triggers and single electrons, which benefit from the architecture changes that include the introduction of a new global trigger in the first trigger level and/or the presence of the HTT.

### Track reconstruction

The tracking performance benefits from the entirely new all-silicon detector that will be installed for HL-LHC running. This detector extends the tracking range in \(\eta\) from \(|\eta|<2.5\) in Run 2 to \(|\eta|<4.0\). The new tracker has a relatively low material budget and provides excellent tracking efficiency and resolution. The tracking efficiency for 10  muons, pions and electrons is shown in Figure 3. Transverse momentum (\(q/p_{\mathrm{T}}\)) resolution and impact parameter (\(d_{0}\)) resolution for muons of representative transverse momentum (\(p_{\mathrm{T}}\)) values are shown in Figures 4 and 4 respectively.

Recent studies have shown that the material budget of the ITk detector was underestimated at the time of the TDR writing, so these results may be optimistic. A careful re-tuning and re-optimization is underway. Some analyses, such as lifetime measurements, analyses with a strong reliance on b-tagging, and other B-physics projections, are particularly sensitive to tracking and vertexing performance. In many of these cases the results have been evaluated with both the TDR-predicted performance and Run 2 performance in order to quantify the sensitivity to tracking and vertexing.

### Electrons

Electron reconstruction and identification benefit from the expected excellent track reconstruction performance of the new inner tracker and its lower material budget as well as its extension to higher \(|\eta|\). The identification requirements have been re-tuned for the new inner tracker and expected HL-LHC conditions and were studied in Ref. [7] and [5]. The \(p_{\mathrm{T}}\)-dependent electron reconstruction and identification efficiencies measured with the ITk for the three identification working points of loose, medium and tight

Figure 2: Muon trigger coverage in the barrel region (\(|\eta|<1\)) using (a) the Phase-I system in HL-LHC conditions and (b) the Phase-II system with resistive plate chambers operated with a two-station coincidence. Figures 6.5 (a,c) from the TDAQ TDR [10].

are shown in Figure 5 for the central (\(0<|\eta|<2.5\)) region. The charge mis-identification probability for central electrons as a function of \(\eta\) is shown in Figure 5, where the effect of a tight identification requirement and the Run 2 performance are also shown for comparison. Furthermore, the performance of an artificial neural network for forward electron identification is shown in Figures 6 (\(Z\to ee\) efficiency) and 6 (truth jet fake rates for loose, medium, and tight working points).

The baseline systematic uncertainty assumption for electrons is that they will remain stable despite the harsher conditions of the HL-LHC, yielding to similar uncertainties as in Run 2. Uncertainties on isolation are expected to slightly decrease due to better understanding of the methods and detectors and yielding a

Figure 4: Track parameter resolution in \(q/p_{\mathrm{T}}\) as a function of \(\eta\) for a single muon sample. Overlaid are the results for the current Run 2 detector. Figure 3.6 from the Pixel Detector TDR [5]. (b) \(d_{0}\) resolution as a function of \(\eta\) for a single muon sample. Overlaid are the results for the current Run 2 detector. Figure 3.6 from the Pixel Detector TDR [5].

Figure 3: Track reconstruction efficiency for single muons, pions and electrons with a constant transverse momentum of \(p_{\mathrm{T}}\) = 10 GeV. Figure 3.3 from the Pixel Detector TDR [5].

Figure 5: (a) Electron efficiency for the various working points for a \(Z\to ee\) simulated sample with \(\langle\mu\rangle\) = 200 in the region \(|\eta|\) ¡ 2.5. Figure 3.26(b) from the Pixel Detector TDR [5]. (b) Electron charge mis-identification probability as a function of \(|\eta|\).

Figure 6: Forward (\(2.5<|\eta|<4.0\)) electron identification neural network performance as a function of truth \(p_{\mathrm{T}}\): (a) efficiency of electrons from simulated \(Z\to ee\) events and (b) fake rate of simulated jets.

lower uncertainty on the combination of the reconstruction, identification and isolation efficiency, from present values based on studies performed by CMS. Representative values of uncertainties are shown in Table 3.

### Muons

Improvements to the inner tracker and increased coverage of the muon detectors result in a higher acceptance for combined muons and improved resolution for low-to-medium muons. The muon momentum resolution is shown in Figure 7(a) and the improvement to the invariant mass resolution for Higgs decays to two and four muons is shown in Figure 7(b). In parametric simulations, the impact of isolation was established by imposing isolation on the particles in the Monte Carlo "truth" record. Expected track-based isolation efficiencies for prompt and secondary muons are shown in 8(a) and 8(b) as a function of and of the muon, though the isolation used was not fully tuned for high-pileup so further improvements can be expected. The reconstruction efficiency is taken from single muon Monte Carlo simulated with Run 2 reconstruction algorithms [16] running on a geometry that includes the Phase-II ITk with the Run 2 muon spectrometer. The ITk's extended range allows the "combined muon" category, which matches a muon track or stub in the muon spectrometer to a track in the inner detector, to extend from the Run 2 value of < 2.5 to.

Uncertainties in muon reconstruction, identification, isolation efficiency, momentum scale, and momentum resolution are very well under control already. It is expected that the same accuracy can be maintained for the large HL-LHC dataset. Systematic uncertainties on muon-related performance from Run 2, which are used for HL-LHC projections, are summarized in Table 4 within the range.

\begin{table}
\begin{tabular}{|c|c|c|} \hline Electron Parameter & Range & Uncertainty \\ \hline \hline Energy scale & \(p_{\mathrm{T}}\approx\) 45 GeV & 0.1\% \\  & high, up to 200 GeV & 0.3\% \\ Reconstruction + Identification Efficiency (ID) & \(p_{\mathrm{T}}\approx\) 45 GeV & 0.5\% \\ Reconstruction + ID + Isolation Efficiency & \(p_{\mathrm{T}}\) > 200 GeV & 2\% \\ \hline \end{tabular}
\end{table}
Table 3: Representative values for systematic uncertainties for electrons at the HL-LHC. These uncertainties are consistent with the Run 2 uncertainties with the exception of the combination of the reconstruction, identification and isolation efficiency at high (above 200 GeV), where dedicated studies at CMS were used as an ATLAS approximation. [15]

\begin{table}
\begin{tabular}{|c|c|c|} \hline Muon Parameter & Range & Run 2 Uncertainty \\ \hline \hline Reconstruction + Identification Efficiency & \(p_{\mathrm{T}}\) < 200 GeV & 0.1\% \\  & 200 GeV \(<p_{\mathrm{T}}\) < 1 TeV & 2-20\% \\ Resolution & \(p_{\mathrm{T}}\) < 200 GeV & 5\% \\  & 200 GeV \(<p_{\mathrm{T}}\) < 1 TeV & 10-20\% \\ Energy Scale & \(p_{\mathrm{T}}\) < 200 GeV & 0.05\% \\ Isolation Efficiency & All working points & 0.5\% \\ \hline \end{tabular}
\end{table}
Table 4: Run 2 systematic uncertainties for muons, which are also assumed for ATLAS running at the HL-LHC. [15]

Figure 8: Efficiency for a track-based isolation requirement that is \(p_{\mathrm{T}}\)-dependent for prompt muons and secondary backgrounds within \(|\eta|\) < 2.7 versus (a) \(|\eta|\) and (b) \(p_{\mathrm{T}}\). Figure 3.28 in the Pixel Detector TDR [5].

Figure 7: (a) Combined muon momentum resolution and the individual contributions from the ITk and the upgraded Muon Spectrometer, with the Run 2 comparison included. Figure 3.26(a) from the Pixel Detector TDR [5]. (b) Di-muon (green) and four-muon (blue) mass resolution for Higgs decays to muons. Figure 3.31 from the Pixel Detector TDR [5].

### Taus

The reconstruction and identification of tau leptons that decay semi-hadronically (\(\tau_{\text{had-vis}}\)) benefits from the ITk detector, with its excellent tracking performance and extension to higher \(\eta\) ranges. The identification algorithms have been re-optimized for the upgrade detector and studied in Ref. [5]. Since then, a more accurate assessment of the expected performance has been carried out, which has been used for the studies in the Yellow Report. The identification efficiency for 1-prong (one charged track) and 3-prong (multiple charged tracks) \(\tau_{\text{had-vis}}\) candidates using simulated \(Z\to\tau\tau\) events are shown in Figures 9(a) and 9(b) respectively for the loose, medium, and tight working points. The jet rejection is shown for both 1-prong and 3-prong \(\tau_{\text{had-vis}}\) candidates at the various working points in Figures 10(a) and 10(b) respectively, as a function of efficiency for candidates above a \(p_{\text{T}}\) of 20 GeV. Current optimizations show the rejection in the HL-LHC optimization out-performing Run 2 in all eta regions except the far-forward region where there is no Run 2 comparison point available.

The systematic uncertainties for \(\tau_{\text{had-vis}}\) candidates have been estimated from Run 2 systematics by scaling down the sources of uncertainty that are driven by statistics, which will improve at the HL-LHC, and making educated assumptions about how the theory and modeling uncertainties are likely to change.

For analyses that are using truth-based projections, the uncertainty on the \(\tau_{\text{had-vis}}\) identification efficiency is taken as 5%, where an optimistic scenario of 2.5% has also been defined. The energy scale uncertainty is conservatively assumed to be at the level of 2-3%.

For projections coming from current analyses, the following scale factors for adjusting the systematic uncertainties have been provided:

* The scale factor to apply to Run 2 systematic uncertainties on tau identification efficiency for 1-prong taus is 0.9 (0.45) in the baseline (optimistic) scenario.

Figure 9: Tau identification efficiency for the three working points (Loose, Medium, and Tight) as a function of \(\eta\) for reconstructed \(\tau_{\text{had-vis}}\) candidates, shown for (a) one-prong and (b) three-prong tau leptons.

* The scale factor on the _in situ_ uncertainty on the tau energy scale is 0.6, which is found by taking the current measurements and setting the sources of statistical uncertainty equal to zero.

Other tau lepton-related systematic uncertainties are expected to remain similar to what they are in Run 2.

### Photons

Figure 11 illustrates the expected energy resolution of photons under \(\langle\mu\rangle=0\) and \(\langle\mu\rangle=200\) pileup conditions, assuming the same reconstruction techniques as those currently employed in Run 2. The resolution is shown only for unconverted photons in the barrel region of the detector (\(|\eta|<0.8\)). The level of electronics noise simulated is that of the existing LAr readout. The photon resolution curves obtained at \(\langle\mu\rangle=0\) and \(\langle\mu\rangle=200\) are subtracted in quadrature in order to illustrate the size of the pileup-only contribution to the photon resolution.

The expected energy resolution is further quantified for the benchmark physics process \(H\to\gamma\gamma\) in Figure 12, showing the expected di-photon mass resolution. Figure 12 shows the effect of pileup on the expected resolution, as well as the comparison with Run 2. Two scenarios for energy resolution, an optimistic one and a pessimistic one, are considered. The optimistic scenario assumes that the statistics available with the HL-LHC will allow for the global constant term to be at 0.7%, which is its design value, while the pessimistic scenario uses the constant term found with 2015 data at 1% in the barrel and 1.4% in the endcap. The scenarios also differ in their treatment of pileup noise with the pessimistic approach using a value consistent with untuned current reconstruction algorithms with full simulation of \(\langle\mu\rangle=200\)

Figure 10: Jet rejection as a function of \(\tau_{\text{had-vis}}\) efficiency for the algorithm optimized for HL-LHC detector and conditions (“HL-LHC tuning”) for \(\tau_{\text{had-vis}}\) candidates with a \(p_{\text{T}}\) above 20 GeV and within \(|\eta|<4.0\) (solid blue), \(|\eta|<2.5\) (dark dashed blue), and \(2.5<|\eta|<4.0\) (dashed light blue), compared to the Run 2 performance optimized for the Run 2 detector and conditions (“Run 2 performance”) for \(\tau_{\text{had-vis}}\) candidates within \(|\eta|<2.5\) (solid black), shown for (a) one-prong and (b) three-prong tau leptons.

and the optimistic approach assuming that future offline corrections can reduce this to the equivalent of the performance of full simulation with \(\langle\mu\rangle\) = 75. It is worth noting that the lower material budget of the upgraded inner detector results in more unconverted photons, which have a better energy resolution than the converted ones. Figure 12(b) compares different hard-scatter vertex selection strategies to show the robustness against the performance of such identification algorithms; the pointing capability of the LAr calorimeter allows for a good mass resolution to be preserved in spite of the high level of pileup.

The baseline systematic uncertainty assumption for photons is that they will remain unchanged from Run 2 values at the HL-LHC, with the exception of the combination of the reconstruction, identification and isolation efficiency, which is reduced from the Run 2 value with a scale factor of 0.8. The reduction comes from expected improvements in the understanding of the current methodology and, to a smaller degree, the increased dataset available. Representative values of uncertainties are shown in Table 5. In analyses where uncertainties due to photons dominate, the impact of halving the uncertainties on the photon resolution and scales was explored.

Figure 11: Photon energy resolution expected under different pileup conditions, and contributions of pileup-only noise to the energy resolution. (Chapter 4, Figure 9 from the LAr TDR) [7].

\begin{table}
\begin{tabular}{|c|c|c|} \hline Photon Parameter & Range & Uncertainty \\ \hline \hline Energy scale & \(p_{\mathrm{T}}\approx\) 60 GeV & 0.3\% \\  & high \(p_{\mathrm{T}}\), up to 200 GeV & 0.5\% \\ Resolution & \(p_{\mathrm{T}}\approx\) 60 GeV & 10\% \\ Reconstruction + ID + Isolation & \(p_{\mathrm{T}}\) \(<\) 200 GeV & 2\% \\ \hline \end{tabular}
\end{table}
Table 5: Some representative values for systematic uncertainties for photons at the HL-LHC. These uncertainties are consistent with the Run 2 uncertainties with the exception of the combination of the reconstruction, identification and isolation, where a scale factor of 0.8 has been applied. [15]

### Jets

Jet reconstruction, as well as the separation between pileup and hard-scatter jets, benefits from the excellent tracking capabilities and extended \(\eta\) range of the ITk detector. At \(\langle\mu\rangle\) = 200, each event is expected to have on the order of 5 jets with \(p_{\mathrm{T}}>30\) GeV produced in pileup interactions. Several techniques to suppress such pileup jets based on tracking information have been developed in Run 1 and 2. The results presented in this section are based on the \(R_{p_{\mathrm{T}}}\) discriminant, which is defined as the sum of the transverse momentum of tracks associated to the jet that originates from the hard-scatter vertex over the jet \(p_{\mathrm{T}}\) (as measured by the calorimeter). Pileup jets will tend to have \(R_{p_{\mathrm{T}}}\) close to zero, while jets originating from the hard-scatter tend to have higher \(R_{p_{\mathrm{T}}}\) values. A pileup jet mitigation \(R_{p_{\mathrm{T}}}\) selection is applied for jets with \(p_{\mathrm{T}}\) <100 GeV and \(|\eta|<3.8\) that has a 2% selection efficiency for pileup jets. The expected number of pileup jets before and after this selection has been applied is shown as a function of \(\eta\) in Figure 13. The efficiency for jets originating from the hard-scatter interaction is shown versus pileup jet efficiency in Figure 13. More advanced taggers are expected to be developed in the HL-LHC timescale, likely enhancing significantly the pileup jets rejection capabilities.

The estimated relative jet \(p_{\mathrm{T}}\) resolution, which is to a very good approximation the same as the relative jet energy resolution, is presented in Figure 14 and the fractional jet mass resolution for trimmed, large radius jets (anti-\(k_{T}\), \(R=1.0\)) is presented in Figure 14. Projections use the expected performance for calorimeter jets; however Figure 14 shows that particle-flow jets, currently under study, have the potential to have better resolution in the low \(p_{\mathrm{T}}\) regime.

Each of the main components of the overall jet energy scale (JES) uncertainty are expected to remain constant or decrease in the transition from Run 2 to the HL-LHC. Two estimates are presented, a default labelled "baseline" and an "optimistic" estimate that assumes an improved understanding of the MC modelling of jet fragmentation and improved understanding of the effects of pileup on the JES. Figures 15 and 15 and Table 6 summarize the "baseline" and "optimistic" scenarios for the fractional uncertainties of the various components of the JES uncertainty.

Figure 12: Diphoton invariant mass for \(H\to\gamma\gamma\) events (a) obtained using data in Run 2, \(\langle\mu\rangle=0\) simulation and \(\langle\mu\rangle=200\) simulation at HL-LHC using the optimistic and pessimistic photon resolution scenarios, (b) for different algorithms used to choose the hard-scatter interaction primary vertex (Chapter 4, Figures 16 and 15 from the LAr TDR) [7].

Figure 14: (a) Relative jet resolution. (b) Fractional jet mass resolution for trimmed, large radius jets.

Figure 13: (a) Expected number of pileup jets per unit of pseudorapidity before and after pileup jet suppression. (b) Efficiency for jets originating from the hard scatter using the \(R_{p_{\mathrm{T}}}\) tagger. In both Figures, a selection based on the \(R_{p_{\mathrm{T}}}\) tagger is applied that achieves a 98% rejection of pileup jets (\(\epsilon_{\mathrm{PU}}=2\%\)) in the region of tracking coverage: \(|\eta|<3.8\).

Figure 15: (a) Baseline and (b) optimistic scenarios for HL-LHC jet energy scale uncertainties with a dijet-like flavour composition.

### Flavour tagging

Flavour tagging benefits from the excellent tracking and \(\eta\) coverage of the ITk detector. A multivariate algorithm [17] has been re-tuned for the expected ATLAS Phase-II detector and its performance assessed. The light-jet rejection versus \(b-\)jet efficiency is shown in various slices of \(\eta\) in Figures 16 and 16 along with a comparison with Run 2 performance.

The performance in \(t\bar{t}\) with \(\langle\mu\rangle=200\) is shown for light-jet rejection and c-jet, b-jet and pileup-jet efficiency in Figure 17 for the working point with an average b-jet efficiency of 70%. In the benchmark channel with \(HH\to\gamma\gamma bb\), the purity of b-jets when both jets are tagged is at the level of 97%.

The expected flavour tagging uncertainties have been derived extrapolating current performance and taking into account new methods that may be used in the future, especially at high-\(p_{\mathrm{T}}\) and large \(\eta\). The expected

\begin{table}
\begin{tabular}{|c|c|c|} \hline Uncertainty component & Percentage Uncertainty & Percentage Uncertainty \\  & (Baseline Estimate) & (Optimistic Estimate) \\ \hline \hline Absolute JES scale & 1\% - 2\% & 1\% - 2\% \\ Pileup & 0 - 4\% & 0 - 2\% \\ JET flavour composition & 0 - 1\% & 0 - 0.5\% \\ JET flavour response & 0 - 1.5\% & 0 - 0.8\% \\ \hline \end{tabular}
\end{table}
Table 6: Expected jet energy scale (JES) uncertainties at the HL-LHC in the “baseline” and “optimistic” scenarios.

Figure 16: Performance of the MV2 b-tagging algorithms in \(t\bar{t}\) events with 200 pileup for the ITk layout. Results are shown for 50\(\times\)50 \(\mu\)m\({}^{2}\) pixels, using digital clustering in the reconstruction. For comparison purposes, the performance for ATLAS during Run 2 with an average of 30 pileup events is shown as crosses. The rejection of (a) light-flavour jets and (b) c-jets for different \(\eta\) regions is shown as a function of b-jet efficiency. Figures 3.21 and 3.23 from the Pixel Detector TDR. [5]uncertainties on identification efficiency for \(b\)-jets, \(c\)-jets and light-jets are summarized in Table 7.

### Missing Transverse Energy (\(E_{T}^{\text{miss}}\))

The event \(E_{T}^{\text{miss}}\) is computed as the negative value of the vectorial sum of calibrated high-p\({}_{T}\) particles and jets, together with a soft-term. The soft-term is computed from reconstructed charged particles that are not associated to high-p\({}_{T}\) objects and are compatible with originating from the hard-scatter interaction.

\begin{table}
\begin{tabular}{|l|c|c|} \hline Uncertainty & Expected value at HL-LHC & Comments \\ \hline \(b\)-jet efficiency & 1\% & \(30<p_{\text{T}}<300\) GeV \\ \(b\)-jet efficiency & 2-6\% & \(p_{\text{T}}>300\) GeV \\ \(c\)-jet efficiency & 2\% & all working points \\ light-jet mistag & 5 - 15\% & working-point dependent \\ \hline \end{tabular}
\end{table}
Table 7: Representative values for systematic uncertainties for flavour tagging at the HL-LHC. [15]

Figure 17: MV2 algorithm performance in \(t\bar{t}\) events with a \(b\)-jet efficiency of 70% and \(\langle\mu\rangle=200\) of (a) the light flavour mistag rate, (b) c-jet efficiency, (c) b-jet efficiency, and (d) pileup jet efficiency.

Pileup jets are suppressed using the same tagger described in Section 4.8. The event \(E_{T}^{\rm miss}\) resolution depends strongly on the final state of the event in question. Detailed studies in \(t\bar{t}\) events with HL-LHC conditions were performed and the expected resolution of \(E_{T}^{\rm miss}\) in such events is shown in Figure 18, illustrating that forward tracking capabilities used in forward pileup jets rejection are crucial for \(E_{T}^{\rm miss}\) resolution.

The systematic uncertainties on all the hard objects used to form the \(E_{T}^{\rm miss}\) are propagated through the \(E_{T}^{\rm miss}\) calculation. These form the dominant systematic uncertainties on this quantity and are highly process- and analysis-dependent.

### Heavy ions

The Heavy Ion physics program is expected to continue at least throughout Run 4, and possibly beyond. The upgraded ATLAS detector is well equipped to take full advantage of such a dataset using dedicated tuning and reconstruction algorithms. The replacement of the ATLAS tracking detector, which extends the \(\eta\) coverage significantly (\(|\eta|<2.5\) becomes \(|\eta|<4.0\) for charged tracks), results in significant improvements for these measurements. Figures 19 and 20 show the expected charged particle reconstruction efficiency and track parameter resolution in minimum-bias (0-100% centrality) Pb+Pb collisions.

Additional improvements will be provided by the HGTD and Zero Degree Calorimeter (ZDC), but these improvements have not yet been taken into account in the HL-LHC studies.

Figure 18: The resolutions of \(E_{T}^{\rm miss}\) in Monte Carlo \(t\bar{t}\) events with an average of 200 pileup events. The resolutions are shown as a function of the scalar sum of the event transverse energy. Three variations of the \(E_{T}^{\rm miss}\) calculation are shown: first, only tracks within \(|\eta|<2.5\) are used for both the pile-up jet rejection and the track soft term (blue line); second, tracks are used for the full \(\eta\) coverage to reject pileup jets (red line); and third, forward tracks are used for both the pileup jet rejection and the track soft term (black line).

## 5 Conclusion

The HL-LHC will provide an unprecedented amount of integrated luminosity to the ATLAS experiment, which enables a wide range of physics to be explored. The ATLAS detector is well positioned to take full advantage of this dataset thanks to a series of upgrades to its sub-detectors.

In this note we summarize and reference the baseline expected performance of the upgraded ATLAS detector. Such performance assumptions are used in recent physics projection studies and will be a baseline reference for future ones. These studies heavily rely on the recent Phase-II Technical Design Reports (TDRs) but include some more recent developments that were not available at the time of the TDRs.

Additionally, many physics projections will be significantly limited by systematic uncertainties. Advancements in detector and theoretical understanding, together with the usage of such a large dataset in _in situ_ techniques, are expected to improve our knowledge and consequently reduce some of these uncertainties.

Figure 19: Track reconstruction efficiency as a function of (a) \(\eta\) and (b) \(p_{\mathrm{T}}\) in minimum bias (0–100% centrality) Pb+Pb collisions with the ITk upgrade. Figure 2 from Ref. [18].

Figure 20: Resolution of (a) track parameters \(d_{0}\) and(b) \(z_{0}\) as a function of \(\eta\) for a minimum track \(p_{\mathrm{T}}\) threshold of 0.4 GeV in minimum bias (0–100% centrality) Pb+Pb collisions with the ITk upgrade. Figure 3 from Ref. [18].

General guidelines, harmonized with the CMS Collaboration, as well as specific recommendations in terms of expected systematic uncertainties, have been presented.

## References

* [1] ed. G. Apollinari, I. Bejar Alonso (Executive Editor), O. Bruning., P. Fessia, M. Lamont, L. Rossi, L. Tavian, _High-Luminosity Large Hadron Collider (HL-LHC) Technical Design Report V. 0.1_, CERN-2017-007-M, url: [http://dx.doi.org/10.23731/CYRM-2017-004](http://dx.doi.org/10.23731/CYRM-2017-004).
* [2] ATLAS Collaboration, _Letter of Intent for the Phase-II Upgrade of the ATLAS Experiment_, CERN-LHCC-2012-022. LHCC-I-023, url: [https://cds.cern.ch/record/1502664](https://cds.cern.ch/record/1502664).
* [3] ATLAS Collaboration, _ATLAS Phase-II Upgrade Scoping Document_, CERN-LHCC-2015-020. LHCC-G-166, url: [https://cds.cern.ch/record/2055248](https://cds.cern.ch/record/2055248).
* European Strategy Update Documents_, tech. rep. CERN-ACC-2019-0006, CERN, 2019, url: [https://cds.cern.ch/record/2653676](https://cds.cern.ch/record/2653676).
* [5] ATLAS Collaboration, _Technical Design Report for the ATLAS Inner Tracker Pixel Detector_, CERN-LHCC-2017-021, url: [https://cds.cern.ch/record/2285585](https://cds.cern.ch/record/2285585).
* [6] ATLAS Collaboration, _Technical Design Report for the ATLAS Inner Tracker Strip Detector_, CERN-LHCC-2017-00, url: [http://cds.cern.ch/record/2257755](http://cds.cern.ch/record/2257755).
* [7] ATLAS Collaboration, _Technical Design Report for the ATLAS Liquid Argon Calorimeter_, CERN-LHCC-2017-018, url: [http://cds.cern.ch/record/2285582](http://cds.cern.ch/record/2285582).
* [8] ATLAS Collaboration, _Technical Design Report for the ATLAS Tile Calorimeter Phase-II Upgrade_, CERN-LHCC-2017-019, url: [http://cds.cern.ch/record/2285583](http://cds.cern.ch/record/2285583).
* [9] ATLAS Collaboration, _Technical Design Report for the ATLAS Muon Spectrometer Phase-II Upgrade_, CERN-LHCC-2017-017, url: [http://cds.cern.ch/record/2285580](http://cds.cern.ch/record/2285580).
* [10] ATLAS Collaboration, _Technical Design Report for the Phase-II Upgrade of the ATLAS Trigger and Data Acquisition System_, CERN-LHCC-2017-020, url: [https://cds.cern.ch/record/2285584](https://cds.cern.ch/record/2285584).
* [11] ATLAS Collaboration, _Technical Proposal: A High-Granularity Timing Detector for the ATLAS Phase-II Upgrade_, CERN-LHCC-2018-023, url: [http://cdsweb.cern.ch/record/2623663](http://cdsweb.cern.ch/record/2623663).
* [12] M. Cacciari, G. P. Salam and G. Soyez, _The anti-\(k_{t}\) jet clustering algorithm_, JHEP **04** (2008) 063, arXiv: 0802.1189 [hep-ph].
* [13] M. Cacciari, G. P. Salam and G. Soyez, _FastJet User Manual_, Eur. Phys. J. **C72** (2012) 1896, arXiv: 1111.6097 [hep-ph].
* [14] R. Abdul Khalek, S. Bailey, J. Gao, L. Harland-Lang and J. Rojo, _Towards Ultimate Parton Distributions at the High-Luminosity LHC_, Eur. Phys. J. **C78** (2018) 962, arXiv: 1810.03639 [hep-ph].
* [15]_High Luminosity LHC Systematics 2018_, ATLAS and CMS TWiki, url: [https://twiki.cern.ch/twiki/bin/view/LHCPhysics/HLHELHCCommonSystematics](https://twiki.cern.ch/twiki/bin/view/LHCPhysics/HLHELHCCommonSystematics).