# New supersymmetry mass reconstruction method at the CERN LHC

K. Kawagoe,\({}^{1}\) M. M. Nojiri,\({}^{2}\) and G. Polesello\({}^{3}\)

\({}^{1}\)Department of Physics, Kobe University, Kobe 657-8501, Japan

\({}^{2}\)YITP, Kyoto University, Kyoto 606-8502, Japan

\({}^{3}\)CERN, CH-1211 Geneva 23, Switzerland, and INFN, Sezione di Pavia, Via Bassi 6, 27100 Pavia, Italy

Received 21 October 2004; published 11 February 2005

###### Abstract

We propose a new mass reconstruction technique for SUSY processes at the LHC. The idea is to completely solve the kinematics of the SUSY cascade decay by using the assumption that the selected events satisfy the same mass shell conditions of the sparticles involved in the cascade decay. Using this technique, we study the measurement of the mass of the bottom squarks in the cascade decay of the gluino. Based on the final state including two high \(p_{T}\) leptons and two \(b\)-jets, we investigate different possible approaches to the mass reconstruction of the gluino and the two bottom squarks. In particular, we evaluate the performance of different algorithms in discriminating two bottom squark states with a mass difference as low as 5%.

DOI: 10.1103/PhysRevD.71.035008

## I Introduction

Supersymmetry is one of the most attractive models beyond the standard model (SM) of elementary particle physics. The superpartners of SM particles (sparticles) might have masses of the order of the TeV, and experiments at the Large Hadron Collider (LHC) should be able to detect such particles up to masses of 2\(-\)3 TeV [1, 2].

The pattern of the sparticle mass spectrum depends on the SUSY-breaking mechanism, which might depend on gravity, space-time structure, or unknown interactions. The unraveling of such a mechanism through the determination of the sparticles' masses is therefore one of the most important physics targets of future collider experiments.

The potential of the LHC for SUSY mass determination has been studied in detail in the past decade. The most promising method involves the study of the end points in the distributions of invariant masses among the visible sparticle decay products. Information on the masses involved in the cascade decay can be extracted from the end point values if the decay distributions are dominated by a single cascade decay chain. Studies based on the end points are documented in [1, 2, 3, 4, 5, 6, 7].

In this paper we explore a new method for reconstructing SUSY events. This method does not rely only on events near the end point. Instead, one kinematically solves the neutralino momenta and masses of heavier sparticles using measured jet and lepton momenta and optionally a few mass inputs.

We concentrate in this paper on the measurement of the mass of the bottom squarks (sbottoms) through the cascade decay:

\[\tilde{g}\rightarrow\tilde{b}b_{2}\rightarrow\tilde{\chi}_{2}^{0}b_{1}b_{2} \rightarrow\tilde{\ell}b_{1}b_{2}\ell_{2}\rightarrow\tilde{\chi}_{1}^{0}b_{1 }b_{2}\ell_{1}\ell_{2}. \tag{1}\]

We address this decay, rather than the equivalent cascade involving a generic \(\tilde{q}_{L}\) for various reasons. First of all, the physics of the third generation squarks and leptons is particularly important in disentangling the pattern of SUSY breaking. In the minimal supergravity (mSUGRA) model, \(\tilde{b}_{L}\) is lighter than \(\tilde{b}_{R}\) due to the renormalization group equation (RGE) running generated by the top Yukawa coupling. The mass of the lighter sbottom state \(\tilde{b}_{1}\) is further reduced by the mixing of the left and right \(\tilde{b}\) states. The sbottom sector is thus sensitive to fundamental parameters of the theory such as the trilinear couplings and tan\(\beta\) which are otherwise difficult to access at the LHC. The third generation sparticle masses are also important parameters for \(B\) and Higgs physics. Second, the chain in Eq. (1) involves two \(b\) quarks, which can be tagged in the detector. The problem of correctly identifying the jets contributing to the interesting decay is thus made much simpler. Finally, as we will discuss in detail below, both sbottom states \(\tilde{b}_{1}\) and \(\tilde{b}_{2}\) yield the decay chain of Eq. (1). The performance and the robustness of the reconstruction algorithms can be benchmarked against the ability in disentangling the two states.

Five sparticles are involved in the cascade decay Eq. (1); therefore one can write five mass shell conditions among the leptons and quarks in the final decay products.

\[\begin{split} m^{2}_{\tilde{\chi}_{1}^{0}}&=p^{2}_{ \tilde{\chi}_{1}^{0}},\qquad m^{2}_{\tilde{\ell}}=(p_{\tilde{\chi}_{1}^{0}}+p _{\ell_{1}})^{2},\\ m^{2}_{\tilde{\chi}_{2}^{0}}&=(p_{\tilde{\chi}_{1}^ {0}}+p_{\ell_{1}}+p_{\ell_{2}})^{2},\\ m^{2}_{\tilde{b}}&=(p_{\tilde{\chi}_{1}^{0}}+p_{ \ell_{1}}+p_{\ell_{2}}+p_{b_{1}})^{2},\\ m^{2}_{\tilde{\ell}}&=(p_{\tilde{\chi}_{1}^{0}}+p_{ \ell_{1}}+p_{\ell_{2}}+p_{b_{1}}+p_{b_{2}})^{2}.\end{split} \tag{2}\]

For a \(bb\ell\ell\) event, the equations contain the 4 unknown degrees of freedom of the \(\tilde{\chi}_{1}^{0}\) momentum. Each event therefore describes a four-dimensional (4D) hypersurface in the five-dimensional (5D) mass parameter space, and the hypersurface differs event by event. From the purely mathematical point of view, five events would be enough to determine a discrete set of solutions for the masses of the involved sparticles, and the probabilistic discussion of the following could be easily developed in a 5D space. In order to illustrate the method in a more transparent way, we will develop the argument by assuming that the masses of \(\tilde{\chi}_{2}^{0}\), \(\tilde{\ell}\)and \(\tilde{\chi}_{1}^{0}\) are known. This is a reasonable assumption at the LHC, where it has been shown that a detailed study of the lepton-lepton system from the \(\tilde{\chi}_{2}^{0}\) decay can be used to precisely constrain these masses [8]. In this case, each event corresponds to a different line in the \((m_{\tilde{g}},\,m_{\tilde{g}})\) plane; therefore two events are enough to solve the gluino and sbottom masses altogether.

We call this technique the "mass relation method," because here one uses the fact that sparticle masses are common for all events which go through the same cascade decay chain. Note that the events need not be close to the end point of the decay distribution in order to be relevant to the mass determination. This means that one can use the mass relation method even if the number of signal events is small.

The purpose of this paper is to explore in detail the implications of the mass relation method which is only sketched for signal events in [9]. In that report a measurement of the gluino and sbottom masses was obtained from the peak of the distribution of the solutions for all possible event pairs, assuming that the \(\tilde{\chi}_{2}^{0}\), \(\tilde{\ell}\), and \(\tilde{\chi}_{1}^{0}\) masses are known. In this paper we extend the previous analysis to take SUSY backgrounds into account in the distributions.

We note that \(\tilde{b}\) in Eq. (1) could be either \(\tilde{b}_{1}\) or \(\tilde{b}_{2}\). The decay was studied in [7] by using the end point method, where the possibility of distinguishing the two sbottom states \(\tilde{b}_{1}\) and \(\tilde{b}_{2}\) was studied for a case where the mass difference was approximately 5% of the sbottom mass. The conclusion showed that even with very large integrated luminosity the result is at best marginal, and crucially depends on the ability of the experimenters to model a very high level of detail the response function of the detector to \(b\)-jets. This is probably an inescapable conclusion, given that the resolution in calorimetric measurement is comparable to the mass splitting one wants to measure. It is however worth studying alternative reconstruction methods which make better use of all the information available for the selected events.

In a subsequent paper [10], a similar process is analyzed by constructing an approximate event-likelihood function for signal events, based on a Bayesian statistical approach. In this paper we construct a different approximation for the likelihood function. We apply this function to the analysis of a simulated data set, and we study how well \(\tilde{b}_{1}\) and \(\tilde{b}_{2}\) can be reconstructed for a sample model point and its variants.

This paper is organized as follows. In Sec. II, we introduce the detailed SUSY models addressed in our study, and briefly present the simulation procedure. We then solve in Sec. III analytically the kinematics for the process Eq. (1), arriving to a compact expression for the masses of \(\tilde{g}\) and \(\tilde{b}\) as the function of \(b\) and \(\ell\) momentum and discuss the typical solutions. In Sec. V, we discuss the event pair analysis on our sample SUSY model, where \(m_{\tilde{g}}\) and \(m_{\tilde{b}}\) are computed from all event pairings in the selected samples. Gluino and sbottom masses consistent with the input values are reconstructed, but we are also forced to artificially select one of the multiple solutions obtained from solving for the masses the coupled quadratic equations for each event pair. In Sec. VI, we therefore define an approximate likelihood function built using all the events in the sample, and we describe an analysis based on this function. The masses reconstructed from the likelihood analysis are in agreement with the input values and the method automatically takes care of the issue of multiple solutions without artificial selection. We also study the possibility to reconstruct the \(\tilde{b}_{2}\) in our sample model. Section VII is devoted to discussions and comments. We especially discuss the theoretical relevance of being able to perform detailed measurements in the third generation squark sector.

## II Model points and simulations

We choose for this study the model point SPS1a as defined in Ref. [11] and its variants. SPS1a has a significant production cross section for the chain of Eq. (1), and has already been the subject of detailed LHC studies [7]. The model is defined in the mSUGRA scenario by the parameters \(\tan\beta=10,\,\,\,m=100\,\,\,\mathrm{GeV},\,\,\,M=250\,\,\,\mathrm{GeV},\,\, \,A_{0}=-100\,\,\,\mathrm{GeV},\,\,\,\mu>0\). In order to evaluate the performance of the analysis for different values of the splitting of the two sbottom states, we also study the points where \(\tan\beta=15\) and \(20\), keeping other GUT scale parameters the same as those for SPS1a. For the additional points, the \(\tilde{g}\), \(\tilde{\chi}_{2}^{0}\), \(\tilde{\chi}_{1}^{0}\), and \(\tilde{\ell}\) masses are almost the same as for SPS1a, while \(m_{\tilde{b}_{1}}\) is reduced because the left-right mixing of \(\tilde{b}\) increases proportionally to \(\mu\tan\beta\).

The masses and decay branching ratios are calculated with the isasusy code [12]. See Table 1 for the list of relevant masses. The \(m_{\tilde{b}_{1}}\) changes by 3% from \(\tan\beta=10\) to \(\tan\beta=20\). We will see later that such a difference in the \(\tilde{b}_{1}\) masses should be measurable at the LHC if systematic effects are kept under control.

Another drastic effect in Table 2 is the decrease of \(Br(\tilde{\chi}_{2}^{0}\to\tilde{\ell}\ell)\) (\(\ell=e,\,\mu\)). This is because the decay width for \(\tilde{\chi}_{2}^{0}\to\tilde{\tau}\tau\) increases as the \(\tilde{\tau}\) mixing angle increases. For \(\tan\beta=20\), the branching ratio into the \(bb\ell\ell\) mode is reduced by a factor of 5 yielding a rather small number of accepted events.

We also list in Table 2 the decay branching ratios relevant to the decay chain of interest. The ratio of the

\begin{table}
\begin{tabular}{c c c c c c} \(\tan\beta\) & \(m_{\tilde{g}}\) & \(m_{\tilde{b}_{122}}\) & \(m_{\tilde{g}_{2}^{0}}\) & \(m_{\tilde{g}_{2}^{0}}\) & \(m_{\tilde{g}_{2}^{0}}\) \\ \hline
10 & 595.2 & 491.9(524.6) & 176.8 & 143.0 & 96.0 \\
15 & 595.2 & 485.3(526.9) & 177.9 & 143.0 & 96.5 \\
20 & 595.2 & 478.7(531.2) & 178.5 & 143.1 & 96.7 \\ \end{tabular}
\end{table}
Table 1: Masses of the relevant sparticles for the three studied points, in GeV.

decay branching ratios \(R_{\tilde{g}}=Br(\bar{g}\to\tilde{b}_{1(2)})\)\(Br(\bar{b}_{1(2)}\to\tilde{\chi}_{2}^{0})/Br(\bar{g}\to\tilde{b}_{1}\to\tilde{\chi}_{2}^{0})\) varies from 0.26 to 0.14 when \(\tan\beta\) changes from 10 to 20. This \(\tan\beta\) dependence comes from the reduction of the \(\tilde{b}_{1}\) mass and the increase of the left-right mixing angle of \(\tilde{b}\), \(\theta\), defined as \(\tilde{b}_{1}=\cos\theta\tilde{b}_{L}+\sin\theta\tilde{b}_{R}\), from \(\theta=0.49\) (\(\tan\beta=10\)) to 0.61 (\(\tan\beta=20\)). Explicitly,

1. \(\Gamma(\bar{g}\to\tilde{b}_{1})\) increases as \(m_{\tilde{b}_{1}}\) is reduced.
2. \(\Gamma(\tilde{b}_{2}\to\tilde{\chi}_{2}^{0})\) increases as \(\theta\) increases. However, \(\Gamma(\tilde{b}_{2}\to\tilde{\chi}_{1}^{+})\) and \(\Gamma(\tilde{b}_{2}\to\tilde{\tau}_{1})\) also increase; therefore \(Br(\tilde{b}_{2}\to\tilde{\chi}_{2}^{0})\) stays more or less the same.
3. \(m_{\tilde{b}_{1}}\) is reduced and \(\Gamma(\tilde{b}_{1}\to\tilde{\tau}_{1}W)\) is kinematically suppressed as \(\tan\beta\) increases.

The branching ratio in principle provides important information for determining the mixing angle \(\theta\) but one needs to know the relevant sparticle mass spectrum to utilize it.

Note that the ratio \(R_{\tilde{b}}\) is small and the mass splitting between \(\tilde{b}_{1}\) and \(\tilde{b}_{2}\) is within 10% over the parameters we study. The \(\tilde{b}_{1}\) therefore gives significant background to the \(\tilde{b}_{2}\) search at the LHC. Nevertheless, a hint for the decay of \(\bar{g}\to\tilde{b}_{2}\) might still be observable in the \(bb\ell\ell\) distribution, given an excellent control of the detector response to \(b\)-jets, as we will see in Sec. VI.

The SUSY events are generated using the HERWIG 6.4 [13, 14] event generator. The produced events are passed through the ATLFAST [15] detector simulator, which parametrizes the response of the ATLAS detector. In particular, we use the parametrization for \(b\)-tagging efficiency corresponding to the expected high luminosity performance of the ATLAS detector. While the performance is a function of the \(p_{T}\) of the jets, a typical performance figure is \(\epsilon_{b}=0.5\) for the \(b\) tagging efficiency for a rejection of 100 on light quark jets.

For each point we have generated \(1.5\times 10^{7}\) events which approximately correspond to an integrated luminosity of 300 fb\({}^{-1}\).

The following cuts are applied in order to select signal events:

1. \(M_{\rm eff}>600\) GeV and \(E_{T}^{\rm miss}>0.2M_{\rm eff}\), where \(E_{T}^{\rm miss}\) is the missing transverse energy and \(M_{\rm eff}\) is the scalar sum of the missing transverse energy and the transverse momenta of the four hardest jets;
2. at least three jets with \(p_{T1}>150\) GeV, \(p_{T2}>100\) GeV, and \(p_{T3}>50\) GeV;
3. exactly two \(b\)-tagged jets with \(p_{T}>50\) GeV;
4. exactly two opposite-sign isolated same-flavor (OSSF) leptons with \(p_{T\ell_{1}}>20\) GeV, \(p_{T\ell_{2}}>10\) GeV, with an invariant mass 40 GeV \(<m_{\ell\ell}<78\) GeV.

The isolation criterion consists of requiring a transverse energy deposition in the calorimeters smaller than 10 GeV in a (\(\eta\), \(\phi\)) cone of radius 0.2 around the lepton direction, where \(\eta\) is the pseudorapidity of the lepton and \(\phi\) is the angle in the plane transverse to the beam. A detailed discussion of the standard model backgrounds after these cuts is given in [7]. The authors show that the standard model background is negligible in comparison to the SUSY background, consisting of SUSY events not including the decay chain of Eq. (1).

In order to perform the reconstruction, we need to identify the position of each of the two \(b\)-jets and of each of the two leptons in the decay chain. In the following analysis, we assume that the \(b\)-jet with larger \(p_{T}\) originates from the \(\tilde{b}\) decay. The assignment is optimal for SPS1a, because \(m_{\tilde{b}_{2}}-m_{\tilde{\chi}_{2}^{0}}\gg m_{\tilde{g}}-m_{\tilde{b}}\). At the same time, one can fix the lepton assignment so that the higher (lower) \(p_{T}\) lepton \(\ell_{\rm high}\) (\(\ell_{\rm low}\)) comes from \(\tilde{\ell}\) to increase the probability of picking up the correct lepton assignment. If we roughly know the masses of \(\tilde{\ell}\), \(\tilde{\chi}_{1}^{0}\), and \(\tilde{\chi}_{2}^{0}\), it is easy to determine which assignment is optimal [8]. For the likelihood analysis on SPS1a, we use \(\ell_{\rm high}\) as \(\ell_{1}\) in Eq. (1).

## III Solutions of the decay kinematics

### Formula for the decay kinematics

It is straightforward to solve the decay process in Eq. (1). We first note that the \(\tilde{b}\) cascade decay can be written as a function of momenta of \(b_{1}\), \(\ell_{1}\), and \(\ell_{2}\), because the four mass shell conditions can be used to eliminate the unknown \(\tilde{\chi}_{1}^{0}\) four momentum.

To systematically solve the system, we expand the \(\tilde{\chi}_{1}^{0}\) momentum with the observed momenta of \(b_{1}\), \(\ell_{1}\), and \(\ell_{2}\):

\[\vec{\rm p}_{\tilde{\chi}_{1}^{0}}=a\vec{\rm p}_{\ell_{1}}+b\vec{\rm p}_{\ell_ {2}}+c\vec{\rm p}_{b_{1}}. \tag{3}\]

The expansion is possible if \(\vec{\rm p}_{\ell_{1}}\), \(\vec{\rm p}_{\ell_{2}}\), and \(\vec{\rm p}_{b_{1}}\) are independent from one another. The three on-shell conditions may then be rewritten as

\[{\cal M}\left(\begin{array}{c}a\\ b\\ c\end{array}\right)=\left(\begin{array}{ccc}-\frac{1}{2}(m_{\tilde{\chi}_{1} ^{0}}^{2}-m_{\tilde{\chi}_{1}^{0}}^{2})&+E_{\ell_{1}}E_{\tilde{\chi}_{1}^{0}} \\ -\frac{1}{2}(m_{\tilde{\chi}_{1}^{0}}^{2}-m_{\tilde{\ell}}^{2}-2p_{\ell_{1}} \cdot p_{\ell_{2}})&+E_{\ell_{2}}E_{\tilde{\chi}_{1}^{0}}\\ \frac{1}{2}[m_{\tilde{\chi}_{1}^{0}}^{2}+m_{\tilde{b}}^{2}+2p_{b_{1}}\cdot(p_ {\ell_{1}}+p_{\ell_{2}})]&-\frac{1}{2}m_{\tilde{b}}^{2}&+E_{b_{1}}E_{\tilde{ \chi}_{1}^{0}}\end{array}\right), \tag{4}\]

\begin{table}
\begin{tabular}{c c c c} \(\tan\beta\) & \(Br(\bar{g}\to\tilde{b}_{1(2)})\) & \(Br(\bar{b}_{1(2)}\to\tilde{\chi}_{2}^{0})\) & \(Br(\tilde{\chi}_{2}^{0}\to\tilde{\ell})\) \\ \hline
10 & \(8.9(4.9)\times 2\) & \(35.8(16.7)\) & \(3.16\times 4\) \\
15 & \(9.8(4.6)\times 2\) & \(37.8(15.9)\) & \(1.26\times 4\) \\
20 & \(10.8(4.1)\times 2\) & \(38.9(13.2)\) & \(0.61\times 4\) \\ \end{tabular}
\end{table}
Table 2: Branching fractions for the decay used in the analysis, in percent.

where

\[{\cal M}\ =\left(\begin{array}{cccc}\bar{\rm p}_{\ell_{1}}\cdot\bar{\rm p}_{ \ell_{1}}&\bar{\rm p}_{\ell_{1}}\cdot\bar{\rm p}_{\ell_{2}}&\bar{\rm p}_{\ell_ {1}}\cdot\bar{\rm p}_{b_{1}}\\ \bar{\rm p}_{\ell_{1}}\cdot\bar{\rm p}_{\ell_{2}}&\bar{\rm p}_{\ell_{2}}\cdot \bar{\rm p}_{\ell_{2}}&\bar{\rm p}_{\ell_{2}}\cdot\bar{\rm p}_{b_{1}}\\ \bar{\rm p}_{\ell_{1}}\cdot\bar{\rm p}_{b_{1}}&\bar{\rm p}_{\ell_{2}}\cdot \bar{\rm p}_{b_{1}}&\bar{\rm p}_{b_{1}}\cdot\bar{\rm p}_{b_{1}}\end{array}\right). \tag{5}\]

The three parameters, \(a\), \(b\), and \(c\) are solved as functions of \(E_{\vec{x}_{1}^{0}}\) if \({\rm det}{\cal M}\neq 0\). By using the on-shell condition of \(\vec{x}_{1}^{0}\), we obtain a quadratic equation in \(E_{\vec{x}_{1}^{0}}\):

\[A_{33}\!\left(\!\frac{E_{\vec{x}_{1}^{0}}}{m_{\vec{x}_{1}^{0}}} \!\right)^{2}+2\!\left(\!A_{13}+\frac{m_{\vec{x}_{1}^{0}}^{2}}{m_{\vec{x}_{1} ^{0}}^{2}}A_{23}\!\right)\!\left(\!\frac{E_{\vec{x}_{1}^{0}}}{m_{\vec{x}_{1}^{ 0}}^{2}}\!\right)+\] \[\left(A_{11}+2\,\frac{m_{\vec{x}_{2}}^{2}}{m_{\vec{x}_{1}^{0}}^{ 2}}A_{12}+\frac{m_{\vec{\ell}}^{4}}{m_{\vec{x}_{1}^{0}}^{4}}A_{22}\right)=0, \tag{6}\]

where \(A_{ij}=[{\rm x}_{i}]^{T}\,{\cal M}^{-1}[{\rm x}_{j}]-\delta_{ij}(i-2)/m_{\vec{ x}_{1}^{0}}^{2}\) and the definition of \({\rm x}_{1}\) is given in the appendix.

As the \(\tilde{b}\) decay kinematics are solved, we now use the on-shell condition of \(\tilde{g}\to\tilde{b}b_{2}\) to obtain

\[Q_{11}m_{\tilde{g}}^{4}+2Q_{12}m_{\tilde{g}}^{2}m_{\tilde{g}}^{ 2}+Q_{22}m_{\tilde{g}}^{4}+2Q_{1}m_{\tilde{g}}^{2}+\] \[2Q_{2}m_{\tilde{g}}^{2}+Q=0. \tag{7}\]

The \(Q\)'s are functions of the momenta of the leptons and \(b\) quarks, \(m_{\vec{x}_{2}^{0}}\), \(m_{\vec{x}_{1}^{0}}\), and \(m_{\tilde{t}}\). The expressions for the \(Q\)'s are shown in the appendix.

Mathematically, when there are two independent events, we have two independent equations of the form Eq. (7). The equation is quadratic for \(m_{\tilde{g}}^{2}\) and \(m_{\tilde{g}}^{2}\) and can be analytically solved.1 There are up to four solutions for an event pair, and one of them must coincide with the true solution.

Footnote 1: Note that when some of the momenta are parallel, \({\cal M}\) cannot be inverted. We ignore the possibility, because experimentally we always require the isolation of leptons from jets.

## IV IV. End point analysis and mass relation method

The decay chain \(\tilde{g}\to\tilde{b}b_{2}\to\tilde{\chi}_{2}^{0}b_{1}b_{2}\to\tilde{\ell}b_{ 1}b_{2}\ell_{2}\to\tilde{\chi}_{1}^{0}b_{1}b_{2}\ell_{1}\ell_{2}\) has already been studied in detail in Refs. [7, 16], using the end point method shown in Ref. [1]. In this method, the masses of the \(\tilde{\chi}_{1}^{0}\) and \(\tilde{\chi}_{2}^{0}\) are assumed to be known from the study of the kinematic edges in the \(\tilde{q}_{L}\) decay. For events near the edge of the \(m_{\ell\ell}\) distribution, the \(\tilde{\chi}_{1}^{0}\) is essentially at rest, and the momentum of the \(\tilde{\chi}_{2}^{0}\) can be approximated with the relation

\[{\bf p}\ _{\tilde{x}_{2}^{0}}\simeq\left(1-\frac{m_{\tilde{x}_{1}^{0}}}{m_{ \ell\ell}}\right){\bf p}_{\ell\ell}. \tag{8}\]

This formula is correct only at the end point of the three-body decay \(\tilde{\chi}_{2}^{0}\to\chi_{1}^{0}\ell\ell\), but is nevertheless approximately correct near the edge of \(\tilde{\chi}_{2}^{0}\to\tilde{\ell}\ell\to\ell\ell\tilde{\chi}_{1}^{0}\) at SPS1a. The sbottom mass can then be calculated by building the invariant mass of the approximate \(\tilde{\chi}_{2}^{0}\) obtained by using Eq. (8) with the leading \(b\)-jet in the event. The parton-level result is shown in Fig. 1(a), where we plot the difference between the reconstructed gluino mass and the reconstructed sbottom mass, to minimize the smearing intro

Figure 1: The distribution of \(m_{\tilde{g}}-m_{\tilde{g}}\) calculated using (a) parton-level \(b\) momentum and using the approximate relation Eq. (8) and (b) by solving Eq. (2). For (a) \(m_{\ell\ell}>65\) GeV is required. For (b), the two \(m_{\tilde{g}}\) solutions for the input gluino mass of \(m_{\tilde{g}}=595\) GeV are plotted in a two-dimensional plane, for both correct and wrong lepton assignment.

duced by the approximation of Eq. (8). The \(\tilde{b_{1}}\) peak is reconstructed correctly. The bump on the left originates from the events from \(\tilde{g}\rightarrow\tilde{b_{2}}\), and is centered on the position \(m_{\tilde{g}}-m_{\tilde{b_{2}}}=70.6\;\mathrm{GeV}\). Even at parton level, with no experimental smearing the bump is not well separated from the \(\tilde{b_{1}}\) peak at 103 GeV.

Unlike the relation Eq. (8), the formula Eq. (7) is exact. For each event we have in this case two possible lepton assignments, and for each lepton assignment, given an input value for the gluino mass, two solutions for the sbottom mass from the quadratic equation Eq. (7). We show in Fig. 1 the smaller solution versus the larger one of Eq. (7) for both of the lepton assignments. For the gluino mass the nominal value is assumed. Unlike in Fig. 1(a) the two peaks from \(\tilde{b_{1}}\) and \(\tilde{b_{2}}\) are clearly separated in the plot. Furthermore the number of the available events for the mass fit are now increased by a factor of 2 compared to the end point analysis because there are no constraints on the value of \(m_{\ell\ell}\) when using Eq. (7).

The advantage of switching to the exact solution for the event kinematics is clearly demonstrated by the plots. In order to evaluate if the heavier sbottom state will be detectable, we need to perform the study taking into account the smearing induced by the fact that \(b\)-jets rather than partons are measured in the detector.

## V V. Event Pair Analysis

As discussed in Sec. III, each event can be represented as a quadratic equation in the \(m_{\tilde{g}}^{2}\), \(m_{\tilde{g}}^{2}\) variables. By taking two events, we have a system of two equations in two unknowns which can be solved analytically. This yields up to four values for the squark and gluino masses. In the following, we start from the selected \(bb\ell\ell\) events, and we build all the possible event pairs. In order to minimize the combinatorial backgrounds, we use the pairings which satisfy the following conditions:2

Footnote 2: Note the selections are rather phenomenological and they may introduce some bias to the reconstructed sparticle masses. We find, however, the obtained peak positions are consistent with the input masses in this study.

1. Equation (7) has a solution for only one of the two possible lepton assignments.
2. For the selected lepton assignment the resulting quartic equation in \(m_{\tilde{g}}^{2}\) has only two solutions, and the difference of the gluino masses for the two solutions is more than 100 GeV. The smaller gluino mass solution is chosen.

The \(m_{\tilde{g}}\) distributions for the \(\mathrm{OSSF}\times\mathrm{OSSF}\) event pairs are shown in the histograms on the upper line of Fig. 2. A significant SUSY background, also shown in Fig. 2, is still

Figure 2: The gluino mass distributions for \(\tan\beta=10\) (left), \(\tan\beta=15\) (center), and \(\tan\beta=20\) (right) with the event pair analysis. The open, gray, and dark histograms in the top figures are for \(\mathrm{OSSF}\times\mathrm{OSSF}\), \(\mathrm{OSSF}\times\mathrm{OSOF}\), and \(\mathrm{OSOF}\times\mathrm{OSOF}\) event pairs, respectively. The open histograms in the bottom figures show the mass distributions after background subtraction. The contributions of \(\tilde{b_{2}}\) are shown by dark histograms.

present in the sample. This background can be estimated from the data themselves by using the \(bb\ell\ell\) events with an opposite-sign opposite flavor (OSOF) lepton pair (i.e., \(\ell\ell=e^{-}\mu^{\mp}\)). For this purpose we produce mass distributions for the three types of event pairs:

1. two OSSF lepton events (OSSF \(\times\) OSSF),
2. an OSSF lepton event and an OSOF lepton event (OSSF \(\times\) OSOF),
3. two OSOF lepton events (OSOF \(\times\) OSOF).

The background-subtracted distribution can then be obtained as the combination of the three distributions: OSSF \(\times\) OSSF \(-\) OSSF \(\times\) OSOF \(+\) OSOF \(\times\) OSOF.

The total number of event pairs is of course much larger than the number of events. Because of the selection criteria imposed to minimize the combinatorial backgrounds, some of the events are not used at all to make event pairs, while events which are used at least once are used O(10) times on average. The three histograms show peaks corresponding to the input value for the gluino mass even before the background subtraction. The gray and dark histograms show the OSSF \(\times\) OSOF and OSOF \(\times\) OSOF distributions, respectively. The distributions after the background subtraction are shown in the histograms on the lower line of Fig. 2. The peak position and its error obtained by a Gaussian fit to the distribution are listed in Table 3. We also show in the histogram the gluino mass distribution for event pairs where at least one of the events comes from \(\tilde{b}_{2}\) decay. The \(\tilde{b}_{2}\) contribution is significantly smaller compared with the distribution of \(\tilde{b}_{1}\) pair and does not affect the gluino mass fit. One can also look into the distribution of \(m_{\tilde{g}}-m_{\tilde{b}}\), estimating the value of this observable by performing a Gaussian fit on the observed peak. The result of the fit is also shown in Table 3.

The statistical error of the gluino mass measurement can be evaluated by performing the analysis on a set of statistically independent experiments. To perform the evaluation within a reasonable CPU budget, we generated a set of events where the \(\tilde{b}_{1}\) is forced to decay with 100% branching ratio into the desired decay chain, for the SPS1a point (\(\tan\beta=10\)). The generated statistics corresponds to 30 experiments with an integrated luminosity of 300 fb\({}^{-1}\) each. By performing the analysis on the 30 experiments, we find that the spread for the measured gluino mass is 1.6 GeV for the benchmark integrated luminosity of 300 fb\({}^{-1}\). By construction, the presence of the combinatorial background is not considered in the error analysis. No

Figure 3: The \(m_{\tilde{g}}\) distributions for \(\tan\beta=10\) (left), 15 (center), and 20 (right) with a fixed gluino mass (\(m_{\tilde{g}}=595\) GeV). The open and gray histograms in the top figures show the distributions of OSSF and OSOF lepton events, respectively. The mass distributions after background subtraction are shown in the bottom figures, where the contribution of the \(\tilde{b}_{2}\) events are shown by the gray regions.

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & \(\tan\beta=10\) & \(\tan\beta=15\) & \(\tan\beta=20\) \\ \hline \(m_{\tilde{g}}\) & 591.9 & 593.1 & 585.1 \\ \(m_{\tilde{g}}-m_{\tilde{b}}\) & 98.9 & 105.1 & 111.6 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Fit results of the gluino and sbottom masses in the event pair analysis, in GeV.

large degradation of the resolution is expected once this effect is correctly taken into account.

Once the gluino mass is fixed by the analysis shown above, Eq. (7) can be solved for each event for the sbottom mass, giving as input the central measured value for the gluino mass. Following this procedure, in Fig. 3, we plot the distribution of the smaller sbottom mass solution \(m_{\tilde{b}}\) (min) for both OSSF (signal) and OSOF (background) lepton pair events (top histograms). We show in the bottom line the mass distributions after the background subtraction, where the gray regions show the contribution of \(\tilde{b}_{2}\). The peak positions are evaluated from a Gaussian fit, and listed in Table 4. Note that the total number of signal \(\tilde{b}_{1}\) events is smaller by factor of 4 for \(\tan\beta=20\) compared with \(\tan\beta=10\), but the mass peak is seen very clearly. The \(m_{\tilde{b}}\) (min) peak and \(m_{\tilde{b}}\) (input) are in good agreement, in contrast to the larger solution \(m_{\tilde{b}}\) (max).

The peak positions of the distributions of events originating from \(\tilde{b}_{2}\) decay are also consistent with \(\tilde{b}_{2}\) masses. It is, however, evident from the plots that in the real experiment it will not be possible to claim the presence of the second peak. The existence of \(\tilde{b}_{2}\) can be established only after understanding \(b\)-jet smearing and the \(\tilde{b}_{1}\) distribution correctly.

## 6 Likelihood Analysis

The analysis shown in the previous section only uses the events in pairs to evaluate the values of the squark and gluino masses. A more efficient use of the available event statistics can be achieved by using all of the events at the same time and finding the \((m_{\tilde{g}},\,m_{\tilde{g}})\) pair for which the combined probability of all events is highest. We define in this section an approximate likelihood function for \((m_{\tilde{g}},\,m_{\tilde{b}})\), and we then apply it to detection of \(\tilde{b}_{2}\).

### Construction of the likelihood function

From Eq. (7), each event is represented as a curve in the \((m_{\tilde{g}},\,m_{\tilde{g}})\) plane. The coefficients of the curve are a function of the four momenta of the detected partons. The partons are measured as jets in the detector, which smears the parton according to a smearing function. It depends on the detector performance and on the algorithms used to cluster the energy deposition in the detector.

Because of these experimental effects, in a frequentist approach, from the measured quadratic form for an event we can build a confidence belt in the \((m_{\tilde{g}},\,m_{\tilde{g}})\) plane. This should be built using a Neyman construction [17], from the probability distribution for the measured values of \((m_{\tilde{g}},\,m_{\tilde{g}})\) as a function of the input values for the same two variables. In order to build this function, the crucial ingredient is the distribution of the measured \(b\)-jet momenta as a function of the \(b\)-parton momenta. Evaluating this distribution is outside the scope of this work, as it requires a detailed simulation of the detector response, which will need to be validated on real data using calibration samples of \(b\)-jets in the detector. Even assuming an approximate form for the \(b\)-jet response, the proper Neyman construction for each event is a very computing-intensive calculation.

We recast equation Eq. (7) in the form

\[f(m_{\tilde{g}},\,m_{\tilde{g}},\,p_{1},\,p_{2})=0,\]

where \(p_{1}\) and \(p_{2}\) are the momenta of the two \(b\)-jets. We build an approximate probability density function according to the formula

\[{\cal L}(m_{\tilde{g}},\,m_{\tilde{g}}) = \int dp_{1}^{\prime}\int dp_{2}^{\prime}\epsilon(p_{1}^{\prime}|p _{1})\epsilon(p_{2}^{\prime}|p_{2}) \tag{9}\] \[\times\ \delta[f(m_{\tilde{g}},\,m_{\tilde{g}},\,p_{1}^{\prime},\,p_{2}^{ \prime})],\]

where \(\epsilon(p^{\prime}|p)\) is the probability density, given a measured value \(p\) of the \(b\)-jet momentum, that an experiment would measure a momentum \(p^{\prime}\) for a jet coming from the fragmentation of the same parton.

In the equation we did not include the possibility of lepton momentum mismeasurement, which has an almost negligible effect, as compared to the smearing of \(b\)-partons. As a further simplification, we assume that the jet direction is not modified by the measurement and we use for \(\epsilon(p^{\prime}|p)\) a Gaussian distribution, with a width \(\sigma\) corresponding to the parametrized jet smearing used in the fast simulation program:

\[\begin{split}\sigma/E&=0.5/\sqrt{E(\mathrm{GeV})} \,+\,0.03(|\eta|<3.0),\\ \sigma/E&=1.0/\sqrt{E(\mathrm{GeV})}\,+\,0.07(|\eta| >3.0).\end{split} \tag{10}\]

The Gaussian smearing is not a very good approximation for \(b\)-jets because in many cases the semileptonic decay of the \(b\)-quark results in jets which contain an unmeasured neutrino. The approximate function takes, however, into account the dominant part of the jet smearing and can be used to demonstrate the method. Note also that, in Eq. (9), we define our \({\cal L}\) using \(\epsilon(p_{1}^{\prime}|p_{1})\) where \(p_{1}\) is the measured \(b\)-jet momentum. The function \({\cal L}\) would correspond to the actual probability function only if the jet response were Gaussian. A detailed experimental simulation will be needed in order to assess the validity of the obtained results in the real experimental situation.

We now show \(\log{\cal L}\) in the \((m_{\tilde{g}}\,-\,m_{\tilde{b}},\,m_{\tilde{g}})\) plane for a few events where the \(bb\ell\ell\) events originate from the cascade

\begin{table}
\begin{tabular}{l c c c}  & \(\tan\beta\,=\,10\) & \(\tan\beta\,=\,15\) & \(\tan\beta\,=\,20\) \\ \hline \(m_{\tilde{g}}\) (true) & 491 & 485.3 & 478.8 \\ \(m_{\tilde{b}}\) (min) & 492.1 \(\pm\) 1.2 & 487.7 \(\pm\) 2.2 & 474.3 \(\pm\) 2.4 \\ \(m_{\tilde{g}}\) (max) & 504.5 \(\pm\) 1.0 & 502.9 \(\pm\) 1.7 & 495.1 \(\pm\) 2.4 \\ \end{tabular}
\end{table}
Table 4: Fit results in GeV of the sbottom mass with a fixed gluino mass (\(m_{\tilde{g}}=\,595\) GeV).

decay of Eq. (1) at SPS1a. We calculate \(\mathcal{L}\) using the following procedure. For each event in our sample, characterized by a \((p_{1},\,p_{2})\) pair of measured momenta for the \(b\)-jets, we generate Monte Carlo events where the two \(b\)-jets have momenta (\(p_{1}^{\prime}\), \(p_{2}^{\prime}\)), where \(p_{1}^{\prime}\) and \(p_{2}^{\prime}\) are randomly generated according to the function \(\boldsymbol{\epsilon}(p_{1}^{\prime}|p_{1})\times\boldsymbol{\epsilon}(p_{2}^ {\prime}|p_{2})\). Each generated event corresponds to a curve in the \((m_{\tilde{g}},\,m_{\tilde{g}})\) plane which satisfies the equation \(f(m_{\tilde{g}},\,m_{\tilde{g}},\,p_{1}^{\prime},\,p_{2}^{\prime})=0\). We histogram the number of curves that go through each bin of a \(1\times 1\) GeV grid in the \((m_{\tilde{g}},\,m_{\tilde{g}})\) plane, for \(n\) Monte Carlo events, normalized by dividing the bin contents by \(n\). In the limit \(n\to\infty\), this corresponds to

\[\mathcal{L}(m_{\tilde{g}},\,m_{\tilde{g}} + \Delta m_{\tilde{g}};m_{\tilde{g}},\,m_{\tilde{g}}+\Delta m_{ \tilde{b}})\] \[= \int DP_{1}^{\prime}\int DP_{2}^{\prime}\boldsymbol{\epsilon}(p_ {1}^{\prime}|p_{1})\boldsymbol{\epsilon}(p_{2}^{\prime}|p_{2})\] \[\times\theta(p_{1}^{\prime},\,p_{2}^{\prime},\,m_{\tilde{g}},\,m_ {\tilde{g}}+\Delta m_{\tilde{g}};m_{\tilde{g}},\,m_{\tilde{g}}+\Delta m_{ \tilde{g}}),\]

where \(\theta(p_{1}^{\prime},\,p_{2}^{\prime},\,m_{\tilde{g}},\,m_{\tilde{g}}+\Delta m _{\tilde{g}};m_{\tilde{p}},\,m_{\tilde{p}}+\Delta m_{\tilde{g}})\) is 1 when the solution of Eq. (7) for the two \(b\)-jet momenta \(p_{1}^{\prime}\) and \(p_{2}^{\prime}\) goes through \((m_{\tilde{g}},\,m_{\tilde{g}}+\Delta m_{\tilde{g}};m_{\tilde{g}},\,m_{\tilde{g }}+\Delta m_{\tilde{g}})\) and otherwise 0. We take \(n=10\,000\) for our calculations.

In Fig. 4, we plot

\[\Delta\log\mathcal{L} = \log[\mathcal{L}(m_{\tilde{g}},\,m_{\tilde{g}}+\,\Delta m_{ \tilde{g}},\,m_{\tilde{g}},\,m_{\tilde{g}}+\,\Delta m_{\tilde{g}})+\,c] \tag{12}\] \[-\,\log[\mathcal{L}(\min)],\]

where \(c=0.001\) is a constant cutoff factor, which is needed as for each event we generate only a finite number of Monte Carlo experiments, and therefore some bins can have zero hits. The shape of the probability density distribution is different event by event, as it depends on the event kinematics. For a few events, the density distribution is parallel to the \(y\) axis, therefore it only has sensitivity to the \(m_{\tilde{g}}-m_{\tilde{g}}\) difference, but little sensitivity to the absolute value of the gluino mass. The size of the band with significant probability is also different event by event, which means that some events will have more weight in the determination of the mass parameters.

For each event, one defines in this way curves of equal probability in the \((m_{\tilde{g}},\,m_{\tilde{g}})\) plane. By combining the probabilities for different events, a region of maximum probability in the \((m_{\tilde{g}},\,m_{\tilde{g}})\) plane is found, where the curves of maximum probability for all events approximately cross. Given the fact that the curves have different shapes for different events, the region thus defined has a limited size, for an adequate number of events. This region can be taken as a measurement for \(m_{\tilde{g}}\) and \(m_{\tilde{g}}\). We perform the combination as the product of \(\mathcal{L}\) for all events, and we define

Figure 4: Likelihood distributions in the \((m_{\tilde{g}}-m_{\tilde{g}},\,m_{\tilde{g}})\) plane for different SPS1a events. The events were selected in order to show different possible distribution patterns on the plane.

\[\log{\cal L}_{\rm comb}(m_{\tilde{g}},\,m_{\tilde{g}})=\sum_{\rm evins}\log{\cal L} (m_{\tilde{g}},\,m_{\tilde{g}}). \tag{13}\]

As an estimator of the probability for a given \((m_{\tilde{g}},\,m_{\tilde{g}})\) pair, one can use

\[\Delta\chi^{2}(m_{\tilde{g}},\,m_{\tilde{g}})\sim\Delta\log{\cal L}=\log{\cal L }_{\rm max}-\log{\cal L}_{\rm comb}(m_{\tilde{g}},\,m_{\tilde{g}}). \tag{14}\]

Given the approximations introduced this does not however correspond to the statistical definition of \(\Delta\chi^{2}\).

## Appendix B Event analysis

By following the procedure described in the previous subsection, we can build the combined likelihood for all the events defined as

\[\log{\cal L}_{\rm comb}(m_{\tilde{g}},\,m_{\tilde{g}}\,+\,\Delta m _{\tilde{g}},\,m_{\tilde{g}}\,+\,\Delta m_{\tilde{g}})\] \[=\sum_{\rm evins}\log[{\cal L}(m_{\tilde{g}},\,m_{\tilde{g}}\,+ \,\Delta m_{\tilde{g}},\,m_{\tilde{g}},\,m_{\tilde{g}}\,+\,\Delta m_{\tilde{g }})+c].\]

As in Eq. (12) we have introduced a constant cutoff parameter \(c=0.001\) and the number of Monte Carlo experi

Figure 5: Contours of the likelihood function \(\log{\cal L}_{\rm sub}\) in the \((m_{\tilde{g}}-m_{\tilde{g}},\,m_{\tilde{g}})\) plane: (a) and (b) for \(\tan\beta=10\) and (c) and (d) for \(\tan\beta=20\), respectively. The contours (b) and (d) are made without \(\tilde{b}_{2}\) contributions.

ments used to build the likelihood for each event \(n=10\,000\).

As we can see in Fig. 2, there are significant backgrounds from accidental leptons. The background subtraction must be carried out using events with OSOF lepton pairs. The correct log likelihood function is schematically expressed as

\[\log\mathcal{L}_{\rm total}(\mathbf{m}_{\tilde{g}},\mathbf{m}_{ \tilde{p}},\ldots) = \sum_{\rm GSSF}\log\mathcal{L}(\mathbf{m}_{\rm sig},\mathbf{m}_{ \rm bg}) \tag{16}\] \[+\sum_{\rm GSOF}\mathcal{L}(\mathbf{m}_{\rm bg}),\]

where \(\mathbf{m}_{\rm sig}\) express the parameters relevant to the signal distribution, such as the masses of the sparticles involved in the cascade decay, the decay branching ratios, and so on. On the other hand \(\mathbf{m}_{\rm bg}\) are all the other parameters relevant to the OSSF and OSOF events. This is a rather complex procedure which is out of the scope of this paper. Instead, we take the difference of the functions for OSSF and OSOF lepton pair events,

\[\log\mathcal{L}_{\rm sub} = \log\mathcal{L}_{\rm OSSF}-\log\mathcal{L}_{\rm OSOF} \tag{17}\] \[= \sum_{\rm GSSF}\log\mathcal{L}-\sum_{\rm GSOF}\log\mathcal{L}.\]

In the limit of infinite statistics, \(\log\mathcal{L}_{\rm sub}\) should be independent from the contribution of accidental lepton pairs. Therefore we use \(\log\mathcal{L}_{\rm sub}\) in this paper.

We plot the contours of the function \(\log\mathcal{L}_{\rm sub}\) in Fig. 5, where plots (a) and (b) [(c) and (d)] are for \(\tan\beta=10\) [\(\tan\beta=20\)]. The distributions (a) and (c) are produced accepting all the events which pass the selections, whereas distributions (b) and (d) are produced using an event sample where the events including a \(\tilde{b}_{2}\) decay have been rejected.

In Figs. 5(a) and 5(c), the position of the peak for \(m_{\tilde{g}}-m_{\tilde{g}}\) is roughly consistent with the input value. Unlike the gluino and sbottom mass fits in the previous section, we obtain the correct peak position without the need to artificially choose between multiple solutions. The likelihood distribution can be used to determine the masses of \(\tilde{g}\) and \(\tilde{b}\). We restrict the likelihood distribution for \(591\,\,{\rm GeV}<m_{\tilde{g}}<599\,\,{\rm GeV}\) (within 4 GeV from the input gluino mass). We then fit the distribution around the peak assuming a Gaussian distribution. The likelihood distribution peaks at a gluino and sbottom mass difference of 99.5 GeV for \(\tan\beta=10\), 104.2 GeV for \(\tan\beta=15\), and 113.9 GeV for \(\tan\beta=20\), where the input values are 103.3, 109.9, and 116.5 GeV, respectively. The fitted values display shifts of about 4 GeV from the true value. We ascribe this effect to our simplified modeling of the jet smearing in building the likelihood function, which should disappear once the detector response is properly taken into account in the unfolding procedure.

By comparing the left side with the right side of Fig. 5, we also observe a slight shift in the position of the maxima of the distributions, showing that the distributions are sensitive to the presence of \(\tilde{b}_{2}\) decays. The \(\tilde{b}_{2}\) contribution however manifests itself in Figs. 5(a) and 5(c) only as a flattening of the distribution around \(m_{\tilde{g}}-m_{\tilde{b}}=70\,\,{\rm GeV}\) at \(m_{\tilde{g}}\sim 595\,\,{\rm GeV}\). No secondary peak can be observed be cause of the experimental smearing, and the fact that the branching ratio into \(\tilde{b}_{2}\) is much smaller. In Fig. 6(a), we show the distribution of \(\log\mathcal{L}_{\rm sub}\) as a function of \(m_{\tilde{g}}-m_{\tilde{g}}\) at \(\tan\beta=20\), restricting the gluino mass in the region \(591~{}{\rm GeV}<m_{\tilde{g}}<599~{}{\rm GeV}\) again. On the left of the peak corresponding to the \(\tilde{b}_{1}\) mass, we see a small bump in the distribution. This bump is not observed in the mass distribution made without a \(\tilde{b}_{2}\) contribution [Fig. 6(b)]. In order to claim the presence of a second component in the distribution on the data, the ability to correctly reproduce the likelihood distribution for \(\tilde{b}_{1}\) events would be needed. It is also difficult to extract a statistical significance for the \(\tilde{b}_{2}\) shoulder as our definition of the likelihood function is an approximate one, and we did not treat the background subtraction correctly as can be seen in Eq. (17).

In Fig. 3, it is rather hard to see the effect of \(\tilde{b}_{2}\) unlike in Fig. 6. The apparent discrepancy probably comes from the fact that the likelihood analysis is more sensitive to the model parameters than simply solving Eq. (7) for a fixed gluino mass. The likelihood analysis not only takes care of the most plausible value of the sbottom mass for a fixed gluino mass, but also includes possible statistical fluctuations, which vary event by event as seen in Fig. 4. For example, badly mismeasured events have less chance of being consistent with the input gluino mass, providing a natural cut for the event selection.

A significant part of the background under the \(\tilde{b}_{2}\) is the tail of the smeared probability distribution for events which correctly reconstruct the \(\tilde{b}_{1}\) mass. One can therefore try to remove from the distributions the events consistent with \(\tilde{b}_{1}\) in order to improve the signal to background ratio for \(\tilde{b}_{2}\). To reduce the \(\tilde{b}_{1}\) events, an event is required to satisfy the condition:

\[\sum_{\rm cut~{}region}{\cal L}<{\cal L}_{\rm cut}, \tag{18}\]

where the sum is made for bins in a cut region in the \((m_{\tilde{g}}-m_{\tilde{g}},\,m_{\tilde{g}})\) plane. We choose the region as \(550~{}{\rm GeV}<m_{\tilde{g}}<650~{}{\rm GeV}\), and \(m({\rm min})<m_{\tilde{g}}-m_{\tilde{g}}<m({\rm max})\), which corresponds to the region around the \(\tilde{b}_{1}\) peak. We use the cut value \({\cal L}_{\rm cut}=20\). The relevant \(m({\rm min})\) and \(m({\rm max})\) values are listed in Table 5. The contours of \(\log{\cal L}_{\rm sub}\) after this cut are shown in Fig. 7: (a) and (b) for \(\tan\beta=10\) and (c) and (d) for \(\tan\beta=15\). The contours (b) and (d) are made without the \(\tilde{b}_{2}\) contribution. By comparing the contours with and without the \(\tilde{b}_{2}\) contribution, the presence of the \(\tilde{b}_{2}\) can clearly be observed in the plots. In Fig. 8, we again plot the likelihood function as the function of \(m_{\tilde{g}}-m_{\tilde{g}}\), for \(550~{}{\rm GeV}<m_{\tilde{g}}<650~{}{\rm GeV}\). The distributions without the \(\tilde{b}_{2}\) contribution are also shown as dashed histograms. The signal to background ratio is much improved with respect to what is seen on the left side of Fig. 6, and it is about 1:1. However, from an inspection of the mass distribution event by event, the purity of the signal after the likelihood cut does not appear significantly improved with respect to Fig. 3. Moreover, the position of the peak corresponding to \(\tilde{b}_{2}\) is dependent on the cuts applied. This is illustrated in Table 5, where the results of fits to the peak position are shown for two different values of the applied cuts both for the full sample and for the pure \(\tilde{b}_{2}\) signal. Even when only considering the \(\tilde{b}_{2}\) signal, the peak position depends on the cuts, albeit with a milder dependence than for the full sample. It will therefore be problematic to extract a mass measurement from Fig. 8, even assuming _a priori_ the existence of a \(\tilde{b}_{2}\) contribution.

## 7 Discussion

Supersymmetric models predict the existence of heavy superpartners which decay subsequently into the lighter superpartners. The lightest SUSY particle is stable and neutral, and escapes detection. Therefore two undetected particles will be present in each event. Moreover, the

Figure 8: The likelihood as a function of \(m_{\tilde{g}}-m_{\tilde{g}}\) with the cut given in Eq. (18): (left) for \(\tan\beta=10\) and (right) for \(\tan\beta=15\). The dashed lines show the distribution after removal of the \(\tilde{b}_{2}\) contributions.

partonic center of mass energy is unknown for hadron collisions. As a result, the complete kinematic reconstruction of SUSY events at hadron colliders is problematic.

We propose a new analysis method to solve the decay kinematics of this decay at the LHC, based on imposing the on-shell condition on the momenta of the particles participating in the cascade. The single cascade decay is solvable if a decay chain consisting of at least four successive two-body decays, involving five sparticles can be identified. In this case each event defines the 4D hypersurface in the 5D sparticle mass space. The potential of this method should be compared to the method previously used for this analysis based on the measurement of kinematic edges of invariant mass combinations of the detected decay particles.

The merits and demerits of the new method may be summarized as follows:

1. The cascade decay is solved based on the exact formulas.
2. Mass peaks would be reconstructed, as opposed to the kinematic edges. This allows us to perform measurements even if significant backgrounds exist or statistics are small. Note that backgrounds will not exhibit peaks corresponding to the signal region.
3. In the case where sfermion masses are heavier than gaugino masses, the cascade decays are expected to be shorter, and one cannot therefore use this method. The end point method provides mass information even in this case.

We note that, in case two decay chains can be simultaneously identified in the event, the method can be applied to shorter decay chains, consisting of only three decays each. In fact, in this case two additional constraints can be applied by requiring that the sums of the transverse components of the momenta of the two lightest neutralinos equal the two components of the measured missing transverse momentum.

Further on, if one sparticle cascade decay is solved by the mass relation method, the candidate lightest supersymmetric particle (LSP) momentum \(p_{T}\) would be obtained. We can then calculate the transverse momentum of the other LSP \(p_{T}^{\prime}\) as

\[p_{T}^{\prime}=-p_{T}+P_{\rm miss}. \tag{19}\]

For the cascade decay to which the second LSP belongs, only two components of the neutralino four momentum are unknown, therefore a cascade decay with \(n_{\rm decay}\geq 3\) can be solved.

To see the performance of the mass relation method, we have studied in this paper the problem of measuring sparticle masses in the cascade decay: \(\tilde{g}\rightarrow\tilde{b}b_{2}\rightarrow\tilde{\chi}_{2}^{0}b_{1}b_{2} \rightarrow\tilde{\ell}b_{1}b_{2}\ell_{2}\rightarrow\tilde{\chi}_{1}^{0}b_{1} b_{2}\ell_{1}\ell_{2}\). We have performed a detailed study for some benchmark SUSY model points including backgrounds and a parametrized simulation of detector effects. We performed the exercise in a simplified fashion, by fixing the masses of the three lighter particles to avoid the practical complications in handling a large number of parameters. Then each event becomes an allowed curve in the gluino-sbottom mass plane, passing through the point corresponding to the true gluino and sbottom masses. We first addressed the mass reconstruction through the "event pair analysis," which determines the sparticle masses from the distribution of the solutions of any event pairs in the selected sample. The method reconstructs \(m_{\tilde{b}_{1}}\) correctly for SPS1a where \(\tan\beta\) is varied from 10 to 20. Note that the signal branching ratio becomes a factor 4 smaller for \(\tan\beta=20\) with respect to \(\tan\beta=10\), but the \(\tilde{b}_{1}\) peak is still clearly observable. On the other hand, in order to obtain the correct mass, one needs to artificially choose among the multiple available solutions.

A more global approach requires the use of all available events simultaneously. For this approach we constructed an approximate likelihood function for the true gluino and sbottom masses, taking into account the experimental smearing in the measurement of the \(b\)-jets. When the peak position of the likelihood distribution is used to extract the mass, the \(\tilde{b}_{1}\) mass is measured without the problem of the multiple solutions of the event pair analysis.

We also try to probe the presence of a \(\tilde{b}_{2}\) in our Monte Carlo sample. The sbottom mass matrix is parametrized by three parameters \(m_{\tilde{b}_{1}}\), \(m_{\tilde{b}_{2}}\), and the mixing angle \(\theta\). Successful extraction of the \(\tilde{b}_{2}\) would be an important step to fully understand the nature of the third generation sparticles. No clear result is achieved for \(\tilde{b}_{2}\), as the branching ratio into \(\tilde{b}_{2}\) is small for the parameters we have chosen, and also the small difference between the two sbottom states is comparable to the resolution in the experimental measurement of jet momenta. It is however clear that, even with the small statistics available for the case \(\tan\beta=20\), a hint for the deviation from a single-mass case can be seen in the distribution.

The physics output of our analysis is therefore the possibility to extract information on the third generation sector, even for rather small input statistics. The measurement of the third generation sparticle masses is important theoretically. In mSUGRA, the \(\tilde{b}_{L(R)}\) masses are the same as the other sparticle masses at the GUT scale but nonuniversality is induced by RGE running at the weak scale due to the Yukawa coupling. In addition to that, the left-right mixing of sbottom is induced by the \(F\) term of the superpotential which is proportional to \(\mu\tan\beta\). The mass shift around 20 GeV from \(\tan\beta=10\) and \(\tan\beta=20\) is due to this mixing effect. Our method is sensitive to the \(\tan\beta\) dependence as it could yield a sensitivity to the mass difference between the two states of the order of a few GeV.

## Acknowledgments

We thank members of the ATLAS Collaboration for helpful discussions. We have made use of ATLAS physics