# **Atlas NOTE**

ATL-PHYS-PUB-2009-000

April 26, 2009

**Misalignment and \(b\)-tagging**

The ATLAS Collaboration1

Footnote 1: This note prepared by J. Alison, A. Bocci, O. Brandt, P. Bruckman de Renstrom, B. Cooper, C. Escobar, T. Golling, S. Gonzalez-Sevilla, G. Gorfine, F. Heinemann, M. Karagoz Unel, V. Lacuesta, W. Liebig, M. Panuskova, S. Marti i Garcia, R. Moles, A. Morley, S. Pataraia, A. Rozanov, J. Schieck, C. Schmitt, and V. Sipica.

_This note is part of CERN-OPEN-2008-020. This version of the note should not be cited: all citations should be to CERN-OPEN-2008-020._

###### Abstract

This note investigates the effects of misalignment on \(b\)-tagging performance using Monte Carlo simulations. Four different alignment sets were considered, two with known random misalignments, one produced with the ATLAS alignment procedures and one with a perfectly aligned detector. Error tuning was investigated to compensate for the larger effective hit errors caused by misalignment. In addition the effects of misalignment on the tracking and vertexing performance were evaluated.

Introduction

The ATLAS detector has been built to provide high precision tracking and vertexing which are essential for good \(b\)-tagging performance. Misalignment of the detector will degrade the tracking resolution and consequently the performance of the \(b\)-tagging is expected to be sensitive to the alignment of the detector. As well as random misalignments of modules which give an effective smearing of each hit, systematic distortions introduced by the structure of the detector and by the alignment algorithms can have unexpected consequences.

The effects of misalignment on \(b\)-tagging have been studied with Monte Carlo simulations using a number of different alignment sets. These include a set that perfectly aligns the detector, two hand-made sets with known levels of random misalignment and an alignment set produced with the actual alignment algorithms to be used to align the ATLAS detector.

The assignment of correct errors for the hits is important for proper track and vertex reconstruction. Because module misalignments add to the intrinsic error of the module, the errors assigned to the hits need to be adjusted depending on the level of misalignment. Samples were investigated with and without this hit error adjustment.

The note is organized as follows: Section 2 describes the four alignment sets. The error tuning procedure and resulting scale factors used to adjust the hit errors are presented in Section 3. Studies were made with both \(t\bar{t}\) and \(WH(m_{H}=120\) GeV) samples and a brief description of these samples is given in Section 4. Section 5 describes the effects of misalignment on the tracking and vertexing performance. The effects of misalignment on the \(b\)-tagging performance, as measured by comparing the \(b\)-jet efficiency versus light jet rejection for the different alignment sets, are presented and discussed in Section 6.

## 2 Residual misalignment sets

In order to study the effects of misalignment, a number of different alignment scenarios were considered. The Monte Carlo simulation used in this investigation includes misalignments introduced at the simulation stage. The level of misplacement is representative of the amount of misalignment expected before any attempt to align the detector. The misalignments are of the order of 10-100 \(\mu\)m at the level of individual modules and assembly structures such as layers and disks and misalignments of the order of a few mm at the whole subsystem level. The level of these misalignment was based on known fabrication precisions and survey measurements. [1]. The misalignments introduced are too large to allow for reasonable reconstruction. What is desired is to reconstruct the resulting data sets with alignment corrections that are typical of what is expected in the real detector, after which only small misalignments should remain. Four alignment sets were used in this study:

* **Perfect:** This is the ideal case where the same set of alignments used in the simulation are used in the reconstruction and so one does not see any misalignment.
* **Aligned:** This uses an alignment set produced using the actual track based alignment algorithms developed for the ATLAS detector. It is expected to include any systematic deformations that the alignment procedure itself causes. While some systematic effects were included in the misalignments introduced in the simulation, such as clocking effects where each subsequent layer was rotated by increasing amounts, it does not contain all the systematic deformations which are expected. In particular large scale structures such as layers and discs were treated as rigid objects without any internal deformations such as a twist. Also pixel stave bows which are known to occur were not introduced. So it is possible that this set is still optimistic. This set is a first attempt at the full scale alignment of the inner detector and so should not be considered the final word on what will be seen in the real detector. However, it is considered to be the most realistic case studied here.
* **Random10:** This is a hand-made alignment set that takes the misalignment set used in simulation and randomly shifts the module positions by small amounts. These residual misalignments were introduced at different levels in the hierarchy. Random shifts and rotations were made to individual modules, and whole layers and disks. A small shift and rotation was also made to the whole pixel structure. Since the degradation of the \(b\)-tagging performance is expected to be dominated by the alignment of the pixel system, only pixel residual misalignments were introduced, The SCT and TRT were corrected perfectly as in the perfect alignment case. Due to movements of higher level structures in this set, some systematic effects may exist. The levels of misalignment are given in Table 1. The axis definitions for the module level uses a local frame where \(x\) and \(y\) are the \(r\phi\) and \(\eta\) measurement directions respectively and \(z\) is out of the plane. For higher levels they correspond to the global frame with \(z\)-axis along the beam direction. _RotX_, _RotY_, _RotZ_ are rotations around the corresponding axes. The module level shifts in the \(r\phi\) measurement direction are around 10 \(\mu\)m. The set attempts to emulate the level of misalignments expected during the early running period. It is not well known what levels of misalignments are expected after certain running periods so this is just an indication rather than being a firm prediction of what is expected at start up. Comparison with the real alignments ("Aligned" set) shows this to be a rather pessimistic scenario.
* **Random5:** As with "Random10", but with levels of misalignment better by about a factor of 1.5 to 2. This is an estimate of what might be expected after several years of running. Like "Random10", this set introduces misalignments at the three levels of hierarchy with levels of misalignment given in Table 2.

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|c|} \hline Level & \(x\) & \(y\) & \(z\) & _RotX_ & _RotY_ & _RotZ_ \\ \hline \hline Module & 10 & 30 & 30 & 0.3 & 0.5 & 0.2 \\ Layer & 10 & 10 & 15 & 0.05 & 0.05 & 0.1 \\ Disk & 10 & 10 & 30 & 0.2 & 0.2 & 0.1 \\ Whole pixel & 10 & 10 & 15 & 0.1 & 0.1 & 0.1 \\ \hline \end{tabular}
\end{table}
Table 1: Residual misalignment for “Random10”. Random misalignments were generated with a Gaussian distribution with \(\sigma\) as tabulated. Shifts are in \(\mu\)m and rotations are in mrad.

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|c|} \hline Level & \(x\) & \(y\) & \(z\) & _RotX_ & _RotY_ & _RotZ_ \\ \hline \hline Module & 5 & 15 & 15 & 0.15 & 0.3 & 0.1 \\ Layer & 7 & 7 & 10 & 0.02 & 0.02 & 0.05 \\ Disk & 7 & 7 & 20 & 0.1 & 0.1 & 0.05 \\ Whole pixel & 7 & 7 & 10 & 0.05 & 0.05 & 0.05 \\ \hline \end{tabular}
\end{table}
Table 2: Residual misalignment for “Random5”. Random misalignments were generated with a Gaussian distribution with \(\sigma\) as tabulated. Shifts are in \(\mu\)m and rotations are in mrad.

## 3 Error scaling

### Error scaling procedure

The intrinsic error of a hit will depend on a number of factors such as the cluster width and track direction. These factors are taken into account when calculating the intrinsic error of the hit. In the case of a perfectly aligned detector, if these intrinsic errors are properly determined one expects the pull distribution (the distribution of the hit residuals divided by the calculated intrinsic error) to have a width close to one.

The differences between the real positions of individual hits and those recorded by a misaligned detector lead to an additional error term that must be added in quadrature to the intrinsic error of the hits.

The errors on the hits directly affect whether a hit is associated to a track, the track propagation and track parameter errors and the objects that use tracks as input, such as vertices. Of particular importance to \(b\)-tagging is the precision of the impact parameter and the vertexing performance. It is therefore necessary to have accurately assigned hit errors.

In this section hits will refer to clusters in the silicon detectors (pixel and SCT) and drift circles in the TRT. To correct the hit errors the diagonal elements of the error matrix are modified using two parameters \(a\) and \(c\):

\[\sigma^{{}^{\prime}2}=a^{2}\cdot\sigma^{2}+c^{2} \tag{1}\]

where:

* \(\sigma\) is the original error assigned to the hit which is a function of the cluster size and track angle. This should normally be close to the intrinsic resolution if properly determined,
* \(a\) is a multiplicative factor on the error, which is meant to compensate for inaccuracies in the intrinsic error determination,
* \(c\) is a constant added in quadrature to the error. This is meant to correct effects attributed purely to residual misalignments.

Since each detector component can have significantly different behaviour, the granularity of each detector component has to be taken into account, and therefore different sets of (\(a\), \(c\)) have to be computed separately for the barrel and endcap regions for each detector technology, as well as for the different \(r\phi\) and \(\eta\) measurement directions in the case of the pixel detector.

For the derivation of the (\(a\), \(c\)) pairs, the distributions of hit residuals and their pull distributions are analyzed, and in particular the deviations of the pull widths from the ideal value of 1 are investigated.

Since the scale factor \(a\) is intended to correct the intrinsic resolutions, this is most easily obtained with a perfectly aligned geometry. Naturally, this is not possible with real data, where more in depth studies will be needed to determine if the assigned intrinsic errors are appropriate. Currently the factor \(a\) is needed as the errors used in the reconstruction do not match those observed in the simulation. It is assumed, however, that the best knowledge from test-beam and simulation will be put into the determination of the intrinsic error such that \(a\) will be close to 1 and any remaining differences would be absorbed into the parameter \(c\).

The widths of the resulting pull distributions can be used directly as the scaling factors \(a\). This is iterated a few times, applying the correction, rerunning reconstruction and then determining new values of \(a\). The iterations are necessary due to correlations between detector components. The factor \(c\) is set to zero when determining the \(a\) factor.

The resulting factors \(a\) are then kept constant when used for the misaligned detector. Several iterations (apply (\(a\), \(c\)) factors, reconstruct sample, analyze pulls) are performed using a misaligned detector, in order to determine the \(c\) factor. It is computed using the formula:

\[c_{i}^{2}=(p_{obs}^{2}-1)a^{2}\sigma_{0}^{2}+p_{obs}^{2}c_{i-1}^{2} \tag{2}\]

where \(c_{i}\) and \(c_{i-1}\) are the values of the \(c\) factor obtained in the iteration \(i\) and \(i-1\), respectively, \(p_{obs}\) is the hit residual pull width observed at step \(i\), and \(\sigma_{0}\) is the average intrinsic detector resolution.

The determination of \(c\) does not rely on any information about the actual detector positions and the procedure can be applied to real data. For this study a sample of high energy single muons was used, while in practice one would need to study the feasibility of extracting the error tuning with a more realistic event sample and track selection.

### Error scaling parameters

The resulting parameters after the tuning are shown in Table 3. The values of \(a\) are seen to be well below one for the SCT and TRT. This is due to an overestimate of the intrinsic errors. This is being improved. The value for \(c\) gives some indication of the level of residual misalignment. For the "Random5" and "Random10" sets, the values of \(c\) are higher than what was input for the module shifts. This is possibly due to a larger error being needed to compensate for the effects of the layer and disc movements. It can be seen that the real alignment results in small values of \(c\) compared to the hand-made sets. In the pixel \(r\phi\) measurement direction one gets \(3\)\(\mu\)m and in the \(\eta\) measurement direction one gets around \(15\)\(\mu\)m for the "Aligned" set.

## 4 Monte Carlo Samples

The performance of \(b\)-tagging was investigated with \(t\bar{t}\) and \(WH(m_{H}=120\)\(\mathrm{\ Ge\kern-1.0ptV})\) samples which are standard samples used in \(b\)-tagging performance studies in ATLAS [2]. The main difference between these two samples is that the \(WH\) events have lower jet multiplicities.

The \(t\bar{t}\) sample includes semi-leptonic and di-lepton channels and this sample is used for measuring both \(b\)-jet and light jet efficiencies. The \(WH(120)\) sample contains two sub samples. \(WH(120)\rightarrow\mu\nu b\overline{b}\) is used to measure \(b\)-jet efficiencies and \(WH(120)\rightarrow\mu\nu u\overline{u}\) for light jet efficiencies. The samples contained no pile-up.

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|} \hline  & All & Perfect & Random10 & Random5 & Aligned \\  & \(a\) & \(c(\mu\mathrm{m})\) & \(c(\mu\mathrm{m})\) & \(c(\mu\mathrm{m})\) & \(c(\mu\mathrm{m})\) \\ \hline \hline Pixel barrel \(r\phi\) & 1.03 & 0 & 31 & 13 & 3 \\ Pixel barrel \(\eta\) & 0.97 & 0 & 71 & 34 & 13 \\ Pixel endcap \(r\phi\) & 1.05 & 0 & 30 & 14 & 3 \\ Pixel endcap \(\eta\) & 1.08 & 0 & 43 & 11 & 15 \\ SCT barrel & 0.78 & 0 & 0 & 2 & 7 \\ SCT endcap & 0.86 & 0 & 6 & 5 & 8 \\ TRT barrel & 0.82 & 0 & 11 & 3 & 37 \\ TRT endcap & 0.77 & 0 & 11 & 10 & 19 \\ \hline \end{tabular}
\end{table}
Table 3: Error scaling parameters for the different alignment scenarios. The parameter \(a\) was tuned using the “Perfect” case and used for all alignment scenarios.

## 5 Effects of misalignment on tracking and vertexing

The tracking and vertexing performance was studied with the \(WH(120)\rightarrow\mu\nu b\bar{b}\) sample, although the other samples could equally have been chosen. A sample size of 27,000 events was used. This sample was reconstructed using three of the alignment sets described in Section 2: "Perfect", "Random10" and "Aligned". All other settings were kept the same. For the "Random10" and "Aligned" sets, samples were investigated with and without error scaling.

### Tracking performance

The track reconstruction efficiency was computed for each scenario by comparing true tracks to corresponding reconstructed tracks. Tracks with \(p_{T}>1\) \(\mathrm{\,Ge\kern-1.0ptV}\) and \(|\eta|<2.5\) were selected. A true track was considered to match a reconstructed track if the true track was the source of at least 50% of the hits associated to the reconstructed track. Next, the efficiency was computed as the ratio of the number of matched tracks to the number of all true tracks. The results for the efficiency for each of the three scenarios are shown in Table 4. The presence of residual misalignment in the "Random10" set causes a loss of about 2% in the efficiency, while the introduction of error scaling completely recovers the loss of performance. The "Aligned" set shows no significant change with respect to the "Perfect" case, with or without error scaling.

The number of fake tracks was also investigated in a similar manner to the track reconstruction efficiency calculation. A track was labeled as "fake" if it had fewer than 50% of its hits from a single true track. The percentage of fake tracks from the total accepted tracks is shown in Table 5 for the different alignment scenarios. The misalignments result in more fakes, and as with the efficiency, this is recovered with the introduction of error scaling.

### Vertexing performance

The performance of the primary vertex finding algorithm was also investigated for the same five scenarios of alignment and error scaling. The efficiency for the primary vertex finding was computed as the ratio

\begin{table}
\begin{tabular}{|l|c|} \hline Setup & efficiency (\%) \\ \hline \hline Perfect & \(97.09\pm 0.02\) \\ Random10 & \(95.50\pm 0.03\) \\ Random10 + error scaling & \(97.22\pm 0.02\) \\ Aligned & \(97.07\pm 0.02\) \\ Aligned + error scaling & \(97.04\pm 0.02\) \\ \hline \end{tabular}
\end{table}
Table 4: Efficiency of track reconstruction.

\begin{table}
\begin{tabular}{|l|c|} \hline Setup & fake tracks (\%) \\ \hline \hline Perfect & \(2.33\pm 0.02\) \\ Random10 & \(2.46\pm 0.02\) \\ Random10 + error scaling & \(2.29\pm 0.02\) \\ Aligned & \(2.34\pm 0.02\) \\ Aligned + error scaling & \(2.27\pm 0.02\) \\ \hline \end{tabular}
\end{table}
Table 5: Ratio of fake tracks to the total number of accepted tracks.

between the total number of reconstructed vertices to the total number of true vertices. It was found that this remains constant, at a value of \(99.68\pm 0.04\%\), irrespective of the misalignment scenario considered.

The primary vertex resolution was evaluated by looking at the difference between the reconstructed and the true vertex position. The resulting distributions for \(x\) and \(z\) directions are displayed in Fig. 1. The results for the \(y\) direction were similar to that in the \(x\) direction. The introduction of residual misalignment causes the distributions to become wider as would be expected with a degradation of the hit resolutions. The shift for the hand-made sets is consistent with the shift of the entire pixel detector that was introduced. For the "Aligned" set a shift in \(z\) of about 90 \(\mu\)m is apparent. The alignment procedures do not fully constrain the six degrees of freedom of the whole detector and no attempt was made to correct to the average primary vertex position in the \(z\) direction. Because of this, the alignment procedure can easily result in such a shift when comparing with truth information.

The values for the resolution are computed as the width of a Gaussian fit to the distributions in Fig. 1 and are shown in Table 6. The resolution is degraded by residual misalignment, for both \(x\) and \(z\) directions. Error scaling helps to partially recover the loss of performance for the "Random10" scenario.

The number of primary vertex outliers was also investigated. Since the shift observed when looking at the resolution should not affect reconstruction, the true vertex position must be corrected by this shift. In the following, a primary vertex was flagged as "outlier" if the distance between the reconstructed vertex and the corrected true vertex position was greater than three sigma (30 \(\mu\)m in the \(x\) direction and 150 \(\mu\)m in the \(z\) direction).

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline Setup & res. in \(x\) (\(\mu\)m) & shift in \(x\) (\(\mu\)m) & res. in \(z\) (\(\mu\)m) & shift in \(z\) (\(\mu\)m) \\ \hline \hline Perfect & \(11.4\pm 0.1\) & \(-0.13\pm 0.07\) & \(51.1\pm 0.4\) & \(-8.2\pm 0.3\) \\ Random10 & \(15.1\pm 0.1\) & \(4.2\pm 0.1\) & \(63.0\pm 0.4\) & \(1.4\pm 0.4\) \\ Random10 + error scaling & \(13.2\pm 0.1\) & \(2.6\pm 0.1\) & \(56.6\pm 0.4\) & \(2.3\pm 0.4\) \\ Aligned & \(13.9\pm 0.1\) & \(-0.18\pm 0.09\) & \(53.7\pm 0.4\) & \(-91.5\pm 0.4\) \\ Aligned + error scaling & \(13.8\pm 0.1\) & \(-0.15\pm 0.09\) & \(55.4\pm 0.4\) & \(-91.6\pm 0.4\) \\ \hline \end{tabular}
\end{table}
Table 6: Primary vertex resolution.

Figure 1: Primary vertex resolution, shown for the \(x\) direction (a) and \(z\) direction (b) for the various misalignment scenarios. ES denotes error scaling.

The percentage of outliers is shown in Table 7, which shows that residual misalignment introduces additional outliers, and therefore indicates a degradation in the primary vertex finding. The number of outliers is however partially diminished by the application of error scaling for "Random10". For the "Aligned" scenario the corresponding scaling factors are much smaller than for "Random10" and the effect of error scaling on the primary vertex performance is negligible.

## 6 Effects of misalignment on \(b\)-tagging performance

For the study of the impact of the residual misalignment on the \(b\)-tagging performance, several data sets were produced with \(WH(m_{H}=120\)\(\mathrm{\ Ge\kern-1.0ptV})\) and \(t\bar{t}\) events. Eight cases were considered corresponding to each specific scenario of residual misalignment ("Perfect", "Aligned", "Random10" and "Random5") with and without error scaling as described in Sections 2 and 3. The performance of the \(b\)-tagging has been assessed by looking at the rejection rate of light quarks at \(b\)-jet efficiencies of 50% and 60% using various tagging algorithms: IP2D, IP3D, SV1 and the combined tagger IP3D+SV1. A description of the different taggers can be found in Ref. [2].

For each of the scenarios using \(WH(120)\) samples, 45,000 \(WH(120)\rightarrow\mu\nu b\overline{b}\) events and 175,000 \(WH(120)\rightarrow\mu\nu u\overline{u}\) events were used. The \(t\bar{t}\) samples contained 50,000 events each with the exception of the "Perfect" scenario without error scaling which had 570,000 events and the "Aligned" scenario with error scaling which had 500,000 events.

### Results

Figure 2 shows the \(b\)-jet efficiency versus light jet rejection for \(t\bar{t}\) and \(WH(120)\) samples for the four misalignment sets with and without error scaling. Rejections for the IP3D and IP3D+SV1 tagger at \(b\)-tag efficiencies of 50% and 60% are tabulated in Table 8 for \(WH(120)\) and in Table 9 for \(t\bar{t}\).

The results for the IP3D+SV1 are also summarized in Fig. 3. As expected, the larger the misalignment, the greater the degradation of the \(b\)-tagging performance. In the case of "Random10", which represents the highest amount of misalignment (shifts of 10 \(\mu\)m in the pixel \(r\phi\) measurement direction), there is almost a factor 2 drop in performance. For "Random5", where the level of misalignment is lower (shifts of the order of 5 \(\mu\)m), the decrease of the light jet rejection rates is lower than in the previous case at around 30% degradation. For the "Aligned" set the loss in performance is around 10 to 20% and lies somewhere between the "Perfect" alignment and the "Random5" set. This is consistent with the level of misalignment suggested by the parameter \(c\) in the error tuning which is 3 \(\mu\)m in the pixel \(r\phi\) measurement direction.

The rejections for \(WH(120)\) are systematically lower than that for \(t\bar{t}\) as observed in other studies [2], however, in general they both show similar trends with misalignment. Some differences are observed with the effects of error scaling which are discussed below. Results are shown mainly for \(t\bar{t}\), although similar conclusions are reached for both samples.

\begin{table}
\begin{tabular}{|l|c|c|} \hline Setup & outliers in \(x\) (\%) & outliers in \(z\) (\%) \\ \hline \hline Perfect & \(1.7\pm 0.1\) & \(4.1\pm 0.1\) \\ Random10 & \(5.5\pm 0.2\) & \(8.3\pm 0.2\) \\ Random10 + error scaling & \(2.8\pm 0.1\) & \(6.1\pm 0.2\) \\ Aligned & \(3.2\pm 0.1\) & \(8.2\pm 0.2\) \\ Aligned + error scaling & \(3.2\pm 0.1\) & \(8.0\pm 0.2\) \\ \hline \end{tabular}
\end{table}
Table 7: Fraction of primary vertex outliers.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{4}{|c|}{Rejection rate} \\ \cline{2-5} Setup & IP3D (50\%) & IP3D (60\%) & IP3D+SV1 (50\%) & IP3D+SV1 (60\%) \\ \hline \hline Perfect & \(331\pm 19\) & \(80\pm 2\) & \(914\pm 86\) & \(243\pm 12\) \\ Perfect + ES & \(332\pm 19\) & \(80\pm 2\) & \(872\pm 79\) & \(234\pm 11\) \\ \hline Random10 & \(97\pm 3\) & \(34\pm 0\) & \(106\pm 3\) & \(41\pm 1\) \\ Random10 + ES & \(76\pm 2\) & \(26\pm 0\) & \(316\pm 17\) & \(89\pm 3\) \\ \hline Random5 & \(250\pm 12\) & \(62\pm 2\) & \(387\pm 23\) & \(113\pm 4\) \\ Random5 + ES & \(154\pm 6\) & \(50\pm 1\) & \(558\pm 41\) & \(148\pm 6\) \\ \hline Aligned & \(321\pm 18\) & \(77\pm 2\) & \(714\pm 59\) & \(190\pm 8\) \\ Aligned + ES & \(273\pm 14\) & \(70\pm 2\) & \(706\pm 56\) & \(180\pm 7\) \\ \hline \end{tabular}
\end{table}
Table 10: Purified light jet rejection rates computed for \(b\)-jet efficiencies of 50% and 60% for the IP3D and IP3D+SV1 taggers for the various misalignment scenarios with and without error scaling (ES) for \(t\bar{t}\) events.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{4}{|c|}{Rejection rate} \\ \cline{2-5} Setup & IP3D (50\%) & IP3D (60\%) & IP3D+SV1 (50\%) & IP3D+SV1 (60\%) \\ \hline \hline Perfect & \(238\pm 11\) & \(68\pm 2\) & \(480\pm 30\) & \(166\pm 6\) \\ Perfect + ES & \(244\pm 11\) & \(70\pm 2\) & \(474\pm 30\) & \(161\pm 6\) \\ \hline Random10 & \(86\pm 2\) & \(32\pm 1\) & \(95\pm 3\) & \(38\pm 1\) \\ Random10 + ES & \(71\pm 2\) & \(25\pm 0\) & \(242\pm 11\) & \(77\pm 2\) \\ \hline Random5 & \(192\pm 7\) & \(56\pm 1\) & \(290\pm 14\) & \(95\pm 3\) \\ Random5 + ES & \(133\pm 4\) & \(46\pm 1\) & \(360\pm 20\) & \(116\pm 4\) \\ \hline Aligned & \(234\pm 10\) & \(67\pm 2\) & \(442\pm 27\) & \(143\pm 5\) \\ Aligned + ES & \(206\pm 8\) & \(62\pm 1\) & \(428\pm 24\) & \(138\pm 5\) \\ \hline \end{tabular}
\end{table}
Table 9: Standard light jet rejection rates computed for \(b\)-jet efficiencies of 50% and 60% for the IP3D and IP3D+SV1 taggers for the various misalignment scenarios with and without error scaling (ES) for \(t\bar{t}\) events.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{4}{|c|}{Rejection rate} \\ \cline{2-5} Setup & IP3D (50\%) & IP3D (60\%) & IP3D+SV1 (50\%) & IP3D+SV1 (60\%) \\ \hline \hline Perfect & \(211\pm 4\) & \(67\pm 1\) & \(399\pm 11\) & \(104\pm 2\) \\ Perfect + ES & \(215\pm 5\) & \(67\pm 1\) & \(372\pm 11\) & \(98\pm 2\) \\ \hline Random10 & \(51\pm 1\) & \(23\pm 1\) & \(49\pm 1\) & \(21\pm 1\) \\ Random10 + ES & \(80\pm 1\) & \(29\pm 1\) & \(166\pm 3\) & \(49\pm 1\) \\ \hline Random5 & \(144\pm 3\) & \(49\pm 1\) & \(165\pm 3\) & \(53\pm 1\) \\ Random5 + ES & \(182\pm 7\) & \(53\pm 1\) & \(311\pm 16\) & \(80\pm 2\) \\ \hline Aligned & \(193\pm 4\) & \(6Figure 3: Light jet rejections using IP3D+SV1 tagger for the four misalignment scenarios at \(b\)-tagging efficiency working points of 50% (left) and 60% (right). Results are shown before and after error scaling (ES).

Figure 2: Light jet rejection versus \(b\)-tagging efficiency for the four different alignment sets for IP3D+SV1 for \(t\bar{t}\) (left) and \(WH(120)\) (right). ES denotes error scaling.

Figure 4 shows the \(b\)-tag weight for IP3D+SV1 tagger for the different alignment scenarios. The differences between the "Aligned" and "Perfect" sets are difficult to see in such plots but for the larger misalignments ("Random10" and "Random5") it is seen that the light jets have slightly larger weights while the \(b\)-jets have lower weights resulting in the loss of discrimination.

### Effects of error scaling

It is observed in Fig. 3 that for the larger misalignment scenarios ("Random10" and "Random5") the error scaling gives a significant improvement, while for the "Aligned" and "Perfect" case the impact of error scaling is small.

Figure 5 compares the \(b\)-tag weights with and without error scaling. Only the "Random10" results are shown. For the other scenarios the differences were less pronounced. The \(t\bar{t}\) events show some differences in behaviour for the error scaling as compared with the \(WH\) events. For \(t\bar{t}\), the error scaling results in only a small difference for the light jets while for the \(b\)-jets the differences are more evident. This is in contrast with the \(WH\) events where the light jets show more differences and the \(b\)-jets are less affected.

The differences are thought to be associated with the \(p_{T}\) spectra of light jets and \(b\)-jets which are different from each other and different for the two event types. The effectiveness of the error scaling is expected to have some \(p_{T}\) dependence since for lower \(p_{T}\), the multiple scattering will dominate and differences in hit errors will be less important. There was insufficient statistics in the samples however to verify if this was indeed the case.

In some cases the use of error scaling results in worse performance. This is discussed further in Section 6.4.

### Purified jets

For comparison with other studies [2] purified jets were also studied. Purification excludes labelling jets as light jets when there is a \(b\)-quark within a cone of 0.8. This gives a more physics independent measure of the performance (although differences will still be seen between samples because of the different \(p_{T}\) and \(\eta\) distributions of the jets contained in the samples). Table 10 shows the results for purified jets for

Figure 4: Jet weight distributions for the IP3D+SV1 tagger for the different alignment scenarios with error scaling for \(t\bar{t}\) (a) and \(WH(120)\) (b).

\(t\bar{t}\). For \(WH\) events only standard jets were considered as other studies [2] show similar results with and without purification. Figure 6 compares standard and purified jets for \(t\bar{t}\) events and it can be seen that the rejections are higher for purified jets but the trends are similar for the different alignment scenarios. The degradation of the "Aligned" case with respect to the "Perfect" alignment is more pronounced after purification (\(19-23\%\) degradation) than for the standard jets (\(10-14\%\) degradation). The effects of error scaling showed similar behaviour for both standard and purified jets.

### Comparison of the different taggers

Figure 7 shows the rejections for different taggers for standard jets. The impact parameter based taggers are the most affected by misalignment with the "Aligned" set showing \(10-20\%\) lower rejections than the "Perfect" case and up to a factor 3 degradation for the largest misalignment. After error scaling, the SV1 tagger shows rather uniform performance for all scenarios considered, with the "Aligned" set giving \(10\%\) degraded performance with respect to the "Perfect" case.

Without error scaling (see Fig. 8) the SV1 tagger shows significant differences for the different alignment scenarios. The ratio between rejections with error scaling to those without error scaling is shown in Fig. 9. It can be seen that the error scaling has the most beneficial effect with the larger misalignments ("Random10" and "Random5") for the SV1 performance. For the "Aligned" scenario the error scaling has little effect while for the "Perfect" case it actually degrades the performance slightly. For the impact parameter based taggers the error scaling has a smaller effect on the \(b\)-tagging performance and even degrades the performance in \(t\bar{t}\) events.

Due to the beneficial effect of the error scaling on the secondary vertexing, the overall performance of the combined tagger (IP3D+SV1) is also improved with error scaling in the case of the "Random10" and "Random5" sets. The error scaling parameter \(c\) is zero for the "Perfect" alignment and small for the "Aligned" set and consequently for both cases the effect of error scaling on the performance of \(b\)-tagging for the combined tagger is also small. For the "Aligned" case, while the relative difference is smaller than the hand-made sets, the error scaling degrades the performance slightly.

The reason for loss of performance with error scaling for some cases can be explained by the following: since the error scaling will generally increase the errors, it will reduce the impact parameter

Figure 5: Jet weight distributions for the IP3D+SV1 tagger comparing with and without error scaling (ES) for “Random10” scenario for \(t\bar{t}\) (a) and \(WH(120)\) (b).

Figure 6: Comparison of light jet rejections using IP3D+SV1 tagger for standard and purified jets in \(t\bar{t}\) events. Left plot: 50% \(b\)-tag efficiency. Right plot: 60% \(b\)-tag efficiency.

Figure 7: Comparison of the light jet rejections for the different taggers, IP2D, IP3D, SV1 and the combined tagger IP3D+SV1. Left plot: 50% \(b\)-tag efficiency. Right plot: 60% \(b\)-tag efficiency. Results are with error scaling using \(t\bar{t}\) events.

Figure 8: As in Fig. 7 but without error scaling.

Figure 9: Ratio of rejections with error scaling to rejections without error scaling. Left plot: 50% \(b\)-tag efficiency. Right plot: 60% \(b\)-tag efficiency.

significance. This is desirable for light jets as it will make them more compatible with zero impact parameter. For \(b\)-jets, however, it also reduces the significance and so will reduce the \(b\)-tagging efficiency for a given weight cut, or in other words, one needs a lower weight cut to obtain the same efficiency and hence results in lower rejection for light jets for a given \(b\)-jet efficiency. The overall effect depends on these two competing effects and so can potentially lead to a loss in performance. While a decrease in performance with error scaling was observed in \(t\bar{t}\) events for the IP2D and IP3D taggers, the opposite was observed for \(WH\) events. As was already discussed above for the \(b\)-tag weight in Fig. 5, the error scaling affects the light jets and \(b\)-jets in the two physics samples differently and this is thought to lead to the differences in the error scaling behaviour seen here.

The effect of error scaling on the secondary vertex tagger will be to recover some secondary vertices which would have otherwise failed quality cuts due to an underestimated error. One will lose some true secondary vertices that are close to the primary vertex as the larger error will make them compatible with the primary vertex, however for similar reasons it will result in fewer fake secondary vertices close to the primary vertex.

### Effects of recalibration

The taggers require probability distribution functions for light jets and \(b\)-jets as described in Ref. [2] and the process of obtaining the set of these reference distributions is known as calibration. The results presented here use the same set of calibrations as used in Ref. [2]. Since misalignments will alter these distributions, it is possible that one can obtain some more discriminating power by recalibrating using the misaligned sample. Methods for obtaining these calibrations from real data are explored in Ref. [3].

To investigate whether recalibrating results in any gain in performance, a new set of reference distributions was obtained for each sample with and without error scaling. In practice one should use independent samples to calibrate and to test the performance, however, here the reference distributions were obtained with the same or a subset of the sample used to measure the performance.

As seen in Fig. 10 recalibration gives better performance, although after error scaling the difference between the fixed calibration and recalibration is only marginal.

One might expect that recalibration may compensate any miscalculation of the errors in a similar way to the error scaling. This is only partially the case as can be seen in Fig. 11, where the relative improvement with error scaling is reduced when recalibrating.

## 7 Conclusion

The effect of misalignment on the tracking performance, as measured by tracking efficiency and fake rates, was small, and error scaling recovered the performance almost to the level that was seen with the perfect alignment. The degradation of the primary vertex was more significant, with resolutions about 2.5 \(\mu\)m degraded and an increase in the number of outliers. The "Aligned" set showed similar performance to the "Random10" despite better \(b\)-tagging performance.

The performance of \(b\)-tagging was clearly degraded with misalignment and the amount of degradation was found to be roughly proportional to the amount of random displacement of modules. Systematic effects are expected to also play an important role, however, the random displacement was the only aspect that was quantified in this study by the parameter \(c\) obtained in the error scaling procedure. In order to disentangle the contributions from random and systematic effects it would be necessary to create dedicated residual misalignment sets with known systematic distortions.

The impact parameter based taggers were observed to be the most affected by misalignment and the introduction of error scaling brought little or even negative benefit to the \(b\)-tagging performance in Figure 11: Ratio of rejections with error scaling to rejections without error scaling. Results are shown for the IP3D+SV1 tagger. Left plot: 50% \(b\)-tag efficiency. Right plot: 60% \(b\)-tag efficiency. Compares using a fixed calibrations and recalibrating for each separate sample.

Figure 10: Comparison of the light jet rejection obtained for the IP3D+SV1 tagger using a fixed calibration or recalibrating for each separate sample. Left plot: 50% \(b\)-tag efficiency. Right plot: 60% \(b\)-tag efficiency.

the case of \(t\bar{t}\) events. Error scaling was important for the performance of the secondary vertex finding, and without it, for larger misalignments the degradation for the secondary vertex based tagger was significant. With error scaling most of the degradation was recovered and the secondary vertex tagger showed uniform performance for all alignment scenarios considered. The behaviour of the combined tagger, IP3D+SV1, follows what one might conclude from the behaviour of the separate taggers, that is, it benefits from error scaling but shows a degradation with misalignment even after error scaling.

The "Aligned" set was the most realistic misalignment scenario studied here and the results were encouraging with rather moderate degradation in the \(b\)-tagging performance. In purified jets from \(t\bar{t}\), the degradation was more evident with 19% loss of rejection at 50% \(b\)-tagging efficiency. However, in a more realistic environment, as seen by looking at standard jets, the amount of degradation was only 10%. At 60% \(b\)-tagging efficiency, the loss of rejection was slightly larger with 23% degradation for purified jets and 14% degradation for standard jets. For WH events the loss of rejection was similar with around 18% degradation at 50% \(b\)-tagging efficiency and 11% degradation at 60% \(b\)-tagging efficiency.

The amount of residual misalignment remaining after applying the actual alignment procedures resulted in only a small loss of performance and so misalignments are not expected to cause a major problem for doing \(b\)-tagging in ATLAS.

## References

* [1] ATLAS Collaboration, _The ATLAS Experiment at the CERN Large Hadron Collider_, JINST 3 (2008) S08003
* [2] ATLAS Collaboration, _b-Tagging Performance_, this volume.
* [3] ATLAS Collaboration, _b-Tagging Calibration with \(t\bar{t}\) Events_, this volume.