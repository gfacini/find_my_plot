# Modelling of the Atlas Data Acquisition and Trigger System

A. Bogaerts, D. Calvet, J. Carter, F. Harris, R. Hauser, C. Hortnagl, S. Hunt, K. Korcyl, H. Li, I. Legrand, I. Mandjadvidze, R. Spiwoks, J. Vermeulen, B. Wu

###### Abstract

This paper details the modelling of the Atlas [1] data acquisition and trigger system using SIMDAQ. The modelling concentrates on the level two system [2], where it is expected that high performance processors and switching systems will be used. As these technologies become available, it is essential to study their impact on Atlas DAQ at full Atlas scale and speed. SIMDAQ, a tool developed to model and study these systems, is described.

## 0 Introduction

The second level trigger is an area of Atlas data acquisition where progress in commercial high speed processors and high performance switching systems has a major impact.

It is not feasible to study the second level trigger at full Atlas scale and speed in the laboratory. Modelling can take the results of small scale laboratory tests and map these to an Atlas scale.

SIMDAQ [3] has been developed, following a proposal [4] in the ATLAS group, as a tool to model these systems. SIMDAQ has been implemented using the object orientated programming language MODSIM II [12]. Previous studies of Atlas DAQ/Trigger in MODSIM have taken place [5][6].

SIMDAQ incorporates current design ideas and technologies with the ability to add new technologies as they become available. It can also be used to model proposed technologies, for example ATM, which are planned for the near future. However, it should be emphasised that an essential part of the system is "generic" switches with precisely defined and understood properties.

### Detector Modelling

There is much work being done in the area of detector design and modelling for Atlas. SIMDAQ is able to take current detector models and map these to the data acquisition model.

These detector models can easily be updated as designs change.

Ref. [7] details the current stage of detector designs for Atlas, with the relevant mappings to the second level trigger system.

For each detector the geometry and segmentation of the readout electronics, the number and capacity of I/O links for data transmission, the size of derandomizing buffers, the number and size (in bytes) of the readout channels (both full granularity and T2 resolution) and a possible reduction factor due to compression or zero-suppression are modelled.

### Input from Physics Simulations

There is also a lot of work being done in the area of simulating physics performance [8] of detectors and trigger algorithms.

These simulations use GEANT [10] to produce readable data files in a portable text format [11] of the output of the detectors for events which have passed the level 1 trigger.

SIMDAQ takes these files and maps them to the detector layouts to give realistic statistics for the input to the modelling simulation, including correlated data. These files also provide level 1 RoI information, which is essential to guide the level 2 system at high luminosities.

### Processing Algorithms and Speeds

Crucial parameters in the simulations are the processing times for the local processors in each subdetector, and global decision timings. These are data dependant and the estimates used are based on Ref. [9].

### Modsim Ii

MODSIM II [12] is a commercial object-orientated simulation language. It incorporates object-orientated methodologies with a powerful discrete event simulator.

_Objects_ can be built which represent the data acquisition components of the second level trigger. _Methods_ can also be built to allow these objects to interact with each other. Many of these objects can be linked in configurations to model the full Atlas data acquisition system. Statistics [13] can be accumulated on various variables of these objects during the simulation run.

### Goals of Modelling

The aims of modelling the Atlas data acquisition are to study the effect of various factors on the design of the DAQ systems at Atlas scale. These factors include:

* The topology of the interconnections.
* The bandwidth and latency of the I/O systems.
* The size of memories.

* The capacity of CPU's.
* The number of CPU's.
* The timings of trigger algorithm execution.

SIMDAQ will help study the influence of these factors on the DAQ system, and also analyse the performance of technologies, including different switching models, and level 2 models, e.g. the farm based model [2].

### The Structure of SIMDAQ

The SIMDAQ simulation model is based on substantial contributions from the Atlas DAQ/Trigger group, RD11, RD13, RD24 and RD31.

An example of a proposed level 2 architecture, which is simulated in SIMDAQ, is shown in Fig. 1.

The SIMDAQ model of DAQ is composed of several groups of objects, these groups are:

Figure 1: A Proposed Level 2 Architecture

* Level 1: The system to read physics data and distribute the data to the level 2 buffers at the appropriate rate and of the appropriate size.
* Processor Technologies: These model the processors which will act on the data and model the latency. These include memories, processors and software.
* Switching Technologies: These model the behaviour of switching systems which are used to pass the data between the processors, and direct data to appropriate processors. Protocols for data transmission are also modelled. The models provided are ATM and SCI (extendable to HIPPI, Fibre Channel and others.)
* Interfaces: Models to act as interfaces between processors and switches. These are I/O connections and I/O protocols.
* Histogramming: Facilities to monitor variables during a simulation run.

These sections are in turn composed of smaller components, which reflects the actual trigger/DAQ structure.

Generic models are available for all of these providing basic functionality without detailed models. These are flexible enough to allow the inclusion of technology models as they become available.

Protocols for the synchronisation of data within different processors are also provided. Initially push architectures are modelled. This can be extended to pull architectures in the future. Different architectures are produced using automatically generated configuration files.

### Input and Parameters for SIMDAQ

The parameters in SIMDAQ are configurable using the _Configure_ and _Partition_ programs [3] to produce input configurations. Some of the less important parameters are still hard-coded into SIMDAQ, but can be moved to configuration options at a later date.

SIMDAQ allows for a number of partitions, which represent subdetectors, to be defined. These partitions can then be linked with a global configuration.

### Detector Modelling for Simulation

The initial simulations have concentrated on modelling the electromagnetic (EMC) and hadronic (HAC) calorimeters and the transition radiation tracker (TRT). These, as discussed in Ref. [7], are modelled in terms of "crate" readout.

So in the barrel of the EMC, for example, there are 16 crates each covering 1.4 x.8 in eta x phi.

[MISSING_PAGE_EMPTY:5]

Table 1 summarises the architectural assumptions for modelling the readout for EMC and HAD and also the TRT into the data buffers, and the data flow from the data buffers (T2 buffers) into the T2 distribution network.

It should be emphasised that we have modelled links from the 'data buffers' to the T2 distribution network (RoI collection network) on the basis of links from a crate rather than a module. This is justified by calculations of the link occupancy.

This means the EMC is split into 32 T2 crate, each crate holding 16 T2 modules. If necessary the full 512 buffer segmentation can be used.

### Physics Input to Simulation

The simulation uses data sets [11] generated by the Atlas detector/physics simulation facility. This has the advantage of correlations in RoI type and spatial distribution, ensuring data distribution is correctly modelled.

The physics input currently provides information for the Calorimeters, TRT and Silicon Tracker (SiT).

\begin{table}
\begin{tabular}{|l|l|l|l|l|} \hline Detector & L2 data crates & RoI data kBytes & RoIâ€™s for jets & Link occupation \\ \hline \hline EMC & 32 & \(\sim\) 1.2 & 3 & 3/32=10\% \\ \hline HAC & 8 & \(\sim\) 0.2 & 3 & 3/8=40\% \\ \hline TRT & 32 & \(\sim\) 0.4 * & 3 & 3/32=10\% \\ \hline \end{tabular}

* This assumes sparse readout 2% occupancy

\end{table}
Table 1: Readout for EMC, HAC and TRT

Figure 4: Segmentation of the TRT into 32 crates

The level 2 data is derived from the high luminosity trigger which is defined below. It produces on average three jet RoI's, 2 electron-gamma RoI's and 1 muon RoI.

The initial datasets were created according to the following level 1 conditions:

The **electron trigger** occurred whenever there was one of;

One or more em clusters with Et > 100 GeV (non isolated.)

One or more em clusters with Et > 35 GeV (isolated.)

Two or more em clusters with Et > 15 GeV (isolated.)

In addition an RoI was flagged for any em cluster with Et > 7 GeV.

The **jet trigger** occurred whenever there was one of;

One or more jet clusters with Et > 200 GeV.

Two or more jet clusters with Et > 150 GeV.

Three or more jet clusters with Et > 50GeV.

RoI's were also flagged for jet clusters with Et > 20 GeV.

The **muon trigger** did not contribute to the first level decision. However, RoI's were flagged when three or four out of four planes were hit in the inner station.

The global first level trigger fired whenever there was a jet or electron trigger.

In the simulation different event type data sets (Jets, Higgs, etc.) can be mixed according to relative cross section. Initially we are running from a data set of Jets, as these dominate the level 2 trigger.

The information relevant to the simulation is:

Type of trigger.

Number of RoI's.

Co-ordinates of each ROI.

Type of each ROI.

Number of active channels in each ROI.

This information is combined, by SIMDAQ, with the detector readout definition to give realistic data volumes and distributions.

### Processors and Processing Times

Processors in SIMDAQ are built from a basic object, which defines the basic fields and operations, and an operating system.

The model of the operating system allows for processes to be added to the operating system. These processes then request the cpu time of the processor, and the operating system implements an interrupt on the hardware cpu.

Processes are linked by internal buffers. The processes take input from an input buffer, perform some function on the data, and then send data to output buffers. Some processors take input from a port, others send output to a port, to communicate with other processors.

Each process takes a certain 'processing time' to act on the data, and this processing time can be modified in the configuration files. The local processing timings we have used are:

* CAL 300us + 25us
* TRT 700us + 200us

For the global processing time, we have used:

* 500us + 10us

The algorithm execution times are modelled as parameterised functions of the input data, determined by algorithm benchmark studies. In initial studies they are modelled as exponential functions. More complex modelling of data dependence will be added.

An example of the internal T2 buffer structure is given in Fig. 5.

The other processor descriptions, of the local and global processors, supervisor and level 3 processor, can be found in Ref. [14].

### Ports

Ports act to take information from one processor and, either, send this information on to another processor, or send the information on to a switching fabric.

Figure 5: Internal structure of a T2 Buffer

The generic port which is provided has a latency for sending and receiving data. This latency is, for output:

* 2 us set up time.
* 1 ns per byte.

The latency for input is:

* 1 us.

A generic "fast" port is also provided which does not take any time for input or output. All ports queue messages if the port is already in use.

### Switches

Switches take data and route the data to a destination.

A generic switch, which performs at 100 Mbytes/s, is provided. This takes:

* 10 us set up time.
* 10 ns per byte.

There is also a "fast" switch provided which takes no time.

### T2 Supervisor

The T2 supervisor schedules which local and global processors should be used for feature extraction and level 2 decision making. This is done when the event is generated. A round robin allocation algorithm is used for both local and global processors.

The T2 supervisor also collects the decisions from the global processors and passes these decisions out to the T2 buffers.

### Level 1 Model

There is a model of the level 1 trigger system which distributes event data and RoI information to the level 2 buffers. Events are produced at an average rate of 100 kHz, gaussian distributed with a small sigma.

Data is distributed according to the input from the physics simulations. Currently no time is taken to distribute the data, and data arrives at all of the buffers at the same time.

There is an option provided to send only RoI information to the buffers. This gives a speed up in simulation execution time, and does not affect the statistics for detectors which are non zero suppressed.

Level 1 can be throttled if T2 buffers become full. The initial study uses limitless buffer to investigate the maximum sizes of buffers.

### Level 2 Model

The level 2 model is constructed of processors and switches, which perform different tasks on the data. Parameters for the level 2 system can be changed in the configuration files, as can parameters for the components of the level 2 system.

### Level 3 Model

The level 3 model is currently a single processor which acts as a sink for all of the data. Data for T2 yes decisions is passed through a switch to the level 3, where it is disposed. Event building, which will operate at about 1 KHz, is not currently modelled.

### SCI in SIMDAQ

The general Atlas simulation is performed by generic switches between T2 buffer and local T2 processors, and also generic switches between local T2 processors and global T2 processors.

The objective of Atlas DAQ simulations with SCI [15] is to replace these generic switches with SCI switching systems, as shown in Fig. 6

### Example SCI topology

SCI switched have an internal structure of smaller switches. The topology of these switches can be altered, but must be specified in a configuration file. An example of the internal structure of an SCI switch for use in SIMDAQ is shown in Fig. 7

Figure 6: Generic SCI simulation model

### Simulation results and analysis

The results of simulations using SCI switches can be found in Ref. [16] and Ref. [17].

### ATM in SIMDAQ

The aim of ATM simulations in SIMDAQ [18] is to replace the generic switches with ATM switches and to study the performance of these switches.

There are several different versions of ATM switches available. These are:

* ATM Alcatel 155
* ATM Alcatel 622
* ATM Fore
* AT&T ATM Fabric (Phoenix)

Currently ATM 622 has been used for several tests. The model is simplified with the following characteristics:

More detailed models of ATM switches will be used in the future.

### Conclusions and Further Information

The Object-Oriented approach has resulted in a flexible and extendable system. Models of new components may be added and existing models can easily be refined for higherprecision when more detailed knowledge becomes available. The model is highly parameterised, reconfigurable (using description files) and not at all restricted to the architecture of Fig. 1. The generic models of interconnections (point-to-point links and switches) may be replaced by technology dependent models which can than be compared under rigorously identical conditions.

More details of architecture modelling activities can be found on the World Wide Web:

[ftp://sunsci.cern.ch/simulation/atlas_daqsim/www/modelling.html](ftp://sunsci.cern.ch/simulation/atlas_daqsim/www/modelling.html)

Further work will include:

* Extension to model other detectors.
* More detailed and accurate switching technologies.
* A more detailed level 1 system, including delays.
* Model of event building.
* Large physics datasets.
* Processing times parameterised as a function of data complexity.

## References

* [1] "ATLAS Letter of Intent for a General-Purpose pp Experiment at the Large Hadron Collider at CERN", Atlas Collaboration, CERN/LHCC/92-4, October 1992.
* [2] Second level Architectures, xxxxx et al., Atlas DAQ note xxx,??? 1994.
* [3] "SIMDAQ Users Guide", SIMDAQ coders, Atlas DAQ note xxx, November 1994.
* [4] "Proposal for ATLAS DAQ Modelling", A. Bogaerts et al., April 1994.
* [5] "Modelling of local/global architectures for second level trigger at the LHC experiment", Z. Hajduk et al., EAST 94-17, February 1994.
* [6] Event Building studies, R. Spiwoks, RD 13 note xxx,??? 1997.
* [7] "Readout data specifications for modelling a level-2 trigger using regions of interest", R Bock and P LeDu, Atlas DAQ note xxx, September 1994.
* [8] "ATLAS Trigger Simulation User Guide", J Carter, Atlas DAQ note xxx, September 1994.
* [9] "Second Level Trigger Feature Extraction Algorithms", R. Hauser & I Legrand, EAST 94-13, June 1994.
* [10] "GEANT Detector Description and Simulation Tool", Application Software Group, CN Division, CERN, CERN Program Library Long Write-ups Q123, June 1993.
* [11] "ATLAS Data for Trigger Studies in a Portable Text Format", J Carter, EAST 94-33, October 1994.
* The Language for Object-Oriented Programming", CACI Products Company, La Jolla, California, January 1993.
* [13] "MODSIM II Histogramming Package for use with ATLAS Trigger/DAQ-Simulations", C.Hortnagl, Internal Note, July 1994.
* [14] "Internal Structure of the Processors in SIMDAQ", S Hunt, Atlas DAQ note xxx, November 1994.
* A Simulation Environment for the Scalable Coherent Interface", B. Wu & A. Bogaerts,???, October 1994.
* [16] "Modelling Results of the Atlas Data Acquisition and Trigger System", Atlas Modeling Group, Atlas DAQ note xxx, November 1994.
* [17] "ATLAS DAQ Simulation with SCI", A Bogaerts,???, October 1994.
* [18] "Using ATM Switches Model in SIMDAQ", D.Calvet,??? Note xxx, August 1994.