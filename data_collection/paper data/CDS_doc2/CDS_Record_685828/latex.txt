###### Abstract

The work and recommendations of the ATLAS Global Descoping Task Force are presented. The revised configuration is believed to be one which retains good integrated physics performance of the detector and reduces the cost by 24.8 MCHF.

Introduction

### Background and Procedures

The ATLAS Cost Task Force was appointed in early October 1995 with the charge of recommending a modest, "physics-driven", descoping of the detector, "at the level of 5%, but more if justified". The descoping was to be one which should retain good overall physics performance of the detector.

The original motivation stemmed from a request by the LHC to list for its November meeting, detector components which could be part of a descoping or staging of the apparatus. At the September meeting of the Collaboration Board ther was a consensus that a global viewpoint, based on overall physics performance, was needed for any sensible descoping or staging. It was indicated that, even if such a viewpoint could not be developed in time for the LHCC document [1], some early perspective might be gained, and that a modest voluntary descoping might be healthy for ATLAS. This could be especially true for the large mechanical subsystems which are about to freeze mechanical designs and to begin Module 0 construction. For these systems, descoping at a later time would be very counter-productive. It was felt that we should not miss this last chance to create some safety margin in the detector costs(contingency) compared to the likely resources, before embarking on the detector construction.

The members of the group were nominated by the ATLAS spokesman, in consultation with the chairman and subsystem coordinators. Members from all the major ATLAS subsystems were included (see table 1), although they were charged with taking a global perspective rather than acting as a representative for their subsystem.

The Task Force met in five closed sessions. Following the first meeting a brief summary of the intentions and planning was distributed to members of the Collaboration Board and comments were solicited. The replies were distributed to all members. Two status reports were given by the chairman to the Executive Board.

At its first meeting, the Task Force considered its mandate and global issues such as overall detector dimensions, and rapidity coverage. At subsequent meetings the descoping options for each subsystem were reviewed from the perspective of their impact on the performance of that subsystem and the overall detector. Contact with each of the subsystem conveners was maintained by the Task Force member from the corresponding subsystem.

### Nature of the Recommendation

This report contains two classes of recommendations. The first has to do with global aspects of the detector in which all subsystems play a role, such as overall dimensions, rapidity coverage, and trigger and data acquisition rates. Specific recommendations are made on these issues. The second class of recommendation involves further descoping in individual subsystems.

The Task Force does not believe it should make detailed design recommendations to the subsystems since these groups themselves are in the best position to optimise their systems within clearly understood constraints. Instead, we have tried to identify aspects of each subsystem which could be legitimately descoped without major impact on the performance or safety margin. Our recommendation is in the form of a reduced cost ceiling for each subsystem with one or more examples of how this target could be reached. We would expect that the subsystem designs would be altered in such a way as to fall within the lowered cost ceiling. It should be emphasized that the ceiling should be met by a demonstrable reduction of the scope of each subsystem (i.e. dimensions, number of detector elements, number of electronic channels, etc), rather than by reduced cost estimates for the original system in the absence of new information. It is proposed that the Spokesman and Resource Coordinator, or a body appointed by them, be responsible for monitoring the compliance.

## 2 Changes in Dimensions

Since the submission of the Technical Proposal (TP) [2], several factors have tended to increase the size of the detector envelope. These include the development of more detailed designs and a better understanding of detector mounting, access, safety clearances, and services. The Task Force considered it appropriate to reconsider the detector envelope to ensure a more comfortable fit in the presently requested cavern, and to provide a small space contingency for future evolution in the detailed design. Clearly there are also cost savings associated with a smaller detector. The maximum detector radius is taken as 11 m. It is also desirable to reduce the total length by at least 2 m to facilitate an improved design of the interface region between the detector and the machine.

The position of the inner edge of the detector with respect to the beam is another important dimension. This affects the design of the shielding in the forward direction and, as described below, modest dimensional changes lead to significant background reductions. Equally importantly, the re

\begin{table}
\begin{tabular}{|l|l|l|} \hline \multicolumn{1}{|c|}{Name} & Detector Responsibility & Institution \\ \hline \hline N. Ellis & Trigger/DAQ & CERN \\ \hline D. Froidevaux & Physics and Inner Detector & CERN \\ \hline F. Gianotti & LAr Calorimetry & CERN \\ \hline C. Guyot & Muon Detector and Magnets & Saclay \\ \hline H. Hoffmann (ex-officio) & Technical Coordinator & CERN \\ \hline P. Jenni (ex-officio) & Spokesman & CERN \\ \hline F. Linde (until 3rd mtg) & Muon Detector & NIKHEF \\ \hline A. Nisati (from 3rd mtg) & Muon Detector & Univ. of Rome \\ \hline J. Pilcher ( chairman) & Tile Calorimeter & Univ. of Chicago \\ \hline L. Rossi & Inner Detector & Univ. of Genoa \\ \hline \end{tabular}
\end{table}
Table 1: _Membership of the Cost Reduction Task Force_duced inner dimensions also lead to a lower detector cost for an acceptably small impact on the physics performance.

### Muon toroids

#### 2.1.1 Reference parameters

In the process of reaching the target cost of 125 MCHF, the barrel toroid is undergoing a thorough redesign. As a result, the muon toroid parameters have been modified in the following way with respect to the values of the TP:

* The magnetic field integral was lowered by 15%. In the barrel this was achieved by decreasing by 20% the number of Ampere-turns per coil. The more effective use of the current comes from a better optimisation of the conductor radial positions for the same radial size of the cryostat. In the end-cap toroids (ECT), the field reduction was achieved by eliminating the innermost loop and lowering the current in the other loops by 11%.
* Prior to the toroid redesign, the ECT was shortened by 16 cm (new cryostat length of 544 cm), and its entry face was shifted to larger \(z\) by 36 cm. At the same time, the barrel half-length was increased by 20 cm.

Figure 1: _Resolution curves at high \(p_{T}\) = 1000 GeV (left) and low \(p_{T}\) = 30 GeV (right) for the reference toroid system. The multiple curves correspond to different azimuthal angles. The solid line corresponds to the average resolution. Regions with bad resolution correspond to poor field coverage in the transition and coil-plane regions, and to the cases with only two measurement stations (barrel ribs)._

This is the configuration recently presented to the LHCC and is now considered the reference for any further parameter changes [1].

The muon spectrometer resolutions obtained with this field configuration, \(B\) = 0.85 \(B_{TP}\), are shown in fig. 1 for muons of 30 GeV and 1000 GeV transverse momentum \(p_{T}\). Compared to the TP values, the resolutions are on average degraded by 15% at high momentum (relevant for Z' searches and asymmetry measurements), and by 10% at low \(p_{T}\) (relevant for low-mass Higgs searches), where the energy loss fluctuations still contribute significantly. Good magnetic coverage is ensured up to a pseudorapidity \(\eta\) = 2.8.

#### 2.1.2 Dimensions and field

The cost dependence of the toroids as a function of the main parameters (field and size) has been estimated in a scaling exercise which takes into account changes in the conductor (length and cross section) and in the cold and warm masses. These masses scale approximately with the field to account for forces which vary like \(B^{2}\). They also affect the costs for tooling, installation, refrigerators, etc. The dependence of the cost on field, for fixed dimensions, is shown in fig. 2 for the barrel toroid. It assumes no major change in technology or design for the lower currents, although small additional steps are expected (e.g. number of voussoirs and ribs). Under these assumptions, lowering the field from 0.85 \(B_{TP}\) to 0.70 \(B_{TP}\) leads to a 5% saving (4.5 MCHF) on the barrel cost. A similar percentage saving holds for the ECT.

Figure 2: _Barrel toroid fractional cost versus magnetic field normalised to the TP field. The reference design and dimensions are used as normalisation. The dashed lines indicate the estimated uncertainties in the cost extrapolation procedure._

Concerning cost dependence on size, a 60 cm reduction of the transverse size of the coil (from 4.2 m to 3.6 m) leads to a saving between 0.7 and 1.1 MCHF depending on the scenario. A reduction of the half-length by 120 cm leads to a saving between 1.8 and 2.6 MCHF. It should be noted that a size reduction also leads to smaller muon chambers and therefore to additional savings. As an example, a reduction of the outer radius by 50 cm produces a saving on the muon instrumentation of about 0.8 MCHF. This is mainly derived from the end-cap detectors. The spectrometer performance is strongly dependent on field and size, especially at high momentum where resolution varies like \(BL^{2}\). The dependence of performance at low and high \(p_{T}\) as a function of the field and the outer radius of the barrel toroid is given in fig. 3. Also shown in this figure is the dependence of the cost on these parameters. Here, the cost corresponds to the total cost of the muon system, i.e. magnets plus instrumentation (170 MCHF in the reference layout).

The fact that iso-performance lines have a weaker slope than iso-cost lines shows that an optimisation of performance at fixed cost favours a rather large outer radius at the expense of a smaller field. However, the cavern cost is not included in this study and there are strong pressures

Figure 3: _Dependence of the muon spectrometer performance at \(\eta\sim\) 0 and of its total cost on the outer radius of the magnet and on the magnetic field. The magnetic field scale factor is normalised to the reference design. The outer radius is defined by the average conductor radius (930 cm in the reference design). The average inner radius is fixed at 510 cm (reference design value). The left-hand and central figures show lines of constant performance, expressed as the inverse of the resolution, for low and high \(p_{T}\). The fractional difference between adjacent contours is 5%. Energy loss and toroid-mass-dependent multiple scattering are taken into account. The right-hand figure shows iso-cost lines with 1% cost difference between contours (to be multiplied by 170 MCHF for absolute cost savings). The cost estimates correspond here to the optimistic scenario of fig. 2._

not to increase the present cavern radius. Given the existing constraints on access and installation, a reduction of radius by at least 50 cm is very desirable, even at the price of slightly reduced performance. This radial reduction, in conjunction with a length reduction described below, maintains the \(\eta\)-value at which the muon transition region is located.

As a first step, the ATLAS radius can be reduced by 25 cm with a more optimal design of the support structure for the BOL muon station1. In addition, we propose to reduce the outer radius of the barrel toroid by 30 cm, thereby gaining an overall reduction of the diameter by 110 cm. The inner radius of the muon system would remain unchanged. As is discussed below, the calorimeter thickness is felt to be already at its minimum value for an adequate measurement of hadronic energy. The 30 cm reduction in the outer radius of the coil leads to a 5% decrease of the field integral. The momentum resolution at low (30 GeV) and high (1000 GeV) \(p_{T}\) are degraded by 3% and 10% respectively (i.e. by 13% and 23% with respect to the TP values).

Footnote 1: Muon-chamber layers are identified by a two or three-letter code in which the first letter (B, T or E) indicates whether the chambers are in the barrel, transition or end-cap region, the second letter (I, M or O) indicates whether the chambers are in the inner, middle or outer station, and, when present, the third letter (L or S) refers to large or small chambers.

The barrel-toroid length depends on the ECT length and placement. Again, a significant reduction (at least 5%) in the overall ATLAS length is very desirable from the point of view of cavern size as well as of cost reduction of the muon system.

Given the already rather high field integral in the forward region (about 6 T\(\cdot\)m at \(\eta=2.5\)), it is proposed to reduce the ECT length by 44 cm (to 5.0 m). This leads to a field integral reduction of 10% on average. In addition, the space allocated to the EI chamber (presently 80 cm) could be reduced by 15 cm by lowering the spacer width from 25 cm to 10 cm. This should be sufficient for the housing of in-plane alignment sensors and support elements, and to ensure the mechanical stability of the chamber. The remaining 65 cm should be sufficient for the insertion of TGCs (about 10 cm thick), MDTs with overlaps (30 cm plus an additional 10 cm) and the alignment system (10 cm for carbon-fibre bars). Further work is needed to make sure that this space can also accomodate the installation of CSCs with a proper overlap with MDTs.

As a consequence of the above, the barrel half-length is reduced by 59 cm. The EO chambers can then be moved inwards by 103 cm. EM moves by 59 cm and the space needed between EI and EO for ECT parking is reduced by 44 cm. With the shorter barrel, one has to face a significant worsening of the field coverage in the transition region which is already a weak point of the toroid system. This can be compensated, as shown in fig. 4, by a better interpenetration of the ECT coils inside the barrel. Such an increase by about 20 cm of the outer ECT radius is made possible with the new barrel-toroid design and the warm voussoirs. The increase of radial forces is small and amounts to 10% for the force per unit length, including the effect of the shorter ECT coil. Although the technical feasibility of this improved interpenetration shows no obvious difficulty, it hasto be assessed by the engineering teams before finalising a decision on the magnet dimensions.

The value of the ECT inner radius has a direct impact on the field coverage at large \(\eta\). We believe there is no compelling physics reason for muon coverage above \(\eta=2.5\) (see Section 3). Hence, it is reasonable to consider the global impact of an increase of the ECT inner bore radius. Little cost saving is expected from the ECT itself, but such a modification would allow the installation of improved shielding. The lower background rates (see Section 2.2) should lead to a less expensive and more reliable forward muon system (see Section 3). An increase of the ECT inner bore radius by 25 cm is proposed. This leads to an acceptable field coverage up to \(\eta=2.6\) (see Section 3).

The proposed radial and longitudinal dimension changes are summarised in table 2 together with the corresponding cost savings from the reduced area of the muon instrumentation. The table includes the savings due to the reduction in outer radius (-25 cm) provided by the optimised BOL support system which is foreseen independently of the toroid dimension changes.

As the toroid system is the most costly item of the ATLAS Common Projects, it is felt that a more significant cost saving, at least at the level of 4% (including the 2% from the dimension reduction) should be recommended. This could be achieved by further reducing the barrel field to 77%

\begin{table}
\begin{tabular}{|l|c|c|} \hline Parameter & Change & Cost saving (MC HF) \\ \hline \hline BARREL TOROID: & & \\ Outer radius & -30 cm & 0.4 \\ Half-length & -59 cm & 0.9 \\ \hline END-CAP TOROIDS: & & \\ Length & -44 cm & 1.2 \\ Outer radius & + 20 cm & Small \\ Inner radius & + 25 cm & Small \\ \hline TOTAL FROM TOROID DIMENSIONS & & 2.5 \\ \hline OTHER CHANGES (design optimisation, current) & & 2.5 \\ \hline \hline Chamber dimension reductions: & & \\ MDT, RPC (BO) & & 0.3 \\ MDT, TGC (TO, EM) & & 0.5 \\ MDT (EO) & & 0.1 \\ TGC (EO) & & 0.1 \\ \hline TOTAL FROM CHAMBER DIMENSIONS & & 1.0 \\ \hline \end{tabular}
\end{table}
Table 2: _Summary of proposed air-core toroid parameter changes with their corresponding cost savings._of the TP value. In any case, a better optimisation of the Ampere-turn distribution between barrel and ECT would have to be considered after the ECT length reduction.

Instead of reduced currents, there may be other methods to achieve a 5 MCHF cost saving and thus to arrive at a 120 MCHF toroid system. These include further optimisation of the magnet designs and the reduction of costs connected with laboratory manpower or industrial contracts. Clearly, the solution, which best preserves the bending power of the magnets within a 120 MCHF cost ceiling, is the most desirable.

The resolutions at high and low momentum are shown in fig. 4 for the worst-case descoped magnet system, relative to both the reference and TP configurations. The calculations assume the new set of dimensions, including the 25 cm increase of the ECT inner radius, a 9% reduction of the barrel field (\(B~{}=~{}0.77~{}\times~{}B_{TP}\)), and a 2% increase of the ECT field (\(B~{}=~{}0.91~{}\times~{}B_{TP}\)). The net degradation in resolution with respect to the reference configuration is \(\sim\) 16% at high momentum.

### Background Radiation

The reduced forward magnet coverage of the muon system permits the insertion of additional heavy material in the forward shielding cone. The resulting reduction in background flux would allow the muon system to work in a less noisy environment and one could therefore envisage the

Figure 4: Ratios of the momentum resolutions (averaged over \(\phi\)), for the proposed toroid dimension changes and worst-case field reduction with respect to the reference and TP resolutions. The current, with respect to the reference design, is decreased by 9% in the barrel and increased by 2% in the ECT. The ratios are shown for high \(p_{T}\) = 1000 GeV (left) and low \(p_{T}\) = 30 GeV (right) respectively. The large variations observed are due to changes in the material distributions and the chamber layout for the reduced dimensions.

descoping of some aspects of the muon spectrometer with little impact on the system performance.

The new shielding never extends beyond \(|\eta|\) = 2.7, so the muon chamber coverage could reach \(|\eta|\) = 2.7, if desired. The outer radius of the copper shielding inside the bore of the ECT has been increased by 25 cm so that it extends from \(|\eta|\) = 4.6 to an outer radius of 98 cm (the inner radius of the ECT cryostat is 101 cm). A layer of "cold" polyethylene, 33 cm thick, has been left inside the ECT, as described in the TP [2]. The free space now available below the first muon station can be used mainly to insert a polyethylene and a lead layer, which were absent in previous layouts for lack of space.

As in the study performed for the TP layout, the prescription described below was followed to derive the detector counting rates from the calculated fluxes:

* neutron fluences, assumed to be isotropic, were folded with the energy-dependent estimated efficiencies for MD Ts of 3 cm tube diameter, operating at 3 Bar with the TP gas mixture. Chamber superlayers were assumed to consist of two sections containing three tube layers each [3];
* photon fluences, assumed to be isotropic, were folded with the energy-dependent estimated efficiencies for the same MDT chamber configuration;
* muon and charged-hadron fluxes were converted to rates, assuming 100% efficiency and one hit per particle;
* the electron detection efficiency was assumed to be zero for energies below 5 MeV, and 100% otherwise.

These assumptions are quite reasonable for the barrel, but less justified in the forward regions, where the background particles are so energetic that the definition of the efficiency is delicate.

The results show that the modified shielding setup is very effective at reducing the background with respect to the reference situation. It is also more effective than the TP shielding layout. This new shielding solves most of the problems and weaknesses found in the post-TP setups. The estimated rates are shown in fig. 5, as a function of \(\eta\), for each of the three superlayer positions. The modified shielding setup is shown on the left and the reference situation on the right. The comparison between the two sets of calculations can be summarised as follows:

* the rates in the barrel are reduced by about 30% and are still dominated by particles emerging from the gap between the barrel and extended barrel tile calorimeters;
* the rates in the forward regions are reduced by factors from 3 to 5, except for the EI chambers, where the reduction is smaller.

It is important to recall, however, that these rates are affected by many uncertainties:

1. the total inelastic pp cross-section and the width of the rapidity plateau;
2. the extent to which the simulated shielding can be implemented in reality;
3. the background fluence predictions;
4. the muon-chamber detection efficiency for low-energy neutrons, photonsand charged particles.

The overall safety factor of five, usually applied to the background rates, corresponds to uncertainties of a factor 1.3 for item 1, of a factor 2 for item 3 and of a factor 2 for item 4. The resulting factor does not include any allowance for item 2.

The improvement in background rates due to this upgraded shielding is considered significant, given the present safety margins on the MD T operating point (see Section 5.4). In particular, it gives more credibility

Figure 5: _Calculated background rates in kHz per cm\({}^{2}\) as a function of \(\eta\), for the inner (top), middle (centre) and outer (bottom) superlayers of the muon system. The rates are shown for the improved shielding (left) and the reference situation (right)._

to the descoping options, which are considered in Section 5.4 for the muon instrumentation.

In the proposed improved shielding design, about 50 tons of copper would be added in each ECT inner bore and about 400 tons of iron to each forward shielding cone. The extra copper shielding, which costs about 0.5 MCHF, would have to be installed at start-up. It would be attractive to add the extra iron shielding, which costs about 1.5 MCHF, as part of an upgrade for high-luminosity running. However, the technical feasibility of such a shielding upgrade needs a more detailed examination.

### Length of Inner Cavity

Since the dimensions of the cavity containing the Inner Detector (ID) influence the size of all the detector systems located outside it, these dimensions are a significant factor in the overall cost of ATLAS. It was not considered practical at this stage of the design of the experiment to study possible changes to the radius of the cavity. On the other hand, a reduction of the length of the cavity by 80 cm (40 cm per side), possibly coupled to a reduction of the length of the solenoid coil by 60 cm (30 cm per side), has been studied in some detail and its potential consequences are reported below.

#### 2.3.1 Impact on Inner Detector

A possible ID layout for the shorter cavity is shown in fig. 6. The highest-\(z\) forward silicon strip disk and three end-cap TRT wheels have been removed on each side. The main consequences of such a layout for the ID and its performance would be:

* a significant degradation of momentum resolution, as shown in fig. 7. The design specifications for the momentum resolution of the ID [4] are no longer met, especially in the case where both the cavity and the solenoid coil are shortened. In the latter case, the expected momentum resolution for 500 GeV \(p_{T}\) muons is degraded from 30% to 34% at \(|\eta|=2.0\) and from 55% to 78% at \(|\eta|=2.5\).
* an increase by \(\sim 10\%\) of the neutron fluence in the cavity. This effect, coupled to the necessity of bringing some of the ID elements down to smaller radii in order to maintain the \(\eta\)-coverage, would mean increased risk for the survival of the ID subsystems.
* the loss of one precision hit for tracks with \(2.3<|\eta|<2.5\). This extra precision hit was added to the two pixel and four microstrip hits per track for the Moges layout of the ID, so as to strengthen the pattern-recognition performance in this most difficult region of the ID fiducial \(\eta\)-coverage.
* increased technical complexity, risk and cost for the TRT. As shown in fig. 6, the last four wheels of the end-cap TRT will have to extend down to an active radius of 38 cm in the case of this shorter cavity, instead of 48 cm in the case of the Moges layout. This is the only way to preserve the coverage of the continuous tracking up to \(|\eta|\) = 2.5. In order to preserve a tolerable straw occupancy in this difficult region, the straw wires would have to be split into two independent pieces, in a way similar to the barrel TRT. These four end-cap wheels would therefore have to be read out at both the outer and the inner radius. Although technically feasible, this solution would imply front-end electronics operating at a radius of \(\sim\) 35 cm, in a radiation flux about a factor of three higher than that of the innermost barrel TRT layers. This might therefore entail a change of technology and an increase in cost for the TRT front-end electronics. Another potential source of cost increase for the TRT arises from the increased number of channels in the shorter cavity layout: this increase would be \(\sim\) 10% if the mechanics of the longer end-cap wheels were modified, in order to increase the straw density at larger radii. Simulations indicate that this would be necessary to maintain an adequate number of crossed straws over the complete \(\eta\)-coverage of the TRT.

Figure 6: _Longitudinal view of the shortened ID layout for \(\eta\)\(>\) 0._

#### 2.3.2 Impact on LAr Calorimetry

A shorter inner cavity would have the following main consequences on the LAr system:

* The total length of the barrel electromagnetic calorimeter would also be reduced by 80 cm. As a consequence, the rapidity coverage of the barrel would decrease from \(|\eta|<1.4\) to \(|\eta|<1.3\), while the coverage of the electromagnetic end-cap would increase from \(1.4<|\eta|<3.2\) to \(1.3<|\eta|<3.2\). The reduced length of the barrel would entail a cost saving of about 1.5 MCHF on the cryostat and on the mechanics. No saving is to be expected, on the other hand, on the electronics, since the channels removed from the barrel would be added to the end-caps (the total coverage of the electromagnetic calorimetry is in fact unchanged).
* The transition region between the barrel and the end-cap electromagnetic calorimeter would shift towards more central rapidity values, and, if the length of the solenoid were not to be reduced by at least 30 cm at both ends, this transition region with degraded performance would become unacceptably large. This is shown in fig. 8, where the total amount of material in front of the electromagnetic calorimeter is plotted for three different layouts. The first bump corresponds to the end of the active barrel, where particles traverse several cryostat walls before reaching the end-cap calorimeter, while the two other (smaller) bumps are due to the cold and warm flanges of the barrel cryostat.

Figure 7: _Momentum resolution versus \(\eta\), for the Morges layout, for the short cavity layout, and for the short cavity and short coil layout._It can be seen that, in the case of the TP cavity, the region where the amount of dead material exceeds \(\sim 4\)\(X_{0}\) is contained within \(\Delta\eta\ \simeq 0.04\). With a shorter cavity, but a coil of the same length as in the TP, this region increases to \(\Delta\eta\ \simeq 0.13\). This is due to the fact that, in the TP layout, the coil ends inside the transition between barrel and end-cap (i.e. in the middle of the first bump in fig. 8 (top)), while if the cavity is made shorter but the coil is kept at the same length, the coil extends beyond the transition region itself and starts to shadow a region where the material thickness would otherwise decrease. Therefore, in order to contain the coil ends within the transition region between barrel and end-cap in a layout with an 80 cm shorter cavity, the coil length has to be reduced by a corresponding 60 cm. The region with a large amount of material in the short cavity thus becomes of a size comparable to that of the TP layout, \(\Delta\eta\ \simeq 0.06\), as shown in fig. 8 (bottom).

The impact of the material on the mean energy response is shown in fig. 9 for the three cases. With the TP cavity, the \(\eta\)-range where the response drops by more than 5 % (i.e. where the energy resolution

Figure 8: _Total material thickness (in radiation lengths) in front of the electromagnetic calorimeter as a function of \(\eta\) in the transition region between barrel and end-cap, for the TP cavity (top), the short cavity and TP coil (centre) and the short cavity and short coil (bottom). The vertical lines indicate the region where the amount of dead material is larger than 4 \(X_{0}\)._

is worse than \(\sim 40\%/\sqrt{(}E)\) and where fiducial cuts are applied in the analysis of physics channels like \(H\rightarrow\gamma\gamma\) and \(H\to 4e\)) has a size \(\Delta\eta\ \simeq 0.15\). With the short cavity and the TP coil, this range increases to \(\Delta\eta\ \simeq 0.24\). With the short cavity and short coil, this range has a size \(\Delta\eta\ \simeq 0.17\), which is somewhat larger than with the TP layout, but still acceptable. These results were obtained with full simulation of the electromagnetic calorimeter and of the Inner Detector, but without magnetic field in the crack between barrel and end-cap, and with a crack size (the distance between the warm wall of the barrel and the warm wall of the end-cap cryostat) of 5 cm instead of the presently proposed 10 cm. For these reasons, the above results are to be considered optimistic.
* The transition between the outer and the inner wheel of the end-cap electromagnetic calorimeter would move from \(\eta\ =\ 2.4\) (TP layout) to \(\eta\ =\ 2.3\). This transition also represents the end of the precision calorimetry, since the outer wheel has the same structure as the barrel calorimeter, in particular it is equipped with strips in the first sampling, while the inner wheel has a coarser granularity. If the detector coverage for precision physics has to extend up to \(\eta\ =\ 2.5\) (see Section 3), then, with a shorter cavity, the inner radius of the outer wheel must be decreased by about 7 cm, and the coverage of the inner wheel is increased by about 10 cm.

Figure 9: _Shower energy reconstructed in the electromagnetic calorimeter (normalised to the generated particle energy) for photons of \(E_{T}\) = 40 GeV as a function of \(\eta\), for the TP cavity (open circles), the short cavity and TP coil (triangles) and the short cavity and short coil (black circles)._

the outer wheel must increase. This would introduce some technical difficulties (for instance, the LAr gap at the inner radius of the outer wheel would become unacceptably small, i.e. less than 1 mm) and also have a negative impact on the performance. In fact the geometrical parameters of the end-cap calorimeter (inner and outer radii of the wheels, thickness and folding angle of the absorber plates, length of the zig-zag, etc.) are chosen in such a way as to minimise the variation of the Accordion response as a function of the particle impact point [5], which directly affects the constant term. With the TP cavity, the response uniformity in the central part of the end-cap region is a factor of two better than with the optimal parameters obtained for a shorter cavity (bigger outer wheel). The consequence is that the local constant term of the energy resolution would increase from \(\sim\) 0.25% for the TP cavity to \(\sim\) 0.40% for the shorter cavity.
* The coverage and dimensions of the forward calorimeter would be slightly reduced. This is because with a shorter cavity the forward calorimeter would move closer to the interaction point. Since the inner radius, which is 7.2 cm at the innermost corner of the electromagnetic section, cannot be further lowered, the forward-calorimeter coverage would be (marginally) reduced from \(|\eta|<\) 4.9 to \(|\eta|<\) 4.8. More importantly, since the transition between the end-cap and the forward calorimeter would be kept at \(\eta\) = 3.2 even with a shorter cavity, the outer radius of the forward calorimeter would be reduced by about 5 cm, which would provide a cost saving of about 0.5 MCHF.

In conclusion, a shorter inner cavity does not bring any benefits to the performance of the LAr calorimetry. In the transition region between barrel and end-cap the performance is not deteriorated in a significant way, provided that the length of the solenoid is reduced by 60 cm. An electromagnetic end-cap calorimeter allowing for precision physics up to \(\eta\) = 2.4-2.5 would be more difficult to build and would introduce a local constant term of the energy resolution larger than with the TP layout.

The total cost saving associated to this change in dimensions would be about 2.0 MCHF from the LAr system. An additional cost saving of about 0.5 MCHF would come from the reduced length of the solenoid.

#### 2.3.3 Impact on Tile Calorimeter

The proposed shortening of the barrel section of the tile calorimeter could be accomodated without a major impact on the basic mechanical design. The module-0 sector, now under construction, would still be useful as a prototype, although it would be 80 cm longer than the final one. The weight of the barrel modules would be reduced by 14% to 17 tons, which could be accomodated more easily by available cranes.

The cost saving from the tile calorimeter for an inner cavity shortened by a total of 80 cm would be 0.8 MCHF.

#### 2.3.4 Impact on muon system

A reduction of the cavity length by 80 cm would lead directly to the same reduction of the barrel toroid length. In the cost model discussed in Section 2.1, this would correspond to a cost saving of 0.6 MCHF.

The impact on muon instrumentation is more delicate to assess, since any change in toroid radius and length requires a new chamber layout. Without changing the inner cavity length, it appears that the layout remains almost unchanged as the border between the barrel and transition regions stays roughly at the same rapidity \(\eta\)-value. This is no longer true with the 40 cm length reduction on each side. If one assumes that it affects only the BO chambers, the additional cost saving on muon instrumentation is about 0.2 MCHF.

#### 2.3.5 Conclusions on Shorter Inner Cavity

In conclusion, the overall cost saving from a reduction of the ID cavity length by 80 cm would be 4.1 MCHF, if one neglects the cost increase of the TRT. This saving is offset by its impact on the ID and electromagnetic calorimeter performances. In particular, the ID momentum resolution becomes significantly worse than its specified at large \(\eta\). The shorter cavity would also imply increased risk to the ID, since its \(\eta\)-coverage would have to be preserved. In addition, the LAr electromagnetic calorimeter performance would be slightly worse in terms of fiducial \(\eta\)-coverage. As will be shown below, a modest descoping of the Inner Detector brings about the same cost savings as a shorter inner cavity. We therefore do not recommend further study of a modified ATLAS design with a shorter cavity.

### Thickness of Tile Calorimeter

Another dimensional change which has been investigated is the reduction of the tile calorimeter thickness by one absorption length. Such a reduction would allow a smaller inner radius for the barrel muon toroid by about 20 cm and a corresponding cost saving. The impact of such a change on the calorimeter performance and on the cost of the toroid has been examined.

The present calorimeter system (LAr plus Tile) represents, at \(\eta=0\), 9.6 \(\lambda\) of active calorimeter, or 10.6 \(\lambda\) of absorber for the muon system. The descoping would reduce these thicknesses to 8.6 \(\lambda\) active and 9.6 \(\lambda\) total.

First, as an independent evaluation of the required thickness, a comparison was made with results of the algorithm used to determine the active thickness of the SDC calorimeter [6]. After small corrections for machine energy and luminosity, this algorithm indicates a required thickness of 9.7 \(\lambda\), in good agreement with the TP design.

Test beam data were used to evaluate, as carefully as possible, the performance of a thinner calorimeter. Two sources of data were available: stand-alone tests of the tile calorimeter prototype, and combined tests with the LAr calorimeter. In the first configuration, the calorimeter thickness was 9.3 \(\lambda\) if all four samplings of the prototype detector were used. IfFigure 11: _Dependence of resolution on energy, for two calorimeter thicknesses. Note that the resolution for the descoped thickness of \(8.6\lambda\) (see text) would lie between the two lines shown._

Figure 10: _Energy resolution for 300 GeV pions, as measured with the tile calorimeter prototype. The left-hand column shows the response for three calorimeter thicknesses without using any weighting to compensate for longitudinal leakage. The right-hand column shows the effect of an optimised weighting of the last sampling to compensate for longitudinal leakage. This weighting introduces a small high energy tail._

a minimum ionising particle was required in the first sampling, the effective thickness was 7.8 \(\lambda\). Finally, full containment could be demanded by vetoing on particles escaping from the rear by using an array of external scintillators. The energy response to 300 GeV pions is shown in fig. 10 for these three cases. If full containment is required, the response is quite Gaussian with a resolution of 4.7% and tails at the level of a few per mil, where tails are defined as events more than 3\(\sigma\) below the reconstructed energy peak. The 9.3 \(\lambda\) configuration shows a similar Gaussian resolution but a 2.7% tail on the low-energy side, corresponding to leakage from the back of the calorimeter. The 7.8 \(\lambda\) configuration shows a tail more than twice as large and a Gaussian resolution degraded to 6.4%. An effort was made to improve the response by compensating for the leakage with a weighting of the signal from the fourth sampling layer. The results are shown on the right-hand side of fig. 10. The Gaussian resolution is improved but the low energy tail is only slightly reduced and a high energy tail is produced. One concludes that for events with leakage close to the average, the performance can be improved by weighting, but events with large fluctuations are not improved, or are even made worse.

Figure 11 shows the resolution versus energy for two calorimeter thicknesses. For the descoped thickness of 8.6 \(\lambda\), which is intermediate between the two curves, the energy resolution would contain a global constant term of 4% (local 3%). This does not meet the goals of 3% and 50%/\(\sqrt{E}\) given in the TP. The size of the low-energy tail is shown in fig. 12 as a function of thickness. Even for the TP thickness, there are leakage effects at the level of 1.6%. For a reduced thickness of 8.6 \(\lambda\) the low energy tail is increased to 3.6%.

From a physics viewpoint, these tails in the response are especially troublesome, since such rare events are unlikely to be described properly by the simulation. The high-energy tail may lead to a false signal for quark compositeness, while the low-energy tail may produce a spurious signal in the missing transverse energy spectrum. The extent of the leakage will depend on details of the jet fragmentation and thus its prediction will contain intrinsic uncertainties.

Figure 12: _For test beam measurements of 300 GeV pions with the tile calorimeter, fraction of events with reconstructed energy more than 3\(\sigma\) below the full energy peak as a function of the calorimeter thickness._

The cost savings for such a change would correspond to 0.2 MCHF from the tile calorimeter and 0.2 MCHF from the barrel muon toroid. The latter figure is small because the higher magnetic field would necessitate a slightly larger cold mass. The background rates in the muon chambers would increase by \(\sim 30\%\). On balance, it was concluded that a reduction in the thickness of the tile calorimeter would not be a wise choice.

## 3 Rapidity Coverage

At this stage of the ATLAS design, it is obviously too late to consider major changes in the \(\eta\)-coverage of the ATLAS detector. However, in the framework of this descoping exercise, where the emphasis is put on minimising the impact on the overall physics performance, removal of non-essential \(\eta\)-coverage in some subsystems should be considered.

The physics studies performed for the ATLAS TP assumed that precision measurements for photons, electron s, muons and jets and identification of photons, electrons, muons, \(\tau\)-leptons and b-quark jets are performed over \(|\eta|<2.5\). Within this fiducial \(\eta\)-coverage, other geometrical losses, such as the crack of \(\Delta\eta=0.15\) between the barrel and end-cap electromagnetic calorimeters and the gaps in the muon trigger and chamber systems, were accounted for where relevant. Although schematic, this assumption is close to the reality of the present design:

* the Inner Detector fiducial coverage, including the longitudinal spread of the interaction point, corresponds to \(|\eta|<2.5\) for single particles. For more complex signatures, such as track isolation cuts applied for clean identification of isolated electrons and muons or b-jet tagging, the assumptions of the physics studies are somewhat optimistic, since the ID \(\eta\)-coverage for single particles would have to extend to about \(|\eta|<2.7\) to achieve these goals. Since it is not in the spirit of the present descoping exercise to propose an increase in the \(\eta\)-coverage of any subsystem, the ID shall be assumed in the following to have a coverage over \(|\eta|<2.5\).
* the precision electromagnetic calorimeter \(\eta\)-coverage extends over \(|\eta|<3.2\) for the energy measurements, but only over \(|\eta|<2.4\) for optimal photon identification, since no \(\eta\)-strips are foreseen in the small wheels of the LAr electromagnetic end-cap calorimeter.
* the magnetic coverage and precision measurements in the muon system extend over \(|\eta|<2.8\).
* accurate measurements of hadronic jet energies, i.e. measurements with a sampling term below \(\sim 50\%\) and a constant term below \(\sim 3\%\), are performed over \(|\eta|<3.2\), using the LAr electromagnetic calorimeters together with the tile and LAr hadronic end-cap calorimeters. It is important to recall here that the complete ATLAS hadronic calorimetry extends over a fiducial coverage of \(|\eta|<4.7\). Any reduction of this overall coverage would seriously degrade all the physics signatures involving missing transverse energy and also the heavy Higgs sector, where jet tagging at large \(\eta\) is an important asset [7].

In the early phase of physics at LHC at low luminosity, the \(\eta\)-coverage of the various subsystems will be important in the search for signatures corresponding to processes with very low rates, such as Higgs boson decays to four leptons, for \(130<~{}m_{H}~{}<180\) GeV, or to \(\mathrm{b\overline{b}}\) pairs. For this reason, the ATLAS \(\eta\)-coverage in terms of particle identification and precision measurements has to be complete at the start-up of the experiment.

The impact of the \(\eta\)-coverage on the sensitivity to possible new physics signatures has been investigated extensively in the past. Two significant examples are quoted below:

* \(H~{}\rightarrow~{}\gamma\gamma\) decays. As discussed in [8], the acceptance for a \(H~{}\rightarrow~{}\gamma\gamma\) signal with \(m_{H}=100\) GeV increases by 15% if the coverage for photon identification increases from \(|\eta|<2.5\) to \(|\eta|<3.0\). At the same time, the acceptance for the \(\gamma\gamma\)-continuum background increases by 20%. The resulting signal significance would increase at most by 5%, even if the quality of the photon identification could be maintained over \(|\eta|<3.0\).
* \(H~{}\rightarrow~{}ZZ^{*}~{}\rightarrow\) 4- lepton decays. The impact of the lepton \(\eta\)-coverage on the sensitivity to this channel is discussed in [9] and illustrated in fig. 13. If the \(\eta\)-coverage of the lepton (electron and/or muon) measurements and identification increases from \(|\eta|<2.5\) to \(|\eta|<3.0\), the acceptance for the signal increases by 21%, both for \(m_{H}=130\) GeV and \(m_{H}=170\) GeV. At the same time, the acceptance for the \(ZZ^{*}/\gamma^{*}\)-continuum background increases by 33% (resp. 26%) for \(m_{H}=130\) GeV (resp. 170 GeV), and the resulting signal significance would increase at most by 5% (resp. 8%). Let us now consider the case of the ATLAS detector, where the ID coverage can clearly not be increased beyond \(\eta=2.5\). One can nevertheless estimate whether the larger coverages of the end-cap electromagnetic calorimeter and muon system would improve the sensitivity to a possible signal in this channel. The improvement one might expect is unfortunately significantly smaller than the ones quoted above, since the absence of Inner Detector information means much worse electron identification, worse muon momentum resolution and larger reducible backgrounds due to the absence of vertexing information. The improvements in signal significance mentioned above would be significantly reduced, probably to 2-3% in the specific case of ATLAS. Since this channel is the one most sensitive to the lepton \(\eta\)-coverage, we conclude that the physics gains resulting from larger lepton \(\eta\)-coverage would be very small, if the increased \(\eta\)-coverage were not to be implemented consistently throughout all subsystems.

These arguments, coupled with the improved background conditions estimated for end-cap toroid magnets with an inner radius larger by 25 cm (see Section 2.2), lead us to propose that the fiducial coverage of the end-cap high-granularity electromagnetic calorimeter and muon system be reduced to \(|\eta|<2.5\):

* the inner wheel of the electromagnetic end-cap calorimeter, which covers the rapidity range \(2.4<|\eta|<3.2\), should be built with re 

[MISSING_PAGE_EMPTY:23]

magnet with larger inner radius is sufficient up to \(\eta=2.6\). The expected cost saving from this reduction is 0.6 MCHF for the CSCs in the EI and EM chambers and 0.1 MCHF for the MDTs in the EO chambers. The corresponding reduction of the magnet cost itself is small.

## 4 Trigger Rates and Readout Bandwidth

### Introduction

It is proposed to reduce the maximum first-level (LVL1) trigger rate of ATLAS in order to obtain savings in the cost of electronics and computing. In the TP design, the LVL1 trigger rate is limited to 100 kHz. We propose reducing the LVL1-rate limit to 75 kHz, which is a less drastic reduction than the one discussed in the recent document to the LHCC [1].

The LVL1-rate limit has implications for the detector front-end systems as well as the Trigger/DAQ system -- the data rate that has to be read out of the LVL1 pipelines directly proportional to the LVL1 rate. Hence, a reduction of the LVL1 trigger rate may bring savings in the electronics chain beyond the pipelines. The extent of any such savings will depend on other constraints, for example those associated with channel groupings or detector modularity, and on fixed costs that do not scale with rate.

Figure 14: Momentum resolution of the end-cap toroid versus \(\eta\), for \(p_{T}=\) 1000 GeV. The radius of the inner bore has been increased by 25 cm with respect to the reference design and the worst-case descoping scenario (see Section 2.1) is assumed.

The main functional blocks in the detector read-out chain are as follows [10]: front-end electronics, front-end link, read-out driver (ROD), read-out link (ROL), and read-out buffer (ROB); in the CORE cost tables, everything up to the ROL is costed with the detectors, while the ROB is costed as part of the DAQ system. Inside the trigger system, the ROB is followed by the second-level (LVL2) trigger system, containing switching networks, and two layers of processing -- so-called local 'feature-extraction' processors and global processors. On the DAQ side, the ROB is followed by the event builder and the LVL3 processors.

In the above, one of the factors that determines the number of components (RODs, ROLs, ROBs, network components) is the data bandwidth. Typically, this is given by the product of the LVL1 trigger rate, the number of channels to be read out, the amount of data per channel, and, in systems where zero suppression is used, the occupancy. Hence, a reduction in the LVL1 rate lowers the bandwidth so that fewer read-out components may be needed.

The processing power required in the LVL2 trigger also depends on the LVL1 rate. To a first approximation, the processing power needed is proportional to the product of the LVL1 rate and the number of instructions needed to process a single event. Hence, a reduction in the LVL1 rate lowers the number of processors required in the LVL2 trigger.

In estimating possible savings from reducing the trigger rate, one has to take into account the fact that there are fixed costs that do not depend on trigger rate. Also, one should keep in mind experience from past experiments where it has often been the case that trigger-rate estimates based on Monte Carlo simulation have been too optimistic. It is therefore considered essential to leave open the possibility of upgrading to the full-performance detector readout and trigger/DAQ system, should this become necessary in the light of experience from initial low-luminosity running.

### Reduced upper limit on LVL1 trigger rate

In the TP, we described a Trigger/DAQ system designed to handle a LVL1 trigger rate of up to 100 kHz. We showed (see Table 5.1 on page 14.0 of the TP) a trigger 'co cktail', efficient for the physics analyses described in the physics chapter of the TP. The calculated rate for this cocktail, for a luminosity of \(10^{34}\) cm\({}^{-2}\)s\({}^{-1}\), is 38 kHz, a factor of 2.5 less than the design limit. It is clearly important to keep a'safety factor' in view of the considerable uncertainties in the rate calculations. However, we propose to reduce the safety factor slightly, lowering the LVL1 rate limit from 100 kHz to 75 kHz in order to economise on the cost of the electronics and computing for the experiment.

Obviously such a measure brings an increased risk to the physics programme which we try to quantify. We do this by evaluating the changes in thresholds that would be required in order to restore the original safety factor -- i.e. the changes in threshold needed to reduce the rates of individual LVL1 triggers by a factor of 0.75. We give changes relative to the high-luminosity threshold conditions listed in the TP. The single electron trigger threshold would have to be raised from \(E_{T}=30\) GeV to \(E_{T}=33\) GeV, close to the Jacobian peak for electrons from W and Z decays. The two-photon and two-electron thresholds would have to be raised from \(E_{T}=20\) GeV to \(E_{T}=22\) GeV, higher than we would like for the H \(\rightarrow\)\(\gamma\gamma\) and H \(\rightarrow\) ZZ\({}^{*}\)\(\rightarrow\)\(4\ell\) searches. The single-muon threshold would have to be raised from \(E_{T}=20\) GeV to \(E_{T}=23\) GeV. Clearly, the rate could be redistributed between the different triggers to optimise the selection of events for physics studies. However, it should be noted that the single-electron and two-photon triggers are responsible for more than half of the total rate quoted in the TP.

### Cost savings in detector readout and DAQ

The lower LVL1 trigger-rate limit diminishes the bandwidth requirements in the detector read-out systems and the DAQ. This implies savings for systems where the number of components is limited by bandwidth.

In the case of the TRT, savings can be made at the level of the RODs and beyond. In the TP design, the number of RODs, ROLs and RODs is limited by bandwidth. This bandwidth was calculated assuming the nominal 100 kHz LVL1 rate, and allowing a factor of two contingency on the hit rate. Given that the 75 kHz rate described above already contains a factor of two contingency, it is considered acceptable to remove the additional contingency factor on the hit rate, provided that it would be possible to upgrade to the full bandwidth system should this prove necessary.

In calculating the reduction in the required number of RODs and other components that results from reducing the occupancy, account must be taken of the overheads associated with the zero-suppression scheme used for the TRT readout. In removing the factor of two contingency on the hit rate, the bandwidth falls to 71% of its previous value. Combining this with a factor of 75% for the trigger-rate reduction, the total bandwidth falls by a factor of about two. Hence, one saves half of the cost of the RODs, ROLs and RODs for the TRT.

In the case of the LAr calorimeter, savings can be made only due to the reduction in the LVL1 trigger rate. Since zero-suppression is not used here, the issue of occupancy is not relevant. Savings are calculated assuming that the numbers of RODs, ROLs and RODs are reduced by 25%. A corresponding reduction has been estimated for the SCT/pixels and the tile calorimeter, scaling according to the respective read-out bandwidths.

For the muon trigger chambers, the read-out modularity is constrained by the layout of the detectors and trigger-tower groupings, and not by bandwidth considerations. Therefore, no significant cost saving is expected from reducing the contingency in trigger rate or occupancy.

The savings possible subsystem by subsystem are summarised in Table 3.

### Cost savings in the LVL2 trigger system

A reduction in the LVL1 trigger rate would also decrease the cost of the LVL2 trigger system -- fewer processors would be needed, and the required bandwidth of switching networks would be reduced. In the following, we make allowance for fixed-cost items that do not scale with LVL1 trigger rate and we assume that the possibility must be retained to upgrade to the full-performance LVL2 system should the need arise.

We assume that the number of processor modules can be reduced by a factor of 75%, which applies both to the local 'feature extraction' processor systems and to the global processor farm. Other LVL2 component costs have been separated into those that scale with rate and those that do not. It should be understood that there are large uncertainties on the required processing power -- work in still in progress to make detailed 'algorithm benchmarking' studies. There are also large uncertainties in the estimated costs of LVL2 components, based on extrapolations of price/performance ratios.

The total savings in the LVL2 trigger system are summarised in Table 4.

We propose not to change the maximum LVL2 trigger rate, so we do not make savings in the DAQ/LVL3 cost other than the ones discussed in the previous section for the read-out buffers. There are three reasons for this:

* Considering the LVL2 trigger cocktail presented in the TP, there is no contingency with respect to the target of about 1000 Hz output rate.

\begin{table}
\begin{tabular}{|l|c|} \hline Item & Cost saving \\  & (MCHF) \\ \hline \hline Processors & 1.4 \\ \hline Other LVL2 components & 0.8 \\ \hline \hline TOTAL & 2.2 \\ \hline \end{tabular}
\end{table}
Table 4: _Cost savings in the level-2 trigger system._

\begin{table}
\begin{tabular}{|l|c|c|} \hline Detector & \(\mathrm{ROD}\), \(\mathrm{ROL}\) & \(\mathrm{ROB}\) \\  & (MCHF) & (MCHF) \\ \hline \hline TRT & 0.8 & 1.3 \\ \hline SCT/pixels & 0.1 & 0.1 \\ \hline LAr calorimeter & 0.5 & 0.8 \\ \hline Tile calorimeter & 0.1 & 0.1 \\ \hline \hline TOTAL & 1.5 & 2.3 \\ \hline \end{tabular}
\end{table}
Table 3: _Cost savings in detector readout and DAQ._* By relaxing slightly the LVL2 selection criteria, it may be possible to minimise the effect on the physics performance of the descoping in LVL1.
* The savings that result from reducing the LVL2 rate are limited to the DAQ/LVL3 system; in contrast, reducing the LVL1 rate brings savings in many subsystems -- detector read-out systems, DAQ and the LVL2 trigger.

### Impact on physics performance

It should be understood that the above descoping may have a negative impact on the physics performance of ATLAS.

Consider first the case of high-luminosity running. If the contingency remaining in the trigger-rate and occupancy calculations is sufficient to cover possible overoptimism in our Monte Carlo simulations, we would be able to maintain the trigger cocktail presented in the TP. If this is not the case, we would have to choose either to raise thresholds or to pay for an upgrade. Assuming an initial period of low-luminosity running, we would have time to make an informed decision once the experiment is operational and the backgrounds have been measured.

The case of B physics is more difficult to address -- this will be performed in the initial period, and it has to be assumed that there would not be time to make an upgrade for this part of the experimental programme. Thus, the only option would be to raise thresholds.

The total LVL1 rate quoted in the TP for a luminosity of \(10^{33}\) cm\({}^{-2}\)s\({}^{-1}\) is 23 kHz, well below the 100 kHz (or 75 kHz) limits. Furthermore, the occupancy will be relatively low in the tracking detectors, and, in particular, in the TRT; hence, bandwidth in the read-out systems will not be an issue.

It must, however, be understood that the LVL2 processing for B physics is very demanding. In contrast to the other triggers, region-of-interest guidance will not be available to search for decay chains such as \(\mathrm{B}\rightarrow\mathrm{J}/\psi X\); \(\mathrm{J}/\psi\rightarrow\ e^{+}e^{-}\), where we are interested in electron \(p_{T}\) down to 1 GeV. Work is in progress to quantify execution times for such LVL2 event reconstruction.

One can make an approximate comparison of the demands of B-physics triggers at low luminosity and those of other triggers at high luminosity. The relevant LVL1 trigger for B-physics studies is the single-muon trigger -- the rate is 8 kHz for a luminosity of \(10^{33}\) cm\({}^{-2}\)s\({}^{-1}\). The LVL1 trigger muon can be validated at LVL2, using region-of-interest guidance from LVL1, reducing the trigger rate to 4 kHz. A search then has to be made for low-\(p_{T}\) tracks in the full TRT at least. This means searching for tracks in a region of \(\eta\)-\(\phi\) space roughly a hundred times bigger than that of a typical region of interest. This is only possible because the muon trigger rate is an order of magnitude lower than the total LVL1 trigger rate at high luminosity, and the TRT occupancy is lower by the same amount. Thus, this very rough calculation shows that the B-physics trigger at 4 kHz input rate at low luminosity is about as complicated as the full cocktail of triggerswith a total input rate of 40 kHz at high luminosity.

It should be noted that the LVL1 low-\(p_{T}\) muon trigger rate of 8 kHz quoted above is the present best estimate at our disposal; in particular, it does not include any safety factor on the backgrounds due to neutron and photon induced hits, secondary hadrons, etc. Increasing these background hit rates by the usual safety factor of five would increase the above LVL1 rate by about a factor of two. This increase would be within the safety margin on the total LVL1 rate, and these background triggers could easily be removed at LVL2.

The above discussion is based on the trigger cocktails set out in the TP. It should be understood that these were intended only to _illustrate_ the ability of ATLAS to trigger in a way consistent with the physics aims of the experiment. In reality, we would probably adjust thresholds at each level in the trigger so as to saturate the next higher level. Note that, just as one would lose physics performance by raising the thresholds compared to the ones listed in the TP, one would gain performance by lowering them. For example, a single-electron trigger threshold of \(E_{T}\) = 25 GeV would be significantly better for selecting W \(\rightarrow\) e\(\nu\) decays than the 30 GeV threshold quoted in the TP.

## 5 Detector Descoping

Each of the subsystems was examined for ways to reduce the cost at modest expense to the physics performance and the operational safety margin.

### Inner Detector

It has been established (see section 3) that it is important to maintain good fiducial coverage over \(|\eta|<2.5\), for all detectors in ATLAS. This is the coverage provided by the present ID design. The considerable amount of optimisation already invested in the ID layout and the short time available to evaluate possible descoping options have pushed us to look for solutions, which can be obtained with small variations around the nominal layout, paying special attention to those variables which induce minimal effects on the performance or which are not yet fully optimised. Two strategies can be considered to reduce the cost of the ID: reducing its performance, or increasing the risk of a failure or a degradation of performance under the severe flux conditions foreseen at the LHC. The effects of the various options on the three subsystems of the ID (pixels, strips and TRT) are evaluated separately below.

#### 5.1.1 Rejected options

The performance reductions which have been considered and rejected are: a degradation of the spatial accuracy, and a smaller number of measurements (see also [1]).

* **Spatial accuracy.** The cost of silicon detectors and of the front-end chips increases approximately linearly with the area of silicon. A degradation of spatial accuracy does not appreciably affect the cost of the pixel system because neither the area of the front-end electronics nor the area of the detectors (which must be approximately the same due to the bump-bonding technique) will change if a different segmentation is used. A reduction of the number of channels would however simplify the cooling and the bump-bonding. This last item is expensive, about 13% of the total cost, but cheaper solutions (i.e. those which are standard in the electronics industry) are available only if one would increase the pitch up to 200 \(\mu\)m, which is considered unacceptable. A reduction of accuracy would only slightly decrease the cost of the strip electronics. An increase of the strip pitch from 75 to 100 \(\mu\)m would imply a 10% degradation of momentum resolution and a 50% deterioration of the two-track resolution. The estimated saving would be about 1.9 MCHF. No saving is expected from the TRT, where the spatial accuracy is provided by a drift-time measurement, if no increase of the straw radius is considered. This possibility is discarded, since the TRT occupancy is already of concern for a 2 mm straw radius.
* **Number of measurement points.** Here the problem is different for the silicon (precision tracking) and the TRT (continuoustracking). Reducing the number of precision points from 6 to 5 would result in significant track losses: the number of 3 (resp. 4)-point tracks would increase from 0.6% (resp. 5.4%) to 4% (resp. 30%). This would put at risk the silicon-initiated pattern recognition. The costs saving would be large, about 5 MCHF depending on the layer removed, but the robustness of the ID performance would be endangered. A reduction of the number of continuous points would give only a small saving. A 10% reduction in the number of straws would reduce the cost of the TRT by only 4% or 0.6 MCHF, and would increase the fake track rate by a factor of 10.

#### 5.1.2 Preferred option

The descoping option proposed here is based on a modest risk increase for the ID, without appreciable performance reduction. This descoping would affect differently the three subdetectors: the TRT would limit its data-transmission bandwidth, the strip detectors would be more exposed to radiation damage, and the pixels would be less effective in pattern recognition. In both types of silicon detectors, the descoping would be achieved by reducing the silicon area, since most of the cost, 75% for the strips and 80% for the pixels, scales with the detector area. The TRT is the device that is expected to produce the highest data rate in ATLAS. The present estimate, 630 Gb/sec, contains a safety factor of two on the expected hit rate. A further safety factor of two is contained in the maximum LVL1 trigger rate (see Section 4). It therefore seems acceptable to drop the first safety factor. This, together with the LVL1 trigger rate reduction described in Section 4, would save 0.8 MCHF in the TRT read-out electronics. The reduction of the LVL1 trigger rate should also decrease somewhat the cost of the silicon read-out electronics. This saving will be precisely evaluated once the read-out architecture has been chosen. For the time being, a cost saving of 0.1 MCHF is estimated. The area reduction in the silicon detectors will follow different criteria as we consider the barrel and the end-cap, or the pixels and the strips. For the barrel strips, a displacement of 2 cm inwards in radius \(R\) is proposed, as well as a non-uniform distribution of the measuring planes along \(R\). The reduction of the external radius from 52 cm to 50 cm gives a better coverage of the transition between the barrel and the end-cap region. The reduction of the innermost radius from 30 cm to 28 cm shortens by \(\sim 10\%\) the detector lifetime because of the irradiation. This last point is of concern, since it is believed that the safety margin for survival is already too small for comfort at a radius of 30 cm. More research and development work on radiation resistance of silicon detectors is obviously to be pursued to increase the lifetime expectation. In particular, further investigations of n\({}^{+}\)-strips on n-bulk and of operation at low temperature (e.g. -15\({}^{o}\)C) are of prime importance, in particular for the pixel detectors. Equal spacing between the SCT barrel planes is not strongly justified, even if preferred for mechanical reasons. Pattern recognition considerations point to a different solution since the extrapolation distance \(\Delta\)R from one layer to the next should follow the evolution of the layer occupancies. A layout based on constant \(\Delta\)R \(\cdot\)\(\Delta\)O, where \(\Delta\)O is the difference in occupancy between the two layers is therefore proposed. This barrel configuration, with radii at 28.0, 34.0, 41.5 and 50.0 cm, is shown in fig. 15. For this layout, the area of the barrel strip detectors is reduced by \(\sim 6.5\%\) and corresponds therefore to a cost saving of 1.4 MCHF. The descoping of the barrel pixel detectors would affect the outer and not the inner radius. The reason can be understood from fig. 16, which shows that, around a radius of 11.5 cm, the dose increases very steeply as the radius decreases. A small reduction of the detector area (and therefore of its cost) would translate into a greatly increased risk for the detector, which is already exposed to the highest dose. The present radial position of the outer (16.5 cm) pixel layer is justified

Figure 15: _Sketch of a possible layout for a descoped Inner Detector. Thin lines represent silicon detectors, while thick lines represent GaAs detectors._

by the lever arm needed to extrapolate to the innermost barrel strip layer, for the case where the pattern recognition procedure starts from the pixel layers. It is also needed to provide sufficiently accurate track segments in space, to be extrapolated to the calorimeters or to the interaction point for the LVL2 trigger. A 30% decrease of this lever arm, corresponding to an outer pixel radius of 15.0 cm, would reduce the barrel pixel area by \(\sim 5.4\%\), and therefore the cost by 0.4 MCHF, while maintaining sufficient extrapolation accuracy. The radii proposed, both for the pixels and the strips, should obviously be further optimised, taking into account other design aspects such as the modularity of the system and the results from full simulation.

The proposed descoping of the end-cap strip detector layout is based on a small reduction of the average number of measurement points, which is close to seven in the Morges layout. One of the two small wheels could be removed and, in addition, the wheel extending down to a radius of 20 cm could be reduced in size, so as to extend down to only 26 cm. This would result in a reduction of area of \(\sim 7.2\%\) for the silicon part and of 13.7% for the GaAs part. The overall cost saving would be about 1.3 MCHF. The number of precision measurement points along \(\eta\) and the probability to have fewer than six precision space points per track are shown in fig. 17.

The number of pixel wheels cannot be reduced, since a minimum of two pixel points and four strip points per track is required. A cost saving, nevertheless, could be obtained by reducing the area of the wheels and installing them at smaller \(z\), in order to cover the same acceptance. This is possible because the pixel barrel layers are placed closer to each other in the proposed descoped layout. The pixel wheels, similarly to the strip wheels, could be designed with a large outer part (from 14.8 cm to 20.5 cm in radius) and a small inner part (from 11.5 cm to 14.8 cm in radius), which, in case of radiation damage, could be replaced. The wheel

Figure 16: _Neutron equivalent flux versus radius integrated over 10 LHC years according to GEANT and FLUKA simulations._

at large \(z\) would only be equipped with the outer part. The reduction in area obtained in this way would be \(\sim 7.3\%\) and would correspond to a cost saving of 0.3 MCHF.

The descoped layout is shown in fig. 15. The comparison of the descoped and Morges layouts, in terms of the number of precision space points per track and momentum resolution, is shown in fig. 17 and in fig. 18 respectively. The descoped layout has marginally worse momentum resolution for \(\eta\sim 2.5\) and a slightly better \(\eta\)-coverage for tracks with at least six space points. The average number of space points for \(|\eta|>1.5\) is, however, lower by about 0.3.

This example of a descoped ID layout is very comparable in performance to the Morges layout. A total cost saving of 4.3 MCHF could thus be obtained at moderate increase of the operational risk to the ID and at small cost to the performance. Given the many degrees of freedom still present today in the ID design, other descoping options are of course possible. In particular, prior to freezing the final ID design, several decisions must still be taken, some of which are not cost neutral. The ID community, which is responsible for the construction and the operation of the detector, would of course be entitled to find better ways to achieve similar cost savings.

Figure 17: _Number of precision tracker space points per track versus \(\eta\) and probability for a track to have fewer than six space points versus \(\eta\). The thin dashed line represents the Morges layout and the thick line the proposed descoped layout._

### LAr Calorimetry

The LAr system has undergone extensive detector optimisation over the last two years. The aim of this work was to satisfy the performance specifications described in the ATLAS LoI and TP without increasing the cost of the detector. On the basis of this principle, options such as liquid krypton as active medium for the barrel calorimeter instead of argon, which would have improved the ATLAS physics reach for channels like \(H\rightarrow\gamma\gamma\) and \(H\to 4e\) by \(\sim 10\%\), have not been adopted [11]. Therefore, at this stage significant changes in the detector layout would degrade its performance, and thus the ATLAS physics potential for channels based on the calorimeter, low mass Higgs searches _in primis_.

Furthermore, the calorimeter design is in an advanced phase, since the construction of some parts, for instance the barrel electromagnetic, has to start immediately if ATLAS wants to meet the LHC schedule.

These considerations limit the descoping scenarios of the LAr system that would be possible in practice. Nevertheless, several descoping possibilities have been considered:

* Reducing the transverse granularity of the barrel and end-cap electromagnetic calorimeter.
* Reducing the longitudinal and transverse granularity of the hadronic end-cap calorimeter.
* Replacing the presampler detector with a massless gap.
* Replacing the honeycomb cold wall of the barrel cryostat with a standard solid wall.

Figure 18: _Momentum resolution for the Morges layout and the descoped layout versus \(\eta\)._* Reducing the dimensions of the forward calorimeter.
* Reducing the number of read-out drivers (ROD) and read-out links (ROL), as a consequence of the global reduction of the LVL1 trigger rate from 100 kHz to 75 kHz (see Section 4).

Advantages and disadvantages of these options are discussed in detail below. Motivations are given why some of them have been retained while others have not.

#### 5.2.1 Granularity of the electromagnetic calorimeter

The longitudinal and transverse segmentation of the electromagnetic calorimeter has been optimised by balancing performance issues, such as electron and photon identification capability and tolerable levels of electronic and pile-up noise, with technical issues (detector capacitance, modularity of the calorimeter mechanical structure) and with cost arguments.

The detector granularity proposed in the LoI was \(\Delta\eta\times\Delta\phi=0.02\times 0.02\). It was subsequently descoped to \(\Delta\eta\times\Delta\phi=0.025\times 0.025\) in the layout of the TP. The following ways of further reducing this granularity have been considered:

1. Reducing the longitudinal and transverse segmentation of the inner wheel of the electromagnetic end-cap (\(2.4<|\eta|<3.2\)). This proposal is discussed in Section 3 and is recommended. The corresponding cost saving is 1.2 MCHF.
2. Reducing the granularity of the \(\eta\) strips, which equip the first sampling of the electromagnetic calorimeter over \(|\eta|<2.4\). The main purpose of the strips, which have a size \(\Delta\eta=0.025/8\simeq 0.003\), is to provide adequate \(\gamma/\pi^{0}\) separation in order to reduce to an acceptable level the large jet background to a possible \(H\rightarrow\gamma\gamma\) signal. More precisely, a \(\pi^{0}\) rejection of \(\sim\) 3 for 90% photon efficiency is required. Figure 19 shows the \(\pi^{0}\) rejection obtained in ATLAS with the TP granularity and with full simulation of the calorimeter and the tracker for \(E_{T}=50\) GeV. It can be seen that in the best case, i.e. when both the information of the calorimeter strips and of the ID are used (open squares), the target rejection factor of \(\sim\) 3 is achieved only close to \(\eta\simeq 0\), while at larger rapidity the rejection is 10% smaller because of the effect of the dead material in front of the calorimeter. These results, which are optimistic since the rejection decreases by another \(\sim\) 10% when the electronic and pile-up noise is included, demonstrate that the strip granularity is not overdesigned. The effect of even a slight reduction of this granularity on the \(\pi^{0}\) rejection can be observed in fig. 20. The minimum practical change, i.e. decreasing the granularity to \(\Delta\eta=0.025/6\simeq 0.0042\), would reduce the rejection by \(\sim\) 15% (even more if one took into account the effect of the increased electronic and pile-up noise), and therefore increase the jet background to \(H\rightarrow\gamma\gamma\) by 20-30%. Though it would allow ATLAS to save about 3 MCHF, this descoping would seriously compromise the possibility of detecting a Higgs signal in the two-photon decay mode, and has therefore been rejected.
3. Reducing the granularity of the \(\eta\) strips only at specific places of the calorimeter coverage: - In the TP design, when going from the central part of the barrel calorimeter to the end-caps, the spatial separation between the two photons from \(\pi^{0}\) decays and the width of the strips are reduced in the same proportion. In principle this should lead to a constant \(\pi^{0}\)-rejection capability as a function of rapidity. However, a limit is reached when the strip pitch becomes too small. With a granularity \(\Delta\eta\simeq 0.003\), the physical size of the strip is less than 2 mm close to \(\eta=2.4\), which is probably too narrow to be effective. Reducing the strip granularity from \(\Delta\eta=0.025/8\) to \(\Delta\eta=0.025/6\) for \(2.0<|\eta|<2.4\) would save about 0.5 MCHF. Simulation results are needed to assess whether this granularity change is acceptable in terms of detector performance for \(\gamma/\pi^{0}\) separation. - Part of the transition region between the barrel and the end-cap calorimeters (see Section 2.3.2), namely the range \(1.38<|\eta|<1.53\) (see fig. 9), probably cannot be used for precision physics, and fiducial cuts are therefore usually applied in this range. Photon identification as well as energy measurements would be difficult in this region, as

Figure 19: _Rejection of \(\pi^{0}\)’s of E\({}_{T}\) = 50 GeV, for 90% photon efficiency, as a function of \(\eta\) in the barrel region._

demonstrated by the top plot in fig. 21. This shows the distribution of the "profile" variable, an indicator of the shower size defined as the energy contained in the two most energetic strips divided by the energy contained in sixteen strips, for photons and \(\pi^{0}\)'s outside the crack (as reference) and for photons inside the crack. It can be seen that while photons at \(\eta\)=2.0 are rather well separated from \(\pi^{0}\)'s at the same rapidity, the shape of single photons in the crack is washed out by the upstream material, so that identification becomes impossible there. Therefore, strips could be removed from a region of size \(\Delta\eta\simeq 0.15\) at the barrel/end-cap transition. This would allow a reduction in the number of channels by 5300 units, and therefore a savings of about 0.6 MCHF if the channels were grouped inside the cryostat. In contrast, photon identification is not hopeless in the regions of the cold and warm flanges of the cryostat (\(\eta\simeq 1.57\) and \(\eta\simeq 1.75\) respectively, see figs. 8 top and 9). As shown in the bottom plot of fig. 21, single photons in these regions maintain a narrower shape than \(\pi^{0}\)'s (the separation would be even better if these photons were compared to \(\pi^{0}\)'s also hitting the flanges). Furthermore, a lot of effort is being invested to improve the cryostat design, so as to reduce the

Figure 20: _Rejection of \(\pi^{0}\)’s of E\({}_{T}\)=50 GeV, for 90% photon efficiency, as a function of the strip granularity, obtained at two different rapidities by using only the information of the strips._

[MISSING_PAGE_EMPTY:38]

barrel consists of 1024 absorber plates arranged in sixteen mechanically independent azimuthal supermodules [2]. The absorber plates are grouped together four-by-four to form \(\phi\) cells of \(\Delta\phi\simeq 0.025\). These cells are in turn grouped four-by-four to form trigger cells of \(\Delta\phi\simeq 0.1\). This \(\Delta\phi\) is also the granularity of the hadronic calorimeters. Any change in the \(\phi\) granularity must satisfy some minimal constraints: there must be an acceptable number (not too large, not too small) of supermodules; this number has to be an even number; there must be an integer number of trigger cells per supermodule. These constraints lead to only one possible solution (besides the TP one), a model in which the calorimeter consists of 896 absorber plates arranged in fourteen supermodules. In this case, the cell granularity would be \(\Delta\phi\simeq\)0.028, and the granularity of the trigger cells, of the strips and of the hadronic calorimeters would therefore become \(\Delta\phi\simeq 0.028\times 4\simeq 0.112\). This solution, which would save 2.7 MCHF, represents a rather soft change of the detector granularity, thus it is expected to have small impact on the performance. There are, however, several technical problems. Apart from the rather unusual modularity of the mechanics, which would be based on a multiple of seven, the smaller number of plates would have consequences on the Accordion bending angle, on the induced plate shrinking in the cold, and on the way of supporting the calorimeter at the internal radius. Such a scheme would require a redesign of the detector. In particular one would have to consider as yet unexplored solutions for the internal support structure in order to avoid the opening of unwanted gaps in between adjacent supermodules. Since this change in design would result in severe delays to the construction of the calorimeter, this descoping option was not retained.

Another possibility, which is technically easier and which does not affect the calorimeter mechanics, would be to group the cells in the second sampling two-by-two in \(\phi\), so that the granularity in this compartment would become \(\Delta\phi\simeq\) 0.05. This solution, which would save 2.9 MCHF, presents two sorts of problem:

* The cell capacitance would increase by a factor of two; in particular it would become as large as 4 nF at the end of the barrel. In addition to the increase in electronic noise and to the decrease of the response speed, such large capacitances, which have so far not been tested on a prototype, would introduce some risks in the detector operation in terms of stability of the electronic chain.
* Concerning the impact on the performance, the contribution of the electronic noise to an electromagnetic shower would increase by 50%. Furthermore, particle identification (\(b\to e\) tagging, \(\gamma\)/jet and electron/jet separation) would be degraded; in particular the jet background to a possible \(H\to\gamma\gamma\) signal would increase by more than 15%. The calorimeter position resolution in \(\phi\) would be deteriorated by a factor 1.7 (fig. 22), thus compromising the use of the shower barycentre as input to the bremsstrahlung fit procedure in the ID, especially at large rapidity. Moreover, the local constant term of the calorimeter, which is due to the modulation of the A recordion response as a function of the shower position in \(\phi\), would increase from 0.2% to about 0.4% because the correction of this modulation would suffer from the degradation of the position resolution shown in fig. 22.

For these reasons, this option is not recommended for descoping. The LAr community is, however, encouraged to consider the possibility of grouping the cells two-by-two in \(\phi\) outside the cryostat as a valid staging scenario, should it become necessary due to lack of funds, since it would allow for a cost deferment of about 2 MCHF.
5. Reducing the granularity of the second sampling in the \(\eta\) direction. Unlike the granularity change in \(\phi\) discussed above, decreasing the

Figure 22: _Position resolution of the electromagnetic calorimeter in \(\phi\) as a function of \(\eta\), for electrons of E\({}_{T}\) = 40 GeV (full simulation). Results obtained with a granularity \(\Delta\phi\ \simeq\ 0.025\) (TP layout) and with a descoped granularity \(\Delta\phi\ \simeq\ 0.05\) are shown._

granularity in \(\eta\) is technically easy and has small impact on the mechanics. This is because the cell segmentation in the \(\eta\) direction is obtained by etching pads on the kapton electrodes. However, descoping the granularity in \(\eta\) and not in \(\phi\) would not be natural for the reasons explained above. Furthermore, with the present granularity the shower is fully contained in a cluster of three cells in \(\eta\) (except at large rapidity, close to \(\eta\) = 2.4), so that any increase in the cell size would introduce additional noise and pile-up without contributing any useful information. The angular resolution in the \(\eta\) direction (pointing), which is needed to reconstruct the vertex position in \(H\rightarrow\gamma\gamma\) events, and which is dominated by the position resolution in \(\eta\) in the second sampling of the calorimeter, would also suffer from a significant descoping of the \(\eta\) granularity. Therefore this option was not retained.

In summary, the retained descoping options for the granularity of the electromagnetic calorimeter are: a reduction of the granularity and longitudinal segmentation of the end-cap inner wheel (estimated cost saving 1.2 MCHF); removal of the strips in the crack region and/or a decrease of the strip granularity at large rapidity (estimated cost saving 0.8 MCHF).

#### 5.2.2 Hadronic end-cap calorimeter

Several cost-effective changes to the layout of the hadronic end-cap calorimeter have been considered in the last months within the LAr community:

* Decrease the number of modules per wheel from 32 to 16. This would reduce the plate machining.
* Halve the number of preamplifiers in the liquid by ganging two pads together. This might be possible thanks to an improved design of the preamplifier chip, but needs to be confirmed by prototype studies over the next months.
* Increase the thickness of the (Cu) absorber plates in the second wheel from 25 mm to 50 mm, which would allow one to reduce the number of LAr gaps and therefore of read-out components (amplifiers, ElectroStatic Transformer boards, cables, etc.).
* Reduce the transverse segmentation from 0.1 \(\times\) 0.1 to 0.2 \(\times\) 0.2 for \(|\eta|>\) 2.4.
* Decrease the number of longitudinal samplings from four to three, which would reduce the number of channels.

These changes are expected to have only small impact on the jet energy resolution, as shown by preliminary simulation studies. On the other hand, the impact on the measurement of catastrophic muon energy losses in the calorimeter is not negligible: the resolution for muon-induced electromagnetic showers of energy \(E>\) 1 GeV would deteriorate from 24%/\(\sqrt{E}\) to 38%/\(\sqrt{E}\) when increasing the plate thickness in the second wheel from 25 mm to 50 mm.

The net cost saving from the above is estimated to be 1 MCHF.

#### 5.2.3 The presampler

The possibility of replacing the presampler detector with a massless gap in order to save cost has been considered.

The presamplerislocated in front of the barrel electromagnetic calorimeter, just behind the cryostat cold wall. It extends over a radial space of 3.5 cm, of which 1 cm is the LAr active part, and has a granularity \(\Delta\phi\times\Delta\eta\simeq 0.1\times 0.025\). The total number of channels is about 7000. This granularity has been already descoped as compared to the TP, and the number of channels reduced from about 28000 (TP layout) to about 7000 (present layout), at the price of a small deterioration in the measurement of the shower angle in the \(\eta\) direction.

The main role of the presampler is to correct for the energy lost by photons and electrons in the dead material in front of the barrel calorimeter. This task is particularly important in the transition region between the barrel and the end-cap calorimeter that was described above.

Figure 23 shows the total dead material in front of the presampler as a function of rapidity (central curve). This material is 1.1 \(X_{0}\) at \(\eta=0\) and increases up to 2.4 \(X_{0}\) at the end of the barrel [12].

Figure 23: _Total amount of material in front of the barrel electromagnetic calorimeter as a function of \(\eta\). Bottom curve: material up to the end of the cryostat (ID included). Central curve: material in front of the presampler. Top curve: material in front of the active calorimeter if the presampler is removed._It can also be seen that the amount of material in front of the active calorimeter is rather large (top curve in fig. 23), namely between 1.5 \(X_{0}\) and 3.3 \(X_{0}\) depending on the rapidity. Therefore, if the presampler were removed, another device for measuring the particle energy losses in this material would be needed, namely a massless gap integrated in the first sampling of the calorimeter. The optimal thickness of such a massless gap [12] would be 4.0-4.5 cm, so that it would take a somewhat larger radial space than the presampler.

The presampler cost is 2.5 MCHF. If it were replaced by a massless gap, however, the cost saving would be only 1.5 MCHF, because the absorber and electrode plates of the calorimeter would have to extend over the radial space presently allocated to the presampler, and would therefore be larger and more expensive.

With the present material budget, the performance of the calorimeter with the presampler is similar to the case with a massless gap. However, the amount of material in front of the massless gap, in a model without presampler, is significantly larger than the material in front of the presampler (see fig. 23). Test beam results [13] and simulation studies have demonstrated that once the dead material in front of the first active layer (the presampler in the TP layout, the massless gap in a layout without presampler) exceeds 2.5-3 \(X_{0}\), recovery of the upstreamenergy losses becomes difficult and the calorimeter energy resolution is unavoidably deteriorated. It can be seen that in a layout without presampler, the amount of material is close to this limit over a large part of the barrel coverage. Therefore, should the material thickness increase, the massless gap will not be able to successfully recover for it. This has been demonstrated by full simulation studies. For instance, by adding 0.4 \(X_{0}\) in the cryostat wall at \(\eta=1.3\) (corresponding to 0.2 \(X_{0}\) additional material at \(\eta=0\)) the resolution for electrons of \(E_{T}=40\) GeV is not affected in the layout with presampler, but is deteriorated from 12.5%/\(\sqrt{E}\) to 15.5%/\(\sqrt{E}\) in a model with an optimised massless gap. This effect is more pronounced for lower electron energies.

An independent device for the energy measurement is particularly valuable in the transition region between barrel and end-cap. The presampler can cover up to \(\eta=\)1.53, therefore it can be used to limit the response deterioration in the middle of the crack (big dip in fig. 9). Although an energy reconstruction accurate enough for precision physics is impossible in this region, as already stressed, recovery of the average shower energy and of the low energy tails is nevertheless important for an acceptable measurement of the missing \(p_{T}\). In the region 1.35 \(<\) \(|\eta|<\) 1.53, the energy resolution for photons of \(E_{T}=40\) GeV is \(\sim\,90\%/\sqrt{E}\) before any correction (with low energy tails in the energy distribution), improving to \(\sim 7\%/\sqrt{E}\) when a weight is applied to the energy deposited in the first sampling of the end-cap calorimeter, and to \(\sim\,55\%/\sqrt{E}\) if the presampler information is used. Similarly, preliminary studies in the region of the warm flange (\(\eta\simeq\)1.75) indicate that the energy resolution is \(\sim 50\%/\sqrt{E}\) before any correction, it improves to \(\sim 30\%/\sqrt{E}\) if the end-cap calorimeter had a massless gap, and to \(\sim 16\%/\sqrt{E}\) if the end-cap were preceeded by a presampler. Althoughthis last result is only academic because an independent presampler is not foreseen in the end-cap, where apart from the crack region the amount of material does not exceed 2 \(X_{0}\), it nevertheless indicates the benefit to the calorimeter response in the crack region coming from an additional device, as already demonstrated by the Tile group.

Finally, on the basis of results obtained in the past with a separate preshower detector [14], it is expected that the presampler can contribute in a significant way to the accuracy of the missing \(p_{T}\) measurement.

#### 5.2.4 The honeycomb wall

In the calorimeter design previous to the TP, the cold wall of the barrel cryostat was a traditional solid wall made of 2.7 cm thick Aluminum and contributing about 0.3 \(X_{0}\) of material at \(\eta\) = 0.

In the recent optimisation of the LAr system [15], a big effort has been invested in reducing the amount of passive material in front of the barrel calorimeter. This has led, among other layout improvements, to replacement of the cryostat cold wall with a new wall, based on an advanced design and much thinner than the previous one. The new wall (TP layout) is a light honeycomb structure, extending over a larger radial space than the old one (4.4 cm instead of 2.7 cm), but consisting of only 0.76 cm of Aluminum equivalent (0.085 \(X_{0}\) at \(\eta\) = 0). This has reduced the dead material in front of the calorimeter by almost half a radiation length in the critical region at the end of the barrel, at the price of about 1 MCHF extra cost.

The impact of this solution on the calorimeter performance can be appreciated from fig. 24, which shows the evolution of the sampling term of the energy resolution for electrons of low and intermediate energy at \(\eta\) = 1.2, as a function of the amount of material in the cryostat [16].

Replacing the honeycomb wall by a traditional solid wall would save 1 MCHF, but would increase the amount of material by 0.4 \(X_{0}\) at this rapidity. Electrons of relatively large energy (\(E_{T}\) = 40 GeV) would not be affected by this increase, owing to the presence of the presampler, as discussed above. On the other hand, the performance for low energy electrons, which are more sensitive to material, would be deteriorated: the sampling term of the energy resolution would be degraded by about 25% and the amount of low energy tails would increase from 12% to 17%. The largest impact on the physics would be on the acceptance of the \(H\to 4e\) channel for \(m_{H}<2m_{Z}\).

#### 5.2.5 Conclusion on the presampler and honeycomb wall

In summary, neither of the two options considered, namely replacing the presampler by a massless gap and/or replacing the cryostat honeycomb wall with a solid wall, are recommended. The motivations are the following:

* In the optimisation of the electromagnetic calorimeter, a large effort has been devoted to reducing the amount of material in front of the barrel part by acting in parallel on several aspects: decrease of the material in the ID (the coil length has been shortened, the design has been improved toward a lighter layout, the moderator has been taken out); careful optimisation of the calorimeter front face (cryostat wall, tolerances, clearances, electronics, etc.); use of a presampler to measure the shower energy well before the calorimeter. The result of this effort can be appreciated from fig. 25, which shows the total amount of material in front of the barrel Accordion as it is today, compared to what it was two years ago. For these reasons, a replacement of the presampler and/or the honeycomb wall represents a step backward.
* In the optimisation process, emphasis has been put in improving the calorimeter resolution in the "low-energy" region, i.e. for electrons and photons in the range 10-100 GeV, where the calorimeter resolution is dominated by the sampling term. This was done in order to maximize the detector potential for Higgs searches in the difficult intermediate mass region (\(m_{H}<2m_{Z}\)), where the detector performance is crucial to observe the small signal over the large backgrounds. As an example, the total thickness of the barrel calorimeter,

Figure 24: _Sampling term of the energy resolution for electrons of \(E_{T}=\) 10 GeV (open circles) and \(E_{T}=\) 40 GeV (closed circles) at \(\eta\)=1.2, as a function of the additional material in the cryostat (zero additional material corresponds to the TP layout)._

which was 25.5 \(X_{0}\) in the TP layout, has recently been reduced to 24 \(X_{0}\). For the same available radial space, this has allowed to reduce the thickness of the absorber plates from 1.8 mm (TP) to 1.5 mm (now), to the advantage of the sampling term, but at the expense of a somewhat larger longitudinal leakage for high-energy showers (\(E>500\) GeV). The low energy region is the most sensitive one to the effects of the dead material. Replacing the presampler and/or the honeycomb wall would require a control of this material to better than 0.2 \(X_{0}\). The resulting sampling term of the energy resolution is shown in fig. 26 as a function of rapidity over the region used for precision measurements. A significant improvement with respect to two years ago, when the optimisation started, can be seen.
* Figure 26 also shows that the average sampling term of the calorimeter is now of the order of 10% \(/\sqrt{E}\), at the level of the LoI specification, although a lot of work is still needed to improve the transition region between barrel and end-cap. Solutions, which would have improved

Figure 25: _Total material thickness in front of the active Accordion as a function of \(\eta\) in the barrel region. The full line is the present layout, the closed circles represent the layout previous to the TP._

this performance beyond the LoI specifications but would have introduced extra cost, have not been retained, as mentioned at the beginning of Section 5.2

In conclusion, it is felt that removing the presampler and/or the honeycomb wall would result in a degradation of the calorimeter performance with respect to the LoI specifications in one of the most critical energy ranges for discovery physics at the LHC.

#### 5.2.6 Dimensions of the forward calorimeter

Reducing the size of the forward calorimeter would save cost. The reason is that the hadronic part of this calorimeters made of tungsten, which is an expensive material.

In a recent document submitted to the LHCC [1], it was considered to move the boundary between the end-cap and the forward calorimeter from \(\eta=3.2\) to \(\eta=3.5\), which gives a cost saving of the order of 0.5 MCHF.

Figure 26: _Sampling term of the energy resolution for photons of \(E_{T}=50\) GeV as a function of \(\eta\) over the full coverage of the electromagnetic calorimeter. The closed circles represent the present performance, the open circles the performance previous to the TP. The horizontal bar indicates the LoI specification._

The exact (best) way of achieving this cost saving is left to the LAr group. There are in principle several solutions: shifting the boundary between the end-cap and the forward calorimeter to larger rapidity, as mentioned above; changing the shape of the forward calorimeter from conical (projective) to cylindrical; moving the forward calorimeter closer to the interaction centre, which would also increase the space for the shielding block sitting behind it and therefore allow one to change the material of the shielding from tungsten to copper. The expected penalty on the detector performance is a larger sensitivity to pile-up.

#### 5.2.7 Conclusion

Table 5 summarises the recommended d descoping options for the LAr calorimetry, together with the associated d cost savings.

As mentioned above, a broader spectrum of scenarios has been discussed, but most of these scenarios have not been retained, either because they would deteriorate the detector performance in an unacceptable way, or because they would result in serious delays to the calorimeter construction schedule. The total cost saving in the LAr calorimetry amounts to 4 MCHF.

### 5.3 Tile Calorimeter

A number of descoping options were considered in the context of coordinated changes to the tile and liquid argon calorimeters. An increase of the \(\phi\)-granularity of each module from 0.098 to 0.112 was considered. This would reduce the number of tile calorimeter modules from 64 to 56 and would be done in the context of a similar change in the liquid argon calorimeter (see Section 5.2.1). There would be no cost savings from the tile calorimeter for this change. In fact, the cost would rise by 0.3 MCHF because a more expensive vendor would have to be used for the steel laminations. It would also have a number of other practical drawbacks. The weight of the barrel modules would increase beyond the capacity of a 20-ton crane and the number of assembly sites would be reduced. The size of the necessary steel plates would be increased and the

\begin{table}
\begin{tabular}{|l|c|} \hline It em & Cost saving (MCHF) \\ \hline \hline En d-cap electromagnetic inner wheel & 1.2 \\ \hline En d-cap hadronic & 1.0 \\ \hline Granularity of \(\eta\)-strips crack region/large rapidity & 0.8 \\ \hline Smaller forward calorimeter & 0.5 \\ \hline Reduced LV L1 rate (ROD, ROL) & 0.5 \\ \hline \hline Total & 4.0 \\ \hline \end{tabular}
\end{table}
Table 5: Summary of the estimated cost saving in the LAr system currently favored vendor would be eliminated. The size of the scintillator plates would be increased and it is not known if successful injection molding can be achieved. On balance, these drawbacks were not considered fundamental enough to rule out this descoping but the \(\phi\)-granularity of the tile calorimeter must match that of the liquid argon calorimeter in order to develop trigger signals.

A descoping option entirely within the tile calorimeter was to reduce the number of longitudinal samplings from three to two. This change would reduce the cost by 0.8 MCHF. This would greatly reduce the capability of tagging low-\(p_{T}\) muons from B-hadron decays in the tile calorimeter [17]. It would also reduce the ability to identify events containing jets with substantial leakage out the back of the calorimeter. On balance, this option was not considered to be a wise choice.

Another option considered wastuse just a single phototube to readout the last sampling. This would save 0.4 MCHF in a descoping scenario. For mechanical reasons, it would be difficult to route a fibre from each side of the scintillator to a single photomultiplier tube. A single fibre from the scintillator would lead to quite non-uniform response over the surface of the scintillator. Analysis of test beam data showed that the hadronic energy resolution is unaffected, but the response to muons would certainly be very non-uniform and some efficiency loss could be expected. This option was therefore not considered further.

In summary, the only cost saving from the tile calorimeter proposed here is a saving of 0.1 MCHF from the reduced readout bandwidth (see Section 4). Contingency for the tile calorimeter needs to come from a plan for staging.

### Muon Detectors

The combination of several descoping options has been considered for the muon instrumentation, some of which are described in [1]:

1. **Reduction of the number of RPC layers in BO from three to two:** this reduction would result in an increase of the fake muon LVL1 trigger rate at high \(p_{T}\). This increase may range from a factor 5 to 10, depending on the exact relative amounts of background hits from soft electrons, hadrons and muons. For the background rates estimated for the TP layout, the LVL1 trigger safety margin would then be reduced from a factor of 18 to a factor of 7. For the improved forward shielding resulting from the reduced \(\eta\)-coverage of the end-cap muon instrumentation, the RPC counting rates in the barrel would decrease by 30%, which would improve the LVL1 trigger safety margin to an acceptable factor of 10. All sources of potential increase in the background rates, such as a possible enlargement of the gap between the barrel and the extended barrel tile calorimeter or a possible reduction of the hadronic calorimeter thickness, remain however a major source of concern.
2. **Displacement of transition from RPCs to TGCs to larger \(\eta\):** this transition is presently foreseen at the natural place where the retangular barrel chambers give way to the trapezoidal end-cap chambers. Nevertheless, a possible extension of the coverage of the RPC trigger chambers from \(|\eta|<1.05\) to \(|\eta|<1.50\) was considered at the time of the TP for reasons of cost. Unfortunately, the limited space for the end-cap muon trigger chambers and the large magnetic field inhomogeneities in the transition region require detector granularities below 1 cm. Safe operation of the RPC chambers has only been achieved up to now for granularities larger than 2 cm; for smaller strip sizes, the detector spatial resolution would always be limited by the physical signal size. In view of the above, no displacement of the transition between RPCs and TGCs is proposed.
3. **Increase of MDT diameter from 3 to 4 cm for the BM, TM, BO, TO and EO stations:** any increase of the MDT diameter \(D\) will be mostly limited by the background rate. Ageing, occupancy and space charge accumulation are the main effects to be considered. Ageing and occupancy increase with \(D^{2}\), whereas the space-charge effects increase even faster. For the background rates estimated for the TP, the BM, BO, TM and TO occupancies increase from 1.6% to 2.9% if \(D\) increases from 3 to 4 cm. If the usual factor of 5 safety margin is included in the rate prediction, the expected occupancy is uncomfortably close to the limit fixed for reliable muon spectrometer operation (20%). The improved forward shielding at large \(\eta\) reduces the detector counting rate by about a factor of two. Including this reduction, the larger-diameter tube occupancies would be similar to those considered in the TP. The impact of this MDT diameter increase on the pattern recognition performance, for background rates five times larger than the TP estimates, is a 1% increase of the track-finding efficiency, due to the higher ratio between the sensitive gas volume and the passive material. In terms of spatial resolution, a significant deterioration of 20% is to be expected, partially compensated by the relative reduction of the size of the zone near the wire. Concerning ageing, the presently considered maximum tolerable integrated charge of 1 C/cm limits the maximum acceptable background rate to 140 Hz/cm\({}^{2}\), for a gas gain of 2\(\times\) 10\({}^{4}\), an estimated 2 m.i.p. equivalent charge deposited by background hits, and including the usual safety factor of five. An increase in tube diameter from 3 cm to 4 cm, in the case of the improved shielding layout described in Section 2.2, would appear acceptable, since the larger ageing caused by the increased ionisation losses in the 4 cm diameter tubes is approximately compensated for by the reduced background rates. Space-charge effects may turn out to be a more serious source of concern than ageing. Space charge produces distorsions to the measured hit position, which depend on the counting rate and the choice of gas and of operating point. Even for gases which minimise such space-charge effects, systematic distorsions of 40 \(\mu\)m, larger than the me chanical tolerances demanded for the precision chamber construction, are expected for detector counting rates around 700 Hz/cm. This detector counting rate translates into a maximum tolerable background rate of 50 Hz/cm\({}^{2}\). The expected background rates at high luminosity exceed this value near the barrel gap and for \(\eta\,>\,1.5\). More work is necessary to assess the exact impact of these space-charge effects on the single tube accuracy, but it is clear that at this stage an increase of the tube diameter would be a major risk and should not be pursued, given the presently available knowledge.
4. **Replacement of CSCs by MDTs/TGCs in the EM chambers:** as mentioned above, ageing and space-charge effects are the main problems to be overcome for guaranteed safe operation of the MDT chambers over the full \(\eta\)-coverage of the muon system. For this reason, it was proposed in the TP to replace the MDT/TGC EI and EM chambers by CSCs at large \(\eta\). As shown in Section 2.2, the improved forward shielding results in large reductions of the background rates in the EM chambers, which would allow the use of MDTs/TGCs instead of CSCs for 2.4 \(<\)\(|\eta|\)\(<\) 2.6.
5. **Replacement of CSCs by MDTs/TGCs in the EI chambers:** in the EI chambers, the maximum tolerable rate of 140 Hz/cm\({}^{2}\) is exceeded for \(\eta\,>\,2.2\) (resp. 2.0) for the TP (resp. improved) shielding layout. Since the background rates in the EI chambers increase very fast as \(\eta\) increases, it is clear from the arguments discussed above, that it would be premature to consider replacing the CSCs by MDTs/TGCs in this region.
6. **Removal of the spacer between layers in BO, TO and EO and reduction of the number of tube layers from 2\(\times\)3 to 1\(\times\)4:** the replacement of 2 multilayers of 3 tube layers, separated by a 35cm spacer structure, by a single multilayer of 4 tube layers has a direct impact both on track reconstruction efficiency and on momentum resolution. From preliminary pattern recognition studies, such a configuration leads to a 3.4% loss of track finding efficiency for a constant fake track rate. In the absence of spacer, the vector capability of the measurement is largely reduced which results in a degradation by about a factor of two of the resolution at \(p_{T}\) = 100 GeV, when the sagitta chamber is missing (this situation corresponds to about 10% of the barrel phase space and 20% of the transition region phase space). Therefore this option has not been considered further.
7. **Reduction of the spacer width in EI and TI:** the muon reconstruction efficiency and the robustness of the pattern recognition performance are not affected by reducing the spacer width in the EI chamber from 25 cm to 10 cm, which justifies this aspect of the dimension reductions proposed in Section 2.1. In fact, this spacer reduction has also to be applied to the TI chambers in the transition region. For the non-negligible fraction (\(\sim\) 20%) of two-point measurements in this region, the reduction of the spacer width results in a 20% degradation of the momentum resolution at \(p_{T}\) = 100 GeV.

8. **Removal of the second-coordinate TGC layer in EO and TM:** the muon reconstruction efficiency and the robustness of the pattern recognition performance are not affected by removing the second-coordinate TGC measurement in EO. A TGC layer is foreseen in TM for a second-coordinate measurement, which would improve the Lorentz angle corrections, track reconstruction efficiencies and also the momentum resolution in the very non-uniform field of the transition region. However, recent progress in the understanding of the pattern recognition performance indicates, that the removal of this TGC layer would not affect significantly the quality of the muon momentum reconstruction. In particular, the track position in the transverse plane can already be estimated with an accuracy well below 1 cm by interpolation between the TGC measurements in TI and TO.
9. **Grouping of pairs of MDT tubes for readout in BOS and BMS:** the single tube occupancy in the small outer and middle barrel MDT chambers, BOS and BMS, is roughly a factor of two lower than that of the longer tubes in the BOL chambers. It is therefore expected that adequate reconstruction efficiency with sufficient safety margin in the pattern recognition procedure can be maintained if the MDT tubes in these chambers are ganged two by two for the readout.
10. **Reduction of the B-field and temperature monitoring instrumentation:** the B-field monitoring studies for the toroid system are still at a preliminary stage. The present estimates for the number of necessary sensors are based on a model, which reconstructs the coil positions in the barrel toroid only, using the information from probes placed on the chambers. The number of sensors presently foreseen would account for possible distorsions of the coils of the order of 1 cm over distances equal to the spacing between consecutive voussoirs. It is quite a pessimistic assumption to envisage such large distorsions, and a reduction of the number of probes by a third can certainly be envisaged in the barrel toroid. The situation in the more complicated transition and end-cap regions would however have to be studied. Concerning the temperature sensors, a model of the temperature and air flow distributions inside the ATLAS hall has not yet been fully developed. The risk implied by also reducing by a third the number of temperature sensors placed on the chambers could probably also be accepted.

In view of the above, a possible descoping scenario could be based on items 1., 4., 8., 9., and 10., which would result in significant cost savings without any major risk to the muon instrumentation operation and performance. A summary of these cost savings is given in table 6. Cost savings due to the reduction of dimensions (Section 2.1), which includes item 7., and \(\eta\)-coverage (Section 3) amount to 1.0 and 0.7 MCHF respectively.

## 6 Infrastructure Descoping

The experiment related infrastructure serves a variety of purposes such as shielding and supports of all kinds, but also cooling and ventilation of electronics racks, cabling, cryogenic and power connections, etc. The cost of items such as shielding depends on the physics requirements and they are therefore optimised like detectors. The cost of items such as cooling and ventilation on the other hand depend strongly on the details of the area and the experiment. However, especially in this category of services, intelligent solutions and moderation in the requirements can save considerable amounts of money without loss of performance.

There are some items which can be eliminated in the list of infrastructure expenditures, such as part of the transverse rails, or replaced by more appropriate solutions, such as fewer gas pipes for the muon chambers, with gas manifolds on the detector itself. However, the proposed additional shielding in the end-cap toroids would increase the overall shielding cost. As a consequence, the net overall possible saving is about 1.5 MCHF.

## 7 Impact on Physics Performance

The LHC will certainly be a rich source of known physics (B-hadrons, top quarks, gauge-boson pairs, photons, hadronic jets...), but there is also great hope, that it will open up whole new fields, such as Higgs boson physics and supersymmetry, not to mention the unpredicted. Many years of work in more and more detailed physics simulations, and a huge detector research and development effort have shaped a picture, which is supported by most of the community today:

\begin{table}
\begin{tabular}{|l|c|} \hline Source of savings & Cost saving (MCHF) \\ \hline \hline (1) RPC (BO) Omit 1 of 3 layers & 1.0 \\ (4) Replace CSCs by MDTs/TGCs in EM & 0.3 \\ (8) Omit TGC (TM and EO) & 1.2 \\ (9) Gang pairs of tubes (BMS, BOS) & 0.7 \\ (10) Reduce B-field and temperature sensors (30\%) & 0.5 \\ \hline \hline TOTAL MUON INSTRUMENTATION N: & 3.7 \\ \hline \end{tabular}
\end{table}
Table 6: _Summary of cost savings on the muon instrumentation. Cost savings due to the reduction of dimensions (Section 2.1) and \(\eta\)-coverage (Section 3) amount to 1.0 and 0.7 MCHF respectively._* even at the highest luminosities foreseen at LHC, it has been demonstrated that high-precision and efficient measurements of all the interesting final-state particles can be performed with the detector we plan to build. These measurements are only possible if the whole detector is operational at the LHC start-up and at the highest luminosities over a period of many years.
* particle signatures are not limited to electrons and muons. Photons, \(\tau\)-leptons, neutrinos, b-jets, c-jets, and W/Z-bosons should all be considered as fundamental objects to be identified with high purity in as inclusive and efficient a way as possible over the full detector acceptance. The accuracy of the measurement of their energy/momentum can only be used fruitfully once they have been identified. Excellent sensitivity to new physics lies more in this aspect of the detector performance than in its ultimate measurement accuracy.

These arguments can only emphasise the importance of considering the physics performance of the ATLAS detector as a whole, rather than that of individual subsystems. The most difficult physics channels at LHC can only be observed with a complete detector, which not only maximises the observable signal rates, but also ensures that potentially dangerous reducible backgrounds can be controlled and brought down to a safe level with respect to the irreducible backgrounds and/or a possible signal.

Another point of reference, not always wisely used, is the other experiment. The claimed subdetector measurement accuracies appear in most cases to be superior in CMS. Nevertheless, detailed comparisons performed for the most sensitive channels, \(H\,\rightarrow\,\gamma\gamma\)[18] and \(H\,\rightarrow\,ZZ^{*}\,\rightarrow\,4l\)[19], have shown that the discovery potentials of ATLAS and CMS are not very different if one uses the same input physics assumptions, and if one takes care in evaluating the background levels and signal reconstruction efficiencies in a consistent way.

The proposed revised configuration of the ATLAS detector presented here is the result of several iterations. Two main guidelines were followed throughout this work:

* reduce global dimensionsand cost whilst preserving the overall physics potential,
* descope all individual subdetectors in order to create some contingency for each of them.

Since the aim is to reach a consensus as soon as possible on the proposals resulting from the first guideline, this Section mainly attempts to bring some perspective to the physics arguments, which have led to the proposed new reduced dimensions, reduced \(\eta\)-coverage and reduced maximum LVL1 trigger rate.

The impact on the overall ATLAS physics performance of the proposed reduced \(\eta\)-coverage and reduced maximum LVL1 trigger rate is very small and has been discussed in Sections 3 and 4 respectively. We therefore concentrate here on the impact of the reduced global dimensions, which concern only the muon system. As discussed in Section 2.1, this reduction in dimensions together with the reduction in field results in a maxi\(\mu\)m degradation of the muon momentum resolution at high momentum of about 16% relative to the reference toroid-magnet design. This muon momentum resolution remains, however, excellent over the full fiducial \(\eta\)-coverage.

A systematic study of the impact of reduced field in the air-core toroid system (and of the descoped and staged scenarios discussed in [1]) is described in an accompanying note [9]. A few examples extracted from this note are discussed below:

* the \(H\to ZZ^{*}\to 4l\) channel, for 130 \(<\) m\({}_{\rm H}\)\(<\) 180 GeV, is the most delicate case in terms of overall rate and signal-to-background ratio, as shown in table 7 for three values of the toroid-magnet field and for an integrated luminosity of 3 \(\times\) 10\({}^{4}\) pb\({}^{-1}\). The left-hand part of table 7 shows the expected mass resolutions and signal significances for the 4-muon channel, in the case of a measurement without using the ID information or the so-called "stand-alone" measurement. The central part of table 7 shows the same quantities, in the case of a "combined" muon spectrometer and ID measurement, where the ID information is used to improve the mass resolution, and also to reject the dangerous reducible backgrounds from \(\rm t\overline{t}\) and \(\rm Zb\overline{b}\) decays through vertexing cuts. The signal rate is reduced with respect to the \(\eta\)-coverage, and the signal rate is reduced with respect to the \(\eta\)-coverage.

\begin{table}
\begin{tabular}{|l|c|c|c|} \hline m\({}_{\rm H}\) = 130 GeV & 4 \(\mu\) stand-alone & 4 \(\mu\) combined & 4 leptons(e+\(\mu\)) \\ \hline \(B=B_{\tt TP}\)\(\sigma_{m}\) (GeV) & 1.45 & 1.1 & 1.3 \\ \hline Signal (events) & 3.3 & 2.8 & 11.3 \\ \hline Background (events) & 1.2 & 0.5 & 2.4 \\ \hline Stat. Signif. (\(\sigma\)) & 1.8 & 2.2 & 4.6 \\ \hline \hline \(B=0.85\)\(B_{\tt TP}\)\(\sigma_{m}\) (GeV) & 1.6 & 1.1 & 1.3 \\ \hline Signal (events) & 3.3 & 2.8 & 11.3 \\ \hline Background (events) & 1.3 & 0.5 & 2.4 \\ \hline Stat. signif. (\(\sigma\)) & 1.7 & 2.2 & 4.6 \\ \hline \hline \(B=0.70\)\(B_{\tt TP}\)\(\sigma_{m}\) (GeV) & 1.8 & 1.2 & 1.35 \\ \hline Signal (events) & 3.3 & 2.8 & 11.3 \\ \hline Background (events) & 1.5 & 0.6 & 2.5 \\ \hline Stat. signif. (\(\sigma\)) & 1.5 & 2.1 & 4.5 \\ \hline \end{tabular}
\end{table}
Table 7: _For \(H\to ZZ^{*}\to 4l\)-lepton decays with m\({}_{\rm H}\) = 130 GeV and for an integrated luminosity of 3 \(\times\) 10\({}^{4}\) pb\({}^{-1}\), expected mass resolutions, signal and background rates and signal significances, for the full air-core muon system with the full TP field, with a field of 85% of the TP value (reference value), and with a field of 70% of the TP value (lower than worst-case value). Also shown are the values of the expected mass resolutions when combining the muon measurement with that of the Inner Detector, and when combining together all the 4-lepton final states. The muon stand-alone performance corresponds to the case where no tracker information is used._to the "stand-alone" measurement because of the inefficiency of the vertexing cuts, but the signal significance is improved, although not sufficiently to observe the signal in the 4-muon channel alone. As shown in the right-hand part of table 7, the signal significance is greatly improved once the electron and muon channels are combined, since this provides a factor four increase in rate. In summary, to observe the Higgs signal in the intermediate mass range, one needs to use the full ATLAS detector, combining muons and electrons, and exploiting the information of the ID. This is the most relevant scenario for the ATLAS physics performance in this channel and table 7 shows that the sensitivity to the signal does not depend strongly on the value of the toroid magnetic field.

Figure 27: _For \(H\ \to\ ZZ\ \to\ 4\mu\) decays with \(m_{\rm H}\) = 300 GeV, stand-alone mass resolution for the reference air-core system with a field of 85% of the TP field (top) and for a descoped air-core system with a field reduced to 70% of the TP field (bottom). For both cases, the 4-muon mass spectrum is shown, for a SM Higgs (hatched histogram) and for a MSSM Higgs with negligible width (white histogram). Both histograms have the same number of entries; the experimental mass resolution increases from 4.0 GeV (top) to 4.7 GeV (bottom)._

* the \(H\to ZZ\to 4\mu\) channel, for \(\mbox{m}_{\PH}\) = 300 GeV, provides discrimination between a SM Higgs boson and a MSSM Higgs boson through the measurement of the signal rate, and also through the measurement of the Higgs boson width. The natural width of the SM Higgs is large, \(\Gamma_{H}^{SM}\) = 8.3 GeV, whereas, in the case of the MSSM, the H-boson width is much smaller and increases from 0.26 GeV for \(\tan\beta\) = 3 up to 0.7 GeV for \(\tan\beta\) = 10. This is illustrated in fig. 27 and table 8 for different values of the toroid-magnet field. A good mass resolution will clearly be a useful tool to distinguish between different models. Since the MSSM \(H\to ZZ\to 4l\) rates are strongly suppressed with respect to the SM (a combined electron and muon signal of \(\sim\) 100 events is expected from a SM Higgs boson above a background of \(\sim\) 20 events for an integrated luminosity of 3 \(\times\) 10\({}^{4}\) pb\({}^{-1}\)), the full statistics of the combined electron and muon channels will nevertheless be necessary to achieve these goals.

* the channel \(A/H\to\mu\mu\), for masses around 300 GeV, is of interest in the MSSM and has negligible rate in the electron mode. Good mass resolution in this channel will provide some sensitivity to \(\tan\beta\), one of the essential MSSM parameters, through the measurement of the A/H natural width which varies from a few GeV to \(\sim\) 20 GeV as a function of \(\tan\beta\)[9]. Table 9 shows that the mass resolution in this channel degrades from 4.6 GeV to 6.2 GeV as the toroid magnet field decreases from the TP value to 70% of the TP value, and that the ID measurement is not good enough to improve the mass resolution at this high mass. For an integrated luminosity of 10\({}^{5}\) pb\({}^{-1}\), the expected signal rates are around 1000 events above a Drell-Yan and tt background of about 10000 events. Assuming that a natural width about 50% larger than the experimental mass resolution could be unfolded, the measured experimental width of the signal would provide sensitivity to values of \(\tan\beta\) larger than 35 (\(\Gamma_{A/H}\sim\) 8 GeV) in the case of the TP field. This sensitivity would be limited to values of \(\tan\beta\) larger than 40 (\(\Gamma_{A/H}\sim\) 10 GeV) in the case of a 70% field.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline \(H\to ZZ\to 4\mu\) & \multicolumn{2}{|c|}{Stand-alone} & \multicolumn{2}{|c|}{Combined} \\ \(\mbox{m}_{\PH}\) = 300 GeV & \(\sigma_{m}\) (GeV) & Events in \(\pm 2\sigma_{m}\) & \(\sigma_{m}\) (GeV) & Events in \(\pm 2\sigma_{m}\) \\ \hline \(B\) = \(B_{TP}\) & 3.5 & 91\% & 2.9 & 93\% \\ \hline \(B\) = 0.85 \(B_{TP}\) & 4.0 & 91\% & 3.2 & 93\% \\ \hline \(B\) = 0.70 \(B_{TP}\) & 4.6 & 91\% & 3.6 & 93\% \\ \hline \end{tabular}
\end{table}
Table 8: _For \(H\to ZZ\to 4\mu\) decays with \(\mbox{m}_{\PH}\) = 300 GeV, expected mass resolutions for zero-width Higgs and acceptances in mass bin, for the air-core muon system with the full TP field, with the reference field of 85% of the TP value, and with a field of 70% of the TP value. The results are shown for both the stand-alone (left) and combined (right) measurements. The muon stand-alone performance corresponds to the case where no tracker information is used. The expected mass resolution in the electron channel is 2.9 GeV._* new heavy neutral gauge bosons may be observed at LHC through their decays into electron, muon and jet pairs. Previous studies [20] have shown that the electron channel will be the best one to discover a possible signal and measure its width, that the muon channel will be the best one to measure the forward/backward asymmetry and thus provide important constraints on the model, and that the jet channel, although suffering from very large QCD backgrounds, will also be observable in many cases, thus providing additional constraints on the model. It has been shown a long time ago [21] that the lepton (electron or muon) momentum resolution has a negligible effect on the accuracy of the asymmetry measurement, since only the sign of the lepton charge is important. Even toroid-magnet field variations much larger than those considered here will therefore not affect the physics performance in this channel. Similar conclusions, although less strong, apply to the case of heavy charged gauge bosons, W'. In conclusion, although the muon momentum resolution at high momentum is degraded with respect to the expected TP performance in the proposed new layout, the impact on the overall ATLAS physics is believed to be tolerable, even in the worst-case scenario, where the new cost ceiling for the toroid magnet system would have to be met by further decreasing the field.

## 8 Conclusions

The Task Force recommends a revised configuration for the detector which results in an estimated total cost saving of 24.8 MCHF. The savings arise from reduced overall dimensions, reduced rapidity coverage, reduced safety marginson the LVL1 trigger rate, and descoping of subdetector instrumentation. The latter savings amount to less than 40% of the total. In many cases, the descoping of instrumentation can be compensated by future upgrades should this prove necessary. The proposed reductions can be grouped in five classes and are sum

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline \(A/\,H\to\mu\mu\) & \multicolumn{2}{|c|}{Stand-alone} & \multicolumn{2}{|c|}{Combined} \\ \cline{2-5} m\({}_{\rm H}\) = 300 GeV & \(\sigma_{m}\) (GeV) & Events in \(\pm 2\sigma_{m}\) & \(\sigma_{m}\) (GeV) & Events in \(\pm 2\sigma_{m}\) \\ \hline \(B\) = \(B_{\rm TP}\) & 4.6 & 92\% & idem & idem \\ \hline \(B\) = 0.85 \(B_{\rm TP}\) & 5.3 & 91\% & idem & idem \\ \hline \(B\) = 0.70 \(B_{\rm TP}\) & 6.2 & 89\% & idem & idem \\ \hline \end{tabular}
\end{table}
Table 9: _For \(A/\,H\to\mu\mu\) decays with \(m_{\rm H}\) = 300 GeV, expected mass resolutions for zero-width Higgs and acceptances in mass bin, for the air-core muon system with the full TP field, with the reference field of 85% of the TP value, and with a field of 70% of the TP value. The results are shown for both the stand-alone (left) and combined (right) measurements. The muon stand-alone performance corresponds to the case where no tracker information is used._marised in table 10 as follows:

1. Reduction of detector dimensions and magnetic fields, leading to an adequate safety margin in the cavern size: * The detector diameter is reduced by 1.1 m. This is achieved by reducing the barrel toroid outer radius by 30 cm and by gaining 25 cm from an improved support structure for the outer barrel muon chambers. * The total length of the detector is reduced by 2.1 m. This is achieved by reducing the end-cap toroid length by 44 cm to 5.0 m, the space for the EI muon chambers from 80 cm to 65 cm, and the distance from the interaction point to the E0 muon chamber by 104 cm. * The radius of the inner bore in the end-cap toroids is increased by 25 cm. Together with the reduced \(\eta\)-coverage described below, this change allows improved shielding in the forward direction and reduces backgrounds in the muon system. * The total cost of the muon toroids should not exceed 120 MCHF. Ways of reaching this new cost ceiling, which best preserve the muon system performance, are obviously to be preferred. In the worst case, it is estimated that the bending strengths should be reduced by no more than \(\sim\) 10%. * These reduced dimensions lead to a corresponding reduction in the area of the muon intrumentation.
2. The fiducial rapidity coverage for high precision measurements of photons, electrons and muons is fixed to \(|\eta|\leq~{}2.5\). This results in a coarser granularity for the inner wheel of the end-cap electromagnetic calorimeter and a reduced size of the forward muon detectors. An effort should be made to develop a design of the end-cap electromagnetic calorimeter, which has fiducial coverage up to \(\eta=2.5\) for precision measurements and photon/electron identification.
3. The design figure for the maximum LVL1 trigger rate is reduced from 100 kHz to 75 kHz. This is still a factor of two above the calculated trigger rate at high luminosity quoted in the TP. Savings accrue here both from the trigger/DAQ electronics, and from the read-out drivers and optical links of individual subdetectors. The modifications should be done in an upgradeable manner.
4. Infrastructure costs are reduced.
5. Detectors are descoped. Specific examples have been described and a revised cost ceiling for each subsystem arrived at. It is left to the individual subsystem groups to optimise their designs within the new ceilings. The descoping examples are as follows: * The inner detector is descoped by reducing the area of both the barrel and forward sections of the SCT. There are additional savings from the reduced bandwidth needed for the TRT and SCT readout.

* In the liquid-argon calorimeter, the fine-grained \(\eta\)-strips, which are located behind the thick material of the transition between the barrel and end-cap could be replaced with towers of \(\Delta\eta=0.025\). The granularity of the end-cap hadronic calorimeter is reduced. Additional savings, associated with further grouping of electromagnetic calorimeter strips at high \(\eta\) and/or changing the interface between the end-cap and forward calorimeters, are also recommended. Savings from this subsystem are also derived from the reduced readout bandwidth requirements.
* The instrumentation of the muon system is descoped in an upgradeable manner, as described in detail in Section 5.4. The current design uses a safety factor of five in counting rate. Experience at low luminosity will be an important guide for any upgrades required.

It is believed that the recommended cost reductions can be achieved with minimal impact on the overall physics performance of the detector.

\begin{table}
\begin{tabular}{|l|r|r|r|} \hline Source of Savings & Amount & Subtotal & Fraction \\  & (\(\,\)M\(\,\)CHF) & (\(\,\)M\(\,\)CHF) & of \(\,\)Total \\ \hline \hline Reduced Dimensions and Fields & & 6.0 & 24\% \\ Muon magnets & 5.0 & & \\ Muon detectors & 1.0 & & \\ \hline Reduced Rapidity Coverage & & 1.9 & 8\% \\ LAr calorimeter & 1.2 & & \\ Muon detectors & 0.7 & & \\ \hline Reduced Trigger Bandwidth & & 5.6 & 23\% \\ Inner detector & & & \\ TRT & 0.4 & & \\ SCT/pixels & 0.1 & & \\ LAr & 0.5 & & \\ Tile calorimeter & 0.1 & & \\ DAQ and LV L2 Systems & & & \\ RO Bs & 2.3 & & \\ LV L2 & 2.2 & & \\ \hline Instrumentation Descoping & & 9.8 & 39\% \\ Inner detector & 3.8 & & \\ LAr calorimeters & 2.3 & & \\ Muon detector & 3.7 & & \\ \hline Infrastructure & 1.5 & & 6\% \\ \hline \hline Total & 24.8 & 24.8 & \\ \hline \end{tabular}
\end{table}
Table 10: _Summary of proposed cost savings._

## References

* [1] Cost ceiling, staging and descoping studies, CERN/LHCC/95-68, 1 November 1995.
* [2] ATLAS Technical Proposal, CERN/LHCC/94-43 (15 Dec., 1994).
* [3] G. Battistoni et al., ATLAS Internal Note, MUON-No-052.
* [4] D. Froidevaux and A. Parker, ATLAS Internal Note, INDET-No-046.
* [5] S.G. Klimenko, Yu.A. Tikhonov and A.I. Chekhtman, ATLAS Internal Note, LARG-No-025.
* [6] Depth Requirements in SSC Calorimeters, Fermi National Accelerator Laboratory report, FERMILAB-FN-570 (1991).
* [7] S. Zmushko et al., ATLAS Internal Note, PHYS-No-008.
* [8] E. Richter-Wast et al., ATLAS Internal Note, PHYS-No-048.
* [9] L. Poggioli, D. Froidevaux and C. Guyot, ATLAS Internal Note, PHYS-No-076.
* [10] Trigger and DAQ interfaces with front-end systems: Requirements document. In preparation.
* [11] G. Parrour et al., ATLAS Internal Note, CAL-No-077.
* [12] M. Seman, H. Gordon and D. Lissauer, ATLAS Internal Note, CAL-No-074.
* [13] B. Aubert et al., RD3 Collaboration, NIM A330 (1993)405.
* [14] D. Cavalli et al., ATLAS Internal Note, PHYS-No-051.
* [15] F. Gianotti et al., ATLAS Internal Note, CAL-No-070.
* [16] D. Cavalli, A. Ferrari and P.R. Sala, ATLAS Internal Note, CAL-No-078.
* [17] J. Budagov et al., ATLAS Internal Note, TILECAL-No-062.
* [18] F. Gianotti et al., ATLAS Internal Note, PHYS-No-064.
* [19] L. Poggioli, ATLAS Internal Note, PHYS-No-066.
* [20] A. Henriques and L. Poggioli, ATLAS Internal Note, PHYS-No-010; M.-C. Cousinou, ATLAS Internal Note, PHYS-No-059.
* [21] B. Dolgoshein et al., RD6 Status Report, CERN/DRD C/91-47, 1991.