**ATLAS Internal Note**

**TILE-NO-60**

**Updated 13 October 1995**

**IMPROVEMENT IN**

\(\pi\)**/\(\mu\)** **separation at low** \(p_{{}_{T}}\)

**in ATLAS Hadron Calorimeter**

**USING ARTIFICIAL NEURAL NETWORKS**

**TECHNIQUE**

A. Astvatsaturov, J. Budagov, I. Chirikov-Zorin, D. Pantea 1, A. Paplevka 2,

Footnote 1: Inst. of Atomic Physics, P.O.Box M G-6, Bucharest, Romania.

Footnote 2: on leave from BSU, Minsk, Belarus

V. Shigaev, S. Sushkov 3

Footnote 3: on leave from GSU, Gomel, Belarus

Joint Institute for Nuclear Research, 141980, Dubna, Moscow region, Russia

M. Bosman

IFAE, Barcelona, Spain

M.Nessi

CERN, Geneva, CH-1211, Switzerland

Advantages of artificial neural networks techniques in handling data from highly granulated ATLAS hadron calorimeter are shown in application to isolated \(\pi/\mu\) separation task in the range \(3<p_{T}<5\) GeV at pseudorapidity \(\eta=0.3\). Such low \(p_{T}\) muons have a significant probability to be absorbed in the calorimeter an d therefore they cannot be reliably registered by the muon detector. JETNET program was used to investigate the performance of neural network classifiers in solving low \(p_{T}\)\(\pi/\mu\) separation task. Data sets for training and analysis were obtained with ATLAS simulation programs.

Introduction

Artificial Neural Networks (ANN) have already found many applications in High Energy Physics [1]. Due to their inherent parallelism, robustness and good statistical properties the ANN are used both in off-line and on-line analysis.

The main goal of the present article is to show advantages of ANN approach in handling data from highly granulated hadron calorimeter (HC) in comparison with other techniques. To demonstrate the potential of ANN approach the task of isolated low \(p_{T}\)\(\pi/\mu\) separation was chosen. In solving the task we can get an insight into what are the most relevant inputs to an effective neural network classifier (discriminator) and what are its performance limits.

Having its own value, the effective solution of isolated low \(p_{T}\)\(\pi/\mu\) separation task may be considered as an auxiliary step towards tackling a more difficult problem - tagging b-jets with low \(p_{T}\) muons using HC information. Muons in the range \(3<p_{T}<5\) GeV have a significant probability to be absorbed in the calorimeter and therefore they cannot be reliably registered by the muon detector. In [2] it was shown that identification of b-jets with muon's \(p_{T}\geq 3\) GeV can increase the statistics of the observed events by a factor of 2.5 in searching for and measurement of CP violation in \(B_{d}^{0}\to J/\psi K_{s}^{0}\) channel with \(J/\psi\rightarrow\mu^{+}\mu^{-}\) decay - the problem mentioned in the ATLAS Technical Proposal [3].

In our investigation we restricted ourselves to testing discrimination power of two types of discriminators: linear threshold discriminators (LTD) as used in [2] and neural net discriminators (NND) built using the package JETNET [4]. The present work is based on simulated data; two HC designs were considered - with 4 and 3 longitudinal samples. Distributions of deposited energies in each section of ATLAS calorimeter are shown in Fig.1.

## 2 Neural networks application scheme and simulation data

In what follows the muon events (calorimeter response to muons) will be refered to as signal events, and the pion events - as background events respectively.

Neural net discriminators being nonlinear nonparametric extensions of conventional classifiers exploit knowledge of joint probability distribution of different features of registered events. Approximation of joint probability distribution is attained through a procedure called neural net training on the basis of a training set of events (simulated or real). Under certain conditions neural net classifiers realize asymptotically optimal, Bayesian decision [5], [6].

To formulate the problem under study closer to identification of low \(p_{T}\) muons in the b-jet context we do not consider information from electromagnetic calorimeter (EMC) nor from any track detectors, thus entirely relying on hadron calorimeter response data.

We adopted the following investigation scheme which consisted of seven distinct steps:

1. Define an interval of interest for \(p_{T}\) value (\(p_{T}\) working interval). In our case it is \(3.0<p_{T}<5.0\) GeV.
2. Form training set of events. It comprises both signal and background events generated at \(p_{T}\) values within the \(p_{T}\) working interval (see below the details).
3. Train the neural net discriminator.
4. Test the neural net discriminator. Testing is performed using another set of events (test events) with \(p_{T}\) within the working interval. Quality of the trained discriminator (its characteristics as a classifier) is evaluated as a function of the threshold level applied to discriminator output signal.
5. Estimate discriminator quality dependence on \(p_{T}\) (for events both within \(p_{T}\) working interval and outside it).
6. Execute steps 2 - 4 for different levels of photostatistics (in the range 10 - 80 photoelectrons per GeV).
7. Execute steps 2 - 4 for two HC designs: a) with four longitudinal samples and b) with three longitudinal samples (samples 2 and 3 grouped together).

The standard ATLAS programs (DICE and ATRECON) were used to simulate calorimeter response to isolated \(\mu\) and \(\pi\) at \(\eta=0.3\) for \(p_{T}\) values uniformly distributed within \(p_{T}\) working interval (3.0, 5.0) GeV. In total 6000 muon events and 6000 pion events were simulated. Actually the \(p_{T}\) working interval was subdivided into four nonoverlapping subintervals of 0.5 GeV width, with 3000 events in each. To evaluate the discriminator quality outside the \(p_{T}\) working interval, we have prepared additional data files for muon and pion events generated at \(p_{T}=2.0\) and 10.0 GeV (4000 events in total). Noise effects were taken into consideration in a simplified way using a cut of 0.1 GeV for thresholding the simulated energy depositions in HC cells.

The resultant trained neural net discriminator depends on \(p_{T}\) distribution in the training set within both classes of events (signal and background). General case of nonuniform \(p_{T}\) distributions is easily simulated by proper adjustments in a procedure that performs access to event patterns during neural net training phase.

Figure 1: _Distributions of deposited energies in sections of preshower detector (\(ps_{1}\), \(ps_{2}\)), EM calorimeter (\(em_{1}-em_{3}\)), Hadron calorimeter (\(ha_{1}-ha_{4}\)) for muons and pions at \(\eta=0.3\) and \(p_{T}\) values uniformly distributed within (3 - 5) GeV interval_

Discriminators and their performance in low \(p_{T}\)\(\pi/\mu\) separation

In this paper results for four models of \(\pi/\mu\) discriminators are presented in the order of their increasing discrimination power.

* linear threshold discriminator that checks the deposited energy \(E_{4}\) in the last HC sample against the threshold value.
* neural net discriminator operating on the energies \(E_{i}\), \(i=\overline{1,4}\), deposited in four HC sections (i.e. on longitudinal samples).
* neural net discriminator operating on values of event features estimated as functions of arguments \(E_{i}\).
* neural net discriminator operating on 3-dimensional pattern of energy deposition in HC (i.e. on energy deposition in cells).

Three-layered perceptrons with input neurons (nodes) in the first layer, \(n_{h}\) neurons in a hidden layer and one output neuron in the third layer were selected for constructing neural net discriminators. Adjacent layers of the perceptrons are fully interconnected. A formula (n, \(n_{h}\), 1) will be used to depict the structure of such perceptrons.

Inputs to the first layer of NND may be thought as components of n-dimensional vector that represents an event in n-dimensional feature space. Dimension n and ordering of input components are fixed for a particular NND. For neurons in the hidden and output layers the nonlinear neuron activation function \(g(a)=(1+\exp(-2a))^{-1}\) was chosen; hence the perceptrons perform nonlinear mappings of n-dimensional space into (0, 1) interval. During training phase the target value of the output neuron was put to 1 for muons and 0 for pions. Training procedure iteratively adjusts weights of connections between neurons in order to minimize mean fit error MFE, i.e. mean squared deviation of actual net output values \(O_{NN}(p)\) from the target values t(p) over the whole training set of events:

\[MFE=\frac{1}{2N_{p}}^{N_{p}}(t(p)-O_{NN}(p))^{2} \tag{1}\]

where p denotes events.

Using a trained perceptron one gets one-dimensional distributions of net output values for muons and pions, and the subsequent part of \(\pi/\mu\) separation task becomes similar to that of LTD discriminator which deals with one-dimensional distributions of \(E_{4}\) values (\(0\leq E_{4}<\infty\)).

In Fig.2(a) distributions of \(E_{4}\) for signal (\(\mu\)) and background (\(\pi\)) events are presented, and in Fig.2(b) - distributions of neural net output values for the same events (the neural net is that of NND\({}_{12}\)).

A fixed point on \(x\)-axis (decision point or threshold) dichotomizes these distributions. Counting events on both sides of the threshold and normalizing the results one gets accumulated probabilities for an event to be correctly classified or misclassified. Applying variable thresholds we get estimates of important characteristics of discriminators:

* efficiency of signal events recognition, i.e. the probability that a muon event be correctly classified,
* inefficiency of signal events recognition, i.e. the probability that a muon event be misclassified (\(\alpha_{\mu}=1-\varepsilon_{\mu}\)),
* survival probability for background events, i.e the probability that a pion event be misclassified.

These characteristics for LTD and NND\({}_{12}\) discriminators are presented in Fig.3 as functions of discriminator's internal parameter (threshold value for energy \(E_{4}\) in case of LTD; threshold value for neural net output signal in case of NND).

Two other characteristics are defined as follows:* \(R_{\pi}=1/\beta_{\pi}-\)rejection factor for background events,
* \(Q=\varepsilon_{\mu}\cdot R_{\pi}-\)enrichment factor.

Enrichment factor Q indicates the change in the ratio

\[\frac{(number\,of\,signal\,events)}{(number\,of\,background\,events)}\]

after applying the discriminator to a mixture of signal and background events. Two lower plots in Fig. 3 present Q-factors for LTD and NND\({}_{12}\) as functions of variable threshold values.

Different types of discriminators may differ in sense and range of their internal parameters which control performance of a discriminator. That is why we prefer to use parameter independent function \(Q(\varepsilon_{\mu})\) for comparing functional behaviour of different discriminators [7], [8], [9]. In Fig. 4\(Q(\varepsilon_{\mu})\) function is presented for LTD and NND\({}_{12}\) discriminators (values of these functions are derived from plots in Fig. 3).

Before presenting and commenting functional behavior of the four discriminators we shall look at what is the difference between neural nets of three NND discriminators. All three nets being perceptrons of the formula (n, 40, 1) differ in two respects:

1) dimension n of input vectors \(\vec{X}_{n}\),

2) sense of components of \(\vec{X}_{n}\).

Components of \(\vec{X}_{n}\) vector are usually called event features. Features are functions of raw data items (cell energies of HC response in our case). It is worth noting that \(E_{i}\) samples are also features: each \(E_{i}\) is a weighted sum of all energies deposited in separate cells of i+h section of HC, all weights being set to 1). Evaluation of feature values is an operation called preprocessing of measurement data (or source data). Note that operation of reordering features in input vector \(\vec{X}_{n}\) is another example of preprocessing if this operation is event dependent.

Figure 2: _(a) Distributions of \(E_{4}\) for \(\mu\) and \(\pi\) events at \(\eta=0.3\) and \(p_{T}\) values uniformly distributed within (3 - 5) GeV interval, (b) Distributions of NND\({}_{12}\) neural net output values for the same events_

It is well known that definition of a feature space is the most critical stage in pattern classification process. Various features of the events were evaluated and many sessions of neural net training and testing were carried out in search for the most effective subsets of features used as inputs to neural nets.

The neural net of NND\({}_{11}\) discriminator is a \((4,40,1)\) - perceptron which uses four longitudinal samples \(E_{i}\), \(i=\overline{1,4}\), as components of input vector \(\vec{X}_{4}\). The order of samples \(E_{i}\) in the vector \(\vec{X}_{4}\) is fixed: \(i\)-th component of \(\vec{X}_{n}\) is assigned \(E_{i}\) value. In Fig.5 the line labeled by \(Q_{1}\) presents \(Q(\varepsilon_{\mu})\) curve for NND\({}_{11}\) discriminator. It follows from the figure that for muon registration efficiencies \(\varepsilon_{\mu}=0.80-0.97\) the enrichment factor \(Q_{1}\) is in the range \(100-105\). \(Q_{1}(\varepsilon_{\mu})\) is a decreasing function for larger \(\varepsilon_{\mu}\) values, and at \(\varepsilon_{\mu}=0.99\) it drops to \(\sim 95\).

Figure 3: _Characteristics for LTD and \(NND_{12}\) as functions of discriminatorâ€™s internal parameter (threshold value for energy \(E_{4}\) in case of LTD; threshold value for neural net output signal in case of NND)_

Figure 4: _Q vs \(\varepsilon_{\mu}\) for LTD and NND\({}_{12}\)_

\(\mathrm{NND}_{12}\) discriminator is also based on the (4, 40, 1) - perceptron and also uses four longitudinal samples \(E_{i}\), \(i=\overline{1,4}\). In contrast to \(\mathrm{NND}_{11}\), assignment of a particular \(E_{k}\) to a component of \(\vec{X}_{4}\) is dependent on the event itself. Here components of \(\vec{X}_{4}\) are an ordered set of longitudinal samples ordered by their values in descending way. \(Q(\varepsilon_{\mu})\) curve for \(\mathrm{NND}_{12}\) discriminator is presented in Fig.5 by the line labeled \(Q_{3}\). For muon registration efficiencies \(\varepsilon_{\mu}=0.80-0.97\) the enrichment factor \(Q_{2}\) is in the range \(120-125\). At efficiency \(\varepsilon_{\mu}=0.99\)\(Q_{2}\) drops to \(\sim 95\).

For conveniency of comparison we present in Fig.6 ratios \(q_{ij}\) of the functions \(Q(\varepsilon_{\mu})\) for different pairs of discriminators at efficiencies \(\varepsilon_{\mu}=0.88-0.99\):

\[q_{ij}(\varepsilon_{\mu})=\frac{Q_{i}(\varepsilon_{\mu})}{Q_{j}(\varepsilon_{ \mu})}=\frac{R_{i}(\varepsilon_{\mu})}{R_{j}(\varepsilon_{\mu})}\,,\,\,i>j\,, \,\,j=0,1,\,2\,,\]

where \(R_{i}(\varepsilon_{\mu})\), \(R_{j}(\varepsilon_{\mu})\) denote corresponding values of pions rejection factor \(R_{\pi}\).

One can see that in comparison with LTD all neural net discriminators have twice as high enrichment factor value Q at the highest efficiency \(\varepsilon_{\mu}=0.99\). At lower efficiencies (\(\varepsilon_{\mu}<0.96\)) different models of neural net discriminators hold Q factors 40 - 80 % higher compared to LTD discriminator.

In search for effective \(\mathrm{NND}_{3d}\) discriminator we tried a number aways to extract additional important features by preprocessing clusters of cells in each HC section. A cluster is defined as the \(3\times 3\) cells window where the maximum summed energy is deposited. The central cell (\(\eta_{c}\), \(\varphi_{c}\)) of a cluster is that with maximum cell energy.

Some of the tested features are:

1. energy of the leading cell in a cluster,
2. summed energy in increasing square bands around the centre of a cluster,
3. summed energy of the cells outside a cluster,
4. ordered sample of cell energies in a cluster,
5. ordered sample of cell energies normalized by the total energy in a cluster,
6. m - number of cells with energy deposition above preset thresholds i.e. multiplicity of active cells in a cluster,
7. \(m_{\eta}\) - number of active cells in a cluster with \(\eta_{cell}\neq\eta_{c}\), (\(m_{\eta}\) - multiplicity),
8. \(m_{\varphi}\) - number of active cells with \(\varphi_{cell}\neq\varphi_{c}\), (\(m_{\varphi}\) - multiplicity),

Aditional features of "longitudinal" type were tested in order to take into account nonuniformity \(V_{E}\) of energy depositions in consequitive HC sections. \(V_{E}\) is defined as following:

\[V_{E}=\overset{-3}{i=1}(v_{i}\cdot E_{i}=v_{i+1}\dot{E}_{i+1})^{2}/E_{i+1}^{2} \,,\,\,E_{i+1}=E_{i} \tag{2}\]

Three sets of \(v_{i}\) constants were used to prepare three versions of \(V_{E}\) feature:

1. \(v_{i}=1\),
2. \(v_{i}=1/d_{i}\), where \(d_{i}\) - thickness of \(i\)-th HC section in nuclear interaction length units,
3. \(v_{i}=1/M_{\mu}(E_{i})\), where \(M_{\mu}(E_{i})\) is mean value of \(i\)-th longitudinal sample in HC for muon events (see Fig.1)

During training and testing sessions we retained only those models of \(\mathrm{NND}_{3d}\) which had higher characteristics and lower dimension of feature vector \(\vec{X}_{n}\). The final version of \(\mathrm{NND}_{3d}\) is based on the (8, 40, 1) - perceptron. The input features are:

* ordered sample of \(E_{i}\) (four features),
* \(m_{\eta}^{\{j_{k}\}}\), \(m_{\varphi}^{\{j_{k}\}}\), \(k=1,2\) (four features),
* are indeces of those two HC longitudinal sections where the greatest summed energies were deposited for an event.
Figure 6: _Ratios \(q_{ij}\!=\!Q_{i}/Q_{j}\) vs \(\varepsilon_{\mu}\) for different pairs of discriminators \(D_{i}\), \(D_{j}\): \(D_{0}-LTD\), \(D_{1}-NND_{11}\), \(D_{2}-NND_{12}\), \(D_{3}-NND_{3d}\)_

Functional behavior of \(\mathbf{NND}_{3\,d}\) is presented by \(Q_{3}(\varepsilon_{\mu})\) curve in Fig. 5. One can see that an increase in Q - factor value is sensible enough (about 25 units) compared to \(\mathbf{NND}_{11}\), but is relatively small (less then 10 units) compared to \(\mathbf{NND}_{12}\). In comparison with all other three discriminators the relative increase in Q for \(\mathbf{NND}_{3\,d}\) is presented in Fig. 6 by \(q_{3j}(\varepsilon_{\mu})\) curves, j = 0, 1, 2.

In our opinion, the moderate increase in Q for \(\mathbf{NND}_{3\,d}\) in comparison with \(\mathbf{NND}_{12}\) may be justified as follows.

Muons loose their energy mainly by ionization, and the number of active cells in an HC section does not exceed 2. Distributions of their deposited summed energies in each of four sections are of gaussian type, centered at \(M_{\mu}(E_{i})\), \(i=\overline{1,4}\) with standard deviations \(0.102<\sigma_{i}<0.125\) (ref. Fig.1). Big deviations from mean values \(M_{\mu}(E_{i})\) in one or more HC sections are used by well trained \(\mathbf{NND}_{11}\), \(\mathbf{NND}_{12}\) discriminators as signatures of a pion. Number of pions misclassified by \(\mathbf{NND}_{11}\), \(\mathbf{NND}_{12}\) is not greate and equals to \(m_{\pi}=N\cdot\beta_{\pi}=N/R_{\pi}\). To substantially increase classification power the \(\mathbf{NND}_{3\,d}\) discriminator should correctly classify a part of \(m_{\pi}\) pions using information on cell distribution of the deposited energy in HC sections. The rise in multiplicity above 2 active cells is with high probability accompanied by the increase in summed energy deposition by an amount that is abnormal to a muon event; the observed multiplicity of active cells in these \(m_{\pi}\) pions events is similar to that in muon events. The little difference in characteristics between \(\mathbf{NND}_{3\,d}\) and \(\mathbf{NND}_{12}\) shows that using information on active cell multiplicity permits \(\mathbf{NND}_{3\,d}\) to lower \(m_{\pi}\) number only by 5%. This result gives rise to an assumption that some of \(m_{\pi}\) pions - all exhibiting deep penetration ability with nonzero energy deposition in the last HC section - most likely did not take part in nuclear interactions at all. Obvious contradiction between the actually observed fraction of misclassified pions (\(\sim 0.01\)) and the fraction of pions (\(<0.0001\)) that could escape nuclear interactions in ATLAS calorimeter at \(\eta=0.3\) leads us to a conclusion that at least a part of the observed \(m_{\pi}\) cases of HC response is most probably not produced by particles entering HC as pions.

Indeed, pion decay process \(\pi^{\pm}\rightarrow\mu^{\pm}+P_{\mu}\) tends to make HC response to a background event (\(\pi\)) look like that to a signal event (\(\mu\)). The probability of the decay is not negligible in our \(\pi/\mu\) separation task: for \(p_{T}\) uniformly distributed in \(3-5\) GeV interval at \(\eta=0.3\) about 0.83% of pions decay prior to the first nuclear interaction and should in average produce muon-like HC responses. At high muon registration efficiencies and 3000 pion events in a test sample we arrive at a limit value \(R_{\pi}=120\pm^{30}_{20}\). It follows from this estimate that longitudinal samples in HC contain enough information for \(\mathbf{NND}_{11}\) and \(\mathbf{NND}_{12}\) to approach the limit values of \(R_{\pi}\) and Q. Hence the subsequent improvements in \(R_{\pi}\) and Q attained by \(\mathbf{NND}_{3\,d}\) could not be high.

Simulated events (12000 in total) have been split into two equal parts: one part used for training neural net and another part - for testing its generalization ability. With 3000 + 3000 events in the test sample and high values of background rejection factors \(R_{\pi}\) attained by discriminators (\(R_{\pi}\sim 100\)) the statistical errors in estimation of Q can not be low: \(\sigma(Q)\approx 15-20\). Nevertheless, the difference in characteristics of any two discriminators may be estimated with higher precision because the common test sample of events is used for evaluating these characteristics which consequently become correlated.

Let \(D_{i}\), \(D_{j}\) be two discriminators tuned to operate at the given fixed efficiency \(\varepsilon_{\mu}=\varepsilon_{0}\), and \(R_{i}\), \(Q_{i}\), \(R_{j}\), \(Q_{j}\) - their background rejection factors and enrichment factors at \(\varepsilon_{\mu}=\varepsilon_{0}\). Assume without loss of generality that \(R_{i}\geq R_{j}\). It can be shown that maximum likelihood estimation of variance of the ratio \(q_{ij}=Q_{i}/Q_{j}=R_{i}/R_{j}\) may be reduced to the following expression:

\[v\dot{a}r(q_{ij})=q_{ij}\cdot\frac{R_{i}}{N}\cdot\stackrel{{\mbox {\tiny{$-$}}}}{{q_{ij}}}+1-2\frac{R_{i}}{R_{ij}} \tag{3}\]

or

\[v\dot{a}r(q_{ij})=q_{ij}\cdot\frac{Q_{i}}{\varepsilon_{0}N}\cdot\stackrel{{ \mbox{\tiny{$-$}}}}{{q_{ij}}}+1-2\frac{Q_{i}}{Q_{ij}}\cdot\frac{ \varepsilon_{ij}}{\varepsilon_{0}} \tag{4}\]

where

N - the number of background events (pions) in the test sample,\(R_{ij},\ Q_{ij},\varepsilon_{ij}\) - background rejection factor, enrichment factor and muon registration efficiency of the compound discriminator \(D_{ij}\) based on \(D_{i},\ D_{j}\) that are operating in parallel (each at \(\varepsilon_{\mu}=\varepsilon_{0}\)) and whose output logical signals 0/1 (classification signals) are processed by "AND" logical funtion to form output signal of the compound discriminator.

Note that in general case the next inequalities hold:

\[R_{ij}\geq R_{i}\geq R_{j}\,\ \ \varepsilon_{ij}\leq\varepsilon_{0}\]

Error bars in Fig.6 correspond to estimates according to (3), (4).

Neural nets were thoroughly trained using up to 7 - 10 thousands epochs in a training session. To reach the minimum of event classification error we tested neural net versions with different forms of neuron activation function, used fixed and variable learning rates in a training session, used back-propagation and Rprop training procedures [4].

Output of a short summary after each epoch proved very useful for supervising the process of neural network training. The summary contains: epoch number, mean fit error MFE (1) in the current epoch, muon and pion recognition efficiency in training and test sets of events, four values of enrichment factor Q at efficiencies \(\varepsilon_{\mu}=0.99,0.95,0.90,0.85\).

As an example of a training session we present in Fig.7 the dynamics of enrichment factor Q (at \(\varepsilon_{\mu}=0.99\)) and mean fit error MFE as functions of the current epoch number in the session.

Figure 7: Dynamics of enrichment factor Q (at \(\varepsilon_{\mu}=0.99\)) and mean fit error MFE in a training session for \(NND_{11}\)

As the next step in our investigation scheme we estimated the dependence of discriminator characteristics on \(p_{T}\) values of events being tested. We evaluated characteristics of different discriminators at four \(p_{T}\) values inside the working interval (3.0, 5.0) GeV and at \(p_{T}=2\) and 10 GeV outside it. It should be noted that results for \(p_{T}\) outside the working interval are highly sensitive to singularities of NND versions and to the threshold values applied to the neural net output signal. Efficiency \(\varepsilon_{\mu}\) and pion reject ion factor \(R_{\pi}\) inside the working interval are constant within statistical errors for all discriminators. At \(p_{T}=10\) GeV \(\varepsilon_{\mu}\) remains as high whereas at \(p_{T}=2\) GeV \(\varepsilon_{\mu}\) drops to the values 0.2 = 0.8 depending on the version of a discriminator.

Due to poor statistics at \(p_{T}=2\) and 10 GeV (1000 pion events at each \(p_{T}\) value) only qualitative conclusions can be drawn from the set of estimates of \(R_{\pi}\) for different discriminators at these two \(p_{T}\) values. The least degradation in \(R_{\pi}\) and \(\varepsilon_{\mu}\) outside the working interval is shown by discriminators of NND\({}_{3d}\) family, the biggest degradation - by LTD. To reach good performance at \(p_{T}=2\) GeV one should include events simulated at \(2\leq p_{T}\leq 3\) GeV into the training set of events.

To investigate the influence of photostatisics on discriminator's performance we repeated steps 2 - 3 of our investigation scheme (see page 2) for seven different photostatistics levels in the range 10 - 80 photoelectrons per GeV. For the fixed muon recognition efficiency \(\varepsilon_{\mu}=0.99\) the dependence of Q - factor upon photostatisics level is presented in Fig.8 for NND\({}_{12}\) and LTD discriminators. It is clearly seen that the neural net discriminator is a more robust classifier which retains its selectivity within the whole range of photostatistics level and whose discrimination power gradually decreases when photostatistics level goes down. In contrast to NND\({}_{12}\), the LTD discriminator cannot retain its selectivity at efficiency \(\varepsilon_{\mu}=0.99\) within the whole range of photostatistics level (25 photoelectrons/GeV is the critical point - ref. Fig.8).

Figure 8: Enrichment factor Q asfunction of photostatistics level for NND\({}_{12}\) and LTD discriminators at fixed efficiency \(\varepsilon_{\mu}=0.99\)

According to the ATLAS Technical Proposal [3] the central two sections of hadron calorimeter will be grouped together. We designate the two HC designs of 4 and 3 longitudinal samples as HC(1,2,3,4) and HC(1,2+3,4). A neural net discriminator of \(\mathbf{NND}_{11}\) family was trained and tested for HC(1,2+3,4). In Fig. 9 its characteristics are presented by the line labeled \(\mathbf{NND}_{11}(\mathbf{3s})\). The line labeled \(\mathbf{NND}_{11}(\mathbf{4s})\) presents characteristics of the \(\mathbf{NND}_{11}\) discriminator given in details earlier for HC(1,2,3,4). One can see that at efficiencies \(\varepsilon_{\mu}<0.90\) the \(\mathbf{NND}_{11}(\mathbf{3s})\) is not inferior to \(\mathbf{NND}_{11}(\mathbf{4s})\). At efficiencies \(0.95<\varepsilon_{\mu}<0.99\) the enrichment factor Q of \(\mathbf{NND}_{11}(\mathbf{3s})\) is only 10% lower in comparison with \(\mathbf{NND}_{11}(\mathbf{4s})\).

## 4 Conclusions

1. Neural net discriminators operating on longitudinal or 3-dimensional deposited energy samples and the linear threshold discriminator operating on total deposited energy in the HC last section were applied to low \(p_{T}\)\(\pi/\mu\) separation. Compared to the linear threshold discriminator an increase of \(80-100\%\) in pion rejection factor at muon recognition efficiency \(0.95-0.99\) was obtained in case of neural network discriminators.
2. Neural net discriminators trained inside the working interval \(3\leq p_{T}\leq 5\) GeV do not show a sharp deterioration of their performance outside the working interval at \(p_{t}=10\) GeV. To keep good performance of neural net discriminators at \(p_{T}=2\) GeV one should include events with \(2\leq p_{T}\leq 3\) GeV into the training set of events.
3. Neural net discriminators proved to be robust classifiers that at high muon registration efficiency \(\varepsilon_{\mu}=0.99\) retain their selectivity in a wide range of photostatistics level (10 - 80 photoelectrons / GeV) and whose discrimination power - in contrast to the linear threshold discriminator - gradually decreases when photostatistics level goes down.
4. There is little difference in characteristics of neural net discriminators for two HC designs - with 4 and 3 longitudinal samples. No difference is observed for efficiencies \(\varepsilon_{\mu}<0.90\). At

Figure 9: Characteristics of neural net discriminators for two different HC designs - with 3 and 4 longitudinal samples

efficiencies \(0.95<\varepsilon_{\mu}<0.99\) the pions rejection factor in case of 3 longitudinal samples is only 10% lower compared to the case of 4 longitudinal samples.

## References

* [1] Proc. of Int. Workshop AIHENP-90 4, Lyon Villeurbanne, France, March 1990 Proc. of Int. Workshop AIHENP-92, La Londle les Maures, France, January 1992 Proc. of Int. Workshop AIHENP-93, Oberammergau, Germany, October 1993 Proc. of Int. Workshop AIHENP-95, Pisa, Italy, April 1995
* [2] J.Budagov, I.Chirikov-Zorin, A.Pantea, D.Pantea, O.Pukhov, M.Bosman, M.Nessi, "B-meson tagging improvement using HCAL information", ATLAS Internal Note, TILECAL-NO-023
* [3] ATLAS, "Technical Proposal for a General-Purpose pp Experiment at the Large Hadron Collider at CERN", CERN/LHCC/94-43, LHCC/P2 (1994)
* A versatile Artificial Neural Network Package", _Comp. Phys. Commun._**81** (1994) 185
* [5] White H., "Connedionist Nonparametric Regression: Multilayer Feedforward Networks Can Learn Arbitrary Mapping", _Neural Networks_, **3** (1990) 535
* [6] Thomas D.S. and Mitche A. "Asymptotic Optimality of Pattern Recognition by Regression Analysis", _Neural Networks_, **7** (1994) 313
* [7] V.V.Palichik, V.M.Severyanov, V.N.Shigaev, Ju.A.Budagov, N.O.Poroshin, "Model Neural Network and Threshold Calorimeter Triggers for b-Quark Events Selection in Fixed Target Experiments", Proc. of Int. Workshop AIHENP-93, Oberammergau, Germany, October 1993 p.347
* [8] J.Budagov, V.Palichik, N.Poroshin, V.Severyanov, V.Shigaev "Assesment of Characteristics of Threshold and Neural Network Triggers for b-Events Selection Using Simulation Data for the Forward Calorimeter of" Multiparticle Spectrometer" Installation on UNK 3 TeV Proton Beam", _Commun. of JINR_, P10-93-140, Dubna, 1993 (in Russian)
* [9] J.Budagov, I.Chirikov-Zorin, D.Pantea, V.Severyanov, V.Shigaev, S.Sushkov, P.Stavina, M.Bosman, M.Nessi, "Application of Artificial Neural Networks to Low \(p_{T}\) Muon Identification in ATLAS Hadron Calorimeter", to be published in Proc. of Int. Workshop AIHENP-95, Pisa, Italy, April 1995