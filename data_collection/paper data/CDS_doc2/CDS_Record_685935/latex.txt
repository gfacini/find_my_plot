Atlas INDET-NO-092

December 1994

\(B\)**-tagging using the Atlas Inner Detector**

**Stephen Haywood - RAL**

## 1 Introduction

In the Introduction, the methods which have been used are explained. After this, the following sections consider the rejection of three different categories of jet:

* Rejection of jets consisting of **prompt** particles produced at the primary vertex.
* Rejection of \(c\)**-quark** jets.
* Rejection of \(\mbox{\bf light-quark}\,(u,d,s)\,\mbox{jets}\).

### Definitions

The following abbreviations are used:

**IP**: Impact parameter, primarily in the \(x\)-\(y\) plane.
**PV**: Primary vertex - where \(p\)-\(p\) collisions occur.
**ID**: The Atlas Inner Detector.
**PR**: Pattern-recognition.

The helix parameters fitted are:

\(R^{-1}\)Inverse radius of curvature, proportional to \(p_{r}^{-1}\).

\(\phi_{0}\)Direction of trackin \(x\)-\(y\) at point of closest approach.

\(\Delta\lambda\)Tangent of dip-angle.

\(d_{0}\)Impact parameter, defined as distance of closest approach to the beam-line.

Sign is positive if track has positive angular-momentum around beam-line.

\(z_{0}\)\(z\)'impact parameter', defined as the value of \(z\) at point on track where \(d_{0}\) is evaluated.

### Methods

For this work, I have used my ownstand-alone code. This incorporates:

* Complete event generation by Pythia, including pile-up for high luminosity.
* Distribution of the PV within the beam-spot envelope: \(\sigma_{bs}=\sigma_{x}=\sigma_{y}=15\)\(\mu\) m and \(\sigma_{z}=5\) cm.
* Detector-planes are treated as barrels or disks, tiled with detectors of realistic dimensions.
* Multiple-scattering is simulated.
* Charged particles are tracked through a uniform magnetic field.
* Hits in detectors are derived from the truccrossing-points, smeared by the nominal resolution.
* Ghosts in the strip detectors are correctly handled.
* A small inefficiency (2-3%) is simulated.
* Noise at the level of 0.1% is simulated in strip detectors.
* To allow for two-hit resolution problems, hits which lie within 3 (6) strips of each other in the SCT (MSGC's) are discarded.

but

* Particle creation (bremsstrahlung, delta's or pairs) is not simulated.
* There is no simulation of 'previous events' in the MSGC's.

The procedure used is:

1. Generate event samples: \(b\)jets and \(non\)-\(b\)jets with Pythia.
2. Simulate the ID: hit generation and reconstruction, followed by PR. Write out parameters for fitted (charged) tracks in jets.
3. Derive efficiencies as a function of cuts for \(b\)jets and \(non\)-\(b\)jets separately.
4. Combine the efficiencies to obtain \(non\)-\(b\)-\(jet\)**Rejection** vs \(b\)-\(jet\)**Efficiency**.

### Pattern-recognition and Track-finding

When considering decays \(t\to bW\), a _trigger 'cone'_ is defined around the known direction of the \(b\)-hadron. This 'cone' has \(|\Delta\phi|<0.30\) rad and \(|\Delta\theta|<0.15\) rad. Hits within this cone (allowing for a \(\pm 3\sigma\) variation of the PV in \(z\)) are considered, and sets of three \(r\phi\) measurements are taken to test for track candidates. This process starts with the outer planes, but eventually considers all hits within the cone. If a plausible track candidate is found:

* \(\geq 4\)\(R\phi\) measurements,
* \(\geq 4\)\(z\) measurements,
* \(\leq 2\) missing hits and
* acceptable residuals,

then it is accepted. The hits on the track are flagged as _used_ and cannot be reused. This simplifies the PR, although causes some efficiency loss. No attempt is made to resolve possible conflicts over the association of individual coordinates or to retain a larger number of possible candidates, possibly sharing coordinates. One consequence of this is that one track candidate may incorporate a hit which comes from another track. Because the hit has been'stolen', it may be difficult to complete the PR for the second track. Because some tracks bend out of the cone, while others bend into it, the momentum vectors of the tracks found lie mainly within the cone, but the edges are not sharp.

The track-candidates are fitted with a helix which correctly allows for the error-matrices at the various detector-planes, but only approximately allows for multiple-scattering. (This will be improved at a later date.)

### Physics Datasets

In the studies performed, the **Rejection**\(R\) of _non-b_jets is determined as a function of the **Efficiency**\(\epsilon_{b}\) for selecting \(b\)-jets. The Rejection is defined as the reciprocal of the corresponding efficiency: \(R_{X}=1/\epsilon_{X}\), where \(X\) denotes the type of jet to be rejected.

In all of this work, decays of the form \(t\to qW\) with \(W\to l\nu\) have been used. These correspond to a physics process of some interest where one would wish to tag \(b\)'s. By forcing the leptonic decay of the \(W\), the complications arising from overlapping jets can be avoided. Clearly this represents an idealistic situation - although it is plausible that in studying \(t\overline{t}\) production, one may choose to select events with the appropriate number of isolated jets.

'Prompt'-jets'

'\(Prompt\)'-jets are obtained from the process \(t\to bW\), where all the particles from the \(b\)-hadron are forced to come from the PV. Using these jets has several advantages:

* The jets are exactly comparable with the \(b\)-jets as far as particle spectra (energies, multiplicities, \(p_{T}\) relative to jet-axis) are concerned. This means that one is sensitive to the lifetime effects, without other confusions.
* The same dataset (step 1, in Section 1.2) can be used with different simulation (step 2) to determine \(\epsilon_{b}\) and \(\epsilon_{prompt}\).

The obvious drawback of this is that there are physics differences between \(b\)-jets and \(u,d,s\)-jets, and for a given physics process, the relevant jet energies may be different. Further, due to the mass of the \(b\)-hadron, the separations between particles in a \(b\)-jet ought to be slightly greater than in a light-quark-jet - this should make PR for latter slightly more difficult.

#### Quark-jets

c-jets and \(u,\,d,\,s\)-jets are created in the process \(t\to qW\) where Jetset is modified to replace the more normal \(b\)-quark by a \(q\)-quark.

#### 'Triggering'

In the standard top decay scenario, \(t\to b\to b\)_-hadron_, the _trigger 'cone'_' is defined around the known direction of the \(b\)-hadron (usually a \(B\) meson). For the forced decays to other quarks, a similar method is used to define the jet direction. This makes a lot of sense for decays to \(b\)'s, since the hard fragmentation causes the \(b\)-hadron to take most of the quark energy and thus define the jet energy and direction. It is less appropriate for the lighter quarks. However, this should not be too critical, since the cone is used for searching for tracks, and not to estimate the jet direction (see Section 1.6).

### Different Layouts and Impact-parameter Resolution

The studies have been made in two regions:

* **Barrel:**\(0\leq\left|\eta\right|\leq 0.9\) and
* **Overlap:**\(0.9\leq\left|\eta\right|\leq 1.9\).

It turns out that the differences are not huge and so by **default**, results will be presented for the **Barrel.**

Three different scenarios have been considered:

#### High luminosity

Pile-up at \(10^{34}\) is included in the detectors simulation, but no vertex detector is considered.

#### Low luminosity with \(\mathbf{h}\) Pixel vertex detector

A pixel vertexing layer at \(r=4\) cm is included with \(\sigma(R\phi)=10\oplus 10\)\(\mu\) m and \(\sigma(z)=87\)\(\mu\) m. The thickness is \(1.1\%\)\(X_{0}\). The **Pixel vertexing layout** is used as the **default** layout for these studies.

#### Low luminosity with \(\mathbf{h}\) Crossed-strip vertex detector

A crossed-strip vertexing layer at \(r=6\) cm is included with \(\sigma(R\phi)=7\oplus 7\)\(\mu\) m and \(\sigma(z)=20\)\(\mu\) m. The detectors are \(6\times 6\) cm\({}^{2}\), and four detectors are bonded togetherlengthways to create ladders of half-length of 23 cm. The thickness is \(0.5\%\)\(X_{8}\).

The IP resolution \(\sigma(d_{\oplus})\) can be approximated as the sum in quadrature of two terms: one arising purely from measurement errors and a second from multiple-scattering. Simon Gadomski [1] has determined these resolutions, which are shown in Table 1 and Figure 1.

Since the helix fits which I have made include multiple-scattering terms in an approximate way, the above resolutions will not be a perfect description of the parameters which I fit. To first order this does not matter; the main consequence being that the resulting probability functions do not quite have their expected interpretation. As it turns out, the resolutions do describe the fits quite well - mainly because particle energies are fairly high causing the multiple-scattering to be less significant.

### Track Cuts and Probability Function

In addition to the cuts placed during track-finding, the following cuts are made on the fitted tracks:

1. \(|p_{T}|>1\) GeV.
2. \(|d_{0}|<2\) mm - to reduce contributions from \(V^{0}\)'s.
3. \(\geq 1\) hit on the high luminosity pixel layers.

At least 2 such tracks are required.

The corresponding vertexing layer resolution is used only if there is a hit in the vertexing layers; if not, the high luminosity resolution is used.

For each jet, the jet direction is estimated in an unbiased way from the \(p_{T}\)-weighted fitted track directions:

\[\hat{\phi}=\frac{\sum p_{T}\phi_{0}}{\sum p_{T}} \tag{1}\]

For each track, the IP \(d_{0}\) is given a sign which is positive (negative) if it crosses the jet-axis in front of (behind) the PV, corresponding to positive (negative) lifetime. With \(d_{0}\) defined in Section 1.1, the signed IP is given by:

\[d_{signed}=sig\,n(\phi_{0}-\hat{\phi})\times d_{0} \tag{2}\]

The probability \(\omega\) that the track represents a particle coming from the PV (situated within the beam-spot envelope) and described by a Gaussian measurement function is evaluated:

\[\omega=\frac{1}{\sqrt{2\pi}}\int_{d_{signed}}^{\infty}\exp{-\frac{x^{2}}{2 \sigma^{2}}dx} \tag{3}\]

where \(\sigma=\sigma(d_{0})\oplus\sigma_{0}\). This probability is small for a particle coming from a long-lived decay, but is O(1) for a well measured particle coming from the PV.

For a given jet, these probabilities \(\omega_{i}\) for each track \(i\) are combined into a probability function \(\Omega\) which measures the probability that the tracks measured are consistent with the hypothesis that they all come from the PV:

\[\Omega=-\ln{\prod_{i}(\frac{\omega_{i}}{0.5})} \tag{4}\]

The factor 0.5 in the denominator allows for the fact that the mean value of \(\omega\) for a well measured prompt track is 0.5, and reduces the dependence of \(\Omega\) on the number of tracks. This probability function behaves a little like a chi-squared.

**Aleph**[2] used the product \(\prod_{i}\omega_{i}\), and evaluated the probability of a more unlikely outcome, based on the hypothesis of all tracks coming from the PV. This has the advantage of no dependence on the number of tracks used and since the probability varies uniformly between 0 and 1 for jets satisfying the hypothesis, the probabilistic interpretation is straightforward. I have tried using this variable, and find that it makes little change to the Efficiency-Rejection curves.

## 2 Rejection of Prompt-jets

### Basic Quantities

At the generator level, the mean number of charged particles originating from a \(b\)-hadron (mostly \(B\) mesons) with \(|p_{T}|>1\) GeV and \(|d_{\parallel}|<2\) mm is 4.9. After the angular cuts imposed by the trigger 'cone', this becomes 4.5. The mean number reconstructed is 5.1 - the difference arising from: genuine tracks from the string-fragmentation, the 'fuziness' of the cone boundaries and reconstruction problems. The charged track \(p_{T}\) distribution is roughly exponential with a mean of 8 GeV, while that of the \(b\)-hadron is 70 GeV.

In Figure 2, the normalised distributions \(d_{\parallel}/\sigma\) are shown for \(b\)-jets and _prompt_-jets. The distributions for tracks corresponding to particles coming from the \(B\) decays (determined from the Monte Carlo truth information) are clearly not described by the measurement error, indicating lifetime; while those from the simulated prompt decays are well described. Some of the particles in \(b\) events which do not come from the \(B\) decays are incorrectly reconstructed, picking up hits from nearby \(b\)-daughters which contain lifetime information, and consequently causing tails in the distribution. It can be seen that the error parameterisations given in the previous section give a plausible description of the measurements determined from this simulation.

In Figure 3, distributions of \(d_{igned}/\sigma\) are shown on a log scale. The effect of the \(b\)-lifetime is clearly visible. The entries for negative values result from reconstruction problems.

In Figure 4, distributions of the probability function \(\Omega\) are given for \(b\)-jets and \(prompt\)-jets. The spike at low values of \(\Omega\) corresponds to jets where \(<2\) good tracks have been reconstructed. The spike at high values corresponds to \(b\)-hadrons with genuine lifetime information, or jets with track-reconstruction problems. In practice, the tail at large \(\Omega\) is difficult to handle, and so a simple transformation of \(\Omega\) is made: \(\Omega\to\Omega^{\prime}\).

The Efficiency is determined by counting the number of jets which lie above a given value of \(\Omega^{\prime}\), ie. \(\Omega^{\prime}_{cut}\). Hence, one obtains \(\epsilon=\epsilon(\Omega^{\prime}_{cut})\). By plotting points \((\epsilon_{0}\,(\Omega^{\prime}_{cut}),1/\epsilon_{prompt}(\Omega^{\prime}_{ cut})\) for different values of \(\Omega^{\prime}_{cut}\), a curve of \(R_{prompt}\) vs \(\epsilon_{0}\) can be constructed. This is shown in Figure 5. This curve is the 'default' against which other comparisons are made. Also shown is the line which corresponds to no discrimination, ie. \(R_{prompt}=1/\epsilon_{0}\). The ratio between the two curves (or difference on a log scale) represents the enhancement of the \(b\)-jets over the \(prompt\)-jets. The curve labeled 'perfect PR' is the result of using the detector simulation but with perfect PR, achieved by using the Monte Carlo truth information.

There are several important features of the measured Rejection curve:

* The offset of the curve at high \(\epsilon_{0}\) corresponding to \(b\)-jets with \(<2\) tracks passing the selection cuts. No discrimination is possible for these jets.
* The steep rise follows fairly well the curve corresponding to perfect PR. It is determined by a) the resolution of \(d_{0}\) for prompt tracks provided by the ID and parameterised in section 1.5 and b) the true lifetime of \(b\)-hadrons.
* The 'knee' at \(\epsilon_{0}=0.8\) corresponding to the level of rejection at which reconstruction errors in the \(prompt\)-jets exceed the Gaussian measurement errors on \(d_{0}\) and become the dominant source of apparent lifetime.

The steep rise is a measure of the resolution power of the ID. This could be simulated at the generator level, using the parameterisation of \(\sigma(d_{0})\). However, the position of the 'knee' and the region of reduced slope is a function of both the intrinsic PR capabilities of the ID and the algorithm used. Hence, thiscannot be simulated at the generator level. The PR problems begin for \(R_{p\,\sigma mpl}\sim 50\), ie. at the 2% level for jets.

In Figure 6, a comparison between jets in the Barrel, Overlap and with high-\(E_{T}\) is made. The rejection of jets in the Overlap is worse by only a factor of about two (quite small on the logarithmic scale). Likewise, high-\(E_{T}\) jets do not look so different. The offset of the high-\(E_{T}\) is closer to \(\epsilon_{b}=100\%\) because there are more tracks reconstructed in the cone, which can be used to provide the discrimination.

In Figure 7 results for the different layouts of Section 1.5 are shown. The difference between the two vertexing options is fairly small compared to some of the uncertainties, and it would be premature to deduce from this plot that one is better than the other. Different PR philosophies (such as starting from the inner layers) could modify the results, and undoubtedly more studies are needed. The performance at high luminosity is markedly worse: most of the difference coming from the absence of a vertexing layer, rather than the effects of pile-up.

For comparison, measurements from Aleph[2] and Delphi[3] (see Table 2) are given for rejection against light-quarks. At high \(\epsilon_{b}\), the LEP results are closer to the Atlas high luminosity curve - presumably reflecting the fact that at Atlas, the particle momenta will be higher than at LEP and consequently, the multiple-scattering will be less significant and the high-\(p_{T}\) limits for \(\sigma(d_{b})\) for the LEP experiments and for high luminosity Atlas are quite similar.

In Figure 8, comparisons are made between various conditions. Replacing all pixels with crossed-strips or introducing more noise creates more PR problems and hence reduces the rejection power. These results inevitably depend on the PR algorithm used.

## 3 Charm-quark Jets

In Figure 9, the signed IP distribution and the transformed probability function \(\Omega^{\prime}\) for c-jets are shown. The rejection which can be obtained is shown in Figure 10. The c-jet rejection is not very impressive - this can be anticipated by looking at the first pair of figures. The region \(0.3\leq\epsilon_{b}\leq 0.9\) corresponds to \(0\leq\Omega^{\prime}\leq 20\).

In a simple decay, the signed IP is directly related to the proper-time lived by the mother. Therefore, one might hope that the distributions shown in Figure 9 would show the same exponential behaviour. Unfortunately this is not the case: the curves are not good representations of exponentials and the c-jet curve rises to meet the \(b\)-jet curve. Some of the reasons for these observations are:

* There are strange decays which tend to exhibit very long lifetimes.
* The decays of the \(b\)- and \(c\)-hadrons result in decay chains with more than one mother with significant lifetime. This complicates the IP distribution.
* The IP also depends on the kinematics of the decay in the rest-frame. Hence the IP is a convolution over a number of distributions.
* The IP distribution has been normalised by the error which is function of the track \(p_{T}\).

At \(\epsilon_{b}=0.3\), \(R_{c}\) is 10 - only a factor 3 enhancement of the \(b\)-jets. This is hardly affected by PR problems, since it is dominated by the lifetimes of the \(b\)- and \(c\)-hadrons. If all \(V^{0}\)'s are removed (by setting their lifetimes to infinity), then \(R_{c}\) increases to 20. If the values of \(\sigma(d_{b})\) used to normalise \(d_{signed}\) are fixed at 20 \(\mu\)m, then \(R_{c}\) increases to 29. This is still a factor of 3 short of what Aleph obtained. At the generator level, I have considered the effects of :

* Running as at LEP, ie. \(e^{+}e^{-}\) collisions at \(\sqrt{s}=92\) GeV,* Relaxing the selection cuts, including those which define the jet,
* Using only those particles which are descendents of the \(b\)- and \(c\)-hadrons.

None of these seem to have large effects. I have not been able to test the use of a 3-D impact parameter.

### Hadron Production and Lifetimes

The poor rejection against \(c\)-jets is no shock, as it arises from the fact that the \(c\)-hadron lifetimes are comparable with those of \(b\)-hadrons. \(c\)-quarks fragment to \(D^{*}\) states (J=1) three times more readily than \(D\) states (J=0) due to spin factors. The \(D^{*}\)'s decay rapidly to \(D\)'s. While the lifetime of \(D^{0}\)'s and \(D^{+}_{s}\)'s is significantly shorter than that of \(B\)'s, the \(D^{+}\) lifetime is quite similar. Table 3 illustrates the production and decay of \(c\)-hadrons which give rise to significant lifetime (baryonic states have shorter lifetimes). Using Jetset, the rate of production of \(D^{+}\)'s (including those produced from \(D^{*}\)'s) is about 24%. If one takes the PDB value for Br(\(D^{*+}\to D^{+}\)_anything_) of 32%, this rate becomes 19%.

One might be inclined to think (as I was) that in one quarter of \(c\)-jets, the result is a \(D^{\pm}\) which has a lifetime which is similar to that of \(B\)'s, and hence the \(b\) enhancement which can be obtained is going to be of the order of four. The fact that the \(B\)'s tend to decay sequentially to \(D\)'s results in IP's which are non-trivial functions of the lifetimes of the hadrons. A simple sequential decay is illustrated in Figure 11. When this is considered for a decay in the plane \(\eta=0\), the IP is given by:

\[d_{0}=l_{B}\theta_{B}+(l_{B}+l_{D})\theta_{D} \tag{5}\]

where \(l\) is the decay-length. The decay-length is given by \(l=\gamma\beta\epsilon t^{*}\) (\(\beta\approx 1\), \(c\equiv 1\)) where \(t^{*}\) is the proper-time, measured in the mother's rest-frame. The angles \(\theta_{B}\) and \(\theta_{D}\) have random signs (causing them to combine in quadrature) and are reduced by the Lorentz boosts. Therefore \(\theta\sim\gamma^{-1}A^{*}\) where \(A^{*}\) is an angular factor evaluated in the rest-frame and is O(1). So

\[d_{0}\sim t_{B}^{*}\,A_{B}^{*}\oplus(\frac{\gamma_{B}}{\gamma_{D}}t_{B}^{*}+ t_{D}^{*})A_{D}^{*} \tag{6}\]

\(\frac{\gamma_{B}}{\gamma_{D}}=\frac{E_{B}}{E_{D}}/\frac{m_{B}}{m_{D}}\) which will typically be O(1). Due to the greater mass of \(B\)'s, \(A_{B}^{*}\) tends to be greater than \(A_{D}^{*}\). So it seems plausible that the effective lifetime to which the IP should be sensitive in \(b\)-jets could be a factor of 1 to 2 greater than simply the \(B\) lifetime. This should make \(b\)-tagging much better than one might naively expect. However, it is quite clear that the interpretation of \(d_{igned}\) and consequently \(\Omega\) is complicated. Also the momentum spectra of some of the daughters may be quite soft and this will have consequences either for track selection or when normalising by \(\sigma(d_{0})\).

## 4 Light-quark Jets

The IP \(d_{0}\) has a distribution which is very roughly the same as that for the proper-decay-length. So although the 2 mm cut on \(d_{0}\) will remove most decay products of the \(K_{s}^{0}\) (\(c\tau=27\) mm) and \(\Lambda\) (\(c\tau=79\) mm), contaminations of the order of several percent are to be expected. If \(V^{0}\)'s are not'removed', this will tend to limit the rejections which can be achieved to numbers in the range \(10^{1}\) to \(10^{2}\) (depending on many things, in particular the rate of production of \(V^{0}\)'s). This is less of a problem in the case of \(c\)-jets where the rejections are limited to similar values because of the non-negligible \(D\) lifetimes. However, in the case of light-quark jets, **if** there are no long-lived decaying particles, as in the case of the \(prompt\)-jets of Section 2, then the limitations arise from PR problems at the level of \(R_{prompt}\sim 10^{2}\) to \(10^{3}\). But clearly for real \(u,d,s\)-jets this will be limited by \(V^{0}\) decays.

The IP distributions are shown in Figure 12. The contributions from \(V^{0}\)'s are clearly visible as long tails. The tails are more symmetric than might have been anticipated (tracks containing lifetime information should appear with positive entries). The reason is that tracks with large negative values of \(d_{signed}\) arise because the direction of the \(V^{0}\) can be significantly different from that of the jet-axis \(\hat{\phi}\), as illustrated in Figure 13. Figure 14 shows the effect on the distribution \(d_{signed}/\sigma\) of removing the \(V^{0}\)'s at the generator level (by using the truth information).

Figure 15 shows the rejection which can be obtained against light-quarks. This should be compared with the rejection against _prompt_-jets shown in Figure 5. The effect of the \(V^{0}\) decays is to reduce the rejection power against light-quarks by over an order of magnitude. However, if \(K^{0}_{s}\)'s and \(\Lambda\)'s can be'removed', then the rejections which can be achieved are much closer to those for the _prompt_-jets. This was achieved by setting the lifetimes of \(K^{0}_{s}\)'s and \(\Lambda\)'s to infinity, so that they did not decay and did not produce charged tracks. Clearly this is different from identifying the decay products and choosing not to use them. If all \(V^{0}\)'s can be removed, then the rejection slightly exceeds that obtained for _prompt_-jets shown in Figure 5, since the limit on the rejection becomes PR problems once more, and these are slightly reduced if the daughters of the \(V^{0}\)'s are no longer simulated.

One simple way in which \(V^{0}\)'s can be removed in'real' data is by cutting on the decay-length. This can be estimated as \(l=d_{\hat{\psi}}/\sin(\phi_{0}-\hat{\phi})\). As with \(d_{signed}\), \(l\) may appear negative. The result of a cut \(|l|<2\) cm can be seen in Figure 14 for \(w\)-jets. This cut, reduces the number of entries in the \(d_{signed}\) distribution beyond \(\pm 3\sigma\) from 3.0% to 1.6% - a factor of 2 improvement. When applied to the s-jets, it reduces the number of entries beyond \(\pm 3\sigma\) from 6.6% to 2.2% - a factor of 3 improvement. When applied to the \(b\)-jets, it reduces the number of entries from 55% to 45%. The rejections which can obtained with the addition of this cut are shown in Figure 16.

## 5 Conclusions

The following conclusions can be drawn from this work:

* The Atlas Inner Detector has a \(b\)-tagging capability at low luminosity (with a vertexing layer) which seems at least as good as that of the LEP detectors. However this is only demonstrated under some idealistic conditions, and it must be verified with more realistic assumptions.
* It is clear that the LEP experiments attained this capability only after much effort on PR and understanding \(V^{0}\)'s and jets. Therefore we will have to do the same, especially as our environment and detector are more complicated.
* The relative importance of \(c\)-jets to light-quark jets will depend on the physics process being studied.
* Rejection of \(c\)-jets will be helped to some extent by removing \(V^{0}\)'s but ultimately will be limited by the real lifetime of the \(c\)-hadrons.
* Rejection of light-quark jets will be limited by the real lifetime of the \(V^{0}\)'s. If these can be removed with high efficiency, then PR problems will become the limiting factor.

### Further Studies

I do not intend to work on \(b\)-tagging in the immediate future. However, I would identify the following topics as worth pursuing. (A 'G' after the topic indicates useful studies could be made at the generator level (just smearing tracks with nominal resolution), an 'F' indicates where a full simulation, including PR, is needed.)

#### Tagging in 3-D (G)

Aleph obtained a factor of \(\sqrt{2}\) improvement1 by using a 3-D IP. However, this was possible because the resolution in \(z\) was comparable with that in \(r\phi\). This is not likely to be the case for Atlas. The use of information in \(r\)-\(z\) requires a knowledge of the \(z\) position of the PV, and this in itself requires substantial effort to obtain reliably (see [2]). This may be difficult to obtain when there is pile-up, leading to several PV's. In the transverse projections, the PV is significantly better defined at LHC than at LEP.

Footnote 1: Such an improvement would be relatively small compared with some of the changes demonstrated in this work.

#### \(V^{0}\)'s (G,F)

It was seen that to obtain very high rejections against light-quarks, it is necessary to identify most of the \(V^{0}\)'s. Only two cuts have been used in this work: \(\left|d_{0}\right|<2\) mm and \(\left|d_{0}/\sin(\phi_{0}-\hat{\phi})\right|<2\) cm, with no attempt to optimise them. There is undoubtedly plenty of room for improvement.

To attain a high efficiency for \(V^{0}\) identification, combinatorial searches with mass cuts are probably needed. Also, it may be desirable to use a \(V^{0}\)-finder. This can be studied to some extent at the generator level, although PR problems will undoubtedly limit the efficiency for identifying the decays. One refinement is that having reconstructed a \(V^{0}\), the IP of this (rather than those of its daughters) can be used in the probability function.

#### Jets (G)

The purpose of jet-finding (in the case of a \(b\)-jet) is a) to identify the set of tracks coming from the \(b\)-hadron and b) determine its direction. In these studies, no attempt has been made to optimise the jet cuts. Firstly, it is probably more sensible to cut on \(\Delta R=\sqrt{\Delta\eta^{2}+\Delta\phi^{2}}\) - a variable motivated by physics - rather than \(\Delta\theta,\Delta\phi\) which was motivated by my thoughts on PR. Further, since the PR is only performed in the 'cone' around a jet, there is no possibility to examine the effect of realistic jet-finding algorithms. Finally, there may be advantages in combining information from the calorimeters and ID to obtain the best definition of jets.

#### Track quality (F)

No attempt has been made to optimise the track cuts: number of hits, chi-squared, minimum \(p_{T}\).

#### PR (F)

Some PR algorithms which are perfectly good for some physics may be less good for reliable estimates of the IP. It has been found in the past that the use of _global_ algorithms which consider the optimal assignment of hits to a set of tracks is important to avoid misassignments which tend to occur with 'first come, first served' algorithms, as described in Section 1.3.

#### \(c\) Rejection (G)

The fact that the rejections presented in this note fall short of those obtained by Aleph by a factor of 3 in the most optimistic case for \(\epsilon_{b}\approx 0.30\) indicate that more work is needed. The fact that the rejection is better when a fixed value of \(\sigma(d_{0})\), independent of \(p_{T}\), is used, suggests that using probabilities based on the measurement errors is not optimal. In deed, for the relatively large IP's which arise from \(B\) and \(D\) decays, resolution is not a big issue.

### Acknowledgements

I wish to thank Bill Murray for his explanations of what Delphi did and for reading this note, and Szymon Gadomski forgiving me the IP resolutions for Atlas.

## References

* [1] The Atlas Technical Proposal, CERN/LHCC/94-43 (1994).
* [2] 'A Precise Measurement of \(\Gamma_{Z\to b\bar{b}}/\Gamma_{Z\to hadrons}\)', Phys. Lett. B313 (1993) p535.
* [3] Numbers provided by Bill Murray.