# Measuring \(R\)-parity violating couplings in dilepton production at the LHC

Debajyoti Choudhury

HarishChandra Research Institute, Chhatnag Road, Jhusi, Allahabad 211 019, India

Rohini M. Godbole

CERN, Theory Division, CH-1211, Geneva, Switzerland

Giacomo Polesello

INFN, Sezione di Pavia, Via Bassi 6, Pavia, Italy

Permanent Address: Centre for Theoretical Studies, Indian Institute of Science, Bangalore, 560 012, India

###### Abstract:

We revisit the issue of probing \(R\)-violating couplings of supersymmetric theories at hadronic colliders, particularly at the LHC. Concentrating on dimuon production, an evaluation of the optimal sensitivity to the \(R\)-violating coupling is performed through a maximum likelihood analysis. The measurement uncertainties are evaluated through a study of fully generated events processed through a fast simulation of the ATLAS detector. It is found that a host of \(R\)-violating couplings can be measured to a statistical accuracy of better than 10% over a significant part of the \(m_{\tilde{f}}-\lambda\) parameter space still allowed by low energy measurements. Since the bounds thus obtained do not simply scale as the squark mass, one can do significantly better at the LHC than at the Tevatron. The same analysis can also be extended to assess the reach of the LHC to effects due to any non-SM structure of the four fermion amplitude caused by exchanges of new particles with different spins such as leptoquarks and gravitons that are suggested by various theoretical ideas.

+
Footnote †: preprint: hep-ph/0903115

## 1 Introduction

Within the Standard Model (SM), electroweak gauge invariance ensures both lepton number and baryon number conservation, at least in the perturbative context. However, this is not so within the Minimal Supersymmetric Standard Model (MSSM). The most general superpotential respecting the gauge symmetries of the SM contains bilinear and trilinear terms which do not conserve either the Baryon number (\(B\)) or the Lepton number (\(L\)). Clearly, a simultaneous presence of both lepton- and baryon-number violating operators could lead to very rapid proton decay, especially for TeV scale sparticle masses. Existence of all such terms can be forbidden by postulating a discrete symmetry [1, 2], called \(R\)-parity, which implies a conserved quantum number \(R_{p}\equiv(-1)^{3B+L+S}\), where \(S\) stands for the spin of the particle. The very definition implies that all the SM particles have \(R_{p}=+1\) while all the superpartners are odd under this symmetry. Thus, apart from suppressing proton decay, it also guarantees the stability of the lightest supersymmetric particle (LSP) thereby offering a ready-made candidate for cold dark matter.

However, while a conserved \(R\)-parity seems desirable, it is perhaps too strong a requirement to be imposed. For one, the measure is an _ad hoc_ one and there does not exist an overriding theoretical motivation for imposing this symmetry, especially since a suppression of proton decay rate could as well be achieved by ensuring that one of \(B\) and \(L\) is conserved. Indeed, it has been argued [3] that this goal is better served by imposing a generalized baryon parity instead. Unlike \(R\)-parity, this latter (\(Z_{3}\)) symmetry also serves to eliminate dimension-5 operators that could potentially have led to proton decay. Furthermore, nonzero \(R\hskip-5.0pt/_{p}\) couplings provide a means of generating the small neutrino masses that the neutrino oscillation experiments seem to call for. Similarly, a significant value of such couplings have been shown to provide respite from the tachyonic nature of sleptons in models with Anomaly Mediated Supersymmetry Breaking [4]. It is thus of both theoretical and phenomenological interest to consider violations of \(R\)-parity.

Limiting ourselves to a renormalizable superpotential, the possible \(R_{p}\)-violating terms can be parametrized as

\[W\supset\sum_{i}\kappa_{i}L_{i}H_{2}+\sum_{i,j,k}\left(\lambda_{ijk}L_{i}L_{j}E _{k}^{c}+\lambda^{\prime}_{ijk}L_{i}Q_{j}D_{k}^{c}+\lambda^{\prime\prime}_{ijk }U_{i}^{c}D_{j}^{c}D_{k}^{c}\right) \tag{1}\]

where \(i,j,k\) are generation indices, \(L\) (\(Q\)) denote the left-handed lepton (quark) superfields, and \(E^{c}\), \(D^{c}\) and \(U^{c}\) respectively are the right-handed superfields for charged leptons, down and up-type quarks. The couplings \(\lambda_{ijk}\) and \(\lambda^{\prime\prime}_{ijk}\) are antisymmetric in the first and the last two indices respectively. A conserved baryon number requires that all the \(\lambda^{\prime\prime}_{ijk}\) vanish identically thereby avoiding rapid proton decay.

As with their \(R_{p}\) conserving cousins, namely the usual Yukawa couplings, these couplings are entirely arbitrary. Some phenomenological constraints exist though. For example, the preservation of a GUT-generated \(B-L\) asymmetry necessitates the preservation of at least one of the individual lepton numbers over cosmological time scales [5]. At a more prosaic level, the failure of various collider experiments [6; 7] to find any evidence of supersymmetry1 have implied constraints in the parameter space. For superpartners too heavy to be produced directly, even stronger bounds on these couplings can be inferred from the remarkable agreement between low energy observables and the SM predictions. These include, for example, meson decay widths [10], neutrino masses [11], rates for neutrinoless double beta decay [12]_etc_. The bounds generally scale with the sfermion mass, and for \(m_{\tilde{f}}=100\:\mbox{GeV}\) range from \(\sim 0.02\) to \(0.8\).

Footnote 1: Although \(R\)-parity violation has been touted as an explanation [8] for the reported excess of high-\(Q^{2}\) events at hera[9], it is no longer clear that this anomaly persists.

In general, therefore, when one studies the collider signals for \(R_{p}\) violating supersymmetry, it is usual to consider the so called 'weak' \(R_{p}\) violation scenario where the production of the superparticles goes through gauge couplings and the only role of \(R_{p}\) violation is in the decay of the lightest supersymmetric particle [13]. Such studies are clearly insensitive to the exact size of the \(R_{p}\) violating coupllarge enough to make the decay length of the LSP undetectable 2. The processes that are directly sensitive to the size of this \(R_{p}\) violating coupling are the production of sparticles through them [15, 16, 17, 8], decays of sparticles through them [18, 19, 20] or through indirect effects of the virtual sparticle exchange by interference of the \(R_{p}\) violating amplitude with the SM one[21, 22, 23, 18, 24].

Footnote 2: If any of the \(R_{p}\)-violating couplings is \(>10^{-6}\) or so, then the LSP will decay within the detector [14].

An inspection of the aforementioned low-energy constraints shows that they are the strongest when the term involves only the first two generations, and are often rather weak when one or more of the superfields belong to the third generation. In the context of collider experiments, a measurement of such couplings could, in principle, be done in more than one way, viz, direct production, decays of particles like the top quark or sparticles other than the LSP through \(R\!\!\!\!/_{p}\) coupling, as well as through virtual exchanges. For example, in the event of a large coupling, one could study the rate for the production of single sparticles. However, such measurements are subject to uncertainties from the luminosity measurement in some cases and also from the knowledge of branching ratios. We, therefore, revisit the issue of the indirect determination of certain of \(\lambda^{\prime}_{ijk}\) couplings at the LHC using their contribution to the production of lepton pairs.

Clearly, for such contributions to be significant, the initial state must involve quarks of the first generation, or in other words, at least one of \(j\) and \(k\) must be 1. Restricting ourselves, for the sake of definiteness, to muons, one sees that the least constrained among the relevant couplings [7]\(\lambda^{\prime}_{231}\) and \(\lambda^{\prime}_{211}\). We look at the reach of the LHC in the two dimensional \(\lambda^{\prime}-m_{\tilde{q}}\) plane. The current study goes much beyond the earlier analysis of this process [21, 23] at the Tevatron in that we exploit the differences in the angular distribution of the leptons as well as the invariant mass distribution of the lepton pair. The use of this additional information increases the sensitivity to the \(R_{p}\) violating couplings. Through a detailed experimental analysis, we show that it should be possible to keep the systematic uncertainties at the level of a few percent. We further find that this analysis would serve a role complementary to that played by looking for \(R\!\!\!\!/_{p}\) violating decays of the squarks.

In the beginning of this note we first outline the details of the production of the \(\mu^{+}\mu^{-}\) pairs at the LHC along with the discriminatory features of the various distributions we use. We present the result of a parton level calculation in this discussion. We then follow it up with the details of the maximum likelihood analysis technique used by us and present the results of the same at the parton level as well as at the level of fully generated events. We then give a discussion of various systematic uncertainties in the analysis. After this we briefly discuss the \(R_{p}\) violating branching ratios of the third generation squark. We show that for the squark mass range considered in this paper, a region in parameter space exists in which the \(\lambda^{\prime}_{231}\)coupling could in priciple be measured at 5% level at LHC at full luminosity. This demonstrates the above mentioned complementarity very nicely.

## 2 Drell-Yan in presence of \(R_{p}\) violation

The Drell-Yan process at a hadronic collider has, over the years, been studied at great detail. Its analysis has served as an excellent theoretical laboratory, first for the Quark Parton model and later for perturbative QCD. In fact, not only the NLO, but even the NNLO corrections have been computed [25]. In the context of the present analysis though, we shall limit ourselves only to leading order calculations. The reasons are manifold. For one, the NNLO calculations, within the SM, have demonstrated that a constant \(K\)-factor gives a very good description of the corrections over a very wide range of kinematic variables. Secondly, the radiative corrections in presence of non-SM physics, such as the case under study, have not yet been calculated. It might be argued though that since we are interested in probing typically small \(R_{p}\) couplings, a very precise calculation of the strong corrections to these additional contributions is not crucial. Instead, we might assume that the \(K\)-factor is essentially the same as in the SM. Clearly, this estimate is quite a reasonable one and is supported by the recent calculations [26] of \(K\)-factors for chargino or neutralino pair production which too receives \(t\)-channel contributions like in the present case. This assumption simplifies the analysis as the Born term is extremely simple to analyze.

A look at the superpotential (eq.1) tells us that it is only the \(\lambda^{\prime}_{ijk}\) couplings that can affect Drell-Yan production of a dilepton pair. Expressed in terms of the component fields, the relevant part of the Lagrangian reads

\[\begin{array}{c}{\cal L}_{\lambda^{\prime}}=\lambda^{\prime}_{ijk}\Big{[} \tilde{\nu}^{i}_{L}\bar{d}^{k}_{R}d^{j}_{L}+\tilde{d}^{j}_{L}\bar{d}^{k}_{R} \nu^{i}_{L}+(\tilde{d}^{k}_{R})^{*}(\tilde{\nu}^{i}_{L})^{c}d^{j}_{L}\\ -\tilde{e}^{i}_{L}\bar{d}^{k}_{R}u^{j}_{L}-\tilde{u}^{j}_{L}\bar{d}^{k}_{R}e^{ i}_{L}-(\tilde{d}^{k}_{R})^{*}(\tilde{e}^{i}_{L})^{c}u^{j}_{L}\,\Big{]}+h.c\end{array} \tag{1}\]

A non-zero \(\lambda^{\prime}_{2jk}\) would then lead to an additional \(u\)-channel (\(\tilde{d}^{k}_{R}\) exchange) diagram for the process \(\bar{u}_{j}u_{j}\rightarrow\mu^{-}\mu^{+}\) and a \(t\)-channel (\(\tilde{u}^{j}_{L}\) exchange) diagram for \(\bar{d}_{k}d_{k}\rightarrow\mu^{-}\mu^{+}\). Note that neither resonance production processes leading to the dimuon final state nor processes such as \(q_{i}\bar{q}_{j}\to e^{-}\mu^{+}\) can occur when only a single \(R_{p}\) coupling is nonzero, an assumption [27] that we shall work with.

The differential cross section is modified in a straightforward way and reads, in the center-of-mass of the \(\mu^{+}\mu^{-}\) system as

\[\frac{{\rm d}\hat{\sigma}}{{\rm d}\cos\theta}[q\bar{q}\rightarrow\mu^{-}\mu^{+}] = \frac{\pi\alpha^{2}\hat{s}}{24}\Big{\{}(1+\cos\theta)^{2}\left[|f^{ s}_{LR}|^{2}+|f^{s}_{RL}|^{2}\right]\] \[+(1-\cos\theta)^{2}\left[|f^{s}_{LL}|^{2}+|f^{s}_{RR}|^{2}\right] \Big{\}}\] \[f^{s}_{LR} = -\frac{Q^{q}}{\hat{s}}+\frac{g^{q}_{L}g^{e}_{L}}{\hat{s}-m_{Z}^{2 }+i\Gamma_{Z}m_{Z}}\] \[f^{s}_{RL} = -\frac{Q^{q}}{\hat{s}}+\frac{g^{q}_{R}g^{e}_{R}}{\hat{s}-m_{Z}^{2 }+i\Gamma_{Z}m_{Z}} \tag{2}\] \[f^{s}_{LL} = -\frac{Q^{q}}{\hat{s}}+\frac{g^{q}_{L}g^{e}_{R}}{\hat{s}-m_{Z}^{ 2}+i\Gamma_{Z}m_{Z}}-\frac{1}{2}\,\frac{(\lambda^{\prime}_{2jk}/e)^{2}}{\hat{u }-m_{\tilde{d}_{kR}}^{2}}\delta_{qu_{j}}\] \[f^{s}_{RR} = -\frac{Q^{q}}{\hat{s}}+\frac{g^{q}_{R}g^{e}_{L}}{\hat{s}-m_{Z}^{ 2}+i\Gamma_{Z}m_{Z}}+\frac{1}{2}\,\frac{(\lambda^{\prime}_{2jk}/e)^{2}}{\hat{t }-m_{\tilde{u}_{jL}}^{2}}\delta_{qd_{k}}\,\]

where \(Q^{f}\) represents the charge of the fermion \(f\) and \(g^{f}_{L,R}\) its couplings to the \(Z\). Clearly, the new contribution is relevant only if \(q=u,d\) or, in other words, only if at least one of \(j\) and \(k\) refer to the first generation. Of the nine \(I\!\!\!R_{p}\) couplings that could, in principle, contribute to dimuon production, we thus need to concern ourselves with only five. For a given strength of the coupling, the change wrought in the total cross section would depend on the mass of the squark(s) involved as well as on the particular subprocess that is being affected. In Fig.1, we present the relative deviation of the total cross section for a particular coupling viz. \(\lambda^{\prime}_{211}\), and different values of the squark masses (for the sake of convenience, we assume that \(\tilde{u}_{L}\) and \(\tilde{d}_{R}\) are degenerate). The lower cut on the dilepton invariant mass assumed for the calculation is 500 GeV. As far as the total cross section is concerned, the difference is only at the level of a few percent, even for moderately large values of the coupling. This however is somewhat misleading since the deviation from the Standard Model increases with the increase of the dilepton mass, and therefore the integral effect observed strongly depends on the lower limit on the dilepton mass taken for the calculation. The extra contributions manifest themselves more pronouncedly in the kinematic distributions, modifying them from those expected within the SM in three essential ways: (1) enhanced cross-section for high \(\ell^{+}\ell^{-}\) invariant mass, (2) different lepton angular distribution in the \(\ell^{+}\ell^{-}\) rest frame and (3) different boost distribution of the \(\ell^{+}\ell^{-}\) system. For a given point in the supersymmetric parameter space, these differences are demonstrated in Fig.2. The figure shows distributions in the invariant mass \(M\) of the dimuon pair, the difference in the rapidities of the two leptons \(\Delta\eta\) and the rapidity of the pair itself \(\eta_{pair}\). Clearly, the use of the differential distributions would result in an enhanced sensitivity as compared to just the event rate comparison of Fig.1. Note the substantial broadening of the distribution in \(M\). In fact, rather than limiting ourselves to a study of a distribution in one of the three independent variables listed above, it is conceivable that the use of the full kinematic information,taking into account the correlation of the kinematic variables would be even more powerful. In the next two sections we discuss how exactly we propose to do this, albeit with a slightly different choice of independent variables than mentioned above.

## 3 Maximum likelihood method

Our goal, then, is to exploit to the full, the differences in the kinematic distribution of the \(\mu^{+}\mu^{-}\) pair caused by the presence of the \(\not{\!\!\!R}_{p}\) interactions. Such a study is expected to yield to a measurement (or at least constraints) in the 2-dimensional supersymmetric parameter space, namely the mass-coupling plane. The problem of simultaneous determination of these two, _viz._, \(\lambda^{\prime}\) and \(m_{\tilde{q}}\), is the classical problem of parameter estimation. In view of the systematic uncertainties (experimental due to the luminosity and theoretical due to parton distributions, K-factors etc.) in the normalisation of the signal, it is best to use the maximum likelihood method which does not require a precise knowledge of the absolute size of the signal but only that of its shape.

As Fig.2 shows, the fall-off in the invariant mass distribution is indeed substantially slower for the \(R_{p}\) violating (RPV) contribution. For the other distributions

Figure 1: Relative change of the dimuon cross-section at the LHC as function of the coupling \(\lambda^{\prime}_{211}\). The assumed lower limit on the dilepton invariant mass is 500 GeV. The curves correspond to four different squark masses: 300, 500, 700 and 900 GeV respectively.

too, the difference is quite discernible. However, instead of using the variables of Fig.2, we choose to work with an equivalent (independent) set, namely the momentum fractions \(x_{1}\) and \(x_{2}\) of the initial state partons and the cosine of the angle of scattering \(\cos\theta\). Neglecting the transverse momentum of the \(\mu^{+}\mu^{-}\) system, the event kinematics for a given event \(i\) is completely specified by these three variables. The log likelihood function is defined as:

\[\ln{\cal L}=\sum_{i=1}^{N_{\rm ev}}\ln F(\lambda^{\prime},m_{\tilde{q}},x_{1}^{i },x_{2}^{i},\cos\theta^{i})\, \tag{10}\]

with \(F\) given by:

\[F=\frac{1}{\sigma(\lambda^{\prime},m_{\tilde{q}})}\ \frac{d\sigma}{dx_{1}dx_{2}d \cos\theta}(\lambda^{\prime},m_{\tilde{q}},x_{1}^{i},x_{2}^{i},\cos\theta^{i}) \tag{11}\]

The cross-section \(\sigma(\lambda^{\prime},m_{\tilde{q}})\) in the denominator is the one obtained _after_ imposing all the analysis cuts. These cuts are of course chosen so as to maximise the RPV contribution in the signal. The best estimate of the true values of the two parameters is then given by the particular pair \((\lambda^{\prime},m_{\tilde{q}})\) that maximizes \(log{\cal L}\) for a given data sample. In addition to the advantage which accrues due to the use of only the shape of distributions as mentioned above, this method also has the good features of not requiring any binning as well as exploiting the correlations among different variables optimally. We note here that the objective of avoiding the systematic (both theoretical and experimental) errors due to the imprecision in the knowledge of the absolute size of the signal, could, in principle, also be achieved by comparing the size

Figure 2: The phase space distributions for the Drell-Yan process at the LHC. We have demanded that the \(\mu^{\pm}\) must have a minimum transverse momentum of 50 GeV each and be within the pseudorapidity range \(-3<\eta<3\). For the rapidity distributions, an additional cut (\(M>500\,{\rm GeV}\)) has been imposed. In each case, the lower curve corresponds to the SM and the upper curve to \(\lambda^{\prime}_{211}=0.5\), \(m_{\tilde{q}}=800\,{\rm GeV}\).

of the dimuon signal with the dielectron one. However, the latter method presupposes that no unknown physics effects exist in the dielectron mass spectrum and hence is not completely model-independent. Furthermore, the comparison of two different spectra involves the compounding of errors thereby affecting the accuracy adversely.

## 4 Data Analysis

For our analysis of the simulated data, we first generate events corresponding to an integrated luminosity of 100 \(\mbox{fb}^{-1}\) which corresponds to an year of the LHC operating in its high luminosity mode. The evaluation of the achievable sensitivity in the \(\lambda^{\prime}\) measurement requires the generation of many times the statistics expected for a single experiment, for a fine grid on \(\lambda^{\prime}\) for a few values of \(m_{\tilde{q}}\). The parton level generation of unit weight events without initial state QCD showering is about ten times faster than the generation of full PYTHIA [28] events followed by the fast detector simulation for the ATLAS detector [29]. We will therefore first evaluate the statistical sensitivity of the experiment at parton level. The results thus obtained will then be compared to the same procedure applied to fully generated events for a few selected points in parameter space, in order to evaluate the effect of the experimental smearing and of the introduction of initial state QCD radiation on the experimental sensitivity.

We select events with two isolated opposite sign muons, satisfying the following two requirements: 1) \(P_{T}^{\mu}>10\) GeV, \(|\eta_{\mu}|<2.5\) and 2) \(m_{\mu^{+}\mu^{-}}>500\) GeV. The first criterion essentially ensures that the muons are visible in the detector. The invariant mass cut, on the other hand, is motivated by the observation that the relative deviation of the cross section starts to become significant only at \(m_{\mu^{+}\mu^{-}}\sim m_{\tilde{q}}\)[21]. The optimal choice of the cut, however, is determined not only by the squark mass but also by the total number of events (in other words, the luminosity). However, rather than working with a squark mass-dependent cut, we choose to adopt the simpler strategy of a fixed choice for the invariant mass cut. Approximately 7500 events events survive these cuts for our choice of luminosity.

As is clear from the definition of the likelihood function, it is necessary to know the kinematics of the event completely to calculate it. However, it must be borne in mind that, in a \(pp\) collider such as the LHC, it is not possible to know for certain the initial direction of the quark (in the \(\bar{q}q\) hard scattering subprocess). Hence, only the absolute value of \(\cos\theta\) is measurable, but not the sign. Part of this information can, however, be recovered, by using the knowledge of \(x_{1}\) and \(x_{2}\) and the fact that, in the proton, the \(x\) distribution for valence quarks is harder than for anti-quarks. Arbitrarily labeling the proton beams "1" and "2", the difference \(x_{1}-x_{2}\) can be inferred from the longitudinal momentum of the dimuon pair.

In Figure 3 we show the distribution of \(x_{1}-x_{2}\), in case the quark is picked up from the proton labeled "1" (left plot) or "2" (right plot). It can be clearly seen that n most cases the quark is picked from the side with higher \(x\). To make use of this information, the likelihood is built by summing the functions \(F\) calculated for both signs of \(\cos\theta\), weighted by the probability, for the given (\(x_{1}\), \(x_{2}\)) combination that the quark is in proton "1" or "2".

### Parton level analysis

For the sensitivity study, we generated a grid of points with different values of \(\lambda^{\prime}\) for four different values of the squark mass ranging from 300 to 900 GeV. For each point, \(5\times 10^{5}\) events with unit weight were generated. The likelihood was calculated in steps of \(\lambda^{\prime 2}\) for \(-0.05\leq\lambda^{\prime 2}\leq 0.2\). The inclusion of the unphysical range is necessary for the evaluation of the confidence interval. If the likelihood function has a local maximum for a positive (physical) \(\lambda^{\prime 2}\), we take this value as _a measurement_. Otherwise, we take the absolute maximum, even though it is in the unphysical (negative) region. The cross section being a quadratic function of \(\lambda^{\prime 2}\), a secondary maximum may appear, and often for negative \(\lambda^{\prime 2}\). In fact, even for \(\lambda^{\prime 2}\) values large enough for the experiment to be sensitive to squark exchange, a small fraction of the Monte Carlo experiments can show up the unphysical maximum to be higher than the physical one. This feature is illustrated Fig. 4, where we display the likelihood as a function of \(\lambda^{\prime 2}_{211}\) for four experiments assuming \(m_{\tilde{q}}=500\) GeV. The upper plots are for \(\lambda^{\prime}_{211}=0.15\) which is below the experimental sensitivity for this particular squark mass. In this case, even when the physical maximum is found, the dip between the two maxima is shallow (\(1\sigma\sim\Delta\ln{\cal L}=0.5\)), and very often the absolute maximum occurs at a negative \(\lambda^{\prime 2}\). The lower plots are for \(\lambda^{\prime}_{211}=0.2\). The two maxima are now always well separated; the rare cases when the absolute maximum is in the unphysical region

Figure 3: _Difference \(x_{1}-x_{2}\) when the quark is picked up from the proton labeled “1” (left plot) or “2” (right plot)._

correspond to experiments for which the positive maximum is somewhat displaced from the nominal value.

In order to evaluate the uncertainty on the \(\lambda^{\prime}\) measurement, we generated \(\sim\) 1500 Monte Carlo experiment for an integrated luminosity of 100 fb\({}^{-1}\) and for each of them we calculated the maximum of the likelihood function according to the above prescription. Since the generated statistics is only \(\sim\)70 times the statistics for a single experiment, each of the Monte Carlo experiments was produced by randomly picking inside the available statistics the \(\sim\)7500 events corresponding to one year of running. With this procedure each event is used for \(\sim\)25 Monte Carlo experiments.

A common behaviour is observed for all of the four squark masses considered. For values of \(\lambda^{\prime 2}\) approximately up to the minimum in the cross-section shown in Fig.1, the distribution of the measured maxima is very broad, and extends up to a

Figure 4: Shape of the log likelihood function as a function of \(\lambda^{\prime 2}_{211}\) for four different Monte Carlo experiments. The generated value of \(\lambda^{\prime}_{211}\), shown as a vertical line, is 0.15 for the upper plots, and 0.2 for the lower plots. The assumed squark mass is \(m_{\tilde{q}}=500\) GeV. The integrated luminosity is 100 fb\({}^{-1}\).

fixed \(\lambda^{\prime 2}\) value, which depends on the mass. The distribution of measured \(\lambda^{\prime 2}\) becomes gaussian only for \(\lambda^{\prime 2}\) values above that value. This means that the experiments start being sensitive to the effect somewhere in this transition region. Fig. 5 shows the results for \(m_{\tilde{q}}=300\) and 700 GeV.

Figure 5: _Distribution of the \(\lambda^{\prime 2}_{211}\) value estimated through the maximisation of the likelihood function for a set of \(\sim\)1500 Monte Carlo experiments. The upper (lower) set corresponds to a squark mass of 300 (700) GeV. For each case, we show the distributions for three generated values of \(\lambda^{\prime}\): 0 (dashed line), a value below the experimental sensitivity for the assumed squark mass and integrated luminosity (left plot, full line), and a value for which a good \(\lambda\) measurement is achievable (right plot). The integrated luminosity is 100 fb\({}^{-1}\)._

### Evaluation of experimental sensitivity

We follow here the frequentist approach of [30], where the sensitivity of an experiment is defined as: "the average upper limit that would be obtained by an ensemble of experiments with the expected background and no true signal". For each considered value of the squark mass, we build, therefore the confidence belt according to the Neyman construction. We adopt as the auxiliary choice for the definition of the belt the one leading to "upper confidence intervals", defined by Equation 2.5 in [30]. For an ensemble of experiments with \(\lambda=0\) we then calculated the upper limit using the confidence belt thus built,and we took the average. The results are shown on the \((m_{\tilde{q}}-\lambda^{\prime})\) plane in Fig. 6, together with the region corresponding to the bounds on \(\lambda^{\prime}_{211}\) from low energy processes.

If no signal is present in the data, the result of the experiment will be the exclusion of the region in the \((m_{\tilde{q}}-\lambda^{\prime})\) above the curve labeled '95% exclusion'. If a signal is present, the experiments will be able to extract a measurement of the \(\lambda^{\prime}\) couplings. The assessment of the precision of this

Figure 6: 95% sensitivity region in the \(m_{\tilde{q}}-\lambda^{\prime}\) plane for an integrated luminosity of 100 pb\({}^{-1}\). The dashed line corresponds to the choice of the central interval in the Neyman construction. The analysis is performed at parton level. The contours corresponding to an uncertainty on \(\lambda^{\prime}\) of 2, 5 and 10% (under the assumption of perfectly known squark mass) are also shown. The shaded region on the left is excluded by low energy measurements.

measurement depends on the available information on \(m_{\tilde{q}}\), and on the dependence of the measured value of \(\lambda^{\prime}\) on the assumed squark mass. As a first, unrealistic, approximation we show in Figure 6 the curves in the \((m_{\tilde{q}}-\lambda^{\prime})\) plane corresponding to a statistical uncertainty on \(\lambda^{\prime}\) respectively of 2, 5 and 10%, if no error is assumed on the squark mass.

It is interesting to consider the dependence of the error estimate on the available prior information on the squark mass. Consider the pair-production of the said squark at the LHC. For the range of values of the \(\lambda^{\prime}\) couplings addressed in this paper, every supersymmetric event will contain two \(\tilde{\chi}_{1}^{0}\) decaying into two jets and a muon

Figure 7: Fractional deviation of the measured \(\lambda^{\prime}\) value from the true one as a function of \(\lambda^{\prime}\) for three values of the squark mass used in the likelihood calculation: the nominal one (dots), reduced by 3% (squares), augmented by 3% (triangles). The four plot are respectively for the four squark masses considered in the analysis \(m_{\tilde{q}}=300,500,700\) and 900 GeV

or a muon neutrino. Detailed studies have shown that in the ATLAS experiment it will be possible to reconstruct the \(\tilde{\chi}^{0}_{1}\) peak from its decay products, and, going up the decay chain to reconstruct the squark masses [31]. The statistical precision of the mass measurement is essentially a function of the squark mass, and for squark masses below \(\sim 1\) TeV, the error on the mass will be dominated by the systematic uncertainty on the reconstruction of the parton energy from the jet energy measurement. Such uncertainty is estimated to be approximately 3% in ATLAS [32]. Therefore, in the sensitivity region we have performed the \(\lambda^{\prime}\) measurement for values of the squark mass displaced upwards and downwards by 3% with respect to the nominal mass. The results are shown in Figure 7 for the four mass values considered in the analysis. The correlation between the \(\lambda^{\prime}\) and \(m_{\tilde{q}}\) measurement is positive, therefore a higher value of \(m_{\tilde{q}}\) in input yields a higher \(\lambda^{\prime}\) measurement. For the assumed value of the uncertainty on \(m_{\tilde{q}}\), the additional uncertainty on \(\lambda^{\prime}\) from this effect is of order 2-3% for all considered mass values. One can also observe from Figure 7 that when the nominal mass value is used, the bias on \(\lambda^{\prime}\) from the likelihood fit is less than 1%.

Finally, we consider the combined precision, in the measurement of \(m_{\tilde{q}}\) and \(\lambda^{\prime}\), that may be achieved if a two-dimensional likelihood is used, and no prior information on the squark mass is assumed. We have performed this study for a few sample points, and the results are shown, in Figure 8, as one-sigma ellipses in the (\(m_{\tilde{q}}-\lambda^{\prime}\)) plane, calculated on a sample of \(\sim\)500 Monte Carlo experiments. The resolution in mass is of order few tens of GeV, and quickly degrades when one gets near to the edge of the sensitivity region. Given the correlation between \(\lambda^{\prime}\) and \(m_{\tilde{q}}\) measurement, the \(\lambda^{\prime}\) measurement is degraded accordingly. This statement is better quantified in Table 1 where we give the parameters of the ellipses corresponding to \(log({\cal L}_{max})-1/2\) for

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|} \hline \(m_{\tilde{q}}\) (GeV) & \(\lambda^{\prime}\) & \(\sigma(\lambda^{\prime})(1)\) & \(\sigma(\lambda^{\prime})(2)\) & \(\sigma(m_{\tilde{q}})\) (GeV) & \(\rho\) \\ \hline
300 & 0.175 & 0.005 & 0.014 & 43 & 0.913 \\
500 & 0.200 & 0.010 & 0.027 & 114 & 0.947 \\
500 & 0.250 & 0.007 & 0.020 & 63 & 0.948 \\
500 & 0.275 & 0.006 & 0.017 & 46 & 0.951 \\
500 & 0.300 & 0.005 & 0.014 & 38 & 0.949 \\
700 & 0.250 & 0.013 & 0.036 & 148 & 0.859 \\
700 & 0.300 & 0.009 & 0.028 & 98 & 0.951 \\
700 & 0.350 & 0.007 & 0.020 & 56 & 0.954 \\
700 & 0.400 & 0.005 & 0.016 & 40 & 0.964 \\ \hline \end{tabular}
\end{table}
Table 1: _Statistical errors on the \(\lambda^{\prime}\) measurement for a few sample points. The value in third column (\(\sigma(\lambda^{\prime})\)(1)) is the uncertainty assuming the squark mass known is with zero error. The last three columns give the parameters of the 1-\(\sigma\) ellipses for the two-dimensional likelihood on (\(m_{\tilde{q}}-\lambda^{\prime}\)), where \(\rho\) is the correlation coefficient for \(m_{\tilde{q}}\) and \(\lambda^{\prime}\)._the studied points, compared to the resolution on \(\lambda^{\prime}\) if the squark mass is known. In particular, the \(\rho\) parameter, which measures the correlation of the two variables is \(\sim\)1, meaning fully correlated variables. Thus, a combined measurement of squark mass and \(\lambda^{\prime}\) is possible with this analysis for a significant fraction of the parameter space.

## 5 Analysis of fully generated events

The analysis in the previous section was performed assuming that the momentum of the \(\mu^{+}\mu^{-}\) system has no component transverse to the beam axis, and that the muon momenta are perfectly measured in the detector.

In order to perform a more realistic evaluation of the precision on \(\lambda^{\prime}\) achievable in a real experiment, the matrix elements for the squark exchange process have been inserted into the PYTHIA [28] event generator as an external process, and full events

Figure 8: _1-\(\sigma\) ellipses for the measurement of \(\lambda^{\prime}\) and \(m_{\tilde{q}}\) if no previous information on \(m_{\tilde{q}}\) is assumed for different points in the \(m_{\tilde{q}}-\lambda^{\prime}\) plane and an integrated luminosity of 100 pb\({}^{-1}\). The full and dashed lines correspond to the 95% exclusion region. The analysis is performed at parton level. The shaded region on the left is excluded by low energy measurements._

have been generated, including the full PYTHIA machinery for QCD showering from the initial state quarks, and for the hadronisation. The events thus generated have been passed through the fast simulation of the ATLAS detector [29], including in particular a very detailed parametrisation of the resolution of the muon momentum measurement.

The values of \(x_{1}\), \(x_{2}\) have been evaluated from the four-momenta of the detected muons, according to the formulas:

\[\frac{2\;P_{L}^{\mu^{+}\mu^{-}}}{\sqrt{s}}\,=\,x_{1}\,-\,x_{2},\;\;\;m_{\mu^{+ }\mu^{-}}^{2}=x_{1}x_{2}s\]

For the evaluation of \(\cos\theta\) we use the Collins-Soper convention [33], consisting in the equal sharing of the \(\mu^{+}\mu^{-}\) system transverse momentum between the two quarks.

We show in Figure 9, the two-dimensional correlation between the generated and the reconstructed values for the variable \(x_{1}\) as well as their ratio. Only events which pass the analysis criteria enter these plots. For \(x_{1}\), the \(RMS\) deviation is \(\sim 10\%\), and is completely determined by the muon momentum resolution. A comparable resolution is obtained for \(|\cos\theta|\) (Fig.10), but with significant tails due to the presence of a non-zero transverse momentum of the \(\mu^{+}\mu^{-}\) system.

Samples of events were generated for four squark masses, 300, 500, 700 and 900 GeV, and for three values of \(\lambda^{\prime}\) for each mass, chosen in each case in an interval

Figure 9: _Left plot: correlation of the reconstructed value of \(\log(x_{1})\) with the generated value for a sample of events passing the analysis requirements. Right plot: distribution of the ratio of the reconstructed and generated value of \(x_{1}\). The distributions are given for a sample of events passing the analysis cuts._

[MISSING_PAGE_EMPTY:18]

leading order formulas in Eq. 2.2 without any attempt at parametrising the \(\mu^{+}\mu^{-}\) transverse momentum distribution.

In the analysis of real data, we also need to consider the backgrounds from non Drell-Yan processes. The dominant background processes for the invariant mass cut applied in this analysis will be \(\bar{b}b\), \(\bar{t}t\), and \(WW\) production. For \(\bar{b}b\) production the muons are not isolated, and we can apply lepton isolation which consists in requiring an energy deposition of less than 10 GeV not associated with the lepton in a pseudorapidity-azimuth (\(\eta-\phi\)) cone of opening \(\Delta R=0.2\) around the lepton direction.

Without any additional cuts, for an integrated luminosity of 100 fb\({}^{-1}\), the back

Figure 11: Distributions of measured \(\lambda^{\prime 2}\) for a set of Monte Carlo experiments for different generated values of \(\lambda^{\prime}\). The full line histograms are the parton-level distributions while the dashed histograms correspond to fully generated events.

grounds from \(\bar{t}t\) and \(WW\) amount to \(\sim 1400\) and \(\sim 500\) events respectively, for a signal of \(\sim 7400\) events. The \(\bar{t}t\) background can be strongly reduced by vetoing \(b\)-jets. We assume a tagging efficiency of 50% for a rejection factor of respectively 100 (10) on light quark (charm) jets, appropriate for high luminosity running, and we veto jets tagged as \(b\)-jets with \(P_{T}>30\) GeV. The \(\bar{t}t\) background is thus reduced to \(\sim 600\) events, with negligible effect on the signal. Both for the \(\bar{t}t\) and \(WW\) backgrounds, the events will have real \(E_{T}^{miss}\) from escaping neutrinos, and further reduction can be achieved by vetoing on high \(E_{T}^{miss}\) events. This requirement, though, has a significant effect on the kinematics of signal events. In fact we are considering here high energy muons, for which the error in momentum measurement induces an instrumental imbalance in the vector sum of the lepton momenta which grows with increasing momentum. Therefore the acceptance of any kinematic cut applied must be convoluted in the test function used for the likelihood in order to obtain the correct result. A complementary approach consists in accepting the relatively high level of background, and incorporating the background shape into the likelihood function. This should be possible with high precision, since the considered

Figure 12: _Curves of \(\sigma(\lambda)/\lambda^{\prime}\) as a function of \(\lambda^{\prime}\) for an integrated luminosity of 100 fb\({}^{-1}\) and for four different squark masses. The full lines give the resolution obtained at parton level, and the points the results of the full event simulation._

backgrounds yield an equal number of \(e\mu\) events as \(\mu\mu\) events, allowing to estimate the background level from the data themselves. The two approaches have different systematic uncertainties, and can be used in parallel thus providing a double check on the result.

## 6 Systematic uncertainties

In the previous section, we have studied in detail the main sources of experimental uncertainty, coming from the imperfect measurement of the event variables. Other possible sources of experimental error are the uncertainties in the muon energy scale, the linearity for high energy muons and the acceptance evaluation. The assessment of the effect of these uncertainties would require a detailed detector simulation which is outside the scope of this work. We should however remark that the analysis described in the previous section displays little sensitivity to the details of the modelling of the experimental resolution and acceptance. In fact, in building the likelihood, the crucial factor is the normalisation integral at the denominator of Eq. 1. That integral is calculated with a sharp cut on the generated lepton pseudorapidity and invariant mass for events with no \(P_{T}^{\mu^{+}\mu^{-}}\). The data selection for the particle level analysis is instead applied on leptons which have been smeared according to the detector resolution, and therefore the acceptance of the cuts, especially the one on \(m_{\mu^{+}\mu^{-}}\) edges, is reproduced in a very approximate way. Notwithstanding this fact, we observe a good agreement between the parton level analysis and the particle level one. This gives us confidence that the additional experimental uncertainty on \(\lambda^{\prime}\) measurement resolution would, at worst, only marginally affect the results of our analysis. More important would be the effect of a non-linearity in the lepton energy measurement which could simulate a deviation from the invariant mass distribution predicted for the Standard Model. A control on the linearity at the percent level will be needed for this analysis.

We also need to consider the theoretical uncertainties in the likelihood calculation. The likelihood function is built by weighting real events according to a theoretical cross-section formula. Any discrepancy between the theoretical formula employed and reality will induce an uncertainty on the measurement of \(\lambda^{\prime}\). Two main sources of uncertainty can be identified: 1)the presence of higher order correction to the processes and 2) the parton distribution function (PDF) for the proton. We consider here the most important QCD higher-order corrections coming from radiation from initial state quarks, which impart a transverse momentum to the lepton-lepton system. From the above discussion of the analysis, it is clear that the results show very little sensitivity to the detailed modelling of the transverse momentum distribution of the dilepton system. In fact, event for the fully generated events the likelihood was built from the pure leading order formulas, whereas the events are generated with the full PYTHIA machinery for initial state radiation. Therefore, the experimental error quoted in the previous section implicitly includes very pessimistic assumptions on our ability to model this effect. In a real experiment a more realistic theoretical modelling will probably be used to build the likelihood. The second source of uncertainty is more important, since it will affect the shapes of the distribution. All the events were generated with the CTEQ4L PDF set. We have evaluated the effect of an uncertainty on PDF parametrisation by performing the likelihood using different sets of PDF's than the ones used for event generation. We chose the PDF's labeled as CTEQ4A1 and CTEQ4A5, which span an extreme range between 213 and 399 MeV for the QCD parameter \(\Lambda^{[4]}\). The value of \(\Lambda^{[4]}\) for the set CTEQ4L is 236 MeV.

We show in Figure 13 the fractional deviation of the measured \(\lambda^{\prime}\) from the true one for the default structure functions (CTEQ4L) as well as for two other possible choices. The deviation for CTEQA1 is small, as expected from the small difference in \(\Lambda^{[4]}\). For the set CTEQA5 the fractional difference is approximately 10% for the lowest values of \(\lambda^{\prime}\) considered, and decreases with increasing \(\lambda^{\prime}\) to a few percent. We can tentatively conclude that the uncertainty on the measurement coming from the choice of PDF's will be at the few percent level, comparable to the statistical one.

## 7 Effect of the \(\not\!\!R_{p}\) couplings on the decays of the squarks

The above discussion establishes that the dimuon production at the LHC has enough sensitivity to \(\not\!\!R_{p}\) couplings to admit their measurement with a fair accuracy. Our analysis shows that a \(\not\!\!R_{p}\) coupling of the order of the gauge coupling can be measured quite accurately even for rather large squark masses; up to \(700-900\) GeV. Clearly, squarks, in this mass range have substantial production cross-section at the LHC. So this naturally brings us to the question whether one could detect or even measure such couplings in the decays of these squarks. A discussion of this issue is clearer if we review a few facts about the possibilites of measuring the \(\not\!\!R_{p}\) couplings in collider experiments in general. These are of course, strongly dependent on the value of the \(\not\!\!R_{p}\) coupling being probed. In the worst case, scenario it may be so small that the only effect it has is to cause the decay of the LSP and that too outside the detector, so that it is mistaken for a stable non-interacting particle. In this situation we will miss the phenomenon of R-parity violation at the colliders altogether. For intermediate values of these couplings, one will get to a region where a significant fraction of the LSP's will decay inside the inner cavity of the LHC detector and in that case one might be able to measure the strength of these couplings by detecting the displaced vertexes inside the detector. To the best of our knowledge, a detailed experimental study to map the parameter space in this case is not available currently. Then comes the range of couplings which are large enough to cause a prompt decay of the LSP giving rise to striking final states but are not large enough to cause single sparticle production or decay of sparticles other than the LSP. In this range of values the distinctive final states caused by the decay of the LSP due to the \(\not\!\!R_{p}\) couplings can provide evidence for the existence of \(R\!\!\!/_{p}\) but can not give any information whatsoever on their size. Then comes the region of the larger \(R\!\!\!/_{p}\) couplings that we have considered, where one is sensitive to the effects of these couplings via virtual exchanges of sparticles on scattering processes as well as decays of sparticles other than the LSP, caused by them. We have demonstrated in the above work, the feasibility of'measuring' the \(R\!\!\!/_{p}\) coupling through the contribution of virtual squark exchanges to the dimuon production. As the only input required for this is the squark mass, with an adequate control of the experimental and theoretical systematic uncertainness of the \(\lambda^{\prime}\) value.

Figure 13: _Fractional deviation of the measured \(\lambda^{\prime}\) value from the true one as a function of \(\lambda^{\prime}\) for three different choices of structure functions in the calculation of the likelihood. The events were generated with CTEQ4L. The upper plot is for \(m_{\tilde{q}}=500\) GeV, the lower one for \(m_{\tilde{q}}=700\) GeV_

ties, this offers perhaps the cleanest way of measuring the \(R\!\!\!/_{p}\) couplings. As already mentioned, for the values of the squark masses under consideration, their production cross-sections at the LHC are substantial. Hence the effect of the \(R\!\!\!/_{p}\) couplings on the decays of the squark produced via the strong interactions, needs to be studied. A particularly attractive case will be when the \(R\!\!\!/_{p}\) decay of the squark competes with an \(R_{p}\) conserving decay with an identifiable signature. A comparison of the two then can give a direct measurement of the \(R\!\!\!/_{p}\) coupling. A promising example for the couplings we have considered is \(R\!\!\!/_{p}\) decay \(\tilde{t}\to\mu+\) jet. To study this issue, we will need to consider both the total production cross sections as well as the branching fractions into the various channels.

Squark pair production has been analysed at length in various papers and depends crucially on the gluino mass. For our purpose though, these findings can be crudely summarised to the result that "for any squark lighter than approximately 800 GeV, pair production cross section at the LHC is large enough to lead to discovery". For the most part, the reach in mass and possibility of discovery, will be independent of whether \(R\)-parity is violated or not. The measurement of the relevant coupling, or even the establishment of its identity, would, however require that at least two channels be measurable with a relatively high degree of accuracy. One of these should be a \(R\)-parity violating one, while the other should be a \(R\)-conserving one. For stop squarks, the presence of leptons and \(b\)-jets in the final state provide a handle for the identification of the exclusive decays of interest. The relevant \(R\)-conserving decay channels are \(\tilde{q}\to q\tilde{g},q\tilde{\chi}^{0}_{j},q^{\prime}\tilde{\chi}^{\pm}_{j },\tilde{q^{\prime}}W\). Each of these channels could lead to a cascade process culminating in a \(R\!\!\!/_{p}\) decay. We are, however, concerned with the \(R\!\!\!/_{p}\) decay of the original squark. In Fig. 14, we display constant \(R\!\!\!/_{p}\)-branching fraction contours for the decay of a 300 GeV stop. The assumed value of \(\lambda^{\prime}_{231}\) is the least that would permit a detection with a statistical accuracy of 5%, if the analysis efficiency the dilution from surviving backgrounds are disregarded. We see, that barring very light charginos, the \(R\!\!\!/_{p}\) mode tends to dominate. An overwhelming \(R\!\!\!/_{p}\) branching fraction, while leading to spectacular signals, is hardly amenable to precision measurement of the coupling. Similar arguments hold for a very small \(R\!\!\!/_{p}\) branching fraction. The best hope is therefore for moderate values of \(M_{2}\) and \(\mu\). It is thus clear that, at the level of branching ratios, stop decays would provide a sufficient number of events for the measurement of the \(R\!\!\!/_{p}\) coupling over a significant parameter space. A detailed experimental analysis, outside the scope of this work, is however needed to ascertain whether it will be possible to isolate the final states produced by the two relevant processes, with adequate efficiency, and with a level of purity which would permit a reasonably accurate determination of the relevant branching fractions.

## 8 Conclusions

To summarise, we demonstrate that an analysis of the Drell-Yan process at the LHCdetectors would be a significant tool in the task of probing the parameter space in a \(R_{p}\)-violating supersymmetric model. While the deviation in the total cross section is at best a few per cent even for large values of the relevant \(R_{p}\)-violating coupling constant, the differential distributions are much more discriminating, the distribution in the dilepton invariant mass proving particularly useful. By adopting the maximum likelihood method we could maximise the sensitivity of the measurement, avoiding at the same time the normalisation uncertainties due to structure functions as well as higher order corrections etc.

Working, for definiteness, with dimuon production in the ATLAS detector, we showed that, for a wide range of the parameter space, \(R_{p}\) violating supersymmetry would be amenable to discovery through this process. Even more importantly, a measurement of the squark mass as well as the \(\not{R}_{p}\)-coupling would be possible with relatively low errors: 2-3% for the coupling and somewhat larger for the mass. These errors could be reduced even further if additional information about the squark mass were to become available from other measurements. We found the systematic errors

Figure 14: Contours for branching fraction of a \(300\:\mathrm{GeV}\) stop (\(\tilde{t}_{L}\)) into the \(R\)-parity violating channel. The unification relation between \(M_{1}\) and \(M_{2}\) has been assumed while the gluino is assumed to be heavier than the stop. The value of the \(R\)-violating coupling (\(\lambda_{231}^{\prime}=0.16\)) is that necessary for a determination accuracy of 5% (see Fig.6). The left and right panels correspond to two different values of \(\tan\beta\).

to be small. The analysis proved to be quite robust and the results gleaned from fully generated events were very similar to those obtained from a parton-level study. Since for the range of squark masses to which our investigation is sensitive, they can be pair produced copiously at the LHC, we also further looked into the possibility of determining _the same_\(R_{p}\) coupling, through its decays.

Finally, let us add that even though we have confined ourselves to dimuon production in a particular theory (namely \(R_{p}\)-violating supersymmetry), a similar analysis could carried out for dielectron production equally well. In general such an analysis can be used to study effects of any alternate theories of physics beyond the SM which affect effect the Drell-Yan process. Our analysis demonstrates that such studies would complement very well the more direct methods for new particle search.

## Acknowledgments

This work was initiated during a workshop held in Les Houches. We warmly thank Patrick Aurenche and all of the organising team for the stimulating program, the excellent atmosphere and the outstanding computing facilities. We thank the ATLAS collaboration members for useful discussion. We have made use of the physics analysis framework and tools which are the result of collaboration-wide efforts. DC thanks the Deptt. of Science and Technology, India for financial assistance under the Swarnajayanti Fellowship grant.

## References

* [1] P. Fayet, Phys. Lett. **B69** (1977) 489.
* [2] G. R. Farrar and P. Fayet, Phys. Lett. **B76** (1978) 575.
* [3] L. E. Ibanez and G. G. Ross, Nucl. Phys. **B368** (1992) 3.
* [4] B. C. Allanach and A. Dedes, JHEP **0006** (2000) 017 [arXiv:hep-ph/0003222].
* [5] H. Dreiner and G. G. Ross, Nucl. Phys. B **410**, 188 (1993) [arXiv:hep-ph/9207221].
* [6] T. Affolder _et al._, Phys. Rev. Lett. **88** 041801-1, (2002).
* [7] B. C. Allanach, A. Dedes and H. K. Dreiner, Phys. Rev. D **60** (1999) 075014 [hep-ph/9906209]; B. Abbott _et al._(D0 Collab.), hep-ex/9907019, _Phys. Rev. Lett._**83** (4476) 1999; D. Choudhury and S. Raychaudhuri, _Phys. Rev._**D 56** (1778) 1997; F. Abe _et al._(CDF Collab.), _Phys. Rev. Lett._**83** (2133) 1999.
* [8] D. Choudhury and S. Raychaudhuri, _Phys. Lett._**B 401** (54) 1997; G. Altarelli, _et al._, Nucl. Phys. **B506** (1997) 3; H. Dreiner and P. Morawitz, Nucl. Phys. **B503** (1997) 55; J. Kalinowski, _et al._, Z. Phys. C**74** (1997) 595; T. Kon and T.