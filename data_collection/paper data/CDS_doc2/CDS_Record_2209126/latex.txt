Expected sensitivity of ATLAS to FCNC top quark decays \(t\)\(\rightarrow\)\(Zq\) and \(t\)\(\rightarrow\)\(Hq\) at the High Luminosity LHC

The ATLAS Collaboration

###### Abstract

The expected sensitivity of the upgraded ATLAS experiment at HL-LHC to the flavour changing neutral current (FCNC) top quark decays \(t\)\(\rightarrow\)\(Zq\) and \(t\)\(\rightarrow\)\(Hq\) is estimated for an integrated luminosity of 3000 fb\({}^{-1}\) at a centre-of-mass energy of \(14\)\(\mathrm{\,Te\kern-1.0ptV}\). The analysis is based on \(t\bar{t}\) events produced in proton-proton collisions in which one top quark decays to \(W(\rightarrow\ell\nu)b\) final states, while the other top quark decays to \(Z(\rightarrow\ell\ell)u/c\) or \(H(\rightarrow\)\(b\bar{b})u/c\) final states via FCNC interactions. Three different ATLAS detector upgrade scenarios are considered in this study. For the most optimistic upgrade scenario the expected statistics-only limits on the FCNC top quark branching ratios are found to be in the ranges \((2.4-5.8)\cdot 10^{-5}\) for the \(t\)\(\rightarrow\)\(Zq\) and \((0.6-1.2)\cdot 10^{-4}\) for the \(t\)\(\rightarrow\)\(Hq\) channels, respectively, at the 95% confidence level, depending on the FCNC modelling. When systematic uncertainties are also considered, the sensitivity decreases to \((8.3-41)\cdot 10^{-5}\) and \((1.1-2.4)\cdot 10^{-4}\), respectively, depending on the detailed assumptions.

The ATLAS Collaboration

## 1 Introduction

This note presents a study of the sensitivity of the upgraded ATLAS detector at HL-LHC to observe flavour-changing neutral currents (FCNC) in top-quark decays. Top-quark decays to neutral bosons and up-type quarks are strongly suppressed in the Standard Model due to the GIM [1] mechanism, but could be significantly enhanced if new physics is present. At the LHC the decay \(t{\rightarrow}Zq\) has been searched for in \(t\bar{t}\) events with 7 [2, 3] and 8 TeV [4, 5] collision data in final states with three leptons, obtaining an upper limit of \(\mathcal{B}(t{\rightarrow}Zq)<50\cdot 10^{-5}\) at 95% C.L.. Shortly after their first searches with data, both ATLAS and CMS studied the sensitivity to FCNC \(t{\rightarrow}Zq\) decays for the HL-LHC, extrapolating the results of Ref. [2] and in a dedicated analysis, respectively, predicting a sensitivity of \(10\cdot 10^{-5}\)[6, 7].

Also \(t{\rightarrow}Hq\) transitions have been actively searched for in \(t\bar{t}\) events at LHC. Searches are performed in three channels, characterised by the decay mode of the Higgs boson (\(\gamma\gamma\), \(b\bar{b}\) or multilepton, the latter targeting \(WW^{\star}\), \(\tau\tau\) and \(ZZ^{\star}\)). The sensitivities in the different channels in Run-1 are similar to each other [8, 9, 10] and limits are computed combining these channels of \(\mathcal{B}(t{\rightarrow}Hu)<45\cdot 10^{-4}\) and \(\mathcal{B}(t{\rightarrow}Hc)<46\cdot 10^{-4}\). The ATLAS analysis in the \(H\rightarrow\gamma\gamma\) channel [8] has been extrapolated to the HL-LHC, predicting sensitivities of \(1.5\cdot 10^{-4}\) for \(\mathcal{B}(t{\rightarrow}Hc)\)[11].

In this note the channels considered include transitions induced by a \(Z\) boson or a Higgs boson with the subsequent decay of the \(Z\) boson into a lepton pair or of the Higgs boson into a \(b\bar{b}\) pair. Three different ATLAS detector upgrade scenarios are studied -- reference, middle and low. The reference detector has an extended inner tracker and a very-forward muon tagger, extending the coverage to \(|\eta|=4.0\)[12]. The performance of the upgraded detector is estimated in the HL-LHC conditions assuming an average number of interactions per crossing of 200 at a centre-of-mass energy of 14 TeV. Sensitivities are reported in three scenarios for the systematic uncertainties, corresponding to negligible systematic uncertainties (statistical uncertainties only), to the same systematic uncertainties as determined for the Run 1 8 TeV analyses [5, 10], and to assumed improved systematic uncertainties for the HL-LHC phase.

## 2 Data and Monte-Carlo simulation samples

Simulation datasets are used to model the expected signal and background events. The process \(pp\to t\bar{t}\) is generated at a centre-of-mass energy of 14 TeV, and the decays of interest, \(t{\rightarrow}Zq\) and \(t{\rightarrow}Hq\) with \(q{=}u,c\), are studied as a decay of one top (or anti-top) quark. The signal \(t\bar{t}\to WbZq\) and \(t\bar{t}\to WbHq\) events are generated with Protos[13, 14, 15] + Pythia, and normalised to the NLO \(t\bar{t}\) prediction. Protos implements a general fermion-fermion-gauge boson interaction description generated by effective gauge-invariant operators of dimension six. As shown in [14, 15] this description requires only \(\gamma^{\mu}\) and \(\sigma^{\mu\nu}\) terms, while the Standard Model contains solely \(\gamma^{\mu}\) terms [16, 17]. The FCNC \(t{\rightarrow}Zq\) decay in Protos is parametrised via four independent couplings, the \(X^{L},X^{R}\) of the \(\gamma^{\mu}\) type and \(\kappa^{L},\kappa^{R}\) of the \(\sigma^{\mu\nu}\) type. The Lagrangian can be written as

\[\mathcal{L}_{tZu}=-\frac{g}{2c_{W}}\bar{u}\gamma^{\mu}\left(X^{L}P_{L}+X^{R}P_ {R}\right)tZ_{\mu}-\frac{g}{2c_{W}}\bar{u}\frac{i\sigma^{\mu\nu}(p_{t}^{\nu}-p_ {u}^{\nu})}{M_{Z}}\left(\kappa^{L}P_{L}+\kappa^{R}P_{R}\right)tZ_{\mu}+h.c.,\]

with the projection operators \(P_{R,L}=1/2\cdot(1\pm\gamma^{5})\). For the present analysis the FCNC \(t{\rightarrow}Zq\) decays produced by the "\(\gamma\)" and "\(\sigma\)" type Lagrangian terms are generated separately. The general description of the FCNC \(t{\rightarrow}Hq\) decays with scalar Higgs bosons requires only two scalar and pseudo-scalar couplings;they are taken to be equal in the generation of the \(t\)\(\rightarrow\)\(Hq\) sample. In this case the Lagrangian can be written as

\[\mathcal{L}_{tHu}=-\frac{1}{\sqrt{2}}\bar{u}\left(\eta^{L}P_{L}+\eta^{R}P_{R} \right)tH+h.c.\]

In total, three different FCNC samples are generated, and the corresponding coupling settings are listed in Table 1, together with the leading-order cross sections and top-quark FCNC decay branching ratios. Only decay modes of \(W\) and \(Z\) bosons containing electrons or muons (leptons1). are considered, while all Higgs boson decay modes are allowed, assuming only Standard Model 125 GeV Higgs boson decays. The FCNC model in Proros does not differ between \(u\) and \(c\) quarks, therefore only processes with \(u\) quarks are generated explicitly. The corresponding events with \(c\) quarks are obtained by the \(u\to c\) replacement in the event record.

Footnote 1: \(\tau\)-lepton decays to electrons or muons are included

The following background processes are considered in the analysis: \(t\bar{t}\), diboson, \(WH\), single-top, \(t\bar{t}V\), \(tZ\), \(tWZ\), \(Z\)+jets and \(t\bar{t}H\) events. The \(t\bar{t}\) dataset is generated using MC@NLO + Jimmy with CT10 PDFs. The diboson events are produced with Herwig using the tune AUET2 and CTEQ6L1 PDFs. The \(WH\) and \(t\bar{t}H\) contributions are simulated using Pythia8 with the AU2 tune and CTEQ6L1 as PDFs, and normalised to their NLO prediction [18]. The single-top production is simulated with Powheg + Pythia using the tune P2011C, except for the \(t\)-channel, which is generated using AcerMC + Pythia. The \(Z\)+jets events are generated with Powheg + Pythia8 using CT10 as PDFs. The \(t\bar{t}V\) events are produced with MadGraph + Pythia, and normalised to their NLO prediction. Contributions from the \(tZ\) and \(tWZ\) processes are taken into account by rescaling the \(t\bar{t}V\) contribution according to the relevant cross sections [19].

## 3 Event reweighting and efficiency simulation

The effect of reconstruction on truth-level events is emulated, using the reference, middle and low layouts. The ATLAS detector efficiencies, resolutions and fake rates are calculated and parameterised assuming an averaged pileup \(\mu=200\). In addition to the luminosity reweighting, the events are reweighted according to the expected trigger efficiency. Pile-up jets are added according to the assumed pile-up efficiency. Furthermore, objects are randomly dropped to simulate the reconstruction efficiency of the different detector scenarios, and non-\(b\)-tagged jets are also randomly dropped to simulate the track confirmation efficiency. Likewise, jets are randomly reconstructed as prompt electrons with modified energies, to simulate the

\begin{table}
\begin{tabular}{c c c c} \hline \hline Type & Couplings & \(\sigma\)[fb] & \(\mathcal{B}\)(\(10^{-5}\)) \\ \hline  & \(\eta^{L}=\eta^{R}=0.01\) & 10.6 & 2.67 \\ “\(\gamma\)” & \(X^{L}=X^{R}=0.01\) & 3.77 & 9.38 \\ “\(\sigma\)” & \(\kappa^{L}=\kappa^{R}=0.01\) & 5.50 & 13.7 \\ \hline \hline \end{tabular}
\end{table}
Table 1: FCNC coupling combinations used to generate the three signal samples with the corresponding LO cross sections and branching ratios. The cross sections and branching ratios are shown for the FCNC top quark decays with the \(u\) quark only. The corresponding parameters for the top quark decays with the \(c\) quark are assumed to be equal.

fake electron rate, following the recommendations from Ref. [20]. The full detector performance simulation [12] demonstrated that the fake muon rate is very small and, therefore, it is not included to the parametrised performance package used in this analysis. Finally, all jets are randomly \(b\)-tagged according to their truth origin to simulate \(b\)-tagging and mis-tagging efficiency.

## 4 Analysis object definitions

Electron and muon candidates are required to satisfy tight identification criteria. The average pile-up is assumed to be \(\mu=200\). The selected leptons and jets are required to be within the upgrade-scenario-dependent tracking region, which is \(|\eta|<4.0\) in the reference scenario, \(|\eta|<3.2\) in the middle and \(|\eta|<2.7\) in the low one [12]. The \(b\)-tagging efficiency is parametrised for the 70% working point using the MV1 algorithm. Leptons within \(\Delta R<0.2\) of a jet are removed.

Jets and \(b\)-jets are required to have a transverse momentum of at least 30. For \(b\)-jets in the \(t\)\(\rightarrow\)\(Zq\) analysis this threshold is increased to 40 to reduce a contribution from mis-tagged pileup and light jets. The transverse momentum threshold for electrons and muons is set to 25 for the \(t\)\(\rightarrow\)\(Hq\) and 30 for the \(t\)\(\rightarrow\)\(Zq\) analysis.

## 5 \(t\)\(\rightarrow\)\(Zq\) trilepton channel analysis

### Event selection

The \(t\)\(\rightarrow\)\(Zq\) trilepton analysis aims to select \(t\bar{t}\) events where one of the top quarks decays via the FCNC process (\(t\)\(\rightarrow\)\(Zq\)\(\rightarrow\)\(\ell\ell u/c\)) while the other top quark decays leptonically (\(t\)\(\rightarrow\)\(Wb\)\(\rightarrow\)\(\ell\nu b\)). Therefore, the following preselection is used:

* exactly three reconstructed leptons,
* at least one opposite-sign, same-flavour (OSSF) lepton pair in the mass window [65, 115],
* the third lepton is either muon or electron within \(|\eta|<2.5\).
* at least two reconstructed jets,
* at least one \(b\)-tagged jet, and
* at least one non-\(b\)-tagged jet.

The distribution of the \(E_{\mathrm{T}}^{\mathrm{miss}}\), number of \(b\)-tagged jets and number of non-tagged (light) jets after applying the preselection for the reference, middle and low detector upgrade scenarios are shown in Figure 1 and Figure 2 for the reference and low scenarios correspondingly.

Table 2 shows the expected background yields after these requirements for the three ATLAS detector upgrade scenarios. The \(t\)\(Z\) and \(t\)\(W\)\(Z\) processes have similar kinematics and composition in terms of leptons and jets to \(t\)\(t\)\(\overline{\mathrm{}}\)\(Z\) events. Thus the \(t\)\(Z\) and \(t\)\(W\)\(Z\) event yields are estimated by scaling the selected \(t\)\(t\)\(\overline{}\)\(Z\) yields to the corresponding cross sections. The \(t\)\(Z\) yield is then scaled by 0.5, correcting for the fact that only one additional source of the third lepton (the top quark) is present, beyond the two leptons from

the \(Z\) boson. Table 3 shows the expected signal yields for the assumed FCNC hypothesis described in Table 1.

### Kinematic reconstruction

After a candidate event passes the event preselection, the kinematic reconstruction described in Ref. [5] is used to reconstruct the \(t\)\(\rightarrow\)\(Zu\) trilepton event. The process seeks to minimise:

\[\chi^{2}=\frac{\left(m_{Z}-m^{\text{reco}}_{\ell_{1}\ell_{2}}\right)^{2}}{ \sigma_{Z}^{2}}+\frac{\left(m_{W}-m^{\text{reco}}_{\ell_{3}\nu}\right)^{2}}{ \sigma_{W}^{2}}+\frac{\left(m_{t}-m^{\text{reco}}_{\ell_{3}\nu_{h}}\right)^{2} }{\sigma_{t\to Wb}^{2}}+\frac{\left(m_{t}-m^{\text{reco}}_{\ell_{1} \ell_{2}j_{u}}\right)^{2}}{\sigma_{t\to Zq}^{2}},\]

where \(m^{\text{reco}}_{ABC}\) is the invariant mass of the physics objects listed in the subscript, the leptons \(\ell_{1}\) and \(\ell_{2}\) are the two OSSF reconstructed leptons that are assumed to be the product of the \(Z\)-boson decay, while \(\ell_{3}\) is the reconstructed lepton that is assumed to have originated from the \(W\)-boson decay. The \(b\)-tagged jet \(j_{b}\) is assumed to be the product of the \(t\)\(\rightarrow\)\(Wb\) decay, while \(j_{u}\) is the non-\(b\)-tagged jet assumed to come from the \(t\)\(\rightarrow\)\(Zu\) decay. \(\nu\) is associated with the four-momentum of the neutrino from the \(W\)-boson decay: the missing transverse momentum of the event is associated with the transverse momentum of \(\nu\)

Figure 1: Distribution of the \(E_{\text{T}}^{\text{miss}}\), number of reconstructed jets and number of \(b\)-tagged jets after applying the selection for the reference scenario. The signal and the sum of all backgrounds are normalised to one.

Figure 2: Distribution of the \(E_{\text{T}}^{\text{miss}}\), number of reconstructed jets and number of \(b\)-tagged jets after applying the selection for the low scenario. The signal and the sum of all backgrounds are normalised to one.

while the value of the longitudinal component (\(p_{Z}^{\nu}\)) is left as a free parameter. The other quantities are constraints to the fit and have the values: \(m_{Z}=91.2\) GeV, \(m_{W}=80.4\) GeV, \(m_{t}=172.5\) GeV, \(\sigma_{Z}=3\) GeV, \(\sigma_{W}=10\) GeV, \(\sigma_{t\to Zq}=14\) GeV and \(\sigma_{t\to Wb}=33\) GeV.

The minimisation is computed over all valid combinations of the reconstructed objects in the events that pass the preselection. For each combination of reconstructed objects, the value of \(p_{Z}^{\nu}\) is chosen such that the value of \(\chi^{2}\) is minimal.

Once the minimisation is completed, it is convenient to define a new set of observables based on the combination giving the best value of \(\chi^{2}\) as follows:

* \(\chi^{2}_{\rm event}\equiv\chi^{2}\),
* \(M_{Z}\equiv m^{\rm reco}_{\ell_{1}\ell_{2}}\),
* \(M^{Z}_{\rm top}\equiv m^{\rm reco}_{\ell_{1}\ell_{2}j_{u}}\),
* \(M^{W}_{\rm top}\equiv m^{\rm reco}_{\ell_{3}\nu j_{b}}\).

The distribution of these reconstructed quantities, based on the results of the \(\chi^{2}\)-minimization for the reference detector upgrade scenario, are shown in Figure 3, where the signal and the sum of all backgrounds

\begin{table}
\begin{tabular}{c|c c c} \hline \hline Process & \multicolumn{3}{c}{Events} \\  & Reference & Middle & Low \\ \hline \(WZ\) & 1900 \(\pm\) 100 & 1430 \(\pm\) 80 & 1070 \(\pm\) 160 \\ \(t\bar{t}W\) & 580 \(\pm\) 16 & 510 \(\pm\) 15 & 390 \(\pm\) 13 \\ \(t\bar{t}Z\) & 11600 \(\pm\) 80 & 10660 \(\pm\) 70 & 9040 \(\pm\) 70 \\ \(Z\)+jets & 2150 \(\pm\) 140 & 1680 \(\pm\) 110 & 1130 \(\pm\) 90 \\ \(t\bar{t}\) & 3950 \(\pm\) 170 & 2280 \(\pm\) 140 & 1300 \(\pm\) 100 \\ \(Wt\) & 480 \(\pm\) 130 & 480 \(\pm\) 130 & 380 \(\pm\) 110 \\ \(tZ\) & 5800 & 5330 & 4520 \\ \(tWZ\) & 1970 & 1810 & 1540 \\ \hline Total & 28400 & 24200 & 19400 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Event yields for the background processes after the selection for the three detector scenarios. The uncertainties are from the limited size of the simulation samples. The \(tZ\) and \(tWZ\) numbers are obtained by rescaling the \(t\bar{t}Z\) one based on the relative cross sections. Statistical only errors are shown.

\begin{table}
\begin{tabular}{c|c c c} \hline \hline Process & \multicolumn{3}{c}{Events} \\  & Reference & Middle & Low \\ \hline “\(\gamma\)” \(t\)\(\rightarrow\)\(Zu\) & 589 \(\pm\) 6 & 541 \(\pm\) 6 & 444 \(\pm\) 5 \\ “\(\sigma\)” \(t\)\(\rightarrow\)\(Zu\) & 838 \(\pm\) 9 & 761 \(\pm\) 9 & 623 \(\pm\) 8 \\ “\(\gamma\)” \(t\)\(\rightarrow\)\(Zc\) & 490 \(\pm\) 5 & 431 \(\pm\) 5 & 348 \(\pm\) 5 \\ “\(\sigma\)” \(t\)\(\rightarrow\)\(Zc\) & 700 \(\pm\) 8 & 611 \(\pm\) 8 & 490 \(\pm\) 7 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Event yields for the signal processes after the selection for the three detector scenarios. They correspond to the simulated FCNC branching ratios \(9.38\cdot 10^{-5}\) and \(13.7\cdot 10^{-5}\) for the “\(\gamma\)” and “\(\sigma\)” type processes correspondingly. Statistical only errors are shown.

are normalised to one. The \(\chi^{2}\) and \(M_{\rm top}^{Z}\) distributions are also shown in Figure 4, normalised to the expected yields at 3000 fb\({}^{-1}\), assuming a \(t\)\(\rightarrow\)\(Zu\) "\(\gamma\)" type process with a branching ratio of \(9.38\cdot 10^{-5}\).

### Statistical \(t\)\(\rightarrow\)\(Zq\) limits

The upper limit on \(\mathcal{B}(t\)\(\rightarrow\)\(Zu,c)\) at 95% confidence level is determined using the maximum likelihood based confidence interval estimation method implemented in the statistical package RooStat[21]. The \(\chi^{2}\) distribution of the kinematic fit, shown in Figure 3, is exploited for the likelihood construction. The

Figure 3: Distributions of \(\chi^{2}\), \(M_{Z}\), \(M_{\rm top}^{Z}\) and \(M_{\rm top}^{W}\) for the selected events after kinematic fit for the reference scenario. The \(\chi^{2}<40\) requirement is applied for all distributions. The signal and the sum of all backgrounds are normalised to one. The \(tZ\) and \(tWZ\) contributions are obtained by rescaling the \(ttZ\) contribution according to the corresponding cross sections.

background-only hypothesis is fitted to the signal and background samples to obtain a limit on the signal cross section, from which a limit on the branching ratio is calculated. Systematic errors are not considered in the fit. The obtained limits for each detector scenario are shown in Table 4.

Comparing these numbers, it is evident that the reference detector scenario produces the strictest limit. In the middle scenario, the expected limit worsens by \(\sim\)8%, while in the low scenario the limit drops by \(\sim\)20%, when compared to the reference scenario.

### Systematic effects

To complete the analysis of the ATLAS HL-LHC sensitivity to the \(t\)\(\rightarrow\)\(Zq\) process systematic effects must be taken into account. An exhaustive list of relevant systematic effects can be found in Ref. [5], but due to the simplified detector performance simulation used in the present analysis the influence of a number of these effects cannot be studied properly. However, as shown in [5], the detector and reconstruction systematic uncertainties result in a few percent (\(\ll\)10%) respective changes in the signal and background

\begin{table}
\begin{tabular}{l|c c c c c c} \hline \hline  & “\(\gamma\)” \(t\)\(\rightarrow\)\(Zu\) & “\(\sigma\)” \(t\)\(\rightarrow\)\(Zu\) & “\(\gamma\)” \(t\)\(\rightarrow\)\(Zc\) & “\(\sigma\)” \(t\)\(\rightarrow\)\(Zc\) & “\(\gamma\)” \(t\)\(\rightarrow\)\(Zu\)\(+\)\(Zc\) & “\(\sigma\)” \(t\)\(\rightarrow\)\(Zc\) \\ \hline Reference & \(4.3\cdot 10^{-5}\) & \(4.3\cdot 10^{-5}\) & \(5.6\cdot 10^{-5}\) & \(5.8\cdot 10^{-5}\) & \(2.4\cdot 10^{-5}\) & \(2.5\cdot 10^{-5}\) \\ Middle & \(4.5\cdot 10^{-5}\) & \(4.6\cdot 10^{-5}\) & \(6.0\cdot 10^{-5}\) & \(6.3\cdot 10^{-5}\) & \(2.6\cdot 10^{-5}\) & \(2.7\cdot 10^{-5}\) \\ Low & \(5.1\cdot 10^{-5}\) & \(5.2\cdot 10^{-5}\) & \(6.7\cdot 10^{-5}\) & \(7.0\cdot 10^{-5}\) & \(2.9\cdot 10^{-5}\) & \(3.0\cdot 10^{-5}\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: FCNC-induced \(t\)\(\rightarrow\)\(Zq\) decays branching ratio limits at 95% \(CL_{x}\) for the different ATLAS detector upgrade layouts. \(Zu\)+\(Zc\) limits are obtained assuming equal production rates for \(u\) and \(c\) quarks.

Figure 4: Distributions of \(\chi^{2}\) and \(M^{Z}_{\rm top}\) for the selected events after kinematic fit for the reference scenario. The \(t\)\(\rightarrow\)\(Zu\) ”\(\gamma\)” type process with the simulated branching ratio \(9.38\cdot 10^{-5}\) is used as a signal. The signal and all backgrounds are normalised to the corresponding number of events at 3000 \(\,\mathrm{fb}^{-1}\). \(tZ\) and \(tWZ\) contributions are obtained by rescaling the \(ttZ\) contribution according to the corresponding cross sections.

yields. These variations are small compared to theoretical and data-driven backgrounds normalisation uncertainties. and can be neglected in the present analysis. Based on the estimations made in [5] the following limited set (Set A) of systematic uncertainties is defined to assess the influence of systematic effects:

* 2% total luminosity uncertainty [22];
* 6% relative uncertainty in the \(WZ\) and signal cross-sections (theory);
* 62% relative uncertainty in the \(Z\)+jets and \(t\bar{t}\) cross sections (Run 1 data-driven fake rate);
* 50% relative uncertainty in the \(tZ\) and \(tWZ\) normalisations (theory);
* 30% relative uncertainty in the \(t\bar{t}V\) normalisations (theory+data).

In most cases the Set A numbers are obtained in [5] by comparing the MC predictions with data in control regions. Due to a very limited amount of data in Run 1 this strategy results in limited precision. Evidently, due to the much larger dataset to be collected at with 3000 fb\({}^{-1}\), the accuracy of the normalisation of the theory predictions using data can be greatly improved at HL-LHC. The uncertainty for backgrounds containing fake leptons (\(Z\)+jets and \(t\bar{t}\)) are assumed to be reduced by one half, since this background is difficult to model in simulation and will be limited by systematic effects. The single top \(t\)-channel \(tZ\) cross section is already known to \(\sim\)10% [19] accuracy, one may expect similar theoretical precision for the other single top channels by HL-LHC time. The theoretical \(t\bar{t}\) cross section is known to \(\sim\)6% [23], HL-LHC data are expected to allow to measure the \(t\bar{t}V\) processes with comparable precision. An improved set of systematic uncertainties for the HL-LHC is defined as follows (Set B):

* 2% total luminosity uncertainty [22];
* 6% relative uncertainty in the \(WZ\) and signal cross-sections (theory);
* 30% relative uncertainty in the \(Z\)+jets and \(t\bar{t}\) cross sections (HL-LHC data-driven fake rate);
* 10% relative uncertainty in the \(tZ\) and \(tWZ\) normalisations (theory [19]);
* 6% relative uncertainty in the \(t\bar{t}V\) normalisations (theory+data).

To obtain the \(t\)\(\rightarrow\)\(Zu,c\) limits including systematic uncertainties the profile likelihood ratio method is used. The method is based on the test statistics \(-2\cdot\ln(\Lambda(\mu))\), where \(\Lambda(\mu)=\frac{L(\mu,\tilde{\Theta}_{\theta}(\mu))}{L(\mu,\tilde{\Theta} _{\theta})}\). Here \(\mu\) is the parameter of interest, while \(\Theta\) stands for a set of nuisance parameters describing various systematic effects. Single circumflexes indicates the unconditional maximum likelihood estimate of the corresponding parameter, while the double circumflex indicates the maximum likelihood estimate for a given \(\mu\) value. Assuming that the test statistics \(-2\cdot\ln(\Lambda(\mu))\) is asymptotically distributed according to a \(\chi^{2}\) distribution with one degree of freedom, a limit on the parameter of interest can be set, taking into account the influence of systematic effects. The implementation of the method in the statistical package RooStat[21] is used in the present analysis. The \(\mathcal{B}(t\)\(\rightarrow\)\(Zu,c)\) limits obtained at 95% CL are presented in Table 5.

By comparing the numbers in Tables 4 and 5 it can be seen that the limited set of systematic effects results in a very significant (factor \(\sim\)5 - 6 for Set A and factor \(\sim\)3 - 4 for Set B) degradation of the analysis sensitivity. With 3000 fb\({}^{-1}\) of data, the systematic uncertainty in the background normalization becomes the dominant uncertainty. Based on this result it can be concluded that the sensitivity of the presented \(t\)\(\rightarrow\)\(Zq\) process search with 3000 fb\({}^{-1}\) is largely defined by the systematic errors. Due to the dominance of systematic effects the different detector upgrade layouts perform similarly in most cases: the observed differences are typically \(<\)10%.

It can be expected that by the time of the HL-LHC era, much progress in theory and the availability of very large sets of data for calibration, will allow to significantly reduce systematic uncertainties.

## 6 \(t\)\(\rightarrow\)\(Hq\) analysis

### Event selection

The \(t\)\(\rightarrow\)\(Hq\) analysis uses \(t\bar{t}\) events, where one of the top quarks decays via the FCNC-induced transition (\(t\)\(\rightarrow\)\(Hq\)\(\rightarrow\)\(b\bar{b}q\)), while the other top quark decays leptonically (\(t\)\(\rightarrow\)\(Wb\)\(\rightarrow\)\(\ell\nu b\)). Therefore, the signature of interest is an energetic lepton, three \(b\)-quarks and either a \(u\)- or a \(c\)-quark. Reconstructed signal events in an ideal case should contain an isolated energetic lepton, three \(b\)-tagged jets and one non-\(b\)-tagged jet. Some reconstructed \(t\)\(\rightarrow\)\(Hc\) events may contain four \(b\)-tagged jets due to a significant probability to \(b\)-tag a jet produced by a charm quark. Due to the limited acceptance of the ATLAS detector, the presence of pile-up and gluon radiation jets, the \(b\)-tagging inefficiency and fake rate, the reconstructed jet multiplicity and composition may not coincide with the assumed quark multiplicity and composition in the event2. A \(t\)\(\rightarrow\)\(Hu\) event may have 4 \(b\)-jets only due to wrongly tagged light jets, which cannot be predicted for pile-up jets with the needed accuracy. The event rate with exactly 4 \(b\)-jets for \(t\)\(\rightarrow\)\(Hc\) events is small and also contains an important fraction of fake \(b\)-jets. To reduce the influence of the non-perfect description of the light and charm jet \(b\)-tagging probabilities in the upgrade simulation on the analysis results and to make the description of the \(t\)\(\rightarrow\)\(Hu\) and \(t\)\(\rightarrow\)\(Hc\) events more similar, the events with 4 and more \(b\)-tagged jets are not considered in the present analysis. Events with one \(b\)-tagged jet are dominated by various backgrounds. Therefore, only events with two or three \(b\)-tagged jets are used in this analysis.

Footnote 2: The analysis uses the 70% \(b\)-tagging working point which corresponds to \(\sim\)20% efficiency to \(b\)-tag a charm jet. Therefore, the probability to reconstruct exactly 4 \(b\)-jets for a \(t\)\(\rightarrow\)\(Hc\) signal event is \((0.7)^{3}\cdot 0.2=0.07\%\), only, not considering acceptance losses.

The final-state composition defines the analysis strategy. The event selection starts by the application of the parameterised single isolated lepton trigger efficiency. Events that passed the trigger requirement are divided into several categories, depending on the reconstructed number of jets and \(b\)-tagged jets. The dominant part of the signal events is expected to fall into six categories, listed in Table 6.

\begin{table}
\begin{tabular}{l|c|c c c c c c} \hline \hline Layout & Set & “\(\gamma\)” \(t\)\(\rightarrow\)\(Zu\) & “\(\sigma\)” \(t\)\(\rightarrow\)\(Zu\) & “\(\gamma\)” \(t\)\(\rightarrow\)\(Zc\) & “\(\sigma\)” \(t\)\(\rightarrow\)\(Zc\) & “\(\gamma\)” \(t\)\(\rightarrow\)\(Zu\)+\(Zc\) & “\(\sigma\)” \(t\)\(\rightarrow\)\(Zu\)+\(Zc\) \\ \hline \multirow{2}{*}{Reference} & A & \(18\cdot 10^{-5}\) & \(16\cdot 10^{-5}\) & \(41\cdot 10^{-5}\) & \(36\cdot 10^{-5}\) & \(13\cdot 10^{-5}\) & \(12\cdot 10^{-5}\) \\  & B & \(13\cdot 10^{-5}\) & \(13\cdot 10^{-5}\) & \(24\cdot 10^{-5}\) & \(23\cdot 10^{-5}\) & \(8.9\cdot 10^{-5}\) & \(8.3\cdot 10^{-5}\) \\ \hline \multirow{2}{*}{Middle} & A & \(18\cdot 10^{-5}\) & \(18\cdot 10^{-5}\) & \(44\cdot 10^{-5}\) & \(40\cdot 10^{-5}\) & \(13\cdot 10^{-5}\) & \(13\cdot 10^{-5}\) \\  & B & \(13\cdot 10^{-5}\) & \(13\cdot 10^{-5}\) & \(26\cdot 10^{-5}\) & \(25\cdot 10^{-5}\) & \(9.0\cdot 10^{-5}\) & \(8.9\cdot 10^{-5}\) \\ \hline \multirow{2}{*}{Low} & A & \(18\cdot 10^{-5}\) & \(17\cdot 10^{-5}\) & \(48\cdot 10^{-5}\) & \(43\cdot 10^{-5}\) & \(14\cdot 10^{-5}\) & \(13\cdot 10^{-5}\) \\  & B & \(14\cdot 10^{-5}\) & \(13\cdot 10^{-5}\) & \(29\cdot 10^{-5}\) & \(28\cdot 10^{-5}\) & \(9.8\cdot 10^{-5}\) & \(9.3\cdot 10^{-5}\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: FCNC-induced \(t\)\(\rightarrow\)\(Zq\) decays branching ratio limits at 95% \(CL\) using the two systematic uncertainties sets described in the text for the different ATLAS detector upgrade layouts.

[MISSING_PAGE_FAIL:11]

\begin{table}
\begin{tabular}{l|c c c c c c} \hline \hline Sample & 4j2b & (\(\geq\) 5j)2b & 3j3b & 4j3b & 5j3b & (\(\geq\) 6j)3b \\ \hline \(t\)\(\rightarrow\)\(Hu\) (ev) & 737 & 552 & 186 & 307 & 227 & 135 \\ \(t\)\(\rightarrow\)\(Hc\) (ev) & 710 & 524 & 265 & 380 & 258 & 151 \\ \hline \(t\overline{t}\)(10\({}^{5}\) ev) & 276 & 209 & 23.5 & 44.0 & 34.8 & 22.1 \\ Single top \(t\)-chan (10\({}^{5}\) ev) & 12.1 & 5.49 & 1.49 & 1.74 & 0.935 & 0.428 \\ Single top \(Wt\) chan (10\({}^{5}\) ev) & 12.4 & 9.71 & 1.12 & 2.04 & 1.71 & 1.18 \\ Single top \(s\)-chan (10\({}^{5}\) ev) & 0.782 & 0.307 & 0.195 & 0.131 & 0.0602 & 0.0245 \\ \(t\overline{t}\) (10\({}^{5}\) ev) & 0.121 & 0.232 & 0.022 & 0.074 & 0.109 & 0.159 \\ \(WH\) (ev) & 5520 & 1860 & 1380 & 910 & 390 & 220 \\ \hline Total background (10\({}^{6}\) ev) & 30.1 & 22.5 & 2.63 & 4.79 & 3.75 & 2.37 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Numbers of selected signal and background events in all final state categories for the 3000 fb\({}^{-1}\) of integrated luminosity and the middle ATLAS detector upgrade layout. The signal \(t\)\(\rightarrow\)\(Hu\) and \(t\)\(\rightarrow\)\(Hc\) event numbers correspond to the FCNC branching ratio \(2.67\cdot 10^{-5}\).

\begin{table}
\begin{tabular}{l|c c c c c c} \hline \hline Sample & 4j2b & (\(\geq\) 5j)2b & 3j3b & 4j3b & 5j3b & (\(\geq\) 6j)3b \\ \hline \(t\)\(\rightarrow\)\(Hu\) (ev) & 610 & 397 & 181 & 267 & 167 & 94 \\ \(t\)\(\rightarrow\)\(Hc\) (ev) & 575 & 359 & 267 & 352 & 202 & 98 \\ \hline \(t\overline{t}\)(10\({}^{5}\) ev) & 221 & 140 & 27.3 & 43.9 & 29.0 & 15.4 \\ Single top \(t\)-chan (10\({}^{5}\) ev) & 7.51 & 2.49 & 1.64 & 1.34 & 0.584 & 0.227 \\ Single top \(Wt\) chan (10\({}^{5}\) ev) & 9.88 & 6.50 & 1.18 & 1.96 & 1.41 & 0.850 \\ Single top \(s\)-chan (10\({}^{5}\) ev) & 0.547 & 0.193 & 0.177 & 0.105 & 0.0444 & 0.0163 \\ \(t\overline{t}\)\(H\) (10\({}^{5}\) ev) & 0.122 & 0.207 & 0.019 & 0.072 & 0.100 & 0.137 \\ \(WH\) (ev) & 3740 & 1150 & 1380 & 750 & 260 & 120 \\ \hline Total background (10\({}^{6}\) ev) & 23.9 & 14.9 & 3.03 & 4.73 & 3.10 & 1.65 \\ \hline \hline \end{tabular}
\end{table}
Table 9: Numbers of selected signal and background events in all final state categories for the 3000 fb\({}^{-1}\) of integrated luminosity and the low ATLAS detector upgrade layout. The signal \(t\)\(\rightarrow\)\(Hu\) and \(t\)\(\rightarrow\)\(Hc\) event numbers correspond to the FCNC branching ratio \(2.67\cdot 10^{-5}\).

To improve the analysis sensitivity, a discriminant variable is constructed in each category, to separate the signal from background. This cannot be done efficiently by using global event information, because the signal and the background are different decay channels of the same \(t\bar{t}\) system. The only distinctive feature is the presence of a Higgs boson with a mass of \(m_{H}=125\) in the signal events and of a \(W\) boson with \(m_{W}=80.4\) in the background events. To exploit this feature the jets from the Higgs boson or \(W\) boson decay need to be identified in event containing several jets.

A probabilistic approach is developed to identify the top quark, Higgs boson and \(W\) boson decay products in a \(t\bar{t}\) event and to construct a discriminant variable based on the presence of a Higgs boson or \(W\) boson in the signal and background correspondingly. The kinematic variables in the event are described by probability density functions similarly to what can be obtained from the exact event matrix element, e.g. resonance peaks or momentum distributions of specific constituents. However, the kinematic variables are calculated for every possible permutation of the reconstructed event constituents independently of their truth origin, and the obtained collection of kinematic pdfs is used to create the discriminant variable. The approach may be summarised as follows:

* Quarks, leptons, and neutrinos are replaced by the reconstructed jets, leptons, and missing momentum;
* The event kinematic pdfs are constructed using simulated events and true jet/lepton origin information (top-quark decay, \(W\) boson decay, etc.);
* The true origin based kinematic pdfs should be applied for all possible jets/leptons origin permutations, as the constituent origin information is absent in data events;

Figure 5: Selected signal and background events in the six analysis categories for the reference ATLAS detector upgrade layout. The signal \(t\)\(\rightarrow\)\(Hu\) and \(t\)\(\rightarrow\)\(Hc\) event numbers correspond to the FCNC branching ratio \(2.67\cdot 10^{-5}\).

Figure 6: Distributions of the number of \(b\)-tagged jets, the reconstructed leptonically decayed top quark mass, the invariant mass of the 2 sub-leading \(b\)-tagged jets in the selected events with 3 \(b\)-tagged jets and the invariant mass of the 2 non-\(b\)-tagged jets in the \(4j2b\) category after applying the \(t\)\(\rightarrow\)\(Hq\) selection in the reference scenario. The signal and the sum of all backgrounds are normalised to one.

Figure 7: Distributions of the number of \(b\)-tagged jets, the reconstructed leptonically decayed top quark mass, the invariant mass of the 2 sub-leading \(b\)-tagged jets in the selected events with 3 \(b\)-tagged jets and the invariant mass of the 2 non-\(b\)-tagged jets in the \(4j2b\) category after applying the \(t\)\(\rightarrow\)\(Hq\) selection in the low scenario. The signal and the sum of all backgrounds are normalised to one.

* The kinematic variables used are assumed to be independent (e.g. mass peaks), therefore they can be jointly described by the product of the corresponding pdfs.
* The discriminant variable \(\mathcal{P}\) is calculated as an average (or maximum) over all possible permutations.

The final discriminant is calculated as \(\mathcal{D}=\log(\mathcal{P}^{\rm Sig}/\mathcal{P}^{\rm Bkg})\).

The major difference between the exact matrix element event description and the approximate description developed for the present analysis is the absence of the information of the origin of the event constituents, which leads to the necessity of permutations. There are other complications, which should be considered in a reconstructed event description, coming from non-ideal event reconstruction:

* The event kinematical pdf should describe events even if some constituents are missing due to a limited detector acceptance;
* The event pdf should consider non-exact \(b\)-jet identification -- limited efficiency and possibility of false identification.

These features cannot be described by any transformation of the exact event matrix element.

In this analysis the signal discriminating variable is defined according to the following expression:

\[\mathcal{P}^{\rm Sig}=M^{t}(b_{1},\ell,E_{\rm T}^{\rm miss})\cdot M^{H}(b_{2},b _{3})\cdot M^{t}(b_{2},b_{3},j)\cdot p_{\rm T}(j).\]

Here \(M^{X}(A,B,C)\) is the invariant mass of the decay products of the object \(X\), \(b_{1},b_{2},b_{3}\) are the \(b\)-jets in a signal event, and \(j\) the light jet in the same event. \(M^{X}\) has a resonance-like shape with width defined by the detector resolution, not necessarily following a Gaussian distribution. A major background is represented by the \(t\bar{t}\) inclusive production, therefore the background discriminating variable is defined as follows

\[\mathcal{P}^{\rm Bkg}=M^{t}(b_{1},\ell,E_{\rm T}^{\rm miss})\cdot M^{W}(j_{1}, j_{2})\cdot M^{t}(j_{1},j_{2},b_{2})\cdot p_{\rm T}(b_{2}).\]

The term \(M^{t}(b_{1},\ell,E_{\rm T}^{\rm miss})\) is common for both, \(\mathcal{P}^{\rm Sig}\) and \(\mathcal{P}^{\rm Bkg}\). It is needed to increase the probability of the correct jet origin (top, Higgs, \(W\)) assignment. It is permutation dependent, therefore it cannot be canceled in the \(\mathcal{D}=\log(\mathcal{P}^{\rm Sig}/\mathcal{P}^{\rm Bkg})\) ratio.

The two pairs of invariant masses, \(M^{t}(b_{1},b_{2},j)-M^{H}(b_{1},b_{2})\) and \(M^{t}(j_{1},j_{2},b)-M^{W}(j_{1},j_{2})\) are strongly correlated. To remove the correlation the \(M^{t}(...)\) is replaced by the quadratic difference, e.g. for the signal \(M^{t}_{\phi}(b_{1},b_{2},j)=\sqrt{M^{t}(b_{1},b_{2},j)^{2}-M^{H}(b_{1},b_{2}) ^{2}}\) (for justification and details see Ref. [10]).

Due to the limited ATLAS detector acceptance some of the jets produced in the event object decays could be lost and eventually get replaced by other jets3. A signal light jet could be replaced by a gluon radiation jet or a lost \(b\)-jet could be replaced by an incorrectly tagged light jet. The mass of the signal+random jet combination does not have a resonance-like behaviour; instead this mass is distributed according to a Phase Space (PS) distribution. This distribution can be obtained by random pairing of jets not coming from the same resonance decay (e.g. gluon radiation or different resonances). Therefore in the discriminant variable definition the following replacement is done:\[M^{X}(...)\longrightarrow\varepsilon^{X}\cdot M^{X}(...)+(1-\varepsilon^{X})\cdot PS (...).\]

Here \(\varepsilon^{X}\) is the probability that all jets, produced in the \(X\) object decay, are correctly reconstructed. Both, \(\varepsilon^{X}\) and \(PS(...)\) depend on the process and on the event selection and therefore should be taken from Monte-Carlo simulation. To complete this description one needs to take into account the decay cascade -- e.g. a top-quark decay \(t\to W(jj)b\) can be reconstructed only if the corresponding decay \(W\to jj\) is reconstructed. Therefore the following replacement is done:

\[\begin{array}{ccc}M^{W}(j_{1},j_{2})\cdot M^{t}_{\odot}(j_{1},j_{2},b) \longrightarrow&\varepsilon^{W}\varepsilon^{t}&\cdot M^{W}(j_{1},j_{2})\cdot M ^{t}_{\odot}(j_{1},j_{2},b)\\ &+\varepsilon^{W}(1-\varepsilon^{t})&\cdot M^{W}(j_{1},j_{2})\cdot PS^{t}_{ \odot}(j_{1},j_{2},b)\\ &+(1-\varepsilon^{W})&\cdot PS^{W}(j_{1},j_{2})\cdot PS^{t}_{\odot}(j_{1},j_{ 2},b).\end{array}\]

The signal FCNC decay \(t\to H(b\bar{b})q\) in the \(t\bar{t}\) system, with the other top quark decaying leptonically, results in 3 \(b\)-quarks in the final state, that should lead to 3 \(b\)-jets. Any of these \(b\)-jets can be lost in the reconstruction due to \(b\)-tagging inefficiencies and the limited detector acceptance, and thus signal events with only two reconstructed \(b\)-jets appear (see Sec.6.1). Due to the presence of two concurrent loss mechanisms a special description of the two-\(b\)-jets signal events should be developed. The case of the \(b\)-tagging inefficiency is the simplest -- every light jet in an event is considered as a \(b\)-jet and the necessary additional permutations for the construction of the dscriminant variable \(\mathcal{P}^{\text{Sig}}\) is made.

In case of a \(b\)-jet lost due to acceptance, the event description depends on which \(b\)-jet is lost. If the \(b\)-jet from the leptonic top-quark decay is lost, the event discriminant variable becomes

\[\mathcal{P}^{\text{Sig}}=M^{H}(b_{1},b_{2})\cdot M^{t}_{\odot}(b_{1},b_{2},j) \cdot p_{\text{T}}(j).\]

If the \(b\)-jet from the FCNC top-quark decay is lost, the event discriminant variable becomes instead

\[\mathcal{P}^{\text{Sig}}=M^{t}(b,\ell,E_{\text{T}}^{\text{miss}})\cdot p_{ \text{T}}(j)\]

The probabilities for these 3 different types of losses to happen can be approximated by using the \(b\)-tagging efficiency (\(\varepsilon_{b}\)) and the probability for a \(b\)-jet4 in signal event to fall into the acceptance region (\(\varepsilon_{\mathcal{A}}\)). Then the relative fractions of the \(b\)-jet loss cases are shown in Table 10.

Footnote 4: For simplicity this probability is assumed to be independent of the \(b\)-jet origin and kinematics.

Finally a recipe to construct the probabilistic description of the inclusive \(t\bar{t}\) background in final states with three \(b\)-jets based on kinematic features is given. Here the third \(b\)-jet may appear either from the \(t\bar{t}\) +jets production or through the mis-tagging of a light jet. No special treatment is needed in case of the \(t\bar{t}\) +jets production, but the mis-tagging case requires to consider the tagged \(b\)-jets for the \(M^{W}(j_{1},j_{2})\) term. The latter contribution can be important in case of \(W\to cs\) decays. The explicit accounting for the tagging of \(c\)-jets as \(b\)-jets could improve the sensitivity to \(t\)\(\rightarrow\)\(Hc\) decays, but is not ex

\begin{table}
\begin{tabular}{c c c} \hline \hline \(b\)-tagging loss & Leptonic top \(b\)-jet acceptance loss & Higgs \(b\)-jet acceptance loss \\ \hline \(3\cdot(1-\varepsilon_{b})\) & \((1-\varepsilon_{\mathcal{A}})\) & \(2\cdot(1-\varepsilon_{\mathcal{A}})\) \\ \hline \hline \end{tabular}
\end{table}
Table 10: Relative fractions of \(b\)-jet loss cases.

Figure 8: The transformed discriminant variable \(\mathcal{D}^{\prime}\) distributions for the signal \(t\bar{t}\to W(\ell\nu)bH(bb)\underline{\mathbf{u}}\) (blue line) and summary background (filled area) in all event categories used in the analysis. The signal and the sum of all backgrounds are normalised to one.

The final set of the functions and efficiencies which should be defined for proper construction of the \(\mathcal{P}^{\rm Sig}\) and \(\mathcal{P}^{\rm Bkg}\) variables for the signal and background events is summarised in Table 11 and Table 12.

The obtained discriminator variables \(\mathcal{D}=\log(\mathcal{P}^{\rm Sig}/\mathcal{P}^{\rm Bkg})\) are transformed to be in the range [-1,1], using the following transformation

\[\mathcal{D}^{\prime}=\tanh\left(\frac{\mathcal{D}-<\mathcal{D}>}{\sigma( \mathcal{D})}\right).\]

The final distributions of \(\mathcal{D}^{\prime}\) are shown in Figures 8 and 9 for the \(t\to Hu\) and \(t\to Hc\) FCNC decay processes and the total background in all analysis regions. The signal and background distributions in 6 regions presented in Figures 8 and 9 and Tables 7,8, and 9 are combined to establish the FCNC processes limits using a profile likelihood method [24] as described in Section 6.2. Table 13 gives the obtained \(t\)\(\rightarrow\)\(Hq\) limits using statistical errors only for the different ATLAS detector upgrade scenarios.

As expected, the reference ATLAS detector upgrade scenario produces the strictest limit. In the middle upgrade scenario, the expected limit worsens by \(\sim\) 6%, while in the low upgrade scenario the limit drops by \(\sim\) 20%, as compared to the reference scenario.

\begin{table}
\begin{tabular}{c|l} \hline \hline \(\varepsilon_{b}\) & \(b\)-tagging efficiency \\ \(\varepsilon_{\mathcal{P}q}\) & Averaged probability to loose a \(b\)-jet due to acceptance in a signal event \\ \(\varepsilon^{t}_{L}\) & Probability to reconstruct the leptonic top decay \\ \(\varepsilon^{W}_{W}\) & Probability to reconstruct the \(W\) decay \\ \(\varepsilon^{tWq}\) & Probability to reconstruct the hadronic top decay if a \(W\) is reconstructed \\ \(\varepsilon^{H}\) & Probability to reconstruct the Higgs boson decay \\ \(\varepsilon^{tHq}\) & Probability to reconstruct the FCNC top decay if a Higgs boson is reconstructed \\ \hline \hline \end{tabular}
\end{table}
Table 11: Probabilities used to construct the analysis discriminant \(\mathcal{D}\).

\begin{table}
\begin{tabular}{c|l} \hline \hline \(M^{t}_{L}(b,\ell,E^{\rm miss}_{\rm T})\) & Resonance-like function describing a leptonic top decay \\ \(\mathrm{PS}^{t}_{L}(b,\ell,E^{\rm miss}_{\rm T})\) & Non-reconstructable leptonic top decay invariant mass \\ \(M^{W}(j_{1},j_{2})\) & Resonance-like function describing the \(W\) decay \\ \(\mathrm{PS}^{W}(j_{1},j_{2})\) & Non-reconstructable \(W\) decay invariant mass \\ \(M^{tWq}_{\odot}(j_{1},j_{2},b)\) & Resonance-like function describing a hadronic top decay \\ \(\mathrm{PS}^{Wq}_{\odot}(j_{1},j_{2},b)\) & Non-reconstructable hadronic top decay invariant mass \\ \(M^{H}(b_{1},b_{2})\) & Resonance-like function describing a Higgs boson decay \\ \(\mathrm{PS}^{H}(b_{1},b_{2})\) & Non-reconstructable Higgs boson decay invariant mass \\ \(M^{Hq}_{\odot}(b_{1},b_{2},j)\) & Resonance-like function describing a FCNC top decay \\ \(\mathrm{PS}^{Hq}_{\odot}(b_{1},b_{2},j)\) & Non-reconstructable FCNC top decay invariant mass \\ \hline \hline \end{tabular}
\end{table}
Table 12: Templates used to construct the analysis discriminant \(\mathcal{D}\).

Figure 9: The transformed discriminant variable \(\mathcal{D}^{\prime}\) distributions for the signal \(t\bar{t}\to W(\ell\nu)bH(bb)_{\mathbf{\bar{\mathrm{c}}}}\) (blue line) and summary background (filled area) in all event categories used in the analysis. The signal and the sum of all backgrounds are normalised to one.

### Systematic uncertainties

From the Run 1 ATLAS result on the best-fit branching ratios [10]: \(\mathcal{B}(t\to\!\!Hc)=1.7\pm 1.2(\mathrm{stat.})\pm 1.7(\mathrm{syst.})\cdot 10^{-3}\) and \(\mathcal{B}(t\to\!\!Hu)=-0.7\pm 1.7(\mathrm{stat.})\pm 2.8(\mathrm{syst.})\cdot 10^{-3}\), it can be seen that the Run 1 analysis sensitivity is strongly influenced by systematic effects. But, as it was already mentioned in Section 5.4, a precise investigation of all these systematic uncertainties is not possible in the present study due to the very simplified detector performance description that is used. Similarly to the \(t\to\!\!Zq\) case, the detector related systematic uncertainties are typically \(\ll\)10% and can be neglected. The dominant systematics uncertainties identified in Ref. [10] are the theoretical uncertainties in the signal and background descriptions (\(\sim\!6\%\)), \(t\bar{t}\)+heavy flavour normalisation (\(\sim\!50\%\)), \(b\)-tagging efficiency (\(\sim\!5-10\%\)), \(c\)-tagging efficiency (\(\sim\!4-13\%\)) and light jet tagging (fake) rate (\(\sim\)20%). Following the same approach used in Section 5.4, a reduced set of dominant systematic uncertainties (Set A) can be defined, using the corresponding estimations obtained at 8 TeV with 20 fb\({}^{-1}\):

* 2% total luminosity uncertainty [22];
* 15% relative uncertainty in the normalisations of the \(t\bar{t}\) background;
* 6% relative uncertainty in the normalisations of the signal and non-\(t\bar{t}\) backgrounds;
* 4% relative uncertainty in the \(b\)-tagging efficiency;
* 20% relative uncertainty in the light jet fake rate.

In the present analysis the \(t\bar{t}\) background is considered as a whole and not split into the \(t\bar{t}\)+light, \(t\bar{t}+c\bar{c}\), \(t\bar{t}+b\bar{b}\) contributions. The assumed 50% [10]\(t\bar{t}\)+heavy flavours normalisation uncertainty is therefore reduced to 15% according to the relative contribution of the \(t\bar{t}\)+heavy flavours to the total \(t\bar{t}\) background.

In Ref. [10] it was observed that the available amount of data in the signal and control regions allows to constrain many systematic uncertainties with 20 fb\({}^{-1}\) already. For example, the assumed 50% total \(t\bar{t}+b\bar{b}\) contribution uncertainty is reduced to 16% in a profile likelihood fit. With 3000 fb\({}^{-1}\) it is expected that this reduction can be even stronger, due to the large amount of data that will be available. Similarly, a significant improvement in the description of other systematics at 3000 fb\({}^{-1}\) can be expected, but the extent of this improvement is difficult to extrapolate, based on current knowledge. Nevertheless, to quantify the influence of the increased dataset in the HL-LHC environment a Set B of improved systematic uncertainties is defined as follows:

* 2% total luminosity uncertainty [22];
* 6% relative uncertainty in the normalisations of the \(t\bar{t}\) background;

\begin{table}
\begin{tabular}{l|c c c} \hline \hline  & \(t\to\!\!Hu\) & \(t\to\!\!Hc\) & \(t\to\!\!Hu\)+\(Hc\) \\ \hline Reference scenario & \(1.2\cdot 10^{-4}\) & \(1.0\cdot 10^{-4}\) & \(0.55\cdot 10^{-4}\) \\ Middle scenario & \(1.2\cdot 10^{-4}\) & \(1.1\cdot 10^{-4}\) & \(0.58\cdot 10^{-4}\) \\ Low scenario & \(1.4\cdot 10^{-4}\) & \(1.2\cdot 10^{-4}\) & \(0.66\cdot 10^{-4}\) \\ \hline \hline \end{tabular}
\end{table}
Table 13: FCNC-induced \(t\to\!\!Hq\) top-quark decay branching ratio limits at 95% C.L. using statistical uncertainties only for the different ATLAS detector upgrade layouts. _Hu+\(Hc\)_ limits are obtained assuming equal branching fractions for \(u\) and \(c\) quarks.

* 6% relative uncertainty in the normalisations of the signal and non-\(t\!t\) backgrounds;
* 2% relative uncertainty in the \(b\)-tagging efficiency;
* 10% relative uncertainty in the light jet fake rate.

Similarly to Section 5.4 the expected limits on the FCNC-induced top-quark decays \(t\to Hu(c)\) are calculated using the profile likelihood method [24] as described in Section 6.2. The statistical package RooStat[21] is used to combine all discriminant variables \(\mathcal{D}^{\prime}\) into a single statistics following the statistical analysis method used in Ref. [10] where further details can be found. Table 14 shows the 95% C.L. limits on the FCNC-induced top-quark decays \(t\!\to\!Hq\) estimated using the Asimov dataset fits in the different ATLAS detector upgrade scenarios.

The profile likelihood fit with the systematic uncertainties shows a factor \(\sim\)2, \(\sim\)2.2 and \(\sim\)2.6 degradation in the reference, middle and low upgrade scenario, respectively, as compared to the corresponding limits obtained using statistical uncertainties only. The degradation caused by the inclusion of systematic effects is thus significantly smaller than in the \(t\!\to\!Zq\) case. In contrast to the \(t\!\to\!Zq\) analysis, where the performance degradation in the limit setting with the systematic effects between reference and low scenarios is \(\sim\)10%, in the \(t\!\to\!Hq\) case this degradation reaches \(\sim\)50%, while for the middle scenario it is \(\sim\)20%. The different responses of the \(t\!\to\!Zq\) and \(t\!\to\!Hq\) FCNC limits to systematic uncertainties can be understood by the very different data statistics in these two analyses. The \(t\!\to\!Zq\) analysis at 3000 fb\({}^{-1}\) uses \(\sim\)\(3\cdot 10^{4}\) data events, while for the \(t\!\to\!Hq\) case the number of events is \(\sim\)\(3-30\cdot 10^{6}\) in the six analysis regions. The large number of expected data events and the use of multiple fit regions allow to contrain the background normalisations in the profile likelihood fit and, therefore, to reduce the influence of the background related systematic uncertainties on the \(t\!\to\!Hq\) analysis sensitivity.

All assumed systematic uncertainties in the \(t\!\to\!Hq\) analysis are expected to be strongly constrained (e.g. a reduction factor \(\sim\)50 for the \(t\bar{t}\) normalisation) in the profile likelihood fit when using a dataset corresponding to 3000 fb\({}^{-1}\). In future a significant reduction of systematic uncertainties is to be expected due to high statistics measurements using the HL-LHC data.

\begin{table}
\begin{tabular}{c|c|c c c} \hline \hline Layout & Set & \(t\!\to\!Hu\) & \(t\!\to\!Hc\) & \(t\!\to\!Hu\)+\(Hc\) \\ \hline \multirow{2}{*}{Reference} & A & \(2.4\cdot 10^{-4}\) & \(2.0\cdot 10^{-4}\) & \(1.1\cdot 10^{-4}\) \\  & B & \(2.4\cdot 10^{-4}\) & \(2.0\cdot 10^{-4}\) & \(1.1\cdot 10^{-4}\) \\ \hline \multirow{2}{*}{Middle} & A & \(2.9\cdot 10^{-4}\) & \(2.4\cdot 10^{-4}\) & \(1.3\cdot 10^{-4}\) \\  & B & \(2.9\cdot 10^{-4}\) & \(2.4\cdot 10^{-4}\) & \(1.3\cdot 10^{-4}\) \\ \hline \multirow{2}{*}{Low} & A & \(3.5\cdot 10^{-4}\) & \(3.0\cdot 10^{-4}\) & \(1.7\cdot 10^{-4}\) \\  & B & \(3.5\cdot 10^{-4}\) & \(3.0\cdot 10^{-4}\) & \(1.7\cdot 10^{-4}\) \\ \hline \hline \end{tabular}
\end{table}
Table 14: FCNC-induced \(t\!\to\!Hq\) top-quark decay branching ratio limits at 95% C.L. for the different ATLAS detector upgrade layouts using the two sets of the systematics effects described in the text. \(Hu\)+\(Hc\) limits are obtained assuming equal branching fractions for \(u\) and \(c\) quarks.

## 7 Conclusion

The expected upper limits on the FCNC processes \(t\)\(\rightarrow\)\(Zq\) and \(t\)\(\rightarrow\)\(Hq\) have been estimated for the high-luminosity LHC period in ATLAS, using three detector upgrade scenarios: reference, middle and low. To quantify the influence of systematic uncertainties on the expected sensitivity, the FCNC limits have been calculated for three different cases: statistical errors only, most significant systematic uncertainties directly taken from the Run 1 8  analyses, and for an assumed reduced set of systematic uncertainties for the HL-LHC phase.

For the \(t\)\(\rightarrow\)\(Zq\) process, if no new physics is discovered, the upper limit at 95% C.L. on the branching ratio, considering statistical errors only, is expected to be \(\mathcal{B}(t\)\(\rightarrow\)\(Zq)<(2.4-5.8)\cdot 10^{-5}\) for the reference scenario, depending on the FCNC process modelling. Using the middle scenario weakens the corresponding limits by \(\sim\)8%, while the use of the low scenario deteriorates the result by \(\sim\)20%. Considering the luminosity and background normalisation uncertainties established in the 8  Run 1 analysis leads to a factor \(\sim\) 6 degradation of the \(t\)\(\rightarrow\)\(Zq\) limits. With a possible reduction of these systematic uncertainties at the HL-LHC the sensitivity improves, obtaining FCNC limits that are a factor \(\sim\) 3.5 worse than the limits obtained with statistical uncertainties only. Taking into account the systematic errors also reduces to \(\sim\) 10% the sensitivity difference between the reference and low detector upgrade scenarios.

For the \(t\)\(\rightarrow\)\(Hq\) process, in the case of the reference detector upgrade scenario and considering only statistical uncertainties the 95% C.L. upper limit on the corresponding decay branching ratio is determined to be \(1.2\cdot 10^{-4}\) if the \(u\)-quark dominates in the FCNC process, \(1.0\cdot 10^{-4}\) if the \(c\)-quark dominates, and \(0.55\cdot 10^{-4}\) if both \(u\) and \(c\)-quarks are produced in equal fractions. The middle upgrade scenario causes only a small degradation (\(<10\%\)) of the expected limits, while the low one causes a degradation of the sensitivity by \(\sim\)20%. Considering the 8  Run 1 systematic errors leads to factors \(\sim\) 2.2 and \(\sim\) 2.6 worsening of the limits on \(t\)\(\rightarrow\)\(Hq\) for the middle and low detector upgrade scenarios. The FCNC sensitivity difference between the reference and low scenario in this case reaches \(\sim\) 50%. The assumed possible reduction of these systematic uncertainties at the HL-LHC does not significantly change the expected sensitivity.

## References

* [1] S. L. Glashow, J. Iliopoulos and L. Maiani, _Weak Interactions with Lepton-Hadron Symmetry_, Phys. Rev. D **2** (1970) 1285.
* [2] ATLAS Collaboration, _A search for flavour changing neutral currents in top-quark decays in \(pp\) collision data collected with the ATLAS detector at \(\sqrt{s}=7\) TeV_, JHEP **09** (2012) 139, arXiv: 1206.0257 [hep-ex].
* [3] CMS Collaboration, _Search for flavor changing neutral currents in top quark decays in \(pp\) collisions at \(7\) TeV_, Phys. Lett. B **718** (2013) 1252, arXiv: 1208.0957 [hep-ex].
* [4] CMS Collaboration, _Search for flavor-changing neutral currents in top-quark decays \(t\to Zq\) in \(pp\) collisions at \(\sqrt{s}=8\) TeV_, Phys. Rev. Lett. **112** (2014) 171802, arXiv: 1312.4194 [hep-ex].
* [5] ATLAS Collaboration, _Search for flavour-changing neutral current top-quark decays to \(qZ\) in \(pp\) collision data collected with the ATLAS detector at \(\sqrt{s}=8\) TeV_, Eur. Phys. J. C **76** (2016) 12, arXiv: 1508.05796 [hep-ex].
* [6] ATLAS Collaboration, _Physics at a High-Luminosity LHC with ATLAS_, ATL-PHYS-PUB-2012-001, 2012, url: [http://cdsweb.cern.ch/record/1472518](http://cdsweb.cern.ch/record/1472518).
* [7] CMS Collaboration, _Projections for Top FCNC Searches in \(3000\) fb\({}^{-1}\) at the LHC_, CMS-PAS-FTR-13-016, 2013, url: [http://cds.cern.ch/record/1605885](http://cds.cern.ch/record/1605885).
* [8] ATLAS Collaboration, _Search for top quark decays \(t\to qH\) with \(H\to\gamma\gamma\) using the ATLAS detector_, JHEP **06** (2014) 008, arXiv: 1403.6293 [hep-ex].
* [9] CMS Collaboration, _Search for anomalous production of events with three or more leptons in \(pp\) collisions at \(\sqrt{s}=8\) TeV_, Phys. Rev. D **90** (2014) 032006, arXiv: 1404.5801 [hep-ex].
* [10] ATLAS Collaboration, _Search for flavour-changing neutral current top quark decays \(t\to Hq\) in \(pp\) collisions at \(\sqrt{s}=8\) TeV with the ATLAS detector_, JHEP **12** (2015) 061, arXiv: 1509.06047 [hep-ex].
* [11] ATLAS Collaboration, _Sensitivity of ATLAS at HL-LHC to flavour changing neutral currents in top quark decays \(t\to cH\), with \(H\to\gamma\gamma\)_, ATL-PHYS-PUB-2013-012, 2013, url: [http://cdsweb.cern.ch/record/1604506](http://cdsweb.cern.ch/record/1604506).
* [12] ATLAS Collaboration, _ATLAS Phase-II Upgrade Scoping Document_, CERN-LHCC-2015-020. LHCC-G-166, 2015, url: [http://cds.cern.ch/record/2055248](http://cds.cern.ch/record/2055248).
* [13] J. A. Aguilar-Saavedra, _PROTOS, a PROgram for TOp Simulations_, url: [http://jaguilar.web.cern.ch/jaguilar/protos/](http://jaguilar.web.cern.ch/jaguilar/protos/).
* [14] J. A. Aguilar-Saavedra, _A Minimal set of top-Higgs anomalous couplings_, Nucl. Phys. B **821** (2009) 215, arXiv: 0904.2387 [hep-ph].
* [15] J. A. Aguilar-Saavedra, _A Minimal set of top anomalous couplings_, Nucl. Phys. B **812** (2009) 181, arXiv: 0811.3842 [hep-ph].
* [16] M. Beneke et al., _Top quark physics_, CERN-TH-2000-100, 2000, arXiv: hep-ph/0003033.
* [17] J. A. Aguilar-Saavedra, _Top flavor-changing neutral interactions: Theoretical expectations and experimental detection_, Acta Phys. Polon. B **35** (2004) 2695, arXiv: hep-ph/0409342 [hep-ph].