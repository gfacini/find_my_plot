ATLAS Internal Note: DAQ-NO-055, 27 June 1996, 27 June 1996, **A Model for Sequential Processing**

**in the ATLAS LVL2/LVL3 Trigger**

**Version 1.0**

J. Bystricky, D. Calvet, J. Ernwein, O. Gachelin, T. Hansl-Kozanecka,

J.R. Hubbard, M. Huet, P. Le Du, I. Mandjavidze, M. Mur,

M. Smizanska, and B. Thooris

CEA - DAPNIA, Saclay

91191 Gif-sur-Yvette, France

**Abstract**

A model of the ATLAS trigger is proposed, including preprocessing, data transfers, algorithm sequences and execution times. Latencies and processor and switch occupations are calculated, based on trigger menus for low luminosity (\(10^{33}\) cm-\({}^{2}\) s-1) described in a previous ATLAS note [1]. A sequential processing option is proposed in which all trigger selection algorithms are executed at LVL2. We show that this option requires fewer resources (network bandwidth and processors) than standard options in which trigger selection is split between LVL2 and LVL3 processing farms.

[MISSING_PAGE_EMPTY:2]

## 1 Introduction

The execution time and the latency of the LVL2 and LVL3 event selection depends on the initial (LVL1) and final (LVL3) trigger menus and on the trigger architecture and implementation. Many of the parameters - algorithm execution times, network transmission time, and overheads - can be measured on today's machines and extrapolated to future machines. In this note, we propose a model for sequential processing of the ATLAS trigger algorithms, and we estimate the parameters required by this model, based on the information we have today.

Two options for LVL2 and LVL3 processing are considered. Both options assume sequential processing of the trigger algorithms. In the first option, the trigger selection is separated into LVL2 algorithms and LVL3 algorithms as described in the ATLAS Technical Proposal [2]; LVL2 reduces the trigger rate to a few kHz, and LVL3 reduces the rate to about 100 Hz (or a bandwidth of about 100 MB/s). In the second option all selection algorithms are executed in the LVL2 processors, and LVL3 is reserved for physics analysis and data acquisition, with an event rate of about 100 Hz.

For each of these two options, we evaluate the event selection latencies and the required processing power and network bandwidth. A trigger menu for low luminosity (\(10^{33}\) cm\({}^{-2}\) s\({}^{-1}\)) described in an earlier ATLAS DAQ note [1] has been used for these studies.

The calculations contained in the present note have been labelled "paper modelling". This model is idealized with respect to the situation we will encounter in a real experiment. In real life, execution times will be distributed about some mean, with tails reaching out to execution times which are much longer than the average times estimated here. Furthermore, even though we have considered processor and network overheads in this note, we have not taken into account queuing delays. The results obtained here are necessarily optimistic with respect to the average parameters assumed, even though the parameters have been estimated conservatively.

## 2 Single Farm Architecture

The LVL2 system described in the Technical Proposal is based on a "local-global" scheme, as shown in Fig. 1. In this scheme, "feature extraction" algorithms are executed in parallel in "local" processor farms on "local" data from each subdetector and each RoI. The results of the local feature extraction are transferred to a "global" processor farm, which makes the overall LVL2 decision.

We propose a different LVL2 architecture with a single processor farm and a single network linking that farm to the Read-Out Buffers (ROBs). This "single-farm" scheme is motivated by the ATLAS physics requirements. Efficient use of resources (networks and processors) requires a sequential processing scheme, in which events can be rejected after any of the processing steps. In our scheme, this is accomplished by assigning a single processor to each event; this processor executes the trigger algorithms step-by-step, requesting data for the next processing step only if the analysis is still consistent with at least one set of trigger conditions.

The specific implementation described here is based on the functional model shown in Figs. 2 and 3. A group of ROBs is connected to a switching network via a ROB-to-Switch Interface (RSI). Similarly, a group of processors (typically 4-8) in the processor farm are connected to the same switching network via a Switch-to-Farm Interface (SFI). The LVL2 Supervisor assigns

an event to a given LVL2 processor, which requests data from the ROBs as needed for processing the sequential trigger algorithms. All of the control messages and all of the data transit through the same bi-directional switching network. The final LVL2 decision is sent to the LVL2 Supervisor by the LVL2 processor in charge of the event. The Supervisor broadcasts the decisions to all of the ROB's via the network.

If the event is accepted at LVL2, the ROBs send all their data to the LVL3 processor specified by the LVL2 (or LVL3) Supervisor; this process is called "Event Building". For certain types of events, partial data instead of full data may be sent to the LVL3 Event Builder, but this case will not be considered in this note.

## 3 Assumptions

In this paper we attempt to model the "final" ATLAS T/DAQ system, rather than today's demonstrators or prototypes. The set of working assumptions listed in this section are our "best guess" values, based in part on measurements made with today's hardware and in part on estimates of future hardware and software performance. Data transfer times are taken to be those which can be obtained with today's ATM switching hardware and software performance. Algorithm execution times are taken to be five times faster than those obtained today.

Many people have contributed to our current understanding of the parameters, partly through discussions and partly by measuring certain parameters on today's hardware. Developing a better set of working assumptions requires more discussion, more measurements, and more complete modellization. We would appreciate constructive criticism of the assumptions used here.

### Data Volumes

Our assumptions concerning the data volumes in the ROBs and the RSIs are based on the work by R. Bock and P. Le Du on the interfaces with the front-end systems [3]. The data volumes (per event) are given in the following table for each subdetector, along with the number of ROBs, the number of RSIs, and \(\Delta\eta\) x \(\Delta\phi\) for the ROBs and the RSIs. There are two entries for the TRT data, one for low luminosity and one for high luminosity.

We assume that there has been zero suppression for the TRT data in the front-end Read-Out Drivers (ROD's). Without zero suppression, the TRT data would be 790 kB. The TRT data includes data from three beam crossings, but we assume that data from a single beam-crossing are used for feature extraction. The SCT data includes 55 kB of pixel data.

The number of ROBs in the table is only half of the standard number of ROBs. This is based on the assumption that we can input data to each ROB from two ROD's (i.e., two 1 Gbit/s links). This assumption needs verification. We will produce tables with the standard hypothesis (1 536 ROBs) in the next version of this note.

The data volume in each Region of Interest (RoI), as well as the size of the RoI for each trigger and/or for each subsystem, is given in the next table.

\begin{tabular}{l l l l l l} \hline \hline \multicolumn{6}{c}{DATA VOLUMES IN RoIs AFTER PREPROCESSING} \\ \hline \hline RoI type & system & RoI data & ROBs/RoI & RSIs/RoI & \(\Delta\eta\) x \(\Delta\phi\) \\ \hline muon trigger & MUON & 1 kB & 1 ROB & 1 RSI & 0.1 x 0.1 \\ muon trigger & CALO & 3 kB & 3 ROB & 2 RSI & 0.4 x 0.4 \\ e / \(\gamma\) / \(\tau\) trigger & CALO & 3 kB & 3 ROB & 2 RSI & 0.4 x 0.4 \\ jet trigger & CALO & 3 kB & 9 ROB & 5 RSI & 1.2 x 1.2 \\ track & L=10\({}^{33}\) & TRT & 0.1 kB & 3 ROB & 2 RSI & 0.8 x 0.2 \\ track & L=10\({}^{34}\) & TRT & 0.3 kB & 3 ROB & 2 RSI & 0.8 x 0.2 \\ track & SCT & 0.2 kB & 2 ROB & 1 RSI & 0.2 x 0.2 \\ TRT scan & L=10\({}^{33}\) & TRT & 16 kB & 256 ROB & 64 RSI & 5.0 x 6.4 \\ TRT scan & L=10\({}^{34}\) & TRT & 64 kB & 256 ROB & 64 RSI & 5.0 x 6.4 \\ missing-\(E_{T}\) & CALO & 16 kB & 256 ROB & 64 RSI & 10.0 x 6.4 \\ b-jet tag & SCT & 3 kB & 8 ROB & 3 RSI & 0.8 x 0.8 \\ \hline \hline \end{tabular}

Note that we assume that only data inside the RoI is transferred to the LVL2 processors (after preprocessing in each ROB).The e / \(\gamma\) and \(\tau\) algorithms are based on the same RoIs; they have been grouped together in the table. The single hadron trigger is a special case of the \(\tau\) trigger.

### Data Transfer

Data transfer rates and overheads have been measured at Saclay, both on ATM switching fabrics and on PCI busses. The nominal transfer rates are 19 MB/s (155 Mbits/s) for each link of the ATM switch, and 132 MB/s for the PCI bus; the maximum rates of useful data were measured to be about 15 MB/s for a ATM link, and 70 MB/s for the PCI bus. The data transfer latency was 50 \(\mu\)s through the ATM switch.

The ATM switches have dual links at each port, for data transfers in the two directions. The occupancy should be calculated for transfers in each direction. In our case, data transfers from the ROBs to the (LVL2 and LVL3) processors (designated ATM1) have much higher bandwidth than the control messages transferred from the processors to the ROBs (ATM2).

The processors suffer overheads for data transfers. The device-driver software overhead for sending a message has been measured to be about 30 \(\mu\)s; we assume that this overhead can be reduced to 10 \(\mu\)s in the future. The overhead for receiving a message has been measured to be about 50 \(\mu\)s; we assume that it will continue to be about 50 \(\mu\)s in the future. (The ATM measurements were made using a 50 MHz PowerPC with a LynxOS operating system and a 50 MHz Sparc20 workstation )

We assume that the data from the ROBs will be reordered in the RSIs before being transferred to the switching network, and that data arriving from different RSIs will again be reordered in the SFTs before transfer to the LVL2 processors. We assume that the data can be reordered at the rate of 50 MB/s.

### Preprocessing

We assume that the raw data in the ROBs is preprocessed before sending it to the LVL2 processors. We assume that this preprocessing is performed separately for each ROB. The preprocessing algorithms have not yet been written (although the calorimeter preprocessing is rather trivial), so their execution times could not be measured. Our assumptions about the preprocessing algorithms and their execution times are given in the following table. Our model assumes intelligence equivalent to a 100 MIPS DSP in each of the ROBs.

### Algorithm Execution Times

Stand-alone versions of the subdetector feature extraction algorithms have been written and benchmarked at several institutions. The pioneer work on algorithms and their execution times was performed at CERN [4]. More recently stand-alone muon feature extraction code has been written and benchmarked in Rome, using a 40 MIPS DSP with optimized Fortran code [5]. The calorimeter feature extraction code has been benchmarked at Saclay on several machines, with different levels of optimization. Detailed studies of the precision-tracker code have been carried out by S.Sivoklokov, R.Dankers, and J.Baines [6]. For the TRT, we use the benchmarks established by Hauser and Legrand [4], even though their algorithm has not yet been compared with the algorithm used in the ATRIG code. For the full TRT scan required for the B-physics algorithms, M.Smizanska has measured execution times on standard CERN processor farms [7]; execution times for optimized code have not yet been measured.

The assumptions about feature extraction execution times shown in the table below are based on extrapolations of the measured execution times to what we would expect using optimized code on a future 500 MHz processor. In general, we have divided the measured execution times by a factor five to account for the expected improvement in the speed of the processors, but we have multiplied the values obtained using stand-alone code by a factor two because we expect that additional data manipulation will be required in the final code. We have also reduced the execution time for the full TRT scan by a factor three because we believe that such an improvement can be obtained when we optimize the code for low-\(p_{T}\) tracks.

The algorithm for the b-jet tag has not been studied in the trigger group. Typically execution times for off-line code are "a few seconds", with long tails at larger execution times.

The estimate in the table below is 250 ms average execution time, using optimized code in the LVL2 processors. This assumes a factor five improvement in the processor speed, and another factor two due to optimization of the LVL2 code.

\begin{tabular}{l c r r r} \hline \hline \multicolumn{5}{l}{FEATURE EXTRACTION PROCESSING TIMES IN LVL2 PROCESSORS} \\ \hline \hline Trigger & system & processing & measured execution times \\  & & (\(\mu\)s) & (\(\mu\)s) & \\ \hline muon trigger & MUON & 100 & 220 & [5] \\ e / \(\gamma\) / \(\tau\) trigger & CALO & 100 & 125 & \\ jet trigger & CALO & 100 & & \\ track & TRT & 600 & 700 & [4] \\ track & SCT & 800 & 1 840 & [6] \\ TRT scan L=10\({}^{33}\) & TRT & 50 000 & 680 000 & [7] \\ TRT scan L=10\({}^{34}\) & TRT & 200 000 & & \\ missing-\(E_{T}\) & CALO & 100 & & \\ b-jet tag & SCT & 250 000 & & \\ \hline \hline \end{tabular} An important feature of the sequential processing model is that the LVL2 processors must be able to perform in a multi-task mode, with several events being processed at the same time. When a processor requests new data for the event being processed, these data will be available only after a delay of several 100 \(\mu\)s. In order to avoid losing this time, the processor must be able to switch to another event. The overhead due to this context switching has been measured at Saclay to be about 60 \(\mu\)s; we assume that the context switching will require 50 \(\mu\)s in the future.

In the more standard option for the ATLAS trigger, some of the event selection is performed at LVL3. Here we assume that any recalculation of the missing-\(E_{T}\) and any calculation of b-jet tags would be performed at LVL3 in this option. We expect that the LVL3 code would be similar to the off-line analysis code, and less optimized than the LVL2 code.

We assume that the processing time would be larger by a factor two at LVL3, compared to the processing time for the same algorithm at LVL2. Furthermore, we assume that the LVL3 analysis is not limited to Regions of Interest, and that the minimum time for the treatment of any event at LVL3 would be about 100 ms. We also assume that a full physics analysis can be performed in a few seconds, on average. These LVL3 execution times are summarized in the following table:

## 4 Processing Sequence

This chapter gives a quantitative model for sequential processing in a single-farm architecture. The timing is given for each step in the processing sequence. These estimated times are then used to calculate the event selection latencies and the resources required (network links and processors) for different LVL2 and LVL3 strategies. The average latency and the resources required are then calculated for a specific trigger menu and for a specific model for the sequential algorithms and for the step-by-step rejection factors.

Two important processing steps have been left out of the present study. For events accepted by the LVL2 trigger, LVL2 data produced by the LVL2 processors (features, masses,etc.) must be transfered through the switching network to the LVL2 trigger ROBs; this process has not been modelled here. Furthermore, the LVL2 and LVL3 processing must be monitored for efficiency and errors; unfortunately, we do not yet have a model for these control functions.

### Processing Sequence Step-by-Step

The LVL2 and LVL3 processing sequence (for any given algorithm) is broken down into 13 processing steps, starting with the transfer of data from the front-end RODs to the ROBs, and ending with the transfer of the LVL3 decision to the supervisor. Any comparison of different event selection strategies must include all of the data transfers and all of the trigger selection algorithms (whether executed at LVL2 or at LVL3).

The execution times in this section are based on the assumptions listed in Chapter 3 of this note. When data transfers are required, an estimate of the data volume to be transferred is given in the last column, after the execution time. Execution times listed as "x/RSI" or "y/ROB" indicate that the execution times (x or y) should be multiplied by the number of RSIs or ROBs implicated in that particular data transfer. Execution times listed as "RoI data / z MB/s" indicate execution times of 1/z us per byte of data in the RoI. The expressions "ROB", "RSI", and "RoI" refer to the number of ROB's, RSI's, or RoI's involved in that particular transfer of data. Preprocessing, feature extraction, and LVL3 algorithm execution times are denoted by "Tpre","T\({}_{\rm{fx}}\)", and "T\({}_{\rm{alg}}\)", respectively.

The sequential nature of the processing model described here is illustrated by the repetition indicated for processing steps 3 to 7. The sequential data requests and data transfers are described in these five processing steps. Each data request is preceded by a test of the compatibility of the event with the LVL2 trigger conditions.

The processing steps and their execution times are given below:

\begin{tabular}{l l l l} \hline \hline
1) & SEND LVL1 DATA TO LVL2 & & & \\  & ROD latency & & 100 \(\upmu\)s \\  & ROBIN & ROD -\(>\) ROB & 10 \(\upmu\)s / link \\  & ROI Builder & RoIs -\(>\) SUPER & 100 \(\upmu\)s \\
2) & ASSIGN LVL2 PROCESSOR & & \\  & SUPER & code message & 50 \(\upmu\)s \\  & & send -\(>\) SFI & 10 \(\upmu\)s \\  & ATM1 & latency & 50 \(\upmu\)s \\  & & transfer & 6 \(\upmu\)s & 0.1 kB \\  & SFI & receive & 50 \(\upmu\)s \\  & & send -\(>\) LVL2 & 10 \(\upmu\)s \\  & PCI & transfer & 2 \(\upmu\)s & 0.1 kB \\  & LVL2 & switch context & 50 \(\upmu\)s \\
3) & REQUEST DATA FROM ROBs & & \\  & LVL2 & process RoI info & 50 \(\upmu\)s \\  & & send -\(>\) SFI & 10 \(\upmu\)s \\  & PCI & transfer & 2 \(\upmu\)s & 0.1 kB \\  & SFI & receive & 50 \(\upmu\)s \\  & & send -\(>\) RSI & 10 \(\upmu\)s \\  & ATM2 & latency & 50 \(\upmu\)s \\  & & transfer & 6 \(\upmu\)s / RSI & 0.1 kB/RSI \\  & RSI & receive & 50 \(\upmu\)s / RSI & \\  & send -\(>\) ROB & 10 \(\upmu\)s / ROB & \\  & PCI & transfer & 2 \(\upmu\)s / ROB & 0.1 kB/ROB \\  & ROB & receive & 50 \(\upmu\)s / ROB & \\
4) & PREPROCESS DATA IN EACH ROB & & \\  & ROB & preprocess & T\({}_{\rm{pre}}\)/ ROB \\ \hline \hline \end{tabular}

5) SEND PREPROCESSED DATA TO LVL2  ROB  send -> RSI 10 \(\mu\)s / ROB  RSI  transfer  RoI data / 70 MB/s  RoI data  RSI  receive 50 \(\mu\)s / ROB  reorder data  RoI data / 50 MB/s  send -> SFI 10 \(\mu\)s / RSI  ATM1  latency 50 \(\mu\)s  transfer  RoI data / 15 MB/s  RoI data  SFI  receive 50 \(\mu\)s / RSI  reorder data  RoI data / 50 MB/s  send -> LVL2 10 \(\mu\)s  PCI  transfer  RoI data / 70 MB/s  RoI data  LVL2  switch context 50 \(\mu\)s
6) EXECUTE FEATURE EXTRACTION ALGORITMS  LVL2  feature extraction  T\({}_{\text{fex}}\) / RoI
7) TEST COMPATIBILITY WITH LVL2 TRIGGER  LVL2  reject / continue 50 \(\mu\)s

8) TEST GLOBAL LVL2 TRIGGER CONDITIONS  LVL2  accept / reject 150 \(\mu\)s
9) SEND LVL2 DECISION TO SUPERVISOR  LVL2  send -> SFI 10 \(\mu\)s  PCI transfer 2 \(\mu\)s 0.1 kB  SFI  receive 50 \(\mu\)s  send -> SUPER 10 \(\mu\)s  ATM2  latency 50 \(\mu\)s  transfer 6 \(\mu\)s 0.1 kB  SUPER  receive 50 \(\mu\)s
10) BROADCAST LVL2 DECISION  SUPER  broadcast -> RSI 10 \(\mu\)s  ATM2  latency 50 \(\mu\)s  transfer 6 \(\mu\)s / RSI 0.1 kB/RSI  receive 50 \(\mu\)s / RSI  send -> ROB 10 \(\mu\)s / ROB 0.1 kB/ROB  receive 50 \(\mu\)s / ROB  clear buffer 10 \(\mu\)s / ROB

### Latency and Occupation Step-by-Step

The execution times can be regrouped to indicate the overall latency at each step of the processing, as well as the total execution time for each of the hardware elements. The notation is the same as in the preceding section, except that the expression "max(ROB/RSI)' is used in the calculation of latencies to take account of the parallel operation of the groups of ROBs assigned to each RSI.

For certain operations involving the LVL2 Supervisor and the broadcast of information by the LVL2 Supervisor, percentage occupations are listed in parentheses after the operation. These percentages are above 100%, so these operations will not be possible without special treatment. In step 1), the 200% WRITE occupation of the ROBs corresponds to the non-standard use of two 1 Gbit/s links for each ROB. The 600% Supervisor occupation in step 2) and the 500% Supervisor occupation in step 9) can be resolved by implementing the LVL2 Supervisor as a farm, with at least six bi-directional links connecting to the switching network. The 600% ROB and the 900% RSI occupations due to the broadcast by the LVL2 Supervisor to all of the ROBsof the final LVL2 decisions can be resolved by grouping the decisions in the Supervisor, and broadcasting them together at fixed intervals (once every 1 ms); the occupation levels of the Supervisor, the RSI PCI busses, and the ATM2 links (Supervisor \(\rightarrow\) ROBs) are also reduced to acceptable levels by this grouping of the final decision broadcasts.

The step-by-step latencies and the occupation of each of the hardware elements is given below:

\begin{tabular}{l l l} \hline \hline
1) & SEND LVL1 DATA TO LVL2 \\  & Latency & 100 \\  & SUPER occupation & 10 \\  & ROB occupation & 20 \\  & RSI PCI occupation & 0 \\  & RSI occupation & 0 \\  & SFI occupation & 0 \\  & SFI PCI occupation & 0 \\  & LVL2 processor occupation & 0 \\ \hline
2) & ASSIGN LVL2 PROCESSOR \\  & Latency & 228 \\  & SUPER occupation & 60 \\  & ROB occupation & 0 \\  & RSI PCI occupation & 0 \\  & ATM1 occupation & 6 \\  & SFI occupation & 60 \\  & SFI PCI occupation & 2 \\  & LVL2 processor occupation & 50 \\ \hline
3) & REQUEST DATA FROM ROBs \\  & Latency & 272 \\  & + 12 \\  & SUPER occupation & 0 \\  & ROB occupation & 50 \\  & RSI PCI occupation & 2 \\  & RSI occupation & 10 \\  & + 50 \\  & ATM2 occupation & 6 \\  & SFI occupation & 60 \\  & SFI PCI occupation & 2 \\  & LVL2 processor occupation & 60 \\ \hline \end{tabular}

[MISSING_PAGE_FAIL:14]

* [7] TEST COMPATIBILITY WITH LVL2 TRIGger

### Detector Parameters for Processes at L=10\({}^{3}\)\({}^{3}\)

The latencies and occupations can be expressed more concisely if the variables are replaced by the detector parameters listed in Section 3. Here we treat the case of low luminosity, L=10\({}^{33}\) cm\({}^{-2}\) s\({}^{-1}\). In the table below, we list the LVL2 parameters for the following processes (or algorithms):

[MISSING_PAGE_FAIL:17]

### Global Resources at L=10\({}^{3}\)\({}^{3}\)

Using the detector parameters listed above, we can calculate the resources required for any given trigger menu. The trigger menu must be decomposed into the trigger rate, the number of data requests for each subsystem and the number of RoIs of each type. Then the occupations can be derived from the equations shown below, where "RATE" is the relevant trigger rate, "REQ" is the number of data requests of a given type and "RoI" is the number of RoIs of that type. The total occupations are obtained by adding the total LVL2 occupations for the given trigger menu to the total LVL3 occupations. The split between LVL2 and LVL3 processing depends on the trigger strategy (option).

The total LVL2 occupations are obtained by adding the "minimal" LVL2 occupations to the contributions from each type of processing performed at LVL2 (RoIs and full TRT scan for both options, and missing-\(E_{T}\) and b-jet tags if all of the selection algorithms are executed at LVL2). The minimal LVL2 processing time includes the initialization steps 1) and 2) (sending theLVL1 data to LVL2, and assigning a LVL2 processor), and the global decision steps 8) and 9). We assume that the final decisions are grouped together in the LVL2 Supervisor and broadcast to the ROBs once per milliec; this adds an average of 500 \(\upmu\)s to the overall latency, but adds less than 10% to the ROB, RSI, and ATM occupancies. Only the 500 \(\upmu\)s latency due to the broadcast of the final decisions has been added into the minimal LVL2 processing numbers listed below.

\begin{tabular}{l l} \hline \hline \multicolumn{2}{l}{GLOBAL RESOURCES FOR LVL2 PROCESSING AT L=10\({}^{\ref{gloBAL}}\)} \\ \hline \hline MINIMAL LVL2 PROCESSING (NO ROI DATA) \\ Buffer occupation & RATE * [ 1 156 \(\upmu\)s ] \\ ROB occupation & 0 \\ RSI PCI occupation & 0 \\ RSI occupation & 0 \\ ATM1 occupation & RATE * [ 6 \(\upmu\)s ] \\ ATM2 occupation & RATE * [ 6 \(\upmu\)s ] \\ SFI occupation & RATE * [ 120 \(\upmu\)s ] \\ SFI PCI occupation & RATE * [ 4 \(\upmu\)s ] \\ LVL2 processor occupation & RATE * [ 210 \(\upmu\)s ] \\ \hline \end{tabular}

MUON algorithms \\ Buffer occupation & REQ * [ 648 \(\upmu\)s ] + & RoI * [ 257 \(\upmu\)s ] \\ ROB occupation & & RoI * [ 160 \(\upmu\)s ] \\ RSI PCI occupation & & RoI * [ 16 \(\upmu\)s ] \\ RSI occupation & & RoI * [ 140 \(\upmu\)s ] \\ ATM1 occupation & & RoI * [ 67 \(\upmu\)s ] \\ ATM2 occupation & & RoI * [ 6 \(\upmu\)s ] \\ SFI occupation & REQ * [ 70 \(\upmu\)s ] + & RoI * [ 70 \(\upmu\)s ] \\ SFI PCI occupation & REQ * [ 2 \(\upmu\)s ] + & RoI * [ 14 \(\upmu\)s ] \\ LVL2 processor occupation & REQ * [ 160 \(\upmu\)s ] + & RoI * [ 100 \(\upmu\)s ] \\ \hline \end{tabular}

\begin{tabular}{l l l l l l} e / \(\gamma\)/ \(\tau\) & algorithms \\ Buffer occupation & REQ * [ 759 \(\upmu\)s ] + & RoI * [ 514 \(\upmu\)s ] \\ ROB occupation & & & RoI * [ 390 \(\upmu\)s ] \\ RSI PCI occupation & & & RoI * [ 48 \(\upmu\)s ] \\ RSI occupation & & & RoI * [ 360 \(\upmu\)s ] \\ ATM1 occupation & & & RoI * [ 200 \(\upmu\)s ] \\ ATM2 occupation & & & RoI * [ 12 \(\upmu\)s ] \\ SFI occupation & REQ * [ 70 \(\upmu\)s ] + & RoI * [ 160 \(\upmu\)s ] \\ SFI PCI occupation & REQ * [ 2 \(\upmu\)s ] + & RoI * [ 42 \(\upmu\)s ] \\ LVL2 processor occupation & REQ * [ 160 \(\upmu\)s ] + & RoI * [ 100 \(\upmu\)s ] \\ \hline \end{tabular}

JET algorithms

[MISSING_PAGE_EMPTY:20]

LVL2 processor occupation REQ * [ 160 \(\mu\)s ] + RoI * [ 1 400 \(\mu\)s ]

Missing-\(E_{T}\) recalculation at LVL2

Buffer occupation REQ * [ 6 120 \(\mu\)s ]

ROB occupation REQ * [ 43 520 \(\mu\)s ]

RSI PCI occupation REQ * [ 741 \(\mu\)s ]

RSI occupation REQ * [ 19 520 \(\mu\)s ]

ATM1 occupation REQ * [ 1 067 \(\mu\)s ]

ATM2 occupation REQ * [ 384 \(\mu\)s ]

SFI occupation REQ * [ 3 590 \(\mu\)s ]

SFI PCI occupation REQ * [ 231 \(\mu\)s ]

LVL2 processor occupation REQ * [ 260 \(\mu\)s ]

Full TRT scan

Buffer occupation REQ * [ 56 110 \(\mu\)s ]

ROB occupation REQ * [ 66 560 \(\mu\)s ]

RSI PCI occupation REQ * [ 741 \(\mu\)s ]

RSI occupation REQ * [ 19 520 \(\mu\)s ]

ATM1 occupation REQ * [ 1 067 \(\mu\)s ]

ATM2 occupation REQ * [ 384 \(\mu\)s ]

SFI occupation REQ * [ 3 590 \(\mu\)s ]

SFI PCI occupation REQ * [ 231 \(\mu\)s ]

LVL2 processor occupation REQ * [ 50 160 \(\mu\)s ]

b-jet tag calculation at LVL2

Buffer occupation REQ * [ 1 534 \(\mu\)s ] + RoI * [ 250 470 \(\mu\)s ]

ROB occupation RSI * [ 6880 \(\mu\)s ]

RSI PCI occupation RSI * [ 58 \(\mu\)s ]

RSI occupation RSI * [ 720 \(\mu\)s ]

ATM1 occupation RSI * [ 200 \(\mu\)s ]

ATM2 occupation RSI * [ 18 \(\mu\)s ]

SFI occupation REQ * [ 70 \(\mu\)s ] + RoI * [ 210 \(\mu\)s ]

SFI PCI occupation REQ * [ 2 \(\mu\)s ] + RoI * [ 42 \(\mu\)s ]

LVL2 processor occupation REQ * [ 160 \(\mu\)s ] + RoI * [ 250 000 \(\mu\)s ]

The total LVL3 occupations are obtained in a similar way, by adding the "minimal" LVL3 occupations to the contributions from any special processing assigned to LVL3. In the standard option, the missing-\(E_{T}\) and the b-jet tag calculations are performed at LVL3. The missing \(E_{T}\) calculation can be absorbed in the "minimal" LVL3 occupations, since the missing-\(E_{T}\) algorithm is much faster than the minimal LVL3 processing assumed here.The b-jet tag, on the other hand, is slow, and must be taken into account explicitly.

The minimal LVL3 occupations are much higher than the minimal LVL2 occupations because we assume that all of the data are transfered to the LVL3 processors. We assume there is no preprocessing in the ROBs, and that the minimum processing time in the LVL3 ROBs is 100 ms. Finally, we assume that the LVL3 code is less optimal than the LVL2 code, so that algorithm execution times are longer by a factor two. The latencies and occupations (per event) for the minimal LVL3 processing and for the b-jet tag calculation are given below:

\begin{tabular}{l c} \hline \hline \multicolumn{2}{c}{GLOBAL LATENCY AND GLOBAL RESOURCES FOR LVL3 PROCESSING AT L=10[33]} \\ \hline \hline Minimal LVL3 processing per event & \\ Latency & 214 779 \(\upmu\)s \\ ROB occupation & 7 680 \(\upmu\)s \\ RSI PCI occupation & 14 786 \(\upmu\)s \\ RSI occupation & 61 020 \(\upmu\)s \\ ATM1 occupation & 69 000 \(\upmu\)s \\ ATM2 occupation & 6 \(\upmu\)s \\ SFI occupation & 30 370 \(\upmu\)s \\ SFI PCI occupation & 14 788 \(\upmu\)s \\ LVL3 processor occupation & 100 060 \(\upmu\)s \\ b-jet tag calculation at LVL3 & \\ Latency & RoI * [ 500 000 \(\upmu\)s ] \\ LVL3 processor occupation & RoI * [ 500 000 \(\upmu\)s ] \\ \hline \hline \end{tabular}

## 5 Sequential Processing

The model for sequential processing is a single LVL2 processing farm performing the full event selection, reducing the event rate from the initial 100 kHz LVL1 rate to the final 100 Hz LVL3 output rate. The supervisor assigns each event to a single LVL2 processor, which requests data from the ROBs as required for the event processing. Events can be rejected by the LVL2 processor at any time, if it is decided that the event does not satisfy the trigger selection criteria.

The processing sequence consists in the following steps:

1. confirm the LVL1 trigger using calorimeter and muon data from the trigger RoIs
2. verify muon, electron, and hadron triggers by matching the features in the calorimeter and muon systems to track parameters measured in the inner detector
3. perform the full TRT scan for events with a confirmed muon trigger
4. verify trigger muon isolation criteria in the calorimeter data
5. analyze non-trigger RoIs flagged by the LVL1.5 trigger menu [2]* 6) recalculate the missing-\(E_{T}\) if required by the trigger menu
* 7) look for b-jet tags if required by the trigger menu
* 8) verify the global selection criteria by combining features from all RoIs satisfying the above selection criteria.

Events can be rejected at each step in the processing sequence.

### Notation

The notation used for the trigger conditions is shown in the following table:

\begin{tabular}{l l l} \hline \hline \multicolumn{3}{c}{TRIGGER ALGORITHMS} \\ \hline \hline Symbol & Subsystem & Description \\ \hline mu & MUON & stand-alone muon algorithm \\ trk & TRT + SCT & track algorithm for RoI \\ calo & CALO & muon isolation algorithm \\ scan & TRT & full TRT scan \\ em & CALO & e / \(\gamma\) / \(\tau\)  algorithms \\ tau & CALO & \(\tau\) / hadron  algorithms \\ jet & CALO & jet algorithm \\ b-jet & CALO + SCT & jet + b-jet tag algorithm \\ me & CALO & missing-\(E_{T}\) calculation \\ \hline \hline \end{tabular}

### Model for Sequential Processing

Trigger menus for low luminosity have been published in a preceding ATLAS note [1]. This trigger menu has been used to construct a model for the sequential processing described above. Rejection rates for each trigger algorithm have been estimated as best we can; a few details are given in ref.[1]. Each line in the table below corresponds to a different sequence of trigger algorithms (involving various threshold and isolation criteria), some of which may be performed in the LVL3 processor farm.

The notation has been described in the previous section. Two columns of event rates are given: the first column is the rate for all events passing that set of algorithms, and the last column is the exclusive rate for that algorithm. The sum of the event rates in the last column should add up to the full LVL1 trigger rate.

[MISSING_PAGE_EMPTY:24]

[MISSING_PAGE_EMPTY:25]

me

### Latency and Occupation at LVL2

The occupation of the trigger hardware can be calculated for each LVL2 or LVL3 process by plugging the numbers in Section 5.3 of this note into the equations in Section 4.4. The result for the LVL2 processes are shown in the tables below.

The (average) buffer occupations are obtained by multiplying the latencies by the event rates. Therefore, the average latencies are obtained merely by dividing the buffer occupation by the relevant trigger rate.

For the "hardware elements", the "number required" in the first column of numbers gives the required number of units for that hardware item (e.g., number of processors occupied at 100%). The second column gives the number of units in our model (see Section 3.1). The last column gives the occupation for those hardware items in percent.

We have assumed that we have a total of 192 RSIs, 192 SFI's, and 650 LVL2 processors. Thus we assume a 192x192 dual-link ATM switch. The physical ATM switch is assumed to have 512 full-duplex ports @ 155 Mbit/s. The 128 remaining ports are reserved for the LVL2 supervisor, the LVL1 and LVL2 trigger ROBs, and other units.

\begin{tabular}{l c c c} \hline \hline \multicolumn{4}{l}{MINIMAL LVL2 PROCESSING (NO ROI DATA)} \\ \multicolumn{4}{l}{LVL1 trigger rate} & 34 270 Hz & \\ LVL2 minimum latency & 1.2 ms & \\ Buffer length required & 39.6 events & & \\ \multicolumn{4}{l}{Hardware element} & Number required & Number in model & Occupation \\ \hline ROB & 0 & 768 & 0 \\ RSI PCI & 0 & 192 & 0 \\ RSI & 0 & 192 & 0 \\ ATM1 & 0.2 & 192 & 0.1 \% \\ ATM2 & 0.2 & 192 & 0.1 \% \\ SFI & 4.1 & 192 & 2.1 \% \\ SFI PCI & 0.1 & 192 & 0.1 \% \\ LVL2 processor & 7.2 & 650 & 1.1 \% \\ \multicolumn{4}{l}{MUON stand alone algorithms} \\ \multicolumn{4}{l}{LVL1 muon trigger rate} & 8 000 Hz & REQs & 8 000 Hz & RoIs & 8 420 Hz \\ LVL2 latency & 0.9 ms & & & \\ Buffer length required & 7.4 events & & & \\ \multicolumn{4}{l}{Hardware element} & Number required & Number in model & Occupation \\ \hline ROB & 1.4 & 128 & 1.1 \% \\ RSI PCI & 0.1 & 32 & 0.4 \% \\ RSI & 1.2 & 32 & 3.7 \% \\ ATM1 & 0.6 & 32 & 1.8 \% \\ ATM2 & 0.1 & 32 & 0.2 \% \\ SFI & 1.2 & 192 & 0.6 \% \\ SFI PCI & 0.1 & 192 & 0.1 \% \\ LVL2 processor & 2.1 & 650 & 0.3 \% \\ \multicolumn{4}{l}{e/\(\gamma\)/\(\tau\) calorimetry algorithms} \\ \multicolumn{4}{l}{LVL1 e /\(\gamma\)/\(\tau\) rate} & 21 700 Hz & REQs & 22 940 Hz & RoIs & 30 372 Hz \\ LVL2 latency & 1.5 ms & & & \\ Buffer length required & 33.0 events & & & \\ \multicolumn{4}{l}{Hardware element} & Number required & Number in model & Occupation \\ \hline ROB & 11.8 & 256 & 4.6 \% \\ RSI PCI & 1.5 & 64 & 2.2 \% \\ RSI & 10.9 & 64 & 17.1 \% \\ ATM1 & 6.1 & 64 & 9.5 \% \\ ATM2 & 0.4 & 64 & 0.6 \% \\ SFI & 6.5 & 192 & 3.4 \% \\ SFI PCI & 1.3 & 192 & 0.7 \% \\ LVL2 processor & 6.7 & 650 & 1.0 \% \\ \hline \hline \end{tabular}

The occupations due to the individual LVL2 algorithms shown above are far from saturation for most of the hardware elements. The exceptions are the TRT ROBs and RSIs and the LVL2 processors. The calorimeter RSIs approach saturation when the contributions from the individual algorithms are summed.

The TRT ROBs and RSIs are saturated in our model due to the 4 kHz rate of the full TRT scan needed for the B-physics algorithms. The saturation is slightly above 100% (125% for the RSIs). We take this as a warning, rather than an alarm, because the parameters of our model (and, in fact, the model itself) are not yet well-understood. On the other hand, our model indicates that it would be extremely difficult to execute the same B-physics algorithms at a luminosity three times higher than the luminosity considered here (i.e., at the intermediate luminosity, 3 10\({}^{33}\) cm\({}^{-2}\) s\({}^{-1}\)).

The LVL2 processors are near saturation (above 80%) for the b-jet algorithm, if this algorithm is performed in the limited LVL2 processor farm (650 processors). Since this algorithm is normally considered to be a LVL3 algorithm, the difficulty could be alleviated by transferring some of the LVL3 processors to the LVL2 farm.

The calorimeter RSIs are near saturation (70%) if the occupation due to the missing-\(E_{T}\) calculations is added to those due to e / \(\gamma\) / \(\tau\) events and the jets. (In the standard option, in which the missing-\(E_{T}\) calculation is performed at LVL3, the total RSI occupation is even higher.) Again, we take this as a warning, rather than an alarm. We need more work on the RSI functions, and we need to understand the probable evolution of the hardware and software performance better than we do today. For now, we consider that the missing-\(E_{T}\) calculations can indeed be performed at LVL2 at the rates obtained from our trigger menu. The warning is none-the-less serious, because we might easily be tempted to increase our jet trigger rates and our missing-\(E_{T}\) rates to increase our acceptance for SUSY events.

### Latency and Occupation at LVL3

The latency and occupation due to trigger algorithms executed at LVL3 (except for B-physics) are shown in the following table. We assume that LVL3 shares the same 192 RSIs and the same 192 SFIs as LVL2, but we assume LVL3 has its own farm of 2 000 LVL3 processors.

\begin{tabular}{l c c c} \hline \hline MINIMAL LVL3 & \multicolumn{2}{c}{} & \\ \hline LVL2 trigger rate & 1 627 Hz & (except B-physics) & \\ LVL3 minimum latency & 214.8 ms & & \\ Buffer length required & 349.5 events & & \\ \multicolumn{2}{c}{} & & \\ \hline Hardware element & Number required & Number in model & Occupation \\ \hline ROB & 12.5 & 768 & 1.6 \% \\ RSI PCI & 24.1 & 192 & 12.5 \% \\ RSI & 99.3 & 192 & 51.7 \% \\ ATM1 & 112.3 & 192 & 58.4 \% \\ ATM2 & 0.01 & 192 & 0.0 \% \\ SFI & 49.4 & 192 & 25.7 \% \\ SFI PCI & 24.1 & 192 & 12.5 \% \\ LVL3 processor & 162.8 & 2 000 & 8.1 \% \\ \multicolumn{2}{c}{} & & \\ \hline \end{tabular}

b-jet TAG USING SCT DATA at LVL3

LVL3 b-jet tag rate & 1 005 Hz & RoIs 2 161 Hz & \\ LVL3 latency & 1 075.1 ms & & \\ Buffer length required & 1 080.5 events & & \\ Hardware element & Number required & Number in model & Occupation \\ \hline LVL3 processor & 1 080.5 & 2 000 & 54.0 \%We note that the average occupation of the RSIs and ATM1 are rather high (above 50%). The occupation of the LVL3 processors is also above 50% because of the calculation of the b-jet tags. We will discuss these items further in the next section.

### Sequential Processing Options

The first of our two processing options splits the algorithms into LVL2 algorithms and LVL3 algorithms. In the model presented here, the b-jet tags and the missing-\(E_{T}\) are calculated at LVL3. The resources required at LVL2 and at LVL3 and the sum of the resources required in LVL2 and LVL3 are shown in the tables below.

\begin{tabular}{l c c c} \hline \hline \multicolumn{4}{l}{TOTAL OCCUPATION FOR LVL2 PROCESSING (without b-jet tag and missing-\(E_{T}\))} \\ \hline LVL1 trigger rate & 34 270 Hz & & \\ LVL2 average latency & 10.6 ms & & \\ Buffer length required & 363.2 events & & \\ Hardware element & Number required & Number in model & Occupation \\ \hline ROB & 318.9 & 768 & 41.5 \% \\ RSI PCI & 5.8 & 192 & 3.0 \% \\ RSI & 113.7 & 192 & 59.2 \% \\ ATM1 & 15.3 & 192 & 8.0 \% \\ ATM2 & 3.0 & 192 & 1.6 \% \\ SFI & 35.8 & 192 & 18.6 \% \\ SFI PCI & 3.4 & 192 & 1.8 \% \\ LVL2 processor & 244.7 & 650 & 37.6 \% \\ \hline \end{tabular}

\begin{tabular}{l c c c} LVL2 trigger rate & 1 627 Hz & (except B-physics) & \\ LVL3 latency & 878.9 ms & & \\ Buffer length required & 1 430.0 events & & \\ Hardware element & Number required & Number in model & Occupation \\ \hline ROB & 12.5 & 768 & 1.6 \% \\ RSI PCI & 24.1 & 192 & 12.5 \% \\ RSI & 99.3 & 192 & 51.7 \% \\ ATM1 & 112.3 & 192 & 58.4 \% \\ ATM2 & 0.01 & 192 & 0.0 \% \\ SFI & 49.4 & 192 & 25.7 \% \\ SFI PCI & 24.1 & 192 & 12.5 \% \\ LVL3 processor & 1 243.3 & 2 000 & 62.2 \% \\ \end{tabular}

TOTAL OCCUPATION FOR LVL2 PLUS LVL3 PROCESSING

\begin{tabular}{l c c} LVL1 trigger rate & 34 270 Hz & \\ LVL2 + LVL3 latency & 52.3 ms & (average for all LVL1 events) & \\ Buffer length required & 1 793.2 events & (LVL2 + LVL3 buffers) & \\ Hardware element & Number required & Number in model & Occupation \\ \hline ROB & 331.4 & 768 & 43.2 \% \\ RSI PCI & 29.9 & 192 & 15.6 \% \\ RSI & 213.0 & 192 & 110.9 \% \\ ATM1 & 127.6 & 192 & 66.5 \% \\ ATM2 & 3.0 & 192 & 1.6 \% \\ SFI & 121.0 & 192 & 63.0 \% \\ SFI PCI & 27.5 & 192 & 14.3 \% \\ LVL2+LVL3 processor & 1 488.0 & 2 650 & 56.2 \% \\ \end{tabular}

The total number of processors required for the trigger selection algorithms with this processing option is 1 488, more than half of the total number of processors (LVL2 plus LVL3) in our model. The switching network is heavily loaded (66% of the maximum bandwidth for data transfers from the ROBs to the processors), and the RSIs are saturated (average occupation 110%).

In our second processing option, all of the algorithms, including the b-jet tags and the missing-\(E_{T}\) calculations, are executed at LVL2. The resources required in this case are given in the following tables:

\begin{tabular}{l c c c} \hline \hline \multicolumn{4}{l}{TOTAL OCCUPATION FOR LVL2 PROCESSING (including b-jet tag and missing-\(E_{T}\))} \\ \hline LVL1 trigger rate & 34 270 Hz & & \\ LVL2 average latency & 26.6 ms & & \\ Buffer length required & 911.2 events & & \\ \multicolumn{4}{l}{Hardware element} & Number required & Number in model & Occupation \\ \hline ROB & 370.1 & 768 & 48.2 \% \\ RSI PCI & 6.5 & 192 & 3.4 \% \\ RSI & 131.6 & 192 & 68.5 \% \\ ATM1 & 16.6 & 192 & 8.6 \% \\ ATM2 & 3.3 & 192 & 1.7 \% \\ SFI & 39.3 & 192 & 20.5 \% \\ SFI PCI & 3.7 & 192 & 1.9 \% \\ LVL2 processor & 785.3 & 650 & 120.8 \% \\ \hline \hline \end{tabular}

MINIMAL LVL3 PROCESSING (all selection at LVL2)

\begin{tabular}{l c c c} LVL2 trigger rate & 107 Hz & (except B-physics) & & \\ LVL3 latency & 214.8 ms & & & \\ Buffer length required & 23.0 events & & & \\ Hardware element & Number required & Number in model & Occupation \\ \hline ROB & 0.8 & 768 & 0.1 \% \\ RSI PCI & 1.6 & 192 & 0.8 \% \\ RSI & 6.5 & 192 & 3.4 \% \\ ATM1 & 7.4 & 192 & 3.8 \% \\ ATM2 & 0.00 & 192 & 0.0 \% \\ SFI & 3.2 & 192 & 1.7 \% \\ SFI PCI & 1.6 & 192 & 0.8 \% \\ LVL3 & 10.7 & 2 000 & 0.5 \% \\ \hline \end{tabular}

The total number of processors required for this option is only 796, nearly 700 less than those required in the standard processing option, where the processing is split between LVL2 and LVL3. Furthermore, the load on the switching network is reduced by a factor five. The occupation of the RSIs is still high (above 70%), but significantly lower than the saturation level observed in the standard option (110%).

### Sequential vs. Parallel Processing

The advantage of sequential processing of the trigger algorithms can be seen in the two tables below, which summarize the number of events, the number of data requests, and the number of RoIs that must be treated in each of the detector subsystems.

The full TRT scan has not been included in the summaries above because the B-physics algorithms used in our rate calculations require new RoIs to be formed after the full TRT scan. This is only possible using sequential processing. At least three alternatives are possible in a parallel processing architecture:

- Parallel processing could be maintained by performing the full TRT scan on the full 8 kHz of LVL1 muon triggers, and executing the SCT algorithms at LVL3.

- The B-physics events could be considered as an exception to the parallel processing scheme, and the sequential algorithms could be executed at LVL2.

- A hybrid solution could be used, in which special data-driven processors perform the TRT full scan and determine the coordinates of the new RoIs. Note that special data-driven processors would be needed in our model if we want to extend the B-physics algorithms to intermediate luminosities (3 10\({}^{33}\) cm\({}^{-2}\) s\({}^{-1}\)) without tightening the selection requirements.

The number of muon and EM calorimeter RoIs that have to be processed is reduced only slightly by using sequential rather than parallel processing. On the other hand, the number of tracking RoIs and the number of jet RoIs are reduced by a factor 4 when sequential processing is used. Note that the advantage of sequential processing is obtained only if the LVL2 processors operate in a multi-task mode, so that they can switch to another event when they post a request for additional data for the event in hand. This multi-task operation has been modelled successfully at Saclay, and the overhead has been measured and included in the model described here.

Missing-\(E_{T}\) and b-jet tags can be calculated at LVL2 using sequential processing, but this is not possible using parallel processing. This processing is only possible with sequential processing because the number of candidate events can be reduced by large factors: the number of missing-\(E_{T}\) events to be processed at LVL2 is reduced by a factor 16 in our model using sequential processing, and the number of b-jet tags is reduced by a factor 34.

## 6 Conclusions

One of the purposes of this study was to establish a method for comparing different LVL2 and LVL3 architectures without the machinery required for full modellization. These "paper models" can be used for initial evaluations and preliminary optimization of proposed trigger architectures. Meaningful comparisons will require the use of similar models and comparable sets of detector parameters for the different architectures. Final evaluation and final optimization will require the full modelling studies with fully-simulated data.

This study has already helped us to locate some of the problem areas in the single-farm architecture, and to begin the optimization procedure. More work is needed to refine the model and to determine the parameters of the final ATLAS system.

The main purpose of this study was to investigate different processing options for the single-farm LVL2 trigger architecture. The striking conclusion is that the trigger selection should not be split between LVL2 and LVL3. The number of processors and the network bandwidth required are reduced if all the selection algorithms are performed at LVL2. The number of processors is reduced because LVL2 uses preprocessed data and fully optimized code. The bandwidth is reduced because only a small fraction of the data is required to complete the selection algorithms at LVL2, whereas the full event must be sent to LVL3.

This study has also allowed us to compare sequential and parallel processing schemes, even though we do not have a complete model for the parallel processing scheme. It is well known that a parallel architecture does not provide a scheme for processing our B-physics algorithms. Furthermore, the number of tracking RoIs and the number of jet RoIs that must be processed is much higher (by a factor 4) in the parallel scheme than in the sequential scheme, because secondary RoIs must be processed, in addition to trigger RoIs, for all events. Finally, b-jet tags and missing-\(E_{T}\) must be calculated at LVL3 in the parallel scheme, whereas resources can be saved by performing these operations at LVL2 in the sequential scheme. There seem to be clear advantages to using sequential processing rather than parallel processing for the LVL2 trigger.

These studies will be extended to intermediate and high luminosities as soon as the corresponding trigger menus are available.

## References

* [1] J. Bystricky, J. Ernwein, T. Hansl-Kozanecka, J.R. Hubbard, P. Le Du, and M. Smizanska, Trigger Menus for the ATLAS Trigger at Luminosity 10\({}^{33}\) cm-2 s-1, ATLAS Internal Note DAQ-N0-054.
* [2] ATLAS Technical Proposal, CERN/LHCC/94-43, 15 December 1994.
* [3] Trigger & DAQ Interfaces with Front-End Systems: Requirement Document, ATLAS Internal Note DAQ-NO-049.
* [4] R. Hauser and I. Legrand, Algorithms in second-level triggers for ATLAS and benchmark results, ATLAS Internal Note DAQ-NO-027.
* [5] S. Falciano, A. Nisati, O Palamara, S. Petrera, and L. Zanello, The ATLAS Muon Trigger Algoritm for Level-2 Feature Extraction, ATLAS Note DAQ in preparation.
* [6] S. Sivoklokov, R. Dankers, and J. Baines, Second Level Triggering in the Forward Region of the ATLAS Inner Tracker, ATLAS Internal Note INDET-NO-111.
* [7] M. Smizanska, Second Level TRT Trigger for B-Physics, ATLAS Internal Note PHYS-NO-089.