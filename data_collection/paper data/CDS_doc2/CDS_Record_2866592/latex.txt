[MISSING_PAGE_EMPTY:1]

## 1 Introduction

High-energy particle collisions such as those produced in the Large Hadron Collider (LHC) [1] can lead to the production of massive particles (_e.g._\(W\)/\(Z\)/\(H\) bosons and top quarks) with much larger transverse momentum (\(p_{\mathrm{T}}\)) than rest mass. The decay products of such particles tend to be collimated, or 'boosted', along the direction of the progenitor particle. If the massive particles are sufficiently boosted, their overlapping hadronic decay products cannot be well-reconstructed with small-radius jets, and require large-radius (large-\(R\)) jet reconstruction.

The identification of hadronically-boosted \(W\) boson decays with large-R jets is vital in many physics analyses at the LHC, such as searches for heavy exotic particles decaying to \(W\) bosons and measurements of Standard Model processes at the TeV energy scale [2; 3; 4]. The dominant backgrounds in hadron collider are jets originating from light quarks and gluons (Quantum Chromodynamic or \(QCD\) jets) as they occur at a much higher rate than boosted \(W\)-jets in LHC collisions. Thus, boosted \(W\) tagging is developed as a key technique to suppress the background.

State-of-the-art \(W\) taggers are typically implemented with deep neural networks (DNNs) or other machine learning (ML) algorithms operating on high-level features such as _jet substructure_[5; 6; 7; 8]. However, such high-level features have been shown [9; 10] to fail to capture some information relevant to the task of tagging boosted \(W\) bosons. A more complete description of the jet is a full list of the kinematics of its constituents, which can be represented as a specific geometric data structure, namely point cloud. Taggers which use the full information of the jet constituents are referred to as constituent-based taggers.

Recent work by the ATLAS and CMS collaborations has shown good performance for constituent-based taggers [11; 12; 13]. In this study we document for the first time the performance of constituent-based \(W\) taggers in ATLAS [14].

This note provides an assessment of the performance of four constituent-based taggers in samples of simulated events. The note is organized as follows. Section 2 describes the generation of the simulation samples used in this study. Section 3 describes the jet selection process and the pre-processing applied to the dataset. The structure and training of each tagger is presented in Section 4. The performance of the taggers is presented in Section 5. The conclusions from the study are discussed in Section 6.

## 2 Monte Carlo Simulation

Samples of simulated proton-proton collisions events generated using Monte Carlo (MC) methods are used throughout this study. All samples are produced using the complete ATLAS detector simulation [15] based on Geant4[16] at \(\sqrt{s}\)=13 TeV. The effects of simultaneous proton-proton collisions ("pile-up") are simulated by overlaying the hard scattering process with inelastic interactions generated with Pythia v8.186 [17] using the NNPDF2.3LO[18] set of parton distribution functions (PDFs) and the A3 set of tuned parameters [19]. The pile-up conditions are taken from the 2017 data taking period [20].

Simulated \(W\) bosons with significant boost are generated via the production of 2 TeV \(W^{\prime}\) bosons decaying to \(W\) and \(Z\) bosons, which subsequently decay hadronically [21]. These events are generated using Pythia v8.235 [22] with the NNPDF2.3LO PDF set and the A14 set of tuned parameters [23]. The crosssection of this process is reweighted to produce an approximately flat jet \(p_{\mathrm{T}}\) distribution to efficiently populate the full kinematic region. Background multi-jet samples are generated in simulated events containing pairs of light quarks or gluons generated using Pythia v8.230 with the NNPDF2.3LO PDF set and the A14 tune.

To assess the dependence of the \(W\) tagger performance on the choice of MC generator, alternative multi-jet MC samples are generated. Sherpav2.2.5 [24] is used [25, 26] with the CT14NNLO PDF set [27] and the Sherpa default \(p_{\mathrm{T}}\)-ordered showering algorithm, based on the Catani-Seymour dipole factorization. Two hadronization models are then considered: the default cluster-based Sherpa hadronization model [28] and the Lund string model [29, 30]. Additionally, Herwig 7.1.3 [31, 32, 33] with the MMHT2014NLO PDF set [34] is also studied with either the default angle-ordered parton shower or a dipole parton shower and cluster hadronization [35]. Further details of these samples may be found in Ref. [36].

## 3 Jet Reconstruction and Selection

### Detector-level jets

Unified Flow Objects (UFOs) [37] are jet input objects optimized for reconstructing large-\(R\) jets by making use of different ATLAS sub-systems in different kinematic ranges. At low transverse momentum, the inner tracking detector provides exceptional angular and momentum resolution for charged constituents, so low \(p_{\mathrm{T}}\) constituents are reconstructed from tracks using the Particle Flow algorithm [38]. At high transverse momentum, the tracking detector loses momentum resolution but retains high angular resolution, and so high \(p_{\mathrm{T}}\) constituents are reconstructed using energy measurements from the hadronic calorimeter [39] and angular measurements from the tracking detector. This scheme provides accurate reconstruction of constituent particles across a wide kinematic range.

The large-\(R\) jets are reconstructed using the anti-\(k_{t}\) algorithm [40] with a radius parameter of \(R=1.0\), as implemented in the FastJet package [41]. This algorithm produces a list of UFOs taken to be the constituents of the jet. The Constituent Subtraction [42, 43] and Soft-Killer [44] jet grooming algorithms are then applied to the neutral Particle Flow Objects (PFOs) during UFO reconstruction to mitigate contamination from any radiation that comes from pile-up collisions rather than the quarks or gluons which initiated the jet. Further, the Soft-Drop jet grooming algorithm [45] is applied to remove soft and wide-angle radiation, which can result from either pile-up or the remnants of the colliding protons ("underlying event").

In this analysis, the detector-level jets are required to have transverse momentum larger than 200 GeV, pseudorapidity of \(|\eta|<2.0\), a jet mass of at least 40 GeV, and at least two constituents. Both leading jet and sub-leading jet in each event are considered.

### Particle-level jets

Simulated stable final state particles1 are clustered into particle-level jets using the same anti-\(k_{t}\) algorithm with the same distance parameter \(R\) as detector-level jets, and with the Soft-Drop jet grooming algorithm applied. Particle-level jets are used to assign truth labels to detector-level ones. Each particle-level jet must be matched to a detector-level jet within \(\Delta R<0.75\)2. The particle-level jets in the signal sample must satisfy additional requirements which ensure the jet is from the decay of a \(W\) boson, and the decay products of the \(W\) boson are fully contained within the jet. These requirements are placed on an ungroomed particle-level jet3 with mass of at least 50 GeV. They require that the particle-level jet does not have a ghost-associated bottom hadron [46], and satisfies a \(p_{\mathrm{T}}\)-dependent requirement on the energy scale of the first \(k_{t}\)-declustering \(\sqrt{d_{12}}\)[47]. The requirements applied on the detector-level and particle-level jets in the simulation samples to produce the training and testing sets are summarized in Table 1.

Footnote 2: ATLAS uses a right-handed coordinate system with its origin at the nominal interaction point (IP) in the centre of the detector and the \(z\)-axis along the beam pipe. The \(x\)-axis points from the IP to the centre of the LHC ring and the \(y\)-axis points upward. Cylindrical coordinates (\(r\), \(\phi\)) are used in the transverse plane, \(\phi\) being the azimuthal angle around the \(z\)-axis. The pseudorapidity is defined in terms of the polar angle \(\theta\) as \(\eta=\ln\tan(\phi/2)\). The angular distance \(\Delta\) R is defined as \(\sqrt{\Delta\eta^{2}+\Delta\phi^{2}}\).

Footnote 3: The grooming algorithm is used for removing pile-up and soft-QCD contributions to the jets.

### Jet \(p_{\mathrm{T}}\) and Training Weights

Processes that produce pairs of QCD jets feature a steeply falling jet \(p_{\mathrm{T}}\) distribution. Simulated QCD background events are generated in several windows of jet \(p_{\mathrm{T}}\), in order to efficiently populate the high-\(p_{\mathrm{T}}\) tails, leading to an unweighted spectrum with unphysical features. A falling jet \(p_{\mathrm{T}}\) spectrum can be obtained by applying physical weights. To avoid learning features of the jet \(p_{\mathrm{T}}\) spectrum in training, events in the background samples are reweighted to match the signal spectrum which is an approximately flat distribution. Note that the reweighting to match the signal is used only for training, while the physical weights are used for performance studies (testing) described in Section 5. The unweighted jet \(p_{\mathrm{T}}\) spectrum, the jet \(p_{\mathrm{T}}\) after applying the training weights, and after applying the testing weights are presented in Figure 1.

### Data Pre-processing

The dataset consists of 25 million jets: half are signal (\(W\)-jets) and half are background (QCD jets). The samples are split into orthogonal training, validating and testing datasets with a ratio of 6:2:2. Each jet includes the four-vector of the jet constituents, i.e. the energy, \(p_{\mathrm{T}}\), pseudorapidity (\(\eta\)), and azimuthal angle (\(\phi\)).

\begin{table}
\begin{tabular}{l|l} \hline \hline
**Jet Requirements** & \(W\)**-jet requirements** \\ \hline Detector-level jet \(|\eta|<2.0\) & \(dR\)(particle-level jet, particle-level \(W\)) \(<0.75\) \\ Detector-level jet \(p_{\mathrm{T}}>200\) GeV & Ungroomed particle-level jet mass \(>50\) GeV \\ Detector-level jet mass \(>40\) GeV & Number of ghost associated \(b\)-hadrons \(=0\) \\ Number of constituents \(\geq 2\) & \(\sqrt{d_{12}}>55.25\times\exp(-2.34\times 10^{-3}\times\text{particle-level jet }p_{\mathrm{T}})\) \\ \(dR\)(detector-level jet, particle-level jet) \(<0.75\) & \\ \hline \hline \end{tabular}
\end{table}
Table 1: A summary of the requirements applied on the detector-level and particle-level jets in the simulation samples to produce the training and testing sets. The additional \(W\)-jet requirements constitute the truth labeling strategy, and are only applied to the signal sample of simulated \(W\).

Figure 1: The jet \(p_{\rm T}\) spectrum for signal and background, without weights (a), after applying the training weights (b) and after applying the testing weights (c).

To facilitate the training and improve the performance of taggers, the dataset is pre-processed to scale the features into a relatively reasonable numerical range of \(\mathcal{O}(1)\), eliminate irrelevant features and capitalize on well-known symmetries. For example,the relative position of a jet constituent with respect to the jet itself depends on the physics process, while the absolute location of a jet constituent in the detector has less bearing on whether it is originated from a \(W\)-jet or QCD jet. In this study, the jet constituents undergo a pre-processing procedure modeled after the one used in the original ParticleNet article [48].

The coordinates of the jet constituents are converted into the relative pseudorapidity (\(\Delta\eta\)) and relative azimuthal angle (\(\Delta\phi\)) between the jet constituents and the jet axis in the pre-processing. Constituents' \(p_{\mathrm{T}}\) and energy values are pre-processed by taking their logarithms, placing their values on an \(\mathcal{O}(1)\) scale.

In addition to pre-processing the constituent four vectors, three other constituent-level features are calculated and used in the tagger. The first is the angular distance between the jet constituents and the jet axis (\(\Delta R\)). The second (third) is the logarithm of the constituent \(p_{\mathrm{T}}\) (energy) normalized to the sum over all constituents \(p_{\mathrm{T}}\) (energy). Distributions of the pre-processed constituent-level features are shown in Figure 2. The distribution of the number of constituents in a large-\(R\) jet is also shown. For the training of ParticleTransformer, a constituent-based ML method discussed in Sec. 4, four-vectors of the form (\(E\), \(p_{x}\), \(p_{y}\),\(p_{z}\)) are used to calculate constituent pair-wise features internally by the network according to the recommendation in Ref. [49].

Figure 2: Raw distributions of the seven constituent-level features for the \(W\) tagger (a - g) and the number of constituents in a large-\(R\) jet (h).

## 4 \(W\)-Jet Taggers

Four constituent-based \(W\) taggers are investigated and presented in this note. The pre-processed constituent-level features used in each tagger are summarized in Table 2. The ATLAS baseline \(W\) tagger is used as a benchmark for comparisons with the constituent-based jet taggers.

In this study, a maximum of 200 constituents are considered by all constituent-based taggers. Only a small portion of jets in the dataset have more than 200 constituents (less than 0.04%). As jet constituents are sorted by decreasing \(p_{\mathrm{T}}\), truncation eliminates the softest constituents of the jet.

All taggers are trained using _Weaver_[50], to minimize the cross entropy loss with the Ranger [51] optimizer.

### Baseline tagger

The DNN studied in Ref. [52] is taken as the baseline for comparison. The DNN consists of three fully-connected 32 node dense layers with a hyperbolic tangent activation function and a single-node output layer with sigmoid activation implemented in Keras[53] and Tensorflow[54]. This network is trained with the Adam optimizer [55], to minimize the binary cross entropy loss. The resulting DNN score is referred to as \(z_{\mathrm{NN}}\) in this note. The performance of the baseline tagger is taken from Ref. [52, 56].

### Energy Flow Network

The Energy Flow Network [57] (EFN) is a model widely-used for jet tagging. The mathematical structure of the EFN limits it to consider information which is linear in constituent \(p_{\mathrm{T}}\) and ensures infrared and collinear (IRC) safety [58]. It also avoids EFN from forming internal non-linear combinations of the \(p_{\mathrm{T}}\). The DeepSets structure [59] is applied to ensure permutation invariance with respect to the network inputs. Permutation invariance within the EFN is a natural way to ensure the tagger performace to be independent of input ordering. In an EFN, the features of each constituents are encoded into a latent space and the jet category is extracted from the summed representation in that latent space. Since the constituent energy is not generally linear in constituent \(p_{\mathrm{T}}\) due to nonzero mass, it is precluded from being used as a network input to ensure IRC safety. The EFN thus only considers the constituent's angular coordinates and the logarithm of the constituent \(p_{\mathrm{T}}\) as inputs.

\begin{table}
\begin{tabular}{l|l} \hline \hline
**Models** & **Features** \\ \hline EFN & \(\Delta\eta\), \(\Delta\phi\), \(\ln p_{\mathrm{T}}\) \\ \hline PFN & \(\Delta\eta\), \(\Delta\phi\), \(\ln p_{\mathrm{T}}\), \(\ln E\), \(\ln\frac{p_{\mathrm{T}}}{\sum_{jet}p_{\mathrm{T}}}\), \(\ln\frac{E}{\sum_{jet}E}\), \(\Delta R\) \\ \hline ParticleNet & \(\Delta\eta\), \(\Delta\phi\), \(\ln p_{\mathrm{T}}\), \(\ln E\), \(\ln\frac{p_{\mathrm{T}}}{\sum_{jet}p_{\mathrm{T}}}\), \(\ln\frac{E}{\sum_{jet}E}\), \(\Delta R\) \\ \hline ParticleTransformer & \(\Delta\eta\), \(\Delta\phi\), \(\ln p_{\mathrm{T}}\), \(\ln E\), \(\ln\frac{p_{\mathrm{T}}}{\sum_{jet}p_{\mathrm{T}}}\), \(\ln\frac{E}{\sum_{jet}E}\), \(\Delta R\) \\  & (\(E\), \(p_{x}\), \(p_{y}\),\(p_{z}\)) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Features used in each tagger. For ParticleTransformer, four-vectors of the form (\(E\), \(p_{x}\), \(p_{y}\),\(p_{z}\)) are used to calculate constituent pair-wise features internally by the network [49].

### Particle Flow Network

The structure of a particle flow network [57] (PFN) is very similar to the EFN. It can naturally solve the problem of input ordering and enforce permutation invariance. Unlike the EFN, it relaxes the IRC safety requirement and allows the constituent energy and any other constituent-level feature to be used as inputs. It also allows non-linear internal combinations of the \(p_{\text{T}}\) and energy. All 7 of the pre-processed constituent-level features described in Section 3.4 are used as inputs for PFN, as shown in Table 2.

### ParticleNet

ParticleNet [48] is a graph neural network (GNN) which represents a jet as a graph composed of nodes and edges. Each constituent in a jet is associated with a node, where all 7 pre-processed constituent-level features defined in Section 3.4 are taken as features of the node. Each node is connected by an edge to its \(k\) nearest neighbors in the \(\Delta\eta\)-\(\Delta\phi\) plane, where \(k\) is a network hyper-parameter. ParticleNet further applies an EdgeConv operation [60] to this graph. The EdgeConv operation is similar to the two dimensional convolution used in convolution neural networks, but it is defined on graphs instead of images. It can be stacked to enable ParticleNet to extract both local and global features in a hierarchical way.

Similarly to the EFN and PFN, ParticleNet naturally handles the variable lengths of jet constituents and enforces permutation invariance. However the EdgeConv operation acts on the feature vectors of pairs of constituents that are spatially close to each other, rather than each constituent separately. This allows ParticleNet to exploit the local relationships between constituents.

### ParticleTransformer

ParticleTransformer [49] (ParT) is a Transformer-based [61] architecture implemented for jet tagging. Two sets of features, constituents' features and pair-wise features of any two constituents in a jet, are considered by ParticleTransformer as inputs. The constituents' features consists of the 7 constituent-level features defined in Section 3.4 and 4 pair-wise features identical to those introduced in the original work [49] are calculated from four-vectors in form (\(E\), \(p_{x}\), \(p_{y}\),\(p_{z}\)) in the implementation of ParticleTransformer in Weaver.

## 5 Tagger Performance

### Comparison of taggers

The performance of four constituent-based taggers is discussed in this section. Table 3 presents the performance metrics of the taggers evaluated on the testing set, along with the number of trainable parameters and the inference time. AUC stands for the area under the ROC (Receiver Operating Characteristic) curve and ACC is the accuracy, defined as the ratio of correctly predicted samples to the total number of samples in the dataset. \(\varepsilon_{bkg}^{-1}\) is the background rejection (inverse of background efficiency) evaluated at working points which yield a given signal efficiency across the entire testing set. For all metrics, a higher value indicates a better performance. The table itself is ordered according to the AUC value. For all taggers, the statistical uncertainty on the metrics caused by the limited size of the testing sample, evaluated through repeated training runs, is much smaller than the relative performance gaps between taggers. Also shown are the number of

[MISSING_PAGE_FAIL:10]

Figure 3: The QCD jets background rejection (\(\varepsilon_{bkg}^{-1}\)) versus the \(W\)-jets signal efficiency (\(\varepsilon_{sig}\)) for all the taggers studied. All of the constituent-based taggers studied surpass the performance of the high-level-feature-based tagger (noted as \(z_{\text{NN}}\) in the figure) in the previous study [52].

uncertainty envelope gives some indication of each tagger's overall model dependence. The size of the envelope is relatively flat as a function of jet \(p_{\mathrm{T}}\) for both working points. The envelope is larger for the 50% signal-efficiency working point, and it is also found to grow with the complexity of the classifier (_i.e._, the network's number of trainable parameters). This finding supports earlier observations of increasing model dependence with network complexity in studies of boosted object tagging performance by ATLAS and CMS [13, 62]. The EFN has the smallest envelope for both working points and the ParticleTransformer tagger has the largest, surpassing differences of 40% in some bins for the 50% signal-efficiency working point.

The sensitivity of tagger performance on the hadronisation and parton shower modeling is shown in Figure 8. The difference of the tagger background rejection between the Sherpa cluster-based and string-based hadronisation models, and the Herwig angle-ordered and dipole parton shower models, is shown as a function of the jet \(p_{\mathrm{T}}\), for both the 50% and 80% signal-efficiency working points. The differences between hadronisation models decrease as the jet \(p_{\mathrm{T}}\) increases, and tend to be smaller overall than those between the parton shower models. Differences between the Herwig parton shower models are significant and evolve with jet \(p_{\mathrm{T}}\), reaching values of up to 20%. This suggests that tagger performance is more susceptible to the models of hard radiation within jets than to models of non-perturbative effects. A dependence on the network complexity is not observed in these comparisons.

Figure 4: Background rejection (\(\varepsilon_{bkg}^{-1}\)) as a function of the jet \(p_{\mathrm{T}}\) of studied \(W\) taggers for \(\varepsilon_{sig}=0.5\) (a) and \(\varepsilon_{sig}=0.8\) (b) working points.

## 5 Conclusion

Figure 5: Comparison of the background rejection (\(\varepsilon_{bkg}^{-1}\)) of \(W\) taggers in different samples of simulated QCD jet, as a measure of model dependence. Shown is the background rejection using the threshold which results in an signal efficiency of 50% (a,c) or 80% (b,d) in each \(p_{\mathrm{T}}\) bin for \(W^{\prime}\to WZ\) testing sample. The top (bottom) row stands for the EFN (PFN) tagger.

Figure 6: Comparison of the background rejection (\(\varepsilon_{bkg}^{-1}\)) of \(W\) taggers in different samples of simulated QCD jet, as a measure of model dependence. Shown is the background rejection using the threshold which results in an signal efficiency of 50% (a,c) or 80% (b,d) in each \(p_{\mathrm{T}}\) bin for \(W^{\prime}\to WZ\) testing sample. The top (bottom) row stands for the ParticleNet (ParticleTransformer) tagger.

## 5 Conclusions

Figure 7: The envelope constructed with the maximum ratio between the Pythia background rejection and the set of four alternative models is presented for bins of jet \(p_{\mathrm{T}}\), for each of the studied taggers, for classifiers with a fixed 50% signal tagging efficiency (a), or 80% signal tagging efficiency (b) in the nominal sample.

Figure 8: The sensitivity of tagger performance on the hadronisation and parton shower modeling, for each of the studied taggers, for classifiers with a fixed 50% signal tagging efficiency (a,c), or 80% signal tagging efficiency (b,d) in the nominal sample.

## 6 Conclusion

The performance of four constituent-based jet taggers for boosted \(W\) bosons in realistic simulated collisions is presented. All of the constituent-based taggers trained in this study (EFN, PFN, ParticleNet, ParticleTransformer) show stronger performance than the tagger using high-level features presented in a previous study. ParticleTransformer achieves the best performance, followed by the ParticleNet, PFN, and EFN. Notably, ParticleTransformer achieves a significant improvement of about 1.8-2.8 (1.6-2.7) times in background rejection compared to the baseline tagger, for a signal efficiency of 0.5 (0.8).

The dependence of tagger performance on the choice of parton shower and hadronization models used in Monte Carlo simulations is also presented. Model dependence of tagger performance is found to increase with the complexity of the classifier, reinforcing earlier studies of model dependence in boosted object tagging by ATLAS and CMS [13; 62]. The difference in background rejection varies from that in the Pythia sample by between 10%-40% (10%-30%), for a signal efficiency of 0.5 (0.8). The performance of \(W\) tagging is found to be more susceptible to parton shower model variations than to models of non-perturbative hadronisation effects.

## References

* [1] L. Evans and P. Bryant, _LHC Machine_, JINST **3** (2008) S08001 (cit. on p. 2).
* [2] ATLAS Collaboration, _Search for diboson resonances in hadronic final states in \(139\,\text{fb}^{-1}\) of \(pp\) collisions at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, JHEP **09** (2019) 091, arXiv: 1906.08589 [hep-ex] (cit. on p. 2).
* [3] ATLAS Collaboration, _Search for heavy diboson resonances in semileptonic final states in \(pp\) collisions at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, Eur. Phys. J. C **80** (2020) 1165, arXiv: 2004.14636 [hep-ex] (cit. on p. 2).
* [4] ATLAS Collaboration, _Search for the electroweak diboson production in association with a high-mass dijet system in semileptonic final states in \(pp\) collisions at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, Phys. Rev. D **100** (2019) 032007, arXiv: 1905.07714 [hep-ex] (cit. on p. 2).
* [5] J. Thaler and L.-T. Wang, _Strategies to Identify Boosted Tops_, JHEP **07** (2008) 092, arXiv: 0806.0023 [hep-ph] (cit. on p. 2).
* [6] A. Altheimer et al., _Jet substructure at the Tevatron and LHC: new results, new tools, new benchmarks_, J. Phys. G: Nucl. Part. Phys. **39** (2012) 063001 (cit. on p. 2).
* [7] R. Kogler et al., _Jet Substructure at the Large Hadron Collider: Experimental Review_, Rev. Mod. Phys. **91** (2019) 045003, arXiv: 1803.06991 [hep-ex] (cit. on p. 2).
* [8] A. Altheimer et al., _Boosted objects and jet substructure at the LHC. Report of BOOST2012, held at IFIC Valencia, 23rd-27th of July 2012_, Eur. Phys. J. C **74** (2014) 2792 (cit. on p. 2).
* [9] Y. Lu, A. Romero, M. J. Fenton, D. Whiteson and P. Baldi, _Resolving extreme jet substructure_, JHEP **08** (2022) 046, arXiv: 2202.00723 [hep-ex] (cit. on p. 2).
* [10] P. Baldi, K. Bauer, C. Eng, P. Sadowski and D. Whiteson, _Jet Substructure Classification in High-Energy Physics with Deep Neural Networks_, Phys. Rev. D **93** (2016) 094034, arXiv: 1603.09349 [hep-ex] (cit. on p. 2).
* [11] ATLAS Collaboration, _Performance of top-quark and W-boson tagging with ATLAS in Run 2 of the LHC_, Eur. Phys. J. C **79** (2019) 375, arXiv: 1808.07858 [hep-ex] (cit. on p. 2).
* [12] CMS Collaboration, _Identification of heavy, energetic, hadronically decaying particles using machine-learning techniques_, JINST **15** (2020) P06005, arXiv: 2004.08262 [hep-ex] (cit. on p. 2).
* [13] ATLAS Collaboration, _Constituent-Based Top-Quark Tagging with the ATLAS Detector_, ATL-PHYS-PUB-2022-039, 2022, url: [https://cds.cern.ch/record/2825328](https://cds.cern.ch/record/2825328) (cit. on pp. 2, 12, 17).
* [14] ATLAS Collaboration, _The ATLAS Experiment at the CERN Large Hadron Collider_, JINST **3** (2008) S08003 (cit. on p. 2).
* [15] ATLAS Collaboration, _The ATLAS Simulation Infrastructure_, Eur. Phys. J. C **70** (2010) 823, arXiv: 1005.4568 [physics.ins-det] (cit. on p. 2).
* [16] J. Allison et al., _Recent developments in Geant4_, Nucl. Instrum. Meth. A **835** (2016) 186 (cit. on p. 2).