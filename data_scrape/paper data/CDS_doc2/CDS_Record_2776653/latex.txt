[MISSING_PAGE_EMPTY:1]

## 1 Introduction

Missing transverse momentum (\(p_{\mathrm{T}}^{\mathrm{miss}}\)) [1] is a key observable in many physics analyses using data recorded by the ATLAS detector [2]. It represents the total transverse momentum of undetected particles produced in a proton-proton collision. By conservation of momentum, \(p_{\mathrm{T}}^{\mathrm{miss}}\) is equal to the negative vectorial sum of the transverse momentum of all the visible particles produced in the hard scatter. A non-zero value of \(p_{\mathrm{T}}^{\mathrm{miss}}\) indicates the production of 'invisible' particles such as Standard Model (SM) neutrinos or, potentially, beyond-the-Standard Model particles that escape ATLAS undetected. However, finite detector resolution, finite detector acceptance, and wrong assignment of particles produced in pile-up interactions to the hard-scatter event can all result in the reconstructed \(p_{\mathrm{T}}^{\mathrm{miss}}\) differing from the true value of \(p_{\mathrm{T}}^{\mathrm{miss}}\) (\(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\)). Contributions to reconstructed \(p_{\mathrm{T}}^{\mathrm{miss}}\) for an event which differ from \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) are called _fake_\(p_{\mathrm{T}}^{\mathrm{miss}}\).

ATLAS employs a suite of working points for \(p_{\mathrm{T}}^{\mathrm{miss}}\) reconstruction which differ in requirements on the hadronic jets entering its calculation to suppress contributions from pile-up activity. Hence, these working points behave differently in terms of pile-up resilience. This motivates the use of regression to combine complementary information from each working point on an event-by-event basis to produce a \(p_{\mathrm{T}}^{\mathrm{miss}}\) prediction with improved resolution. Deep learning provides an ideal set of tools to this end. In this note, a neural network (NN) is trained to predict \(p_{\mathrm{X}}^{\mathrm{miss,\;True}}\) and \(p_{\mathrm{Y}}^{\mathrm{miss,\;True}}\) given the reconstructed \(p_{\mathrm{X}}^{\mathrm{miss}}\) and \(p_{\mathrm{Y}}^{\mathrm{miss}}\) for each working point and additional information characterising the event topology. The NN's predictions for \(p_{\mathrm{X}}^{\mathrm{miss}}\) and \(p_{\mathrm{Y}}^{\mathrm{miss}}\) form a 2-vector: (\(\mathrm{METNet_{x}},\mathrm{METNet_{y}}\)). This allows the definition of a new suite of observables, including in particular the magnitude of the predicted two-vector: 'METNet'1, which is studied in this note and offers improved resolution and pile-up resilience compared to the current working points. Since the NN is designed to predict both components of the \(p_{\mathrm{T}}^{\mathrm{miss}}\) rather than just the magnitude of the 2-vector, this approach can be used in many more contexts where kinematic variables are constructed using the components of the \(p_{\mathrm{T}}^{\mathrm{miss}}\). Obvious examples of this are the transverse mass, \(m_{\mathrm{T}}\), used in many analyses to look for heavy particles [3] or reject Standard Model backgrounds [4], and also more complicated variables like \(m_{\mathrm{T2}}\)[5], \(m_{\mathrm{MMC}}^{\tau\tau}\)[6; 7], and the reconstructed top mass [8].

Footnote 1: This name was chosen given the historical convention of calling \(p_{\mathrm{T}}^{\mathrm{miss}}\) ‘MET’.

For searches and measurements wanting to separate signal processes with real \(p_{\mathrm{T}}^{\mathrm{miss}}\) from backgrounds without real \(p_{\mathrm{T}}^{\mathrm{miss}}\), \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance, defined by weighting \(p_{\mathrm{T}}^{\mathrm{miss}}\) by the reciprocal of its resolution \(\sigma\), is used to further discriminate between signal and background. The state-of-the-art ATLAS implementation is an object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance, as defined in Ref. [9], where \(\sigma\) is a function of the \(p_{\mathrm{T}}\)-dependent resolutions of all the objects entering the \(p_{\mathrm{T}}^{\mathrm{miss}}\) calculation. Object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance is used widely in ATLAS, for example in Refs. [10; 11; 12]. By extending the NN to additionally output a confidence in its \(p_{\mathrm{x,y}}^{\mathrm{miss}}\) predictions, a machine learning-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance, 'METNetSig', can be defined. Unlike the object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance, this is not limited by separate measurements of each object's resolution (dominantly hadronic jets). This can be used to discriminate between processes with real and fake \(p_{\mathrm{T}}^{\mathrm{miss}}\).

This note presents the machine-learning methods used to define METNet and METNetSig, and studies their performance compared to current ATLAS reconstruction methods. The note is organised as follows: Sections 2 and 3 describe the simulated samples, and object and event selection, used for training and testing the NN, respectively. The NN architecture and data pre-processing steps are described in Section 4. Sections 5 and 6 present the results for the METNet and METNetSig variables, respectively. The note concludes with Section 7.

## 2 Simulated samples of events

Simulated events are used to model the SM processes in the study, and to model a supersymmetry (SUSY) signal used to test the performance of METNetSig. The MC samples were processed through a full simulation of the ATLAS detector [13] based on Geant4[14] or a fast simulation using a parameterisation of the ATLAS calorimeter response and Geant4 for the other components of the detector [13]. All SM samples used are listed in Table 1 along with the relevant parton distribution function (PDF) sets, the configuration of underlying-event and hadronisation parameters (tune), and the cross-section order in \(\alpha_{\mathrm{s}}\) used to normalise the event yields for these samples. Further information on the ATLAS simulations of \(t\bar{t}\), single top (\(Wt\)), multiboson and boson plus jet processes can be found in the relevant public notes [15; 16; 17; 18].

To study the effectiveness of METNetSig at discriminating between processes with different amounts of real \(p_{\mathrm{T}}^{\mathrm{miss}}\), an electroweak \(R\)-parity conserving SUSY process is considered as an example of a process with a large amount of real \(p_{\mathrm{T}}^{\mathrm{miss}}\) in the final state, in the form of two stable neutralinos (\(\bar{\chi}_{1}^{0}\)). The process considered is direct pair production of sleptons (\(\tilde{\ell}^{\pm}\)), each decaying into a lepton and a neutralino, where the neutralino is the lightest neutralino and considered to be bino-like, and the sleptons are either selectrons or smuons. All other SUSY particles are decoupled and the branching fraction of this decay is assumed to be 100%. The SUSY particle masses considered are \(m(\tilde{\ell})=200\,\mathrm{GeV}\) and \(m(\bar{\chi}_{1}^{0})=100\,\mathrm{GeV}\). The SUSY sample was generated as described in Table 1, with more detail of both the model and simulation provided in Ref. [10]. SUSY sample cross sections are calculated to next-to-leading order in the strong coupling constant, adding the resummation of soft gluon emission at next-to-leading-logarithmic accuracy (NLO+NLL) [19; 20; 21; 22; 23]. The nominal cross section is taken from an envelope of cross section predictions using different PDF sets and factorisation and renormalisation scales, as described in Ref. [24].

The effect of pile-up in the same and neighbouring bunch crossings was modelled by overlaying the simulated hard-scattering event with inelastic proton-proton events generated with Pythia 8.186 [25] using the NNPDF2.3lo set of parton distribution functions (PDF) [26] and the A3 set of tuned parameters [27]. The MC samples were reweighted so that the distribution of the average number of interactions per bunch crossing reproduces the observed distribution in the data.

## 3 Object definition and event selection

Candidate events were selected by triggers that required at least one electron or muon.

Leptons selected for analysis are categorised as baseline or signal leptons according to various quality and kinematic selection criteria. Baseline objects are used in the calculation of conventional missing transverse

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline Physics process & Generator (ME) & Parton shower & Normalisation & Tune & PDF (ME) & PDF (PS) \\ \hline Slepton pair production & Mu.Galaxy\_ALMC@NLO & Pythia8.186[25] & NLO+NLL & [19; 20; 21; 22] & A14[33] & NNPDF2.3lo [26] & NNPDF2.3lo \\  & 2.6.1 [28] & & & 30–2] & & \\ \(t\bar{t}\) & Pours Box2[34; 35; 36; 37; 38; 39; 40; 41; 42; 43; 44; 45; 46; 47; 48; 49; 50; 51; 52; 53; 54; 55; 56; 57; 58; 59; 60; 61; 62; 63; 64; 65; 66; 67; 68; 69; 70; 71; 72; 73; 74; 75; 76; 77; 78; 79; 80; 81; 82; 83; 84; 85; 86; 87; 88; 89; 90; 82; 84; 86; 89; 91; 83; 85; 87; 84; 88; 89; 92; 93; 94; 95; 96; 97; 98; 99; 100; 99; 101; 102; 103; 104; 105; 106; 107; 108; 109; 111; 112; 113; 114; 115; 116; 117; 118; 119; 120; 121; 122; 123; 124; 125; 126; 127; 128; 129; 130; 131; 132; 133; 134; 135; 136; 137; 138; 139; 140; 141; 142; 143] & NNPDF3.0NLO & NNPDF2.3lo \\ \(Z/y^{*}(-\ell)\)+jets & Susak2.21 [43; 44; 45] & Susak2.21 & NLO [46] & Susak2.4feh [45] & NNPDF3.0NLO [40] & NNPDF3.0NLO [40] \\ \(W\,W\,,Z,ZZ\) & Pours Box2[35; 36; 47; 48] & Prunu8.210 & NLO [17; 47; 48] & A2NLO [89] & CT10 NLO [50] & CTEQ4.[15] \\ \hline \hline \end{tabular}
\end{table}
Table 1: Simulated SM event samples with the corresponding matrix element (ME) and parton shower (PS) generators, cross-section order in \(\alpha_{\mathrm{s}}\) used to normalise the event yield, underlying-event tune and the generator PDF sets used.

momentum. Leptons used for the final topology selections must satisfy more stringent signal requirements, in addition to the baseline requirements.

Baseline electron candidates are reconstructed using clusters of energy deposits in the electromagnetic calorimeter that are matched to an ID track. They are required to satisfy a _Loose_ likelihood-based identification requirement [52], have pseudorapidity2 in the range \(|\eta|<2.47\) and have \(p_{\mathrm{T}}>10\,\mathrm{GeV}\). They are also required to be within \(|z_{0}\sin\theta|<0.5\) mm of the hard-scatter primary vertex3 where \(z_{0}\) is the longitudinal impact parameter relative to the hard-scatter primary vertex. Signal electrons are required to satisfy a _Tight_ identification requirement [52] and the track associated with the signal electron is required to have \(|d_{0}|/\sigma(d_{0})<5\), where \(d_{0}\) is the transverse impact parameter relative to the reconstructed primary vertex and \(\sigma(d_{0})\) is its uncertainty. They must also have \(p_{\mathrm{T}}>25\,\mathrm{GeV}\).

Footnote 2: ATLAS uses a right-handed coordinate system with its origin at the nominal interaction point (IP) in the centre of the detector and the \(z\)-axis along the beam pipe. The \(x\)-axis points from the IP to the centre of the LHC ring, and the \(y\)-axis points upward. Cylindrical coordinates \((r,\phi)\) are used in the transverse plane, \(\phi\) being the azimuthal angle around the \(z\)-axis. The pseudorapidity is defined in terms of the polar angle \(\theta\) as \(\eta=-\ln\tan(\theta/2)\).

Footnote 3: Primary vertices are by default required to have two tracks associated with them. The hard-scatter primary vertex is defined as the vertex with the highest scalar sum of the squared transverse momentum of associated tracks with \(p_{\mathrm{T}}>500\) MeV.

Baseline muon candidates are reconstructed in the pseudorapidity range \(|\eta|<2.7\) from Muon Spectrometer tracks matching Inner Detector tracks. They are required to have \(p_{\mathrm{T}}>10\,\mathrm{GeV}\), to be within \(|z_{0}\sin\theta|<0.5\) mm of the hard-scatter primary vertex and to satisfy the _Medium_ identification requirements defined in Ref. [53]. For signal muons, \(p_{\mathrm{T}}>25\,\mathrm{GeV}\) is required. Finally, the track associated with the signal muon must have \(|d_{0}|/\sigma(d_{0})<3\).

Signal electrons and muons are also subject to isolation criteria. Electrons with \(p_{\mathrm{T}}<200\,\mathrm{GeV}\) or \(p_{\mathrm{T}}>200\,\mathrm{GeV}\) must pass the _Loose_ or _HighPtCaloOnly_ isolation working point requirements defined in Ref. [52], respectively. Muons are required to pass the _Loose_ isolation working point requirements defined in Ref. [54], using the 'variable radius' variant defined therein.

Baseline hadronic jets are reconstructed from a combination of topological clusters of energy in the calorimeter and tracker information -- using the Particle Flow algorithm [55] and the anti-\(k_{t}\) jet clustering algorithm [56] as implemented in the FastJet package [57], with a radius parameter \(R=0.4\). The reconstructed jets are then calibrated by the application of jet energy scale corrections derived from 13 TeV data and simulation [58]. Only baseline jet candidates with \(p_{\mathrm{T}}>20\,\mathrm{GeV}\) and \(|\eta|<4.5\) are considered. After calibration and reconstruction, jets are filtered further to'signal' jets using the jet vertex tagging (JVT) algorithm to select those originating from the hard-scatter, as detailed in Ref. [59]. Signal jets are associated to the hard-scatter interaction by requiring a JVT score greater than 0.5 for jets with \(p_{\mathrm{T}}<60\,\mathrm{GeV}\) and \(|\eta|<2.4\). Signal jets are also required to have \(|\eta|<2.8\). For signal jets with \(|\eta|>2.5\) and \(p_{\mathrm{T}}<120\,\mathrm{GeV}\), pile-up suppression is achieved through the forward jet vertex tagger (fJVT) [60, 61], which exploits topological correlations between jet pairs. Signal jets are required to have fJVT \(<0.4\). For reconstructing \(p_{\mathrm{T}}^{\mathrm{miss}}\), the JVT, fJVT and \(p_{\mathrm{T}}\) requirements depend on the working point used. A \(b\)-tagging algorithm is applied to jets with \(p_{\mathrm{T}}>20\,\mathrm{GeV}\) and \(|\eta|<2.5\), to identify those likely to have originated from a \(b\)-quark. The DL1 algorithm described in Ref. [62] is used, with a 77% efficiency working point.

The reconstructed baseline analysis objects serve as inputs for the \(p_{\mathrm{T}}^{\mathrm{miss}}\) calculation which is detailed in Ref. [1]. Reconstruction of missing transverse momentum consists of two parts. The so-called _hard_ term is built from hard, calibrated objects possibly identified in the detector: electrons, muons, hadronically decaying taus and jets. This selection is analysis dependent and in the studies presented in this note only electrons, muons and jets are considered4. Tracks not assigned to a reconstructed object but associated with the hard-scatter vertex, and jets with a \(p_{\mathrm{T}}<20\GeV\) are added via the _soft_ term. Several \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points are defined to optimise the performance in different environments.

The definitions of the working points used in this study are listed in Table 2, and are distinguished by their requirements on jets entering the \(p_{\mathrm{T}}^{\mathrm{miss}}\) calculation. In addition to varied requirements on the transverse momentum of the jets, different requirements are placed on the JVT and fJVT variables, which are designed to reject jets originating from pile-up whilst retaining hard-scatter jets. Other hard objects entering the \(p_{\mathrm{T}}^{\mathrm{miss}}\) calculation (electrons and muons) are identical for each working point. Each working point is optimal for different event topologies. For example, Figures 2(a) and 2(b) show the root-mean-square (RMS) of the difference between the reconstructed \(p_{\mathrm{x,y}}^{\mathrm{miss}}\) values of each \(p_{\mathrm{T}}^{\mathrm{miss}}\) working point and generator-level \(p_{\mathrm{x,y}}^{\mathrm{miss}}\) (\(p_{\mathrm{x,y}}^{\mathrm{miss,\;True}}\)) from the simulated samples for \(t\bar{t}\) and \(Z\to\mu\mu\) events (with the selections described below), respectively. The RMS is shown in bins of the number of primary vertices (\(\mathrm{N_{PV}}\)), which is a metric for the level of pile-up activity. For low pile-up \(t\bar{t}\) events, the _Loose_ working point has the best-performing RMS, as it has the most inclusive jet selection. For \(Z\to\mu\mu\) events, which contain fewer jets, the _Tenacious_ working point has the best RMS as its stricter jet selections allow improved rejection of pile-up jets without rejecting jets from the hard scatter.

For the purpose of training the network, no specific requirements are added to select for the process topologies considered. When testing the performance of the network on different processes however, further requirements are placed on events to refine the final state considered for each process. When testing METNet on \(t\bar{t}\) events, leptonic decays of the top are preferred to obtain a final state with sources of real \(p_{\mathrm{T}}^{\mathrm{miss}}\). Thus at least one signal lepton is required, along with at least two signal jets, exactly two of which are \(b\)-tagged. When testing METNet on \(Z\to\mu\mu\) events, exactly two signal muons are required, along with a veto on the presence of any additional baseline leptons. The two signal muons must be oppositely charged and have an invariant mass within \(\pm 15\GeV\) of the \(Z\)-boson mass. The highest-\(p_{\mathrm{T}}\) muon is set to be over the single-muon-trigger efficiency plateau, by requiring \(p_{\mathrm{T}}>30\GeV\). When testing METNet on \(ZZ\to\nu\nu\ell\ell\), the same event selections are made as for \(Z\to\mu\mu\)  but also allowing two signal electrons instead of two signal muons. When testing METNet on \(WW\to\ell\nu\ell\nu\), two oppositely charged signal leptons with \(p_{\mathrm{T}}>25\GeV\) are required, with a veto on the presence of any additional baseline leptons.

To study the performance of METNetSig, a selection is applied to pick out the SUSY signal topology. Exactly two signal muons are required as we only consider the \(Z\to\mu\mu\) background (not \(Z\to ee\)), along with a veto on the presence of additional baseline leptons. The highest \(p_{\mathrm{T}}\) muon is set to be over the single-muon-trigger efficiency plateau, with a small loss of signal acceptance, by requiring \(p_{\mathrm{T}}>27\GeV\). There must be no \(b\)-tagged jets, and a maximum of one light-flavour signal jet. The two muons must be oppositely charged and have an invariant mass at least \(\pm 15\GeV\) away from the \(Z\)-boson mass.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & & \multicolumn{2}{c}{Sections} \\  & \(p_{\mathrm{T}}\) [GeV] for jets with: & & fJVT for jets with \\ Working point & \(|\eta|<2.4\) & \(2.4<|\eta|<4.5\) & JVT for jets with \(|\eta|<2.4\) & \(2.5<|\eta|<4.5\) and \(p_{\mathrm{T}}<120\GeV\) \\ \hline _Loose_ & \(>20\) & \(>20\) & \(>0.5\) for \(p_{\mathrm{T}}<60\GeV\) jets & - \\ \hline _Tight_ & \(>20\) & \(>30\) & \(>0.5\) for \(p_{\mathrm{T}}<60\GeV\) jets & \(<0.4\) \\ \hline _Tighter_ & \(>20\) & \(>35\) & \(>0.5\) for \(p_{\mathrm{T}}<60\GeV\) jets & - \\ \hline _Tenacious_ & \(>20\) & \(>35\) & \(>0.91\) for \(20<p_{\mathrm{T}}<40\GeV\) jets & \(<0.5\) \\  & & & \(>0.59\) for \(40<p_{\mathrm{T}}<60\GeV\) jets & \\  & & & \(>0.11\) for \(60<p_{\mathrm{T}}<120\GeV\) jets & \\ \hline \hline \end{tabular}
\end{table}
Table 2: Jet selections for the \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points used in this study.

## 4 Neural network architecture

### Input and target features

The NN receives 60 event variables as input features, including:

1. \(p_{\text{T}}^{\text{miss}}\) predictions and unique jet- and soft- terms for each working point (see Table 3).
2. Lepton \(p_{\text{T}}^{\text{miss}}\) terms (see Table 4). These terms are independent of the working point used.
3. Additional variables which characterise the pile-up and topology of each event (see Table 5).

Input features for both training and testing data are passed through two pre-processing steps:

1. Rotate each event such that \(p_{\text{T}}^{\text{miss, Tight}}\) points along the x-axis by construction. This removes \(\phi\) invariance from the inputs, increasing the statistical power of the training data.
2. Standardise each input and output variable by subtracting the mean and dividing by the standard deviation. This is standard practice for deep learning regression problems.

The NN's outputs are transformed by the inverse of these steps to produce the final METNet prediction. This rotation pre-processing step renders the variables \(p_{\text{x}}^{\text{miss, Tight}}\) and \(p_{\text{y}}^{\text{miss, Tight}}\) redundant, hence they are not included in the training. Additionally, soft \(p_{\text{T}}^{\text{miss}}\) terms for the _Tight_ working point are excluded, as this resulted in improved performance on test data.

The desired output for the NN is a prediction for (\(p_{\text{x}}^{\text{miss}}\), \(p_{\text{y}}^{\text{miss}}\)), so the variables (\(p_{\text{x}}^{\text{miss, True}}\), \(p_{\text{y}}^{\text{miss, True}}\)) are used as target values during training. Alternative target variables have also been tested, including (\(p_{\text{T}}^{\text{miss, True}}\), \(p_{\text{\phi}}^{\text{miss, True}}\)) and \(\left(\frac{p_{\text{T}}^{\text{miss, Tight}}}{p_{\text{T}}^{\text{miss, True}}},p_{\text{\phi}}^{\text{miss, True}}\right)\). Targeting (\(p_{\text{x}}^{\text{miss}}\), \(p_{\text{y}}^{\text{miss}}\)) results in the best performing network overall.

### METNet network architecture

METNet uses a multi-layer perceptron network consisting of an input and output layer, plus three fully connected hidden layers, each with 100 nodes. Each hidden layer uses the Scaled Exponential Linear Unit (SELU) activation function [63] and layer normalisation [64], and the output layer uses a linear activation function. This architecture is summarised in Table 6 along with additional network hyperparameters. These hyperparameters have been selected through a combination of hyperparameter scans and known best-practice for regression problems, though there may be scope for further hyperparameter optimisation. Training is performed with Keras [65] using the TensorFlow backend [66].

The network's parameters are determined during training by minimising a loss function. Loss functions are defined separately for the x- and y-components of \(p_{\mathrm{T}}^{\mathrm{miss}}\) which are then averaged to obtain an overall loss function. Results for two choices of the loss function are presented here:

\[\mathcal{L}=\mathcal{L}_{\mathrm{Huber}} \tag{1}\]

and

\[\mathcal{L}=\mathcal{L}_{\mathrm{Huber}}+\mathcal{L}_{\mathrm{Sinkhorn}}. \tag{2}\]

\begin{table}

\end{table}
Table 6: METNet neural network achitecture and hyperparameters.

\begin{table}

\end{table}
Table 5: Additional input variables.

Here \(\mathcal{L}_{\text{Huber}}\) is the Huber loss function [69], given by

\[\mathcal{L}_{\text{Huber}}=\left\{\begin{array}{ll}\frac{1}{2}(y-\hat{y})^{2}&, \quad|y-\hat{y}|\leq\delta\\ \delta|y-\hat{y}|-\frac{1}{2}\delta^{2}&,\quad\text{otherwise}\end{array}\right. \tag{3}\]

where \(y\) is \(p_{x,y}^{\text{miss, True}}\), and \(\hat{y}\) the NN's predicted value. The \(\delta\) hyperparameter is set to the Keras default value, \(\delta=1.5\).

\(\mathcal{L}_{\text{Sinkhorn}}\) is the Sinkhorn distance [70] between the output and target batch, which is a regularised form of the Wasserstein distance between two distributions. This term is included to reduce an observed bias in the distribution of the NN's predictions, which is discussed further in Section 5.

To reduce a bias in the NN's predictions towards the bulk of the \(p_{\text{T}}^{\text{miss}}\) training data, \(\mathcal{L}_{\text{Huber}}\) is calculated as a weighted average over the events in each batch. The weight for each event is equal to the reciprocal of the \(p_{\text{T}}^{\text{miss, True}}\) histogram of the training set, up to \(p_{\text{T}}^{\text{miss, True}}=300\text{ GeV}\). Events with \(p_{\text{T}}^{\text{miss, True}}>300\text{ GeV}\) receive the same weight as events with \(p_{\text{T}}^{\text{miss, True}}=300\text{ GeV}\). Similarly, events with \(p_{\text{T}}^{\text{miss, True}}<50\text{ GeV}\) receive the same weight as events with \(p_{\text{T}}^{\text{miss, True}}=50\text{ GeV}\). The weights are then scaled such that the average weight for all samples is equal to 1.

### Training and testing data

The NN must see a variety of topologies during training in order to generalise well.

The training set includes a mixture of \(t\bar{t}\), \(ZZ\to\nu\nu\ell\ell\) and \(WW\to\ell\nu\ell\nu\) events -- topologies which produce real \(p_{\text{T}}^{\text{miss}}\). Topologies with no real \(p_{\text{T}}^{\text{miss}}\), such as \(Z\to\ell\ell\), are excluded from the training set, as they were found to introduce a severe bias towards zero in the NN's predictions.

The NN is trained on about 3 million events of which about half are from \(t\bar{t}\), while the remaining 30% and 20% of events originate from \(ZZ\) and \(WW\) processes, respectively. These events do not have MC generation event weights applied, nor are they weighted to account for their cross-sections. 90% of these events are used to actually train the network's parameters, while the remaining 10% form a validation set. The loss for the validation set is evaluated after each training epoch to monitor overtraining. Training proceeds for 32 epochs or until the loss of the validation set does not improve for 20 consecutive rounds.

The results in Sections 5 and 6 are produced by evaluating the network on independent test MC datasets, which were not seen by the NN during training.

### METNetSig network architecture

In order to define a \(p_{\text{T}}^{\text{miss}}\) significance, the NN must produce a 'confidence' measure along with a \(p_{x,y}^{\text{miss}}\) prediction. To achieve this, the Huber loss function is replaced with the Gaussian negative log likelihood (GNLL) loss [71, 72],

\[\mathcal{L}_{\text{GNLL}}=\log\sigma+0.5\left(\frac{y-\hat{y}}{\sigma}\right) ^{2} \tag{4}\]

where \(y\) is \(p_{x,y}^{\text{miss, True}}\) and \(\hat{y}\) the NN's predicted value as before, and \(\sigma\) is an additional output variable which represents the network's confidence. This is combined with \(\mathcal{L}_{\text{Sinkhorn}}\) to give the overall loss function

\[\mathcal{L}=\mathcal{L}_{\text{GNLL}}+\mathcal{L}_{\text{Sinkhorn}}. \tag{5}\]A separate loss calculation is performed for the x and y components of \(p_{\mathrm{T}}^{\mathrm{miss}}\), which are averaged to produce a final loss value. Each event's contribution to \(\mathcal{L}_{\mathrm{GNLL}}\) is weighted, with weights calculated via the same procedure described in Section 4.2.

The resulting NN has 4 outputs: \((p_{\mathrm{x}}^{\mathrm{miss,\;NN}},\;\sigma_{x},\;p_{\mathrm{y}}^{\mathrm{ miss,\;NN}},\;\sigma_{y})\). From these outputs, METNetSig is defined as

\[\mathrm{METNetSig}=p_{\mathrm{T}}^{\mathrm{miss,\;NN}}/\sigma \tag{6}\]

where

\[p_{\mathrm{T}}^{\mathrm{miss,\;NN}}=\sqrt{(p_{\mathrm{x}}^{\mathrm{miss,\;NN} })^{2}+(p_{\mathrm{y}}^{\mathrm{miss,\;NN}})^{2}} \tag{7}\]

and

\[\sigma=\frac{\sqrt{(p_{\mathrm{x}}^{\mathrm{miss,\;NN}}\sigma_{x})^{2}+(p_{ \mathrm{y}}^{\mathrm{miss,\;NN}}\sigma_{y})^{2}}}{p_{\mathrm{T}}^{\mathrm{miss, \;NN}}}. \tag{8}\]

It has been verified that \(\sigma\) produces the correct quantiles. For example, approximately 73% (96%) of test \(t\bar{t}\) events have \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) within the 1\(\sigma\) (2\(\sigma\)) window around \(p_{\mathrm{T}}^{\mathrm{miss,\;NN}}\).

The event rotation and output variable standardisation pre-processing steps are not performed when using the log likelihood loss. The input variables are still standardised as described previously. Other than these changes, the METNetSig NN architecture is the same as that used for METNet.

## 5 METNet: comparison with current \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points

### Resolution

Figure 1 shows the root-mean-square (RMS) of the \(p_{\mathrm{x}}^{\mathrm{miss}}\) and \(p_{\mathrm{y}}^{\mathrm{miss}}\) distributions once \(p_{\mathrm{x}}^{\mathrm{miss,\;True}}\) and \(p_{\mathrm{y}}^{\mathrm{miss,\;True}}\), respectively, have been subtracted, both with and without the Sinkhorn loss. This quantity measures the resolution of the \(p_{\mathrm{T}}^{\mathrm{miss}}\) more accurately than a Gaussian fit since despite an approximately Gaussian core, the distribution tails are non-gaussian. The RMS is shown binned in \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) for (a) \(t\bar{t}\) and (b) \(WW\to\ell\nu\ell\nu\) test MC events. Each event enters the plot twice, once for the component in the x direction and once for the component in the y direction. Due to the rotational symmetry of the detector the resolutions in x and y are expected to be similar. For \(t\bar{t}\) events METNet has superior resolution to the \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points across the entire range of \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\). Including the Sinkhorn loss (Eq. 2) results in a slightly improved performance at high \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\), and a slight decrease in performance at low \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\). For \(WW\to\ell\nu\ell\nu\) events, the inclusion of the Sinkhorn loss decreases the performance of METNet at high \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\).

Figure 2 shows the equivalent plots in bins of number of primary vertices, for (a) \(t\bar{t}\) events, (b) \(Z\to\mu\mu\) events. For both topologies METNet is more stable against pile-up. \(Z\to\mu\mu\) is a topology which was not seen by the NN during training and which contains no real \(p_{\mathrm{T}}^{\mathrm{miss}}\). METNet generalises well to this new topology, with improved RMS compared to current \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points. It was observed that removing diboson events from the training set degrades METNet's performance on \(Z\to\mu\mu\) test events. Similarly, the inclusion of \(t\bar{t}\) events in training allows the network to generalise well to single-top events. Hence, including a reasonably wide range of SM processes in the training allows the network to generalise to other processes that have not been seen, indicating that a single network could be used by a wide variety of ATLAS searches and measurements.

### Bias and tails

The aim is to have a calibrated \(p_{\mathrm{T}}^{\mathrm{miss}}\) reconstruction such that there is not any bias towards higher or lower values for a given value of \(p_{\mathrm{T}}^{\mathrm{miss,\,True}}\), due to e.g. unbalanced training data. Figure 3(a) shows the \(p_{\mathrm{T}}^{\mathrm{miss}}\) distribution for METNet (both with and without the Sinkhorn loss), \(p_{\mathrm{T}}^{\mathrm{miss,\,True}}\) and four \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points, for \(t\bar{t}\) events. Without the Sinkhorn loss, the METNet \(p_{\mathrm{T}}^{\mathrm{miss}}\) distribution is biased towards zero. This can also be seen in Figure 4, which shows the response (\(p_{\mathrm{T}}^{\mathrm{miss}}/p_{\mathrm{T}}^{\mathrm{miss,\,True}}\)) as a function of \(p_{\mathrm{T}}^{\mathrm{miss,\,True}}\) for (a) \(t\bar{t}\), (b) \(WW\to\ell\nu\ell\nu\), (c) \(ZZ\to\nu\nu\ell\ell\) and (d) \(\bar{\ell}^{+}\bar{\ell}^{-}\to\ell^{+}\ell^{-}\bar{\chi}_{1}^{0}\bar{\chi}_{ 1}^{0}\) events. For METNet, the response dips

Figure 1: Root-mean-square of the difference between the predicted value of \(p_{\mathrm{x,y}}^{\mathrm{miss}}\) and \(p_{\mathrm{x,y}}^{\mathrm{miss,\,True}}\) in bins of \(p_{\mathrm{T}}^{\mathrm{miss,\,True}}\). METNet is shown with and without the Sinkhorn (Sk) loss, along with current \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points for (a) \(t\bar{t}\) events, (b) \(WW\to\ell\nu\ell\nu\), events. The lower panel shows the ratio with respect to the _Tight_ working point, and the hatched band indicates the statistical uncertainty for the _Tight_ working point.

Figure 2: Root-mean-square of the difference between the predicted value of \(p_{\mathrm{x,y}}^{\mathrm{miss}}\) and \(p_{\mathrm{x,y}}^{\mathrm{miss,\,True}}\) in bins of number of primary vertices. METNet is shown with and without the Sinkhorn (Sk) loss, along with current \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points for (a) \(t\bar{t}\) events, (b) \(Z\to\mu\mu\) events. The lower panel shows the ratio with respect to the _Tight_ working point, and the hatched band indicates the statistical uncertainty for the _Tight_ working point.

below one between \(20\GeV<p_{\mathrm{T}}^{\mathrm{miss,\;True}}<100\GeV\) for \(t\overline{t}\), \(WW\to\ell\nu\ell\nu\) and \(ZZ\to\nu\nu\ell\ell\) events, which indicates a negative bias. Including the Sinkhorn loss improves both the response and the agreement of the METNet distribution with \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) for \(t\overline{t}\) events. Also, the closure in Fig. 4(d) is particularly notable as the \(\tilde{\ell}^{+}\tilde{\ell}^{-}\to\ell^{+}\ell^{-}\tilde{\chi}_{1}^{0}\tilde {\chi}_{1}^{0}\) topology was not seen by the network during training. Note that in all cases the response rises as \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) approaches 0 by the way the variable is constructed.

For METNet including the Sinkhorn loss some deterioration of performance in the tail of Fig. 3(a) is observed with respect to the variant without. This likely originates from the Sinkhorn loss mainly penalizing deviations in the bulk of the target distribution, and limited training statistics at large \(p_{\mathrm{T}}^{\mathrm{miss}}\). Additionally, since training sample weights are calculated using the \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) histogram up to \(p_{\mathrm{T}}^{\mathrm{miss}}=300\GeV\), METNet underestimates \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) beyond \(p_{\mathrm{T}}^{\mathrm{miss}}=300\GeV\).

For \(Z\to\mu\mu\) events (Fig. 3(b)), the METNet distribution has a reduced fake-\(p_{\mathrm{T}}^{\mathrm{miss}}\) tail. The \(p_{\mathrm{T}}^{\mathrm{miss}}>60\GeV\) tail contains 0.9% of events for the _Tight_ working point, compared to 0.5% and 0.4% for METNet and METNet (Sk) respectively. The number of \(Z\to\mu\mu\) events with large reconstructed \(p_{\mathrm{T}}^{\mathrm{miss}}\) is reduced by the NN reconstruction, however, it is not clear how much of this improvement is caused by the small negative bias.

Overall, METNet has improved agreement with \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) for a range of topologies. The inclusion of the Sinkhorn contribution to the loss function reduces an observed bias in the NN's \(t\overline{t}\) predictions.

## 6 METNetSig: comparison with object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance

To evaluate the performance of different \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance definitions, the rejection of background events which are expected to have less real \(p_{\mathrm{T}}^{\mathrm{miss}}\) than the signal is evaluated in the context of an analysis searching for supersymmetry [10]. Figure 5 compares the signal-to-background separation power of (a) METNetSig and (b) object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance [9]. The distributions are shown for the supersymmetric signal process described in Section 2, alongside some of the main backgrounds present in the search from Ref. [10]: \(Z\to\mu\mu\) and \(WW\to\ell\nu\ell\nu\) with the kinematic selections described in Section 3. The lower pad shows the

Figure 3: \(p_{\mathrm{T}}^{\mathrm{miss}}\) distribution for METNet (with and without the Sinkhorn loss), \(p_{\mathrm{T}}^{\mathrm{miss,\;True}}\) and four \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points, for (a) \(t\overline{t}\) and (b) \(Z\to\mu\mu\) events. Events are unweighted.

signal significance, as defined in Ref. [73], which approximates the sensitivity to the SUSY signal model for a lower-bound cut at each value on the x-axis. The overall shape of METNetSig for each topology is similar to object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance, but with a lower cut-off point. A maximum significance of \(Z=10.6\) is achieved for METNetSig, compared to \(Z=12.2\) for object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance. Therefore the separation power of METNetSig is similar to object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance.

As a quantative comparison of the performance of object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance and METNetSig Table 7 shows the percentage of \(WW\to\ell\nu\ell\nu\) and \(\bar{\ell}^{+}\bar{\ell}^{-}\to\ell^{+}\ell^{-}\bar{\chi}_{1}^{0}\bar{\chi}_{ 1}^{0}\) events surviving cuts which remove 90-99.9% of \(Z\to\mu\mu\) events, for object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance and METNetSig. METNetSig has similar ability to reject fake \(p_{\mathrm{T}}^{\mathrm{miss}}\). Even these very preliminary results show a promising separation between the different processes, showing that METNetSig is achieving its goal of distinguishing between real and fake \(p_{\mathrm{T}}^{\mathrm{miss}}\).

Figure 4: Response of the predicted \(p_{\mathrm{T}}^{\mathrm{miss}}\) for METNet and four current \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points in different event topologies that contain sources of real \(p_{\mathrm{T}}^{\mathrm{miss}}\) in the final state: (a) \(t\bar{t}\), (b) \(WW\to\ell\nu\ell\nu\), (c) \(ZZ\to\nu\nu\ell\ell\) and (d) a SUSY benchmark signal considering slepton pair production.

## 7 Conclusion

This note documents the performance of METNet and METNetSig compared to current \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points and object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance. These variables are calculated from outputs of a neural network trained on \(p_{\mathrm{T}}^{\mathrm{miss}}\)-terms for four established working points for \(p_{\mathrm{T}}^{\mathrm{miss}}\) reconstruction, in addition to variables that characterise event topology. The resulting METNet variable studied has significantly improved resolution and pile-up resilience for a range of topologies, including those not seen during training, compared to current \(p_{\mathrm{T}}^{\mathrm{miss}}\) working points. A negative bias is observed in the NN's predictions, which is reduced by including a Sinkhorn contribution to the loss function. Further performance improvements can be expected in the future, for example by further optimising the training variables to include track-based \(p_{\mathrm{T}}^{\mathrm{miss}}\)[1], and increasing training statistics.

The approach of training the NN to directly output the \(p_{\mathrm{x}}^{\mathrm{miss}}\) and \(p_{\mathrm{y}}^{\mathrm{miss}}\) components of \(p_{\mathrm{T}}^{\mathrm{miss}}\), rather than just the magnitude of the two-vector, allows a much greater flexibility of application. Widely-used variables such as the transverse mass \(m_{\mathrm{T}}\) can be calculated using the NNs outputs, in addition to the magnitude of the 2-vector, opening the potential for the NN's improved resolution and pile-up resilience to be beneficial

Figure 5: Distributions of \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance for the supersymmetric signal point and \(WW\) and \(Z\to\mu\mu\) backgrounds, for (a) METNetSig and (b) object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance. Events are weighted to \(36.2\,\mathrm{fb}^{-1}\), corresponding to the 2015+2016 ATLAS proton–proton collision dataset luminosity. The lower plot shows signal significance calculated by applying a lower-bound cut at each x-axis bin value.

in more contexts.

The NN's confidence can additionally be used to define a machine learning-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance variable METNetSig  which shows similar behaviour per-topology to object-based \(p_{\mathrm{T}}^{\mathrm{miss}}\) significance. Although the current implementation of METNetSig performs slightly worse than the object-based variable for the tested signal topology, it remains a promising approach as its performance can be expected to improve further with more optimisation and training statistics.

In summary, the studies in this note indicate potential to significantly improve \(p_{\mathrm{T}}^{\mathrm{miss}}\) resolution using machine learning techniques.

## References

* [1] ATLAS Collaboration, _Performance of missing transverse momentum reconstruction with the ATLAS detector using proton-proton collisions at \(\sqrt{s}=13\,\text{TeV}\)_, Eur. Phys. J. C **78** (2018) 903, arXiv: 1802.08168 [hep-ex] (cit. on pp. 2, 4, 13).
* [2] ATLAS Collaboration, _The ATLAS Experiment at the CERN Large Hadron Collider_, JINST **3** (2008) S08003 (cit. on p. 2).
* [3] ATLAS Collaboration, _Search for a heavy charged boson in events with a charged lepton and missing transverse momentum from \(pp\) collisions at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, Phys. Rev. D **100** (2019) 052013, arXiv: 1906.05609 [hep-ex] (cit. on p. 2).
* [4] ATLAS Collaboration, _Search for squarks and gluinos in final states with one isolated lepton, jets, and missing transverse momentum at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, Eur. Phys. J. C **81** (2021) 600, arXiv: 2101.01629 [hep-ex] (cit. on p. 2).
* [5] C. Lester and D. Summers, _Measuring masses of semi-invisibly decaying particles pair produced at hadron colliders_, Phys. Lett. B **463** (1999) 99, arXiv: hep-ph/9906349 [hep-ph] (cit. on p. 2).
* [6] A. Elagin, P. Murat, A. Pranko and A. Safonov, _A new mass reconstruction technique for resonances decaying to \(\tau\tau\)_, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment **654** (2011) 481 (cit. on p. 2).
* [7] ATLAS Collaboration, _Cross-section measurements of the Higgs boson decaying into a pair of \(\tau\)-leptons in proton-proton collisions at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, Phys. Rev. D **99** (2019) 072001, arXiv: 1811.08856 [hep-ex] (cit. on p. 2).
* [8] ATLAS Collaboration, _Search for heavy particles decaying into top-quark pairs using lepton-plus-jets events in proton-proton collisions at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, Eur. Phys. J. C **78** (2018) 565, arXiv: 1804.10823 [hep-ex] (cit. on p. 2).
* [9] ATLAS Collaboration, _Object-based missing transverse momentum significance in the ATLAS Detector_, ATLAS-CONF-2018-038, 2018, url: [https://cds.cern.ch/record/2630948](https://cds.cern.ch/record/2630948) (cit. on pp. 2, 11).
* [10] ATLAS Collaboration, _Search for electroweak production of charginos and sleptons decaying into final states with two leptons and missing transverse momentum in \(\sqrt{s}=13\,\text{TeV}\)\(pp\) collisions using the ATLAS detector_, Eur. Phys. J. C **80** (2020) 123, arXiv: 1908.08215 [hep-ex] (cit. on pp. 2, 3, 11).
* [11] ATLAS Collaboration, _Search for heavy resonances decaying into a \(Z\) boson and a Higgs boson in final states with leptons and \(b\)-jets in \(139\,\text{fb}^{-1}\) of \(pp\) collisions at \(\sqrt{s}=13\,\text{TeV}\) with the ATLAS detector_, ATLAS-CONF-2020-043, 2020, url: [https://cds.cern.ch/record/2728053](https://cds.cern.ch/record/2728053) (cit. on p. 2).
* [12] ATLAS Collaboration, _Search for dark matter produced in association with a dark Higgs boson decaying into \(W^{\pm}W^{\mp}\) or \(ZZ\) in fully hadronic final states from \(\sqrt{s}=13\,\text{TeV}\)\(pp\) collisions recorded with the ATLAS detector_, Phys. Rev. Lett. **126** (2021) 121802, arXiv: 2010.06548 [hep-ex] (cit. on p. 2).