[MISSING_PAGE_EMPTY:1]

## 2 Discrete event simulation with SIMDAQ

### General approach

#### 2.1.1 Objects

For simulation a model of the system to be simulated is needed. The latter will consist of interacting objects. Therefore object-oriented programming provides a natural way to construct software models. In the model all entities in the system to be simulated are represented by objects. In many cases modelling can be done on basis of a hierarchy of objects. For example for modelling a system consisting of PCs, each with a processor board and a network interface, one could construct an object modelling the PC from an object modelling the processor board and an object modelling the network interface. Objects assembled from other objects, "component objects", are referred to as "aggregate objects". Component objects may in turn be aggregate objects. Non-aggregate objects are referred to as "basic objects".

#### 2.1.2 Structure of basic objects

A basic object is modelled as a state machine. Events concerning the object cause transitions in the state machine, may generate new events for the object, and may lead to invocation of member functions of other objects. Each basic object has a function for handling events (the EventHandle method), which is invoked when an event for the object occurs. This is further discussed in Section 2.2.

#### 2.1.3 Instantiation of objects

Objects are coming into existence by instantiation. A straightforward approach for instantiation of aggregate objects is to cause automatic instantiation of the component objects. In the example of Section 2.1.1 instantiation of the object modelling the PC would lead to instantiation of the objects modelling the CPU board and the network interface. When an object is instantiated, its constructor function, if defined, is called. In the constructor other objects can be instantiated. In the constructor of an aggregate object the component objects can be instantiated. When the component objects are also composite objects, their component objects can be instantiated in their constructors, etc.. It may be necessary for a component object to access data members or to invoke function members of its parent object. This is made possible by means of a data member of the component object pointing to the parent object, which is set in the constructor of the aggregate object after instantiation of the component object.

#### 2.1.4 Interactions between the objects

The interaction between two objects is modelled on the basis of calling a member function of one of the objects from a member function of the other object, and vice versa. It is desirable to have the possibility to specify the interactions at the level of the aggregate objects, without the need to specify explicitly in the code objects of which member functions need to be invoked. For example for modelling the system mentioned in Section 2.1.1 at the level of the PCs only specification of the connections between PCs and a switch to which they connect should be necessary. An event causing a change of state in a network interface of one of the PCs may lead to an interaction with one of the switch ports, so at the level of these objects it should be known which of these objects interact with each other.

The interaction pattern can be established using pointers to the basic objects of which member functions should be invoked. These pointers are set on the basis of a specification in a configuration file.

#### Level of detail of the models

The choice of the level of detail of the models is critical : too much detail results in complicated models and long simulation times, while not enough detail will result in inaccurate results. In SIMDAQ the hardware details of processors are in most cases taken into account by means of software execution times obtained or estimated from benchmarking (and specified in the configuration file). In all cases the software running on a processor is modelled as consisting of a multi-priority multi-tasking kernel and of as many processes as required. The process with the lowest priority can be a polling process of which the execution is interrupted if a higher priority process becomes executable. For communication links it is assumed that a complete message or packet has a transfer time depending only on the link speed and the number of bytes in the message or packet.

#### Including new objects

With a straightforward procedure new classes implementing new models can be added to the program. Apart from code implementing a new model code for a number of methods has to be provided. These methods are necessary for configuration of the simulated system and for setting the parameters as specified in the configuration file. The name of a new class also needs to be registered in the program, so that it can be referred to in the configuration file.

#### Support for different network models

All network connections are assumed to be point-to-point connections between a pair of ports. The type of port determines the network model used. With the procedure outlined in the previous section a new network model can be supported by adding new classes for ports and switches to the program. As processors connect to switches the type of switch can be used to determine the type of port(s) to be used for connecting the processors. This is done by the program, so that the network technology is determined by specification of the type of switch in the configuration file. Values of parameters associated with the network technology (e.g. link transfer speed) can be read in from the configuration file.

### The mechanism of discrete event simulation

#### Principle

Simulation is done on the basis of events (not to be confused with events due to particle interactions, observed in an experiment and in this document referred to as "physics events") occurring at certain simulation times and of determining of the response of the simulated system to each event. The response may consist of the generation of new events at the same simulation time as the original event occurred or at future simulation times. This type of simulation is called discrete event simulation. It can be efficiently implemented on the basis of a so-called "event list". Data structures representing the events are stored in the list in an order determined by the (simulation) times at which they should occur. They are inserted in the list by the actions of the simulated objects. The data structure will contain (i) the simulation time at which the event should occur, (ii) an identifier from which the action to be caused at the occurrence of the event can be derived (a pointer to an object), and (iii) additional information. It should be noted that events caused by one object may lead to events for and state transitions in another object. Hence, if for each entity to be simulated a separate event list is maintained it will be necessary (for a meaningful simulation) to scan all event lists for the earliest event. Therefore the use of a single global event list is to be preferred.

#### 2.2.2 Implementation

In its simplest form, a single global event list can be maintained in C++ as a linked list of data structures representing the events. The events in the list are ordered with respect to the times at which they should occur. Events are retrieved from the head of the queue. The memory space used for the event data structure should be released after returning from the event handler. New events are inserted in the queue by calling a function with as arguments at least the time of occurrence and a pointer to the object that should handle the event. The function allocates memory for a new event data structure and determines after which entry it should be inserted in the list. The use of pointers to objects requires that either all objects belong to the same class, or that their classes are derived from the same class. The first requirement in general cannot be satisfied, hence all classes have to be derived from a single class (in SIMDAQ this is the BasicTDAQObject class). The main loop of a simulation program will have the structure shown in Figure 1. For a further discussion on implementation issues with respect to efficiency and functionality see [5], [6] and [7].

### Input and output of the program

#### 2.3.1 The configuration file

Specification of the system configuration is done in terms of so-called "high-level" objects that are connected to each other via "ports" connecting to point-to-point links. A high-level object can have an arbitrary number of ports. Each high-level object is identified with three items :

* the name of the class of the object,
* the name of the "system part" (ROBIns and ROBOuts associated with different subdetectors, the processor farm and the supervisor all are associated with different system parts) with which the object is associated,
* a number.

Figure 1: Basic structure of the main loop of a discrete event simulation program. The event list is implemented as an object with name List. RetrieveEvent() is a member function of this object.

High-level objects usually are aggregate objects. In the configuration file the composition of aggregate objects cannot be specified directly (although their composition can be controlled with suitable parameters).

The specification of the configuration is done in three steps :

* Definition of the high level objects used in the system model,
* Specification of the values of certain parameters,
* Definition of the connections between the objects.

The configuration file format reflects these three steps [7].

While reading the configuration file objects are instantiated, parameters are set, connections between objects are established and routing tables in switches are set up automatically.

#### 2.3.2 The trigger menu file

Each item of the trigger menu is specified in the trigger menu file. The exclusive rate for each item determines the probability that an event will correspond to the item. Also the analysis sequence, the associated acceptance factors and dependencies on acceptance (e.g. of the TRT scan on the acceptance of a muon RoI) are specified in the trigger menu file. The name of the trigger menu file is specified in the configuration file.

#### 2.3.3 The file with the ROBIn Look-Up Tables and information on the LVL1 RoIs

A further input file required by SIMDAQ is a file with the ROBIn Look-Up Tables and information on the LVL1 RoIs. This file can be generated with the "ROBsPerRol" program on the basis of files describing the mapping of the subdetectors onto the ROBIns and files describing the LVL1 RoIs. The ROBIn Look-Up Table provides information on which ROBIns are hit if a RoI of a certain type occurs at a certain position. The information on the LVL1 RoIs consists of the possible RoI positions and of the areas in eta-phi space associated with each of these positions. The latter quantity provides the probability for occurrence of the position associated with the area, as this probability is assumed to be independent of the location of the area in eta-phi space. The "ROBsPerRol" program also provides information on the average number of ROBIns per RoI and per subdetector for the various types of RoIs. This information is used in the paper model studies [4].

#### 2.3.4 Histogram and statistics dump file

Histograms and statistics information can be output in an ASCII file, which also contains a dump of the configuration and menu files to avoid confusion with respect to the configuration and trigger menu used for generating the results. This file can be generated on request if the GUI is used, it is also possible to write a file each time a certain number of LVL2 decisions have been generated or only once at the end of a simulation run. In the configuration file the number of decisions and the name of the file to be generated can be specified. A sequence number is added to the name if more than one file will be written.

The histograms in the dump file can be displayed with the "histoview" program, which makes use of the same GUI as SIMDAQ itself. It is also possible to copy the data from single histograms into a Microsoft Excel spreadsheet for further analysis and display. The histograms in this note have been produced in this way.

The statistics information consists of an overview of minima, average and maxima for a number of quantities like event fragments stored in the ROBIn buffer memories and in other buffers, data volumes passing through ports, message rates for ports and processor occupancies for algorithm execution and for task switching. All these quantities can be compared to results obtained from the paper model. For this purpose the statistics information can be copied to a spreadsheet that is coupled to the paper model spreadsheet. The tables with comparison results presented in this note have been obtained in this way.

### Representation of physics event data and generation of physics events

Each physics event is represented by a number of objects storing relevant event information. There is one "EventData" objects representing the event itself, for each RoI there is an individual "RoIInfo" object, with which for each subdetector a "FEXInfo" object is associated, for which per ROBIn an "EventFragInfo" object is associated. These objects are also used for storing time stamps (indicating e.g. start of sending RoI data by the ROBIn, arrival of this data in the farm processor, etc.). Messages are always represented in the program with "MessageInfo" objects, which contain a pointer to an "EventFragmentInfo" object. Conditionally compiled debugging code added to the "MessageInfo" and "EventFragmentInfo" classes ensures that incorrect use of these objects is detected. With this debugging code bugs can be and have been found which are otherwise very hard to trace, as their effect usually shows up in obscure ways and long after the erroneous use.

Physics events are generated on the basis of the information contained in the trigger menu file and the file with the ROBIn Look-Up Tables and information on the LVL1 RoIs. The rates for the various trigger items specify the relative probability of occurrence of the trigger items. For each event with the help of a random number generator one of the items is picked. The number of RoIs is then known as well as the processing sequence. With the help of the acceptance factors and again of the random number generator the processing sequence for the event considered is then determined. The positions of the LVL1 ROIs are chosen taking into account the probability for each possible position (see Section 2.3.3). Correlations between positions of different RoIs hence are not taken into account. With the help of the ROBIn Look-Up Tables for each step it is determined which ROBIns need to send data to the LVL2 system. With the information thus obtained all objects representing the physics event data are requested from their respective object stores1, after which processing of the event starts.

Footnote 1: In view of efficiency reasons objects that can be deleted are returned to another object (the “object store”) that stores these objects and makes them available on request. New objects are instantiated by the object store if an object is requested and no objects are available. In this way dynamic memory allocation and deallocation is avoided as much as possible.

### GUI and supported platforms

The program uses a modified version of SUIT (the "Simple User Interface Toolkit" from the University of Virginia) [8] as platform independent GUI, supporting UNIX/Linux, Windows and MacOS environments. This GUI has been modified to provide support for on-line display of histograms. Histogram contents can be dumped to file in ASCII format (see Section 2.3.4) at regular intervals (determined by the number of physics events handled, as specified in the configuration file) and / or by means of a clicking a button when the program is running with the GUI enabled. It is possible to switch the GUI off for batch processing.

Versions of SIMDAQ for UNIX machines, for MacOS and for Windows95/98 or Windows NT are available [3]. Most of the source code is the same for the various platforms. Development tools used are CodeWarrior Pro 5.2 (MacOs and Windows), Visual C++ (Windows) and gcc / egcs (UNIX). Project files or makefiles (for UNIX) are included in the distribution.

## 3 The model and associated parameters

### System model

An overview of the pilot project model of the system architecture and the data streams is presented in Figure 2. The model is the same as in [4], apart from the aspects that do not play a role in the paper model.

Data from the subdetector RODs (not shown in the figure) are transferred to the ROBIns through Read Out Links (ROLs), each ROBIn servicing one ROL. The total number of ROBIns is 1530. For the simulations reported in this note the RODs have been handled in a simplified way in view of efficiency reasons. It has been assumed that the data from the RODs arrives simultaneously and immediately after the LVL1 trigger at the inputs of the ROBIns. This is done by broadcasting the events (via a special "switch" with one input port and many output ports, which copies MessageInfo objects received via the input port to all output ports) from one "ROD" per subdetector to all ROBIns of that subdetector. Of course the RODs can be simulated individually. However, for each LVL1 trigger all 1530 RODs in the model need to generate and handle simulation

Figure 2: System architecture : baseline model.

events, which has a considerable impact on the execution time of the program. From the results obtained can be concluded that the simplifying assumption described is justified.

ROBIns are connected either to the LVL2 network or to a ROBOut. Every ROBOut has an individual link to the LVL2 network, the Event Builder (EB) network is connected to the ROBIns. It is also possible to use the LVL2 network for passing accepted events to a farm of Event Filter processors. The LVL2 _supervisor_ consists of a number of processors receiving RoI information from the LVL1 system. The RoI information for an event is passed to one of these processors. This processor assigns a _LVL2 processor_ to that event and sends it the RoI information. For the results presented in this document it has been assumed that each supervisor processor is associated with a separate partition of the LVL2 processor farm. From the LVL2 processors the supervisor processor receives back the trigger decisions, forms blocks of decisions and sends (broadcasts) these blocks to all ROBIns and ROBOuts connected to the LVL2 network. The LVL2 processors each have an individual network connection. All the LVL2 control messages and all of the LVL2 data transit through a single bi-directional _network switch_.

The processing in the Event Filter is ignored in the baseline model. In all simulation runs the accepted event data is passed to a farm of 512 Event Filter processors, either via a separate store and forward crossbar switch connected to the ROBIns as mentioned above or via the switch also used for the LVL2 traffic. For the results presented in this document it has been assumed that the LVL2 Supervisor processor dealing with the event assigns one of the Event Filter processors to the event after the event is accepted by the LVL2 system (see also the discussion in Section 4.1.3). Each Supervisor processor is assumed to be associated with a separate partition of the Event Filter processor farm, in the same way as it is associated with a separate partition of the LVL2 processor farm.

### Physics information and processing strategies

Two trigger menus are used, a low luminosity menu and a high luminosity menu. These menus consist of a number of trigger items defining the LVL1 RoIs together with exclusive rates and are specified in [9]. For both menus the LVL1 trigger rate is approximately 40 kHz. Results have also been obtained for a LVL1 trigger rate of 75 kHz. In that case the exclusive rates for each item are scaled, with the exception of the rates associated with the B-physics trigger (the scan of the TRT data and associated analysis of data from the SCT and pixels), and the accept rates. The rates of these items are kept constant, as has been done for paper modelling [4]. Also the event building rate is kept constant at 5 % of the nominal LVL1 rate.

For each trigger item of a trigger menu the processing strategy has to be determined. The most straightforward strategy is to request from the ROBIns all data associated with the LVL1 RoI. However, the bandwidth and processing requirements may be reduced considerably if the data is analyzed in steps and for each step the data needed for that step is requested. After each step an accept or reject decision is taken. In the present note the two variants of this trigger strategy described in [4] are considered :

* In the _sequential strategy_ all data required from the electromagnetic calorimeter is requested in one step. RoIs are handled independent of each other. However, for low luminosity the TRT scan depends on validation of at least one muon RoI.
* In the _fully sequential strategy_ the data required from the electromagnetic calorimeter is requested per layer and processed sequentially for em and for muon RoIs. This is possible as each ROBIn receives a part of a layer. Furthermore the processing of data from a RoI may depend on the processing of data from another RoI (e.g. an event triggered as 2 * EM 15I menu of the low luminosity menu may be rejected if the first EM15I RoI is not confirmed, as there is no trigger item with a single EM15I RoI, so that there is no need to confirm the second EM15I RoI). In this note the results are only for the "approximate fully sequential strategy" of [4], i.e. only for items with relatively high rates and for which the strategy is relevant this strategy has been used.

For the low luminosity B-physics trigger, if a muon is confirmed, the data from the TRT is scanned, followed by track finding in the SCT/Pixel detectors. The processing sequence of [4] is assumed :

* All data of the TRT, SCT and pixels is requested after validation of at least one muon RoI (probability : 40 % per LVL1 muon RoI). This is done in two steps : first the data of the TRT is requested and only when the data from all TRT ROBIns has been received the data from the SCT and Pixels is requested, while at the same time processing of the TRT data can start. In this way a delay of the start of processing of the TRT data due to queueing of fragments from the SCT and Pixels in front of TRT fragments in the output buffers of the switch (see also the next section) is avoided,
* The scan followed by track finding in the SCT/Pixel detectors generates always two muon RoIs for which data from the muon detectors and the calorimeters are requested.

For further information on menus, processing sequences and acceptance factors see [4]. In [4] also further information on possible positions of the LVL1 RoIs, sizes of LVL2 RoIs, ROBIn mapping and average event fragment sizes can be found. All event fragment sizes have been assumed to be constant, although this can only be justified for data from the calorimeters. Also the number of RoIs generated by the TRT scan and associated analysis of the data from the SCT and Pixels has assumed to be constant. It is foreseen that distributions will be used in future work.

### Component models and parameters

The component models and parameters follow the decisions of the Amsterdam modelling meeting of January 1999 [10][4]. The LVL2 trigger algorithm execution times have been extrapolated to 1000 MIPS CPUs, i.e. current top-of-the-line commodity PCs. Per network link a bandwidth of 15 MByte/s is assumed. All execution times are assumed to be constant. Also here it is foreseen that distributions will be used in future work, for which support is available in SIMDAQ.

For the LVL2 switch and the EB switch, if present, a single store and forward crossbar switch is assumed with infinite size buffers in the input and in the output ports and with arbitration on access to the output ports. The bandwidth of a single internal connection is specified in the configuration file. Values of 15, 30, 60 or 120 MByte/s have been used, as well as an infinite bandwidth. The switch is assumed to support multi-casting. A multi-cast transfer can only start if access to all output ports participating in the multi-cast is possible. Once the multi-cast is started it is assumed that the data is flowing in parallel from one of the input ports via crossbar connections to all the output parts involved. A further assumption made is that traffic in one direction inside the switch is independent of traffic in the opposite direction. This allowed to implement the model of a single bi-directional switch with two uni-directional switches1.

The program supports switch fabrics assembled from up to three layers of switches. Routing of messages in a fabric via an alternative route if possible and if an earlier attempted route is blocked is also supported. Models for ports supporting subdivision of messages into packets are part of the program as well as a switch model supporting routing of packets. Also with the latter switch model fabrics can be assembled from up to three layers of switches. For the results presented in this note models of switch fabrics and packet switching have not been used. However, for further work based on more realistic models of switching technologies the models mentioned can be expected to provide a good starting point.

## 4 Results

### High luminosity

#### 4.1.1 Overview of simulation conditions and of results on ROBIn buffer sizes and farm occupancies

Results have been obtained for a number of different choices made for processing and processor assignment strategies and for some of the parameters. Table 1 and Table 2 contain an overview. The possible assignment strategies are either round-robin (labeled with "rr") or "least-queued" (labeled with "lq"). Each supervisor processor only assigns processors within the farm partition associated with it (see Section 3.1). For the "least-queued" strategy for each farm processor the number of events assigned to it and for which not yet a decision has received is stored by the supervisor processor1. For each assignment to be made the farm processor with the least number of events assigned is chosen. The processing strategies are either non-sequential ("nseq"), sequential ("seq") or fully sequential ("fseq"), see Section 3.2. The maximum number of fragments found to be buffered at any time in the ROBIns is specified in the column labeled with "minimum ROBIn buffer size". This number is a measure for the average decision time (due to the averaging over the twenty decisions in a single decision block) and is almost the same (differences of a few fragments are seen) for all ROBIns. The required size of the buffer memory can be found by multiplying with the largest fragment size, which is 1800 Bytes (for the calorimeters). The largest difference between largest and smallest event id of event fragments stored at the same time in the ROBIn memory is contained in the column labeled with "ROBIn buffer size for cyclic buffer". This number is a measure for the maximum LVL2 decision time, by multiplying with the maximum fragment size the minimum size of a ROBIn buffer memory implemented as cyclic memory without fragmentation management can be found. The tables also contain the maximum number of fragments seen in any of the input buffers and any of the output buffers of the switch.

Footnote 1: Ports in the program are uni-directional, so two ports are needed for modelling a bi-directional network interface. If required, handshaking between a single sending and a single receiving port is possible.

The figure numbers in the tables refer to numbers of figures in Section 4.1.2 containing distributions of the LVL2 decision time. The LVL2 decision time is defined as the time interval between generation of an event and the arrival of the decision in one of the supervisor processors. Section 4.1.3 contains a discussion of the results.

[MISSING_PAGE_EMPTY:11]

#### 4.1.2 LVL2 decision time distributions

Figure 4: Sequential processing, round-robin assignment, 60 MByte/s per crossbar connection

Figure 5: Sequential processing, round-robin assignment, pre-processed calorimeter data, infinite bandwidth crossbar connections

Figure 3: Sequential processing, round-robin assignment, infinite bandwidth crossbar connectionsFigure 8: Non-sequential processing, round-robin assignment, pre-processed calorimeter data, 60 MByte/s per crossbar connection

Figure 6: Sequential processing, round-robin assignment, pre-processed calorimeter data, 60 MByte/s per crossbar connection

Figure 7: Sequential processing, round-robin assignment, pre-processed calorimeter data, 30 MByte/s per crossbar connection

Figure 11: Sequential processing, least-queued assignment, 60MByte/s per crossbar connection

Figure 10: Sequential processing, least-queued assignment, infinite bandwidth crossbar connections

Figure 9: Sequential processing, round-robin assignment, pre-processed calorimeter data, 120 MByte/s per crossbar connection, network used for LVL2 data \(+\) data for EF

Figure 12: Sequential processing, least-queued assignment, pre-processed calorimeter data, infinite bandwidth crossbar connections

Figure 13: Sequential processing, pre-processed calorimeter data, least queued assignment, 60 MByte/s per crossbar connection

Figure 14: Sequential processing, pre-processed calorimeter data, least queued assignment, 30 MByte/s per crossbar connection

Figure 16: Non-sequential processing, pre-processed calorimeter data, least queued assignment, 60 MByte/s per crossbar connection

Figure 17: Sequential processing, least-queued assignment, infinite bandwidth crossbar connections, network used for LVL2 data + data for EF

Figure 15: Fully sequential processing, pre-processed calorimeter data, least queued assignment, 60 MByte/s per crossbar connection

Figure 19: 75 kHz LVL1 rate, sequential processing, least queued assignment, 60 MByte/s per crossbar connection

Figure 20: 75 kHz LVL1 rate, sequential processing, pre-processed calorimeter data, least queued assignment, 60 MByte/s per crossbar connection

Figure 18: Sequential processing, pre-processed calorimeter data, least queued assignment, infinite bandwidth crossbar connections, network used for LVL2 data \(+\) data for EF

#### 4.1.3 Discussion

Figure 3, Figure 4, Figure 5 and Figure 6 show that for round-robin assignment changing the bandwidth per crossbar connection in the switch from 60 MByte/s to infinite bandwidth only has a small effect. However, reducing the data volume from the calorimeter has a large impact. The occupancy of the links into the farm without pre-processing is about 80 %, with it about 50 %. From Table 1 it can be seen that the maximum number of event fragments in the output buffers of the switch is about 1.5 times larger without than with pre-processing. Histograms with distributions for the transfer time across the network show longer transfer times if no pre-processing is applied than with pre-processed data. Also histograms with distributions for the time interval between event generation and the start of sending RoI data by the ROBIns show a much longer tail without than with pre-processing, see Figure 21 and Figure 22 for examples. This is caused by late sending of RoI requests, which is due to several effects :

* The limited bandwidth of the network links causes delays in the arrival of messages in the farm,
* The messages are output by the switch in the order of arrival in the output buffers, the order being determined by the operation of the switch. Hence the messages may not be queued in the order implied by the time at which they are input to the switch. The result could be that processing in the farm is delayed even further than would be the case without this effect,
* For sequential processing only after completion of a processing step new RoI requests may be generated. As the processing step can be delayed by late arrival of input data (and / or high processor utilization), these new RoI requests can also be delayed, resulting in late arrival in the ROBIns and hence to late sending of RoI data,
* Messages with RoI information sent by the supervisor are transferred to the farm processors via the same switch output buffers as event fragments which may cause a delay in the arrival of these messages and therefore delayed generation of RoI requests for the first sequential step.

All these effects become less important if the link utilization is lower and if the processor assignment strategy does take into account the number of events assigned to each processor. Figure 23 shows distributions for this number with and without pre-processing for 60 MByte/s crossbar connections and for round-robin assignment.

Figure 21: Time interval between time of generation of an event and sending of em /hadron RoI data by the Pixels ROBIns (left) and the em calorimeter ROBINs (right) without pre-processing of the calorimeter data for sequential processing, round-robin assignment and 60 MByte/s crossbar connections. Em /hadron RoI requests for the Pixels ROBIns only are sent after confirmation of the calorimeter data (two steps for em RoIs and one step for hadron RoIs)Figure 7 shows that the behavior of the model also for 30 MByte/s crossbar link bandwidth and for pre-processed calorimeter data is about the same as for infinite bandwidth crossbar connections.

Figure 8 shows for non-sequential processing with pre-processing, with an high utilization (87 %) of the links into the farm, a better behavior of the decision time distribution than for sequential processing with pre-processing, with a link utilization of 80 %. This can be attributed to the absence of the effect of RoI requests arriving late in the ROBIns due to a delayed start of processing steps generating these RoI requests. The distributions presented in Figure 24 also suggest this. Figure 8 shows that the decision time distribution starts at larger decision times than for sequential processing. This is explained by the fact that all RoI data has to be collected and analyzed before a decision is taken.

Figure 23: Number of events assigned to a farm processor at the time that a new assignment to that processor just has been made for round-robin assignment without (left) and with (right) pre-processing for sequential processing, round-robin assignment and 60 MByte/s crossbar connections

Figure 22: Time interval between time of generation of an event and sending of em /hadron RoI data by the Pixels ROBIns (left) and the em calorimeter ROBINs (right) with pre-processing of the calorimeter data for sequential processing, round-robin assignment and 60 MByte/s crossbar connections. Em /hadron RoI requests for the Pixels ROBIns only are sent after confirmation of the calorimeter data (two steps for em RoIs and one step for hadron RoIs)

Figure 9 shows that already with 120 MByte/s crossbar connections interference occurs between RoI data and data to be sent to the Event Filter. In Table 1 can be seen that the maximum number of fragments in any of the input buffers is much larger than without data for the Event Filter. The start of the decision time distribution is quite different from that in Figure 3 - Figure 8, where the queueing in the output buffers of the switch predominantly causes late arrival of RoI requests. Here it can take a relatively long time for data output by the ROBIns to be transferred across the switch, as the transfer inside the switch to an output port of a message at the head of an input queue has to wait till access to that output port is possible. Hence all later messages are blocked. In particular for traffic for the Event Filter this is an important effect, as in the model the data from 921 sources has to flow to a single destination. The arrival of RoI data in the farm and therefore the sending of RoI requests after the first step in sequential processing may considerably be delayed, see Figure 25. This figure also shows that requests of RoI data for the first processing step are not delayed. This is as expected as the messages sent by the supervisor processors cannot be blocked in the input buffers of the switch by data to be passed to the Event Filter. The time required for event building is almost the same as for infinite bandwidth connections inside the switch, for which blocking of data in the input buffers of the switch does not occur, see Figure 27 and the discussion on Figure 17. This is due to the many sources participating in sending data for the same event to the Event Filter, while any order of arrival of the fragments from different ROBIns is allowed.

Figure 10 and Figure 11 show that "least queued" assignment has a positive effect on the decision time distribution, while Figure 12, Figure 13 and Figure 14 show that reduction of the sizes of the calorimeter event fragments results in even shorter decision times. With pre-processing of the calorimeter data there is almost no queueing, without pre-processing about 70 % of the events is assigned to a processor to which already one or two other events were assigned, see Figure 26. The smaller event fragment size for the calorimeter results in smaller transfer times which, in particular for the jet RoIs, for which tens of fragments have to be collected1, are considerably larger than the feature extraction time2. The "shoulder" seen clearly in Figure 10 and

Figure 24: Time interval between time of generation of an event and sending of em /hadron RoI data by the Pixels ROBIns (left) and the em calorimeter ROBIns (right) with pre-processing of the calorimeter data for **non**-sequential processing, round-robin assignment and 60 MByte/s crossbar connections

Figure 11 is caused by these jet RoIs. Due to the reduction in fragment size from 1832 to 1056 Bytes the "shoulder" in Figure 12, Figure 13 and Figure 14 does extend only to about half the decision time as observed without pre-processing. Again the bandwidth per crossbar connection of the switch does not matter much as long as it is 60 MByte/s or higher. For 30 MByte/s a relatively small effect is seen.

_Figure 25. Time interval between time of generation of an event and sending of em/hadron RoI data by the Pixels ROBIns (left) and the em calorimeter ROBIns (right) with pre-processing of the calorimeter data for sequential processing, round-robin assignment and 120 MByte/s crossbar connections. Em /hadron RoI requests for the Pixels ROBIns only are sent after confirmation of the calorimeter data (two steps for em RoIs and one step for hadron RoIs)_

Figure 15 shows that "fully sequential processing" in combination with pre-processing and "least queued" assignment results in an even narrower decision time distribution than observed for sequential processing under the same conditions. In Table 1 can be seen that the utilization of the input links for the farm and of the farm processors is considerably lower than for sequential processing, allowing to use a much smaller farm. In the case of non-sequential processing the utilizations are much higher, but, as can be seen in Figure 16, the "least-queued" assignment strategy limits their effect, see also Figure 8 for results for non-sequential processing in combination with round-robin assignment and the discussion on the results shown in this figure.

_Figure 26. Number of events assigned to a farm processor at the time that a new assignment to that processor just has been made for "least-queued" assignment without (left) and with (right) pre-processing and infinite crossbar link bandwidth_

2. 1.33 ms per RoI, in this time about to 11 fragments of 1832 Bytes can be transferred over a 15 MByte/s link Figure 17 shows a situation in which a bottleneck occurs. The horizontal scales now extend to 400, resp. 20 ms, while in the other figures this was 125, resp. about 10 ms. In this case RoI data to be transferred to the LVL2 processor farm and data for the Event Filter have to pass via the same links into the switch. Without pre-processing the output links of some of the em calorimeter ROBOuts run close to the bandwidth limit. The transmission of RoI data can be delayed by data for the Event Filter. This will result in long decision times. Oscillations of the average decision time could occur, as longer average decision times will cause a reduction in the number of decisions generated per second and hence in the number of accepted events per second, which in turn will cause less data to be sent to the Event Filter, so that RoI data will suffer less delay and more decisions per second can be produced. More data will then need to be sent to the Event Filter and the transmission of RoI data will again be delayed. It could be that the semi-oscillatory behavior seen in the decision time distribution is caused by this effect.

Figure 18 shows that the problem disappears if the bottleneck is removed by pre-processing the calorimeter data. This figure also shows that the transmission of data for the Event Filter and of RoI data do not interfere with each other for infinite bandwidth crossbar connections. However, Figure 9 shows that already with 120 MByte/s crossbar connections interference occurs, leading to delayed transmission of RoI data, as already mentioned. Figure 27 shows the event building time with 120 MByte/s and with infinite bandwidth crossbar connections. As can be seen the event building process is not disturbed at all. These distributions are also seen if the data for the Event Filter is passed via a separate network. However, in earlier work distributions with a very long tail have been observed. It has been found that this was caused by the method of Event Filter processor assignment : an event was assigned to an Event Filter processor at the same time that it was assigned to a LVL2 farm processor. A round-robin assignment strategy was used. This is a good strategy for event building with fixed size fragments (which are used in the simulations discussed), however, most of the events are rejected by the LVL2 system (95 % for the nominal LVL1 rate). This results in an appreciable probability for accepted events to be sent to the same destination at about the same time, causing the long tail in the event building time. Hence the assignment should only be made for accepted events. This has been done for the simulations reported in this note and with the 512 processors assumed no contention is observed, as is clear from figure 23. The length of the event building time is predominantly determined by the link bandwidth of 15 MByte/s : the whole event has to pass via such a link to the Event Filter processor, so for an event size of 2.2 MByte (for high luminosity) 150 ms is required, as has been found.

Figure 27: Event building time for 120 MByte/s (left) and infinite bandwidth (right) crossbar connections if data for the Event Builder is passed through the LVL2 switch.

Figure 19 shows the consequences of trying to run the links into the processor farm at the high utilization of more than 98 %, resulting in a relatively large maximum for the number of fragments in the switch output buffers (the horizontal scales in the figure are 400 resp. 20 ms in stead of 125 resp. about 10 ms used in other figures). Figure 20 shows that with somewhat more spare bandwidth (at maximum 93% used in stead of more than 98 %) and with pre-processed calorimeter data the problem is solved, even with a reduced number of 132 in stead of 192 processors (as 3 supervisor processors are needed for handling the 75 kHz LVL1 rate 132 - divisible by 3 - rather than 128 processors have been used). In Table 2 it can be seen that the maximum number of fragments in the switch output buffers is almost halved with respect to the number found if the calorimeter data is not pre-processed.

For the results presented in Table 1 the minimum ROBIn buffer memory size for the nominal LVL1 rate is about 400 kByte (for 1800 Byte fragments), corresponding to a time interval of 5 ms. For a cyclic buffer memory at minimum about 2 MByte is required and the corresponding maximum of the decision time plus the time required for transferring the decisions to the ROBIns in decision blocks with a size of 20 plus the time required for processing the decisions by the ROBIns is 30 ms. For 75 kHz LVL1 rate, see Table 2, the minimum ROBIn buffer size would be 1.5 MByte (corresponding to a time interval - indicating the average decision time - of 11 ms) and for a cyclic buffer memory at minimum 6.5 MByte (corresponding to a time interval - indicating the maximum decision time - of 50 ms) would be required. Figure 28 shows distributions for the number of fragments stored in the buffer memory obtained by histogramming for each event passing through the ROBIn the number of fragments stored. These distributions show the effect of averaging over the 20 decisions contained in the decision block.

Figure 28: Number of event fragments stored in the em calorimeter ROBIns, sampled at the arrival of each event in the ROBIn for sequential processing, 60 MByte/s crossbar connections and round-robin assignment (left) or “least-queued” assignment (right)

[MISSING_PAGE_FAIL:24]

[MISSING_PAGE_EMPTY:25]

Figure 31: Sequential processing, pre-processed calorimeter and TRT data, round-robin assignment, 60 MByte/s per crossbar connection

Figure 32: Sequential processing, pre-processed calorimeter and TRT data, round-robin assignment, 120 MByte/s per crossbar connection, network used for LVL2 data \(+\) data for EF

Figure 30: Sequential processing, round-robin assignment, 60 MByte/s per crossbar connection

Figure 31: Sequential processing, pre-processed calorimeter and TRT data, round-robin assignment, 60 MByte/s per crossbar connection

Figure 33: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, infinite bandwidth crossbar connections

Figure 34: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, 60 MByte/s per crossbar connection

Figure 35: Sequential processing, pre-processed calorimeter and TRT data, least queued assignment, 60 MByte/s per crossbar connection

Figure 36: Sequential processing, pre-processed calorimeter and TRT data, least queued assignment, 30 MByte/s per crossbar connection

Figure 37: Sequential processing, least queued assignment + least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 60 MByte/s per crossbar connection

Figure 38: Sequential processing, least queued assignment + least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 30 MByte/s per crossbar connection

Figure 41: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter data (no pre-processed TRT data), infinite bandwidth crossbar connections

Figure 40: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, infinite bandwidth crossbar connections

Figure 39: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 15 MByte/s bandwidth per crossbar connection

Figure 42: **Fully sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 60 MByte/s bandwidth per crossbar connection**

Figure 43: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 120 MByte/s per crossbar connection, network used for LVL2 data \(+\) data for EF

Figure 44: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 60 MByte/s bandwidth per crossbar connection, fast scan, 400 processor farm

Figure 45: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 60 MByte/s bandwidth per crossbar connection, fast scan, 450 processor farm

Figure 46: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 60 MByte/s bandwidth per crossbar connection, fast scan, 500 processor farm

Figure 47: 75 kHz LVL1 rate, sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 60 MByte/s bandwidth per crossbar connection

Figure 45: Sequential processing, least queued assignment \(+\) least queuing of events with at least one muon RoI, pre-processed calorimeter and TRT data, 60 MByte/s bandwidth per crossbar connection, fast scan, 450 processor farm

#### 4.2.3 Discussion

Many aspects of the results discussed in this section are similar to the high luminosity results, for a more detailed discussion of these aspects see Section 4.1.3.

Figure 29, Figure 30 and Figure 31 show that the round-robin processor assignment strategy causes decision times longer than 400 ms. The maximum decision time can be estimated from Table 3 from the ROBin buffer size required for a cyclic buffer : this is about 50,000 events, corresponding to about 1250 ms. The decision time distribution is about the same for a 60 MByte/s or an infinite bandwidth per crossbar connection, as well as with or without pre-processing of the data. In contrast to the high luminosity case the processor occupancy is high. This determines the queueing in the system. The round-robin assignment strategy in combination with the variations in processing time (which are considerably larger than for high luminosity triggering, due to the B-physics trigger) causes queueing in the input and output buffers in the switch and in the processors, see also the left part of Figure 48. The small peaks in the distribution of Figure 31 seem to be separated by a time interval equal to the length of one round-robin cycle of 768 * 25 = 19 ms.

Figure 32 shows that sending data for the Event Filter via the switch has some effect, however, the general shape of the decision time distribution does not dramatically change. The start of the distribution shows, as also observed for high luminosity, that the transmission of data to the Event Builder interferes with the transmission of RoI data. The histogram for the event building time consists of a peak of a single channel at the time expected (125 ms), so the transmission of RoI data does not interfere with the transmission of data to the Event Filter.

Figure 33 and Figure 34 show the effect of the "lqm" assignment strategy : the long tail of the decision time distribution has disappeared, the maximum decision time is now about 250 ms in stead of more than 1 s. Figure 35 and Figure 36 show the effect of "least-queued" processing in combination with pre-processing. The horizontal scale for the left distributions extends to 200 ms in stead of to 400 ms in the previous figures. These figures show a prominent peak between 60 and 65 ms. The peak is due to events for which the B-physics trigger (i.e. TRT scan, track finding in SCT and Pixels and generation of two muon RoIs) is run. Figure 37 and Figure 38 show the effect of the "lqm" assignment strategy in combination with pre-processing. By comparing to Figure 35 and Figure 36 it is seen that avoiding assigning events with at least one muon

Figure 48: Number of events assigned to a farm processor at the time that a new assignment to that processor just has been made for round-robin assignment without pre-processing (left) and “lqm” assignment with pre-processing (right) and 60 MByte/s crossbar connectionsRoI to the same processor has a further positive effect. However, the "least queued" assignment in combination with pre-processing and without the additional complication of the "lqm" assignment strategy may provide sufficient suppression of queueing. The right part of Figure 48 shows that the with the "lqm" assignment strategy almost complete suppression of queueing is possible.

Figure 38 and Figure 39 show that lower values of the bandwidth of the crossbar connections have clearly a negative effect on the LVL2 decision time distribution. This is due to transfers between input and output ports inside the switch taking more time. Queueing in the input ports then becomes important : output ports will be unavailable for transfers during a longer time, the arbitration on access to the output ports may delay more often transfers out of the input buffers, so that also event fragments queued in these buffers but to be passed to output ports that can accept new output data are blocked. In Table 3 it is seen that in particular for 15 MByte/s crossbar connections the maximum number of fragments queued in the input buffers of the switch is large compared to the numbers for higher values for the bandwidth of a crossbar connection. For 15 MByte/s crossbar connections data flows inside the switch into an output port as fast as it flows into the link connecting to the port. However, the variation in fragment sizes causes that up to 20 fragments may need to be queued in the output buffers (as a large fragment may be in transit on the link, while smaller fragments arrive inside the switch).

Figure 33, Figure 40 and Figure 41 show what the impact is of pre-processing if infinite bandwidth crossbar connections are used (the horizontal scale of Figure 33 extends to 400 ms, in the other figures to 200 ms). A large effect from pre-processing the calorimeter data is seen. It may be possible to use pre-processed calorimeter data only, which could be an advantage in view of the simple method of pre-processing (consisting of selection of the first 1024 Bytes of a block of 1800 Bytes) compared to the more complicated pre-processing of the TRT data.

Comparison of Figure 42 and Figure 37 shows that the effect of fully sequential processing in combination with the "lqm" assignment strategy and with pre-processing is small relative to sequential processing under the same conditions. The difference in LVL2 processor utilization and farm input link utilization is also small, see Table 3.

Figure 43 shows the effect of interference between traffic for the Event Filter and RoI data to be passed to the LVL2 processors for 120 MByte/s crossbar connections. Queueing in the input buffers of the switch causes delays in the transmission of RoI data, for the event building process this effect has a very small impact.

Figure 44, Figure 45 and Figure 46 show the effect of reducing the execution time of the TRT scan to 10 % of the nominal value (27.8 ms), in combination with farm sizes of 400, 450 and 500 processors. For a farm size of 400 processors the processor occupancy is about 90 % (see Table 3). The results shown in Figure 45 and Figure 46 clearly show the effect of the reduced processor occupancy (80 % or 72 % for 450 or 500 processors).

Figure 47 shows results for 75 kHz LVL1 rate which are similar to results obtained for the nominal LVL1 rate, although more queueing in the system occurs as can be seen from the decision time distribution. The similarity is explained by the B-physics trigger rate which is kept constant for both rates.

For the results presented in Table 3 and Table 4 it is seen that the minimum ROBIn buffer memory size at the nominal LVL1 rate is about 1.8 MByte (for 1800 Byte fragments), corresponding to a time interval (indicating the average decision time) of 25 ms. For a cyclic buffer memory at minimum about 9 MByte is required and the corresponding time interval (indicating the maximum decision time) is 130 ms. For 75 kHz rate, see Table 5, the minimum ROBIn buffer size would be 3 MByte (corresponding to a time interval of 23 ms) and for a cyclic buffer memory at minimum 22 MByte (corresponding to a time interval of 160 ms) would be required.

## 5 Comparison of computer and paper model results

In Table 7 (for high luminosity) and Table 8 (for low luminosity) a selection is presented of computer model and of paper model results, with for each result the deviation of the computer model result from the paper model result. All computer model results are for 60 MByte/s per crossbar connection. Most deviations are small with the exception of some minima. However, the paper model results for maxima and minima are lower and upper limits, calculated from sums of a few numbers, where for each the minimum or maximum value was used. The computer model results are consistent with these lower and upper limits. Usually the maxima obtained from the computer model are about the same as the paper model upper limits, the paper model lower limits are in a number of cases considerably lower than the computer model minima.

The tables have been obtained from a spreadsheet which was coupled to the NIKHEF paper model spreadsheet [4] and in which the statistics information from the output files of SIMDAQ was entered. Table 6 contains a specification of the meaning of the labels used in Table 7 and in Table 8.

\begin{table}
\begin{tabular}{|p{56.9pt}|p{284.5pt}|p{284.5pt}|} \hline Component & Label & Description \\ \hline \hline \multirow{4}{*}{ROBIns and ROBOuts} & proc & percentage of time spent on processing \\ \cline{2-3}  & OS & percentage of time spent in task switching \\ \cline{2-3}  & sum & sum of “proc” and “OS” \\ \cline{2-3}  & min & minimum value for “sum” \\ \cline{2-3}  & max & maximum value for “sum” \\ \hline \multirow{3}{*}{ROBIn} & r-out & total message rate output to the LVL2 network* \\ \cline{2-3}  & v-out & the total data volume output to the LVL2 network* \\ \hline \multirow{4}{*}{ROBOOut} & r-in & message rate input from the LVL2 network \\ \cline{2-3}  & v-in & data volume input from the LVL2 network \\ \cline{2-3}  & r-out & message rate output to the LVL2 network \\ \cline{2-3}  & v-out & data volume output to the LVL2 network \\ \hline \multirow{4}{*}{Farm processor} & Rol Form. & time fraction needed for formulation of RoI requests \\ \cline{2-3}  & FEX & time fraction needed for feature extraction \\ \cline{2-3}  & Global & time fraction required for the global step \\ \cline{2-3}  & FEXInput & average number of times per event that the FEX process is invoked \\ \cline{2-3}  & global & average number of times per event that the global process is invoked \\ \cline{2-3}  & output & average number of times per event that the output process is invoked \\ \cline{2-3}  & FEX time per RoI & total FEX processing time summed over all processors for indicated subde- \\ \cline{2-3}  & proc & vector and indicated RoI in seconds per second \\ \hline \multirow{3}{*}{RoI Processor} & proc & percentage of time spent on processing \\ \cline{2-3}  & OS & percentage of time spent in task switching \\ \cline{2-3}  & sum & sum of “proc” and “OS” \\ \hline \multirow{2}{*}{EF Processor} & r-in & input message rate per EF processor \\ \cline{2-3}  & v-in & input data volume per RF processor \\ \hline \end{tabular}
\end{table}
Table 6: Meaning of labels used in Table 7 and in Table 8

*includes messages to be sent to the Event Builder if accepted data flow through the LVL2 network 

[MISSING_PAGE_FAIL:35]

[MISSING_PAGE_FAIL:36]

[MISSING_PAGE_FAIL:37]

[MISSING_PAGE_FAIL:38]

\begin{table}
\begin{tabular}{|c|c||c|c|c||c|c|c|c|c|c|c|c|c|} \hline \multicolumn{2}{|c|}{Comparison of computer and} & \multicolumn{3}{c|}{40.1 kHz LV11 rate} & \multicolumn{3}{c|}{40.1 kHz LV11 rate} & \multicolumn{3}{c|}{40.1 kHz LV11 rate} & \multicolumn{3}{c|}{75 kHz LV11 rate} \\ \multicolumn{2}{|c|}{paper model results} & \multicolumn{3}{c|}{Sequential} & \multicolumn{3}{c|}{Fully Sequential} & \multicolumn{3}{c|}{Sequential, fast scan*} & \multicolumn{3}{c|}{Sequential} \\ \hline \hline Subsystem & Sim & Paper & **\%** & Sim & Paper & **\%** & Sim & Paper & **\%** & Sim & Paper & **\%** & Sim & Paper & **\%** \\ \hline \hline  & proc (\%) & 4.63 & 4.63 & **0.1** & 4.63 & 4.63 & **0.0** & 4.61 & 4.63 & **-0.4** & 6.87 & 6.88 & **-0.1** \\ \cline{2-13}  & OS (\%) & 18.64 & 18.65 & **0.0** & 18.63 & 18.65 & **-0.1** & 18.58 & 18.65 & **-0.3** & 31.49 & 31.54 & **-0.2** \\ \cline{2-13} MuonPreci- & sum (\%) & 23.27 & 23.28 & **0.0** & 23.26 & 23.28 & **-0.1** & 23.20 & 23.28 & **-0.4** & 38.36 & 38.42 & **-0.1** \\ \cline{2-13}  & r-in (kHz) & 4.16 & 4.16 & **0.0** & 4.16 & 4.16 & **-0.1** & 4.15 & 4.16 & **-0.3** & 6.94 & 6.95 & **-0.2** \\ \cline{2-13} ROBOut & v-in (MB/s) & 0.228 & 0.228 & **-0.1** & 0.228 & 0.228 & **-0.2** & 0.228 & 0.228 & **-0.3** & 0.406 & 0.407 & **-0.2** \\ \cline{2-13}  & r-out (kHz) & 2.15 & 2.15 & **0.1** & 2.15 & 2.15 & **0.0** & 2.14 & 2.15 & **-0.4** & 3.19 & 3.20 & **-0.1** \\ \cline{2-13}  & v-out (MB/s) & 1.79 & 1.79 & **0.1** & 1.79 & 1.79 & **0.0** & 1.78 & 1.79 & **-0.4** & 2.66 & 2.66 & **-0.1** \\ \hline \hline  & proc (\%) & 7.41 & 7.40 & **0.1** & 7.40 & 7.40 & **0.0** & 7.37 & 7.40 & **-0.4** & 10.98 & 10.99 & **-0.1** \\ \cline{2-13}  & OS (\%) & 28.24 & 28.24 & **0.0** & 28.23 & 28.24 & **0.0** & 28.13 & 28.24 & **-0.4** & 45.74 & 45.79 & **-0.1** \\ \cline{2-13} MuonTrigig & sum (\%) & 35.64 & 35.64 & **0.0** & 35.63 & 35.64 & **0.0** & 35.50 & 35.64 & **-0.4** & 56.72 & 56.78 & **-0.1** \\ \cline{2-13} ger & r-in (kHz) & 6.56 & 6.56 & **0.0** & 6.56 & 6.56 & **0.0** & 6.53 & 6.56 & **0.0** & 10.50 & 10.51 & **0.0** \\ \cline{2-13} ROBOut & v-in (MB/s) & 0.286 & 0.286 & **-0.1** & 0.286 & 0.286 & **-0.2** & 0.285 & 0.286 & **-0.3** & 0.492 & 0.492 & **-0.1** \\ \cline{2-13}  & r-out (kHz) & 4.55 & 4.55 & **0.1** & 4.55 & 4.55 & **0.0** & 4.53 & 4.55 & **-0.4** & 6.75 & 6.76 & **-0.1** \\ \cline{2-13}  & v-out (MB/s) & 1.88 & 1.88 & **0.1** & 1.88 & 1.88 & **0.0** & 1.87 & 1.87 & **-0.4** & 2.78 & 2.79 & **-0.1** \\ \hline \hline  & proc (\%) & 70.70 & 70.51 & **0.3** & 70.34 & 70.27 & **0.1** & 65.19 & 65.46 & **-0.4** & 73.26 & 73.29 & **0.0** \\ \cline{2-13} Farm : & OS (\%) & 8.66 & 8.64 & **0.2** & 8.44 & 8.44 & **0.0** & 14.69 & 14.74 & **-0.4** & 10.39 & 10.39 & **0.0** \\ \cline{2-13}  & sum (\%) & 79.36 & 79.15 & **0.3** & 78.78 & 78.71 & **0.1** & 79.87 & 80.20 & **-0.4** & 83.65 & 83.68 & **0.0** \\ \cline{2-13} per process & r-in (kHz) & 6.97 & 6.95 & **0.3** & 6.85 & 6.84 & **0.1** & 11.82 & 11.87 & **-0.4** & 7.75 & 7.75 & **0.0** \\ \cline{2-13} sor & v-in (MB/s) & 1.44 & 1.44 & **0.0** & 1.32 & 1.32 & **-0.2** & 2.44 & 2.45 & **-0.4** & 2.23 & 2.24 & **-0.1** \\ \cline{2-13}  & r-out (kHz) & 2.82 & 2.81 & **0.2** & 2.67 & 2.67 & **0.1** & 4.78 & 4.80 & **-0.4** & 3.41 & 3.41 & **0.0** \\ \cline{2-13}  & v-out (MB/s) & 0.034 & 0.034 & **0.0** & 0.031 & 0.032 & **-0.2** & 0.058 & 0.058 & **-0.4** & 0.053 & 0.053 & **-0.1** \\ \hline \hline Farm : & RoI Form. & 0.16 & 0.16 & **0.1** & 0.17 & 0.17 & **-0.1** & 0.27 & 0.27 & **-0.4** & 0.25 & 0.25 & **-0.1** \\ \cline{2-13} \% of time & FEX & 70.25 & 70.06 & **0.3** & 69.88 & 69.81 & **0.1** & 64.42 & 64.69 & **-0.4** & 72.47 & 72.50 & **0.0** \\ \cline{2-13} per CPU & Global & 0.29 & 0.29 & **-0.2** & 0.29 & 0.29 & **-0.1** & 0.49 & 0.50 & **-0.3** & 0.54 & 0.54 & **-0.2** \\ \hline \hline Farm : & FEXinput & 132.5 & 132.0 & **0.4** & 130.0 & 129.9 & **0.1** & 131.8 & 132.0 & **-0.2** & 78.4 & 78.4 & **0.1** \\ \cline{2-13} \# of times & global & 2.07 & 2.07 & **0.1** & 2.29 & 2.29 & **0.1** & 2.07 & 2.07 & **-0.1** & 1.84 & 1.84 & **-0.1** \\ per event & output & 27.49 & 27.45 & **0.1** & 25.28 & 25.31 & **-0.1** & 27.41 & 27.45 & **-0.2** & 22.88 & 22.90 & **-0.1** \\ \hline \hline  & Pix-SCT, em & 0.76 & 0.77 & **-0.5** & 0.70 & 0.70 & **0.4** & 0.76 & 0.77 & **-0.4** & 1.42 & 1.43 & **-0.6** \\ \cline{2-13}  & TRT, em & 0.48 & 0.48 & **-0.5**The consistent deviation in Table 8 of about -0.3 % for the "fast TRT scan" results is probably caused by a statistical fluctuation in the time required for 1,200,000 events to complete LVL2 processing. The averages have been calculated by dividing the sums of e.g. time spent in a process or of the number of messages received by the total time during which the simulation was run. In this particular case the average LVL1 rate obtained was 0.25 % lower than the nominal LVL1 rate, which explains the difference.

## 6 Discussion and conclusions

The excellent agreement between paper and computer model results provides confidence in the correctness of the (different) computation procedures used for both models. With SIMDAQ results with good statistical accuracy can be obtained for the model studied in an acceptable time (10 - 20 hrs per run for 1.2 million LVL1 triggers) on commodity PCs with 64 MByte (for runs with not too much queueing) to 256 MByte (for runs with excessive queueing) of memory.

The current state of SIMDAQ allows simulation of data-flow aspects of the ATLAS LVL2 system and parts of the DAQ system. A more accurate simulation of Event Building is within reach. Results have been obtained for the pilot project architecture on the basis of up-to-date information on trigger menus, detector mapping on the ROBIns, event fragment sizes and algorithm execution and task switching times. This information is incomplete and may need to be updated, in particular with respect to relevant distributions for event fragment sizes and processing times. It is also desirable to estimate the uncertainties in the trigger menus.

Only abstract models have been used for obtaining the results presented in this note. In particular the models of network and switch technology need to be made more realistic. With the help of recent modelling of testbed results, with the facilities available in SIMDAQ for adding new models and with the support already available for switch fabrics and packetizing of messages this should be feasible.

The results obtained so far provide insights in the dynamic behavior of the system modelled and in the required event buffer sizes in the ROBIns. The following conclusions can be drawn :

1. For sequential or fully sequential processing strategy the average decision times are smaller than for non-sequential processing if the processor farm size is kept the same for the different strategies. Fully sequential processing results in lower processing and bandwidth requirements and smaller average decision times than sequential processing, the effect is larger for high luminosity than for low luminosity for the trigger menus used,
2. Queueing of events in the switch and in the LVL2 farm processors has a large impact on the behavior of the system in the model studied, in particular for sequential processing. This is caused by the fact that a processing step has to wait until all input data is available in the processor. After completion of the processing step new RoI requests may be generated. As the processing step can be delayed by queueing causing late arrival of required input data, these new RoI requests can also be delayed, resulting in late arrival of the RoI request in the ROBIns and hence in late sending of RoI data. Furthermore messages with RoI information sent by the supervisor are transferred in the switch via the same output buffers as event fragments, which may cause a delay in the arrival of these messages. It is therefore desirable to minimize the amount of queueing, as is clearly demonstrated by the simulation results obtained. In the context of the model studied several measures are possible to achieve this :

* Applying a good assignment strategy : the "least queued" strategy (and its variant which also avoids to assign more than one event with one or more muon RoIs to a single processor) is a good candidate. It can be implemented on the supervisor processors using only information on the number of events assigned to and the number of decisions received from each farm processor. For its variant, also information on the number of events with a muon RoI assigned to and the number of decisions for those events received from each farm processor is used as input.
* 80 % utilization of LVL2 processor input link bandwidth capacity and LVL2 processor capacity seems prudent. The simulation results show that this is a valid "rule of thumb",
* The method of scheduling processing on the farm processors affects the impact of queueing in the processors. In the model it is assumed that processing of an event continues until a processing step (e.g. feature extraction for a subdetector) is completed. With time-slice scheduling the available processing time could be shared between processing steps for different events, so that long waiting times due to in particular the TRT scan and associated analysis of SCT and Pixels data can be reduced, at the cost of longer average processing times. With small modifications of the SIMDAQ program this scenario can be studied.
3. Without sufficient internal bandwidth in the switch event fragments may be blocked in the input buffers. This effect becomes more important if also Event Builder traffic is flowing through the switch. With sufficient internal bandwidth queueing may still occur in the output buffers of the switch due to a non-optimal processor assignment strategy and / or to high output link utilizations. Messages to be output by the switch are queued in the order of arrival, the order being determined by the operation of the switch. Hence fragments may not be queued in the order implied by the time at which they are output by the ROBIns or ROBOuts. The result could be that processing in the farm is delayed even further than without this effect. It should be remarked that the model used for network link protocol and the switch is simple, for studying the effects mentioned in more detail the use of more realistic models is desirable,
4. The application of pre-processing reduces the bandwidth requirements, while also the processing requirements are somewhat lower (as less data has to be moved) with respect to the requirements if no pre-processing is applied. Results presented in this note for constant farm size with and without application of pre-processing show a favorable effect on the decision time distribution, due to reduced transfer times and less queueing in the switch input and output buffers,
5. ROBIn buffer memory sizes of at minimum about 1.8 MByte (9 MByte for a cyclic memory without fragmentation handling) are required for the models studied for the nominal 40 kHz LVL1 rate. For higher LVL1 rates these numbers increase. With the current trigger menus, processing sequences, acceptance factors and the scaling procedure used it seems reasonable to assume that 4 MByte (32 MByte for cyclic memory) is sufficient for LVL1 rates up to 100 kHz,
6. With sufficient bandwidth per crossbar connection and output links of ROBIns and ROBOuts not running close to their maximum bandwidth LVL2 traffic and Event Builder traffic do hardly interfere with each other if passing through the same switch.

## References

* [1] A.Bogaerts et al., "Modelling of the ATLAS Data Acquisition and Trigger System", Atlas internal note ATL-DAQ-94-018, Nov. 1994
* [2] S. Hunt et al, "SIMDAQ: A System For Modeling DAQ/Trigger Systems", IEEE Trans.Nucl.Sci.43 (1996), 69-73
* [3] [ftp://ftp.nikhef.nl/pub/experiments/atlas/tdaq/simdaq](ftp://ftp.nikhef.nl/pub/experiments/atlas/tdaq/simdaq)
* [4] J. Bystricky, J.C.Vermeulen, "Paper modelling of the ATLAS LVL2 trigger system", Atlas internal note ATL-DAQ-2000-030, April 2000
* [5] J.C.Vermeulen, "Simulation of Data-Acquisition and Trigger Systems in C\(++\)", New Computing Techniques in Physics Research III, ed. K.-H.Becks and D.Perret-Gallix, World Scientific, 1994, 107-112
* [6] J.C.Vermeulen et al., "Discrete Event Simulation of the ATLAS Second Level Trigger", IEEE Trans. on Nucl. Sci, vol. 45, no. 4 (1998), 1989-1993, also available as Atlas internal note ATL-DAQ-98-086, April 1998
* [7]SIMDAQ documentation, available from [3]
* [8] SUIT, [http://www.cs.virginia.edu/~suit/](http://www.cs.virginia.edu/~suit/)
* [9] S.George et al., "RoI-based event descriptions for modelling the ATLAS second level trigger", Atlas internal note ATL-DAQ-99-010, April 1999
* [10] R.Cranfield, F.Wickens, J.Vermeulen: Notes on Pilot Project modelling meeting, NIKHEF, January 27+28, 1999, Amsterdam, [http://www.nikhef.nl/pub/experiments/atlas/daq/Modelling-27-28-1-99.pdf](http://www.nikhef.nl/pub/experiments/atlas/daq/Modelling-27-28-1-99.pdf)