**Supersymmetry Signatures with High-\(p_{T}\) Photons or**

**Long-Lived Heavy Particles**

The ATLAS Collaboration1)

Footnote 1: This note prepared by S. Bressler, K. De, A. Dell’Acqua, W. Ehrenfeld, H. Hayward, J. Haller, S. Hellman, M. Johansen, B. King, O. Jinnouchi, R. Mackeprang. P. Mermod, D. Milstead, P. Nilsson, H. Nomoto, S. Tarem and M. Terwort.

_This note is part of CERN-OPEN-2008-020. This version of the note should not be cited: all citations should be to CERN-OPEN-2008-020._

**Abstract**

In certain Supersymmetry breaking scenarios, characteristic signatures can be expected which would not necessarily be found in generic SUSY searches for events containing high \(p_{\rm T}\) multi-jets and large missing transverse energy. This paper describes the expected response of the ATLAS detector to four signatures: high-\(p_{\rm T}\) photons which may or may not appear to point back to the primary collision vertex and long-lived charged sleptons and \(R\) hadrons. Such processes often have the advantage of small Standard Model backgrounds and their observation could provide unique constraints on the different SUSY breaking scenarios. Using these signatures discovery potentials are estimated for either Gauge-Mediated Supersymmetry Breaking or Split-Supersymmetry scenarios. Using Monte Carlo samples of SUSY and background processes corresponding to integrated luminosity of about 1 fb\({}^{-1}\) we study all aspects of the analysis, including the expected trigger response and offline data reconstruction.

Introduction

Supersymmetry (SUSY) is one of the most widely investigated theories of physics beyond the Standard Model [1, 2, 3, 4]. Searches for signatures of new physics processes predicted within SUSY models are thus central to the physics program of the ATLAS experiment [5], which will be sensitive to the production of SUSY particles with masses up to several TeV [6]. To facilitate the exploitation of early LHC data, a number of preparatory studies have been undertaken by the ATLAS SUSY group to estimate the response of the ATLAS detector to a variety of physics processes and to optimise and test the software which is necessary for the analysis of collider data. As a part of this exercise, the ATLAS SUSY group has performed a number of studies. Techniques to estimate Standard Model backgrounds have been developed [7, 8] and calculations have been made of the discovery potential for generic inclusive SUSY signatures [9], based largely on the minimal SUGRA model [10, 11, 12, 13, 14] for which the principal observables are high-\(p_{\mathrm{T}}\) jets and missing transverse energy. However, there exist a number of SUSY scenarios which predict specific final state topologies which may not be observed by generic searches, such as prompt photons and long-lived stable massive particles. In this work, the response of the ATLAS detector to such signatures is studied and, where appropriate, calculations are made of discovery potentials for early LHC running for which an integrated luminosity of around 1 fb\({}^{-1}\) is assumed. Although the work is performed within the framework of SUSY searches, the techniques which have been developed are more generally applicable to searches for new phenomena.

The theoretical models used in this work are based on the minimal Gauge Mediated Supersymmetry Breaking (GMSB) model [6, 15, 16, 17, 18, 19, 20, 21], the Split-SUSY model [22, 23, 24, 25] and the gravitino LSP model [26]. A description of the models is given in Section 2.1 while specific choices of parameters are found in the sections devoted to each of the studied signatures. Four signatures are investigated and are described below.

**Two high-\(p_{\mathrm{T}}\) photons + \(E_{\mathrm{T}}^{\mathrm{miss}}\)** : In a GMSB scenario in which the next lightest supersymmetric particle (NLSP) is the \(\tilde{\chi}_{1}^{0}\), two high-\(p_{\mathrm{T}}\) photons are expected in each signal event each arising from the decay of a \(\tilde{\chi}_{1}^{0}\) to a \(\tilde{G}\) and photon. Such events with two isolated high-\(p_{\mathrm{T}}\) photons plus large \(E_{\mathrm{T}}^{\mathrm{miss}}\) have small Standard Model backgrounds and a high mass discovery reach is expected even in the early LHC running. In the high mass regime, however, the production cross-section for SUSY events and the signal is of the same order as the instrumental background which includes misidentified photons arising from electrons or jets, and the irreducible background of radiation from leptons. Earlier experiments have exclusions limits of 93 GeV in \(\tilde{\chi}_{1}^{0}\) mass and 167 GeV in \(\tilde{\chi}_{1}^{\pm}\) mass [27].

**Non-pointing photons**: In certain GMSB scenarios, the \(\tilde{\chi}_{1}^{0}\) could be relatively long-lived. When the decay length is comparable to the size of ATLAS inner-detector, high-\(p_{\mathrm{T}}\) photons could enter the electromagnetic calorimeter surface at large incident angles with respect to a pointing direction to the beam interaction point. An estimation of how the photon reconstruction and identification efficiency is degraded for such non-pointing photons is essential in any measurement of the \(\tilde{\chi}_{1}^{0}\) lifetime, which is directly connected to the SUSY breaking scale. Current lower limits on the mass and lifetime are 101 GeV and 5 ns, respectively [28].

**Stable sleptons**: Stable2 heavy charged sleptons appear in certain regions of parameter space in GMSB scenarios. This signature consists of a penetrating charged track. Since interactions with detectors are ionizations only, the observed tracks will look more like muons, except for their higher energy deposition and longer time of flight than muons. The ATLAS muon system provides a time of flight measurement with an excellent time resolution (\(\sigma_{tof}\approx 0.7\)ns) [29], which allows for a precise particle mass measurements for slow particles. Owing to the very high LHC bunch crossing rate, the development of an appropriate triggering scheme is critical to the ensuring the detection of such particles. Previous experiments have provided a lower limit of around 105 GeV in slepton mass [30]

**Stable \(R\) hadrons**: Stable massive supersymmetric hadrons (\(R\) hadrons) are predicted in Split-SUSY models or in the gravitino LSP scenario of SUGRA models [26]. The signature of \(R\) hadrons is similar to that of stable sleptons although multiple nuclear interactions before reaching the muon system lead to characteristic event topologies, such as the appearence of high-\(p_{\rm T}\) tracks in the muon system with no matching track in the inner-detector, or the electric charge flipping between the inner-detector and the muon system. Lower mass limits of around 200 GeV have already been established by other experiments [31].

This paper is organized as follows. Section 2 provides an overview of the different models and a description of the Monte Carlo datasets which were used in this work. Sections 3-6 describe the studies of signatures described above. Finally, a conclusion is given in Section 7.

## 2 Overview of the SUSY models and Monte Carlo datasets

The signal Monte Carlo data samples used in this paper are based on the specific supersymmetry breaking scenarios. These models are described in Section 2.1. Some technical details and parameter values used in individual datasets are summarized in Section 2.2. Common background samples are used which are described in the introduction to this chapter [32]. In some cases, fast simulation (ATLFAST-I [33]) samples are also used when estimating the background contributions.

### SUSY scenarios considered in this paper

* GMSB (Gauge-Mediated Supersymmetry Breaking) scenarios: in GMSB, SUSY breaking which takes place in hidden sector is transmitted to visible MSSM fields through a messenger sector whose mass scale is much below the Planck scale (\(M_{m}\ll M_{P}\)) via the ordinary Standard Model gauge interactions. The gravitino is very light (in general \(\ll 1\) GeV) and is always the LSP. In the minimal model of GMSB, all Supersymmetry breaking interactions are determined by a few parameters. The phenomenologies studied in this paper are based on this minimal model. Discussions of the non-minimal GMSB models are found elsewhere [34, 35]. The squarks, the sleptons, and the gauginos obtain their masses radiatively from the gauge interactions with the massive messengers; their masses therefore depend on the number of messenger generations, \(N_{5}\) (the index 5 comes from the fact that the messenger fields form complete \(SU(5)\) representations). The gaugino masses scale like \(N_{5}\) while the scalar masses scale like \(\sqrt{N_{5}}\). Hence for \(N_{5}=1\), the NLSP is the lightest neutralino (\(\tilde{\chi}_{1}^{0}\) ) which decays into photon and a gravitino (\(\tilde{G}\) ). For \(N_{5}\geq 2\), the NLSP is a charged stau (\(\tilde{\tau}_{1}\)). When \(\tan\beta\) is not too large, the mass splitting between the \(\tilde{\tau}_{1}\) and the right-handed selectrons, smuons (\(\tilde{e}_{R},\tilde{\mu}_{R}\)) is small, rendering them co-NLSP's which decay into leptons and gravitinos. In contrast, in the large \(\tan\beta\) region, the stau is the sole NLSP. The effective SUSY breaking order parameter \(F_{S}\), felt by the messengers, may not coincide with the intrinsic underlying SUSY breaking order parameter \(F\), which determines the coupling strength. When \(F_{S}\) is smaller, the NLSP decay length becomes longer. The dimensionless factor \(C_{G}=F/F_{S}(\geq 1)\) is introduced to control the NLSP decay length with all the other parameters fixed. The decay length is proportional to the square of the control parameter, i.e. scales as \(C_{G}^{2}\). The effective visible sector SUSY breaking parameter, \(\Lambda(=F_{S}/M_{m})\) sets the overall mass scale for all the MSSM superpartners, which scales linearly with \(\Lambda\). On the other hand, these masses only depend logarithmically on the messenger scale \(M_{m}\). The MSSM masses are therefore predominantly determined by the scale \(\Lambda\).

* Split-SUSY scenario: Stable exotic hadrons feature in a number of SUSY scenarios. Split-SUSY is one such model. Within this approach the hierarchy problem and the fine tuning of the Higgs mass is accepted, or assumed to be set by another, as yet unknown, mechanism. Phenomenologically, within Split-SUSY scenarios the gauginos and higgsinos have light masses of order the weak scale, which are protected by the chiral symmetry while the scalars have a mass scale \(m_{s}\) which can be near the GUT scale. Since gluino decays proceed via internal squark lines, gluinos can be meta-stable. A meta-stable gluino will form a bound state, a so-called \(R_{\tilde{g}}\)-hadron.
* A gravitino LSP and a stop NLSP scenario: in addition to stable gluinos, meta-stable stops are also features of some SUSY models. Here, the stops are usually the NLSP and decay to a gravitino LSP with gravitational strength interactions. The generic possible candidate for NLSP is the lightest stop \(\tilde{t}_{1}\), which, like the gluino case in split SUSY scenario, would form stable bound states, denoted \(R_{\tilde{t}}\).

### Parameter values used in this work

The basic feature of the samples used in this paper are similar to those introduced in [32]. However, our studies also investigate sparticles which decay with a measurable decay length, and new techniques have been introduced to allow these to be simulated. As in Ref. [32], ISAJET7.74 [36] was used to generate the sparticle mass spectrum in the context of minimal GMSB scenarios. The leading order (LO) and the next-to-leading order (NLO) cross-sections were assessed independently using PROSPINO2.0 [37, 38, 39]. The mass spectrum tables from ISAJET were used by HERWIG/JIMMY [40, 41] to generate the sparticle cascade decays, parton showers, hadronisations, and underlying events. The HERWIG option _pltcut_ (lifetime threshold above which the Herwig does not decay the particles) was set to \(3.3\times 10^{-11}\) s, hence sparticles with finite decay length are not decayed at event generator level3). In the detector simulation phase, the \(\tilde{\chi}^{0}_{1}\) decaying into \(\tilde{G}\) and \(\gamma\), decay length was passed to the ATLAS interface to GEANT4 and the sleptons (\(\tilde{\tau}_{1},\tilde{e}_{\rm R}\) and \(\tilde{\mu}_{\rm R}\)), interaction with detector materials, i.e. ionization loss was implemented.

Footnote 3): the value is set in order not to decay \(K^{0}\) and \(\Lambda\) at event generator level, but at detector simulation level.

In \(R\)-hadrons scenarios, the masses of the stable sparticles (\(M_{\tilde{g}},M_{\tilde{t}}\)) fully determine the phenomenology and other supersymmetric parameters (other sparticle masses) do not enter into any calculation. The generated samples are therefore highly model independent, and the only parameter that varies is the mass of the stable sparticle.

Tables 1-2 summarize the properties of the Monte Carlo signal samples used in this note. Tables 1 and 2 describe the GMSB samples with a neutralino or slepton NLSP, respectively, while Table 3 summarizes the \(R\)-hadron samples.

## 3 Discovery potential of GMSB SUSY with photon signatures

In GMSB models with \(N_{5}=1\) and low \(\tan\beta\) the lightest neutralino \(\widetilde{\chi}^{0}_{1}\) is the NLSP and decays to a gravitino \(\widetilde{G}\) and, in scenarios where the neutralino is mainly a photino, to a photon. Therefore the standard SUSY decay cascade of squarks and gluinos is extended by the decay \(\widetilde{\chi}^{0}_{1}\to\gamma\widetilde{G}\), as shown in Figure 1. Depending on the branching ratios of the squarks and gluinos decaying to various types of SUSY particles, this decay chain may also contain multiple jets. Events with two high energy photons are expected in \(pp\) collisions, if the NLSP lifetime is not too long (\(C_{\rm grav}\sim 1\)). These photons originate close to the primary interaction vertex ("prompt photons"). The corresponding event signatures and the discovery potential for these models are discussed in this section. The case of large \(C_{\rm grav}\) and therefore long lived neutralinos, resulting in non-pointing photons, is discussed in Section 3.3. For detailed reconstruction 

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|c|} \hline name & NLO (LO) \(\sigma\) [pb] & \(\Lambda\) [TeV] & \(M_{m}\) [TeV] & \(C_{G}\) & \(c\tau\) [mm] & \(M_{\tilde{\chi}_{1}^{0}}\) [GeV] \\ \hline GMSB1 & 7.8 (5.1) & 90 & 500 & 1.0 & 1.1 & 118.8 \\ GMSB2 & 7.8 (5.1) & 90 & 500 & 30.0 & \(9.5\cdot 10^{2}\) & 118.8 \\ GMSB3 & 7.8 (5.1) & 90 & 500 & 55.0 & \(3.2\cdot 10^{3}\) & 118.8 \\ \hline \end{tabular}
\end{table}
Table 1: Summary of the neutralino NLSP samples. Dataset GMSB1 is a prompt photon decay sample, while dataset GMSB2 and GMSB3 are the non-pointing photon samples. \(N_{5}=1,\tan\beta=5,\text{sgn}(\mu)=+\) are used at each point.

\begin{table}
\begin{tabular}{|l|c|c|c|} \hline name & NLO (LO) cross-section [pb] & sparticle & Mass [GeV] \\ \hline R-Hadron1 & 567 (335) & \(\tilde{g}\) & 300 \\ R-Hadron2 & 12.2 (6.9) & \(\tilde{g}\) & 600 \\ R-Hadron3 & 0.43 (0.23) & \(\tilde{g}\) & 1000 \\ R-Hadron4 & 0.063 (0.033) & \(\tilde{g}\) & 1300 \\ R-Hadron5 & 0.011 (0.006) & \(\tilde{g}\) & 1600 \\ R-Hadron6 & 0.0014 (0.00075) & \(\tilde{g}\) & 2000 \\ R-Hadron7 & 11.4 (7.8) & \(\tilde{t}\) & 300 \\ R-Hadron8 & 0.27 (0.18) & \(\tilde{t}\) & 600 \\ R-Hadron9 & 0.010 (0.0064) & \(\tilde{t}\) & 900 \\ \hline \end{tabular}
\end{table}
Table 3: \(R\)-hadron samples. Dataset R-Hadron1 – R-Hadron6 are the \(R_{\tilde{g}}\) samples, while dataset R-Hadron7 – R-Hadron9 are the \(R_{\tilde{t}}\) samples.

and trigger studies we consider the GMSB1 model point as a typical example (see Table 1). For this point the branching ratio of the decay of the lightest neutralino to a photon and a gravitino is \(\sim 97\%\), and the total SUSY production cross-section is \(\sim 7.8\,\mathrm{pb}\).

In the following we discuss the optimisation of the signal selection, including the trigger selection, the expected background from Standard Model processes and a detailed study of the discovery potential with early data. Since for the latter a fast simulation approach is used, a comparison of fast and full simulation results is also presented.

### GMSB1 full simulation studies

#### 3.1.1 Signal trigger strategy

The signal events studied here possess the standard SUSY event properties at the LHC: large \(E_{\mathrm{T}}^{\mathrm{miss}}\) and multiple jets with high \(p_{T}\). These can be used for triggering the events. In addition, the feature of two high energy photons gives an additional way to trigger on these events independently of \(E_{\mathrm{T}}^{\mathrm{miss}}\) and jet triggers. In the following we consider two different trigger menus:

* The first menu is the ATLAS initial menu foreseen for data-taking at a luminosity of \(10^{31}\,\mathrm{cm}^{-2}\mathrm{s}^{-1}\)[42]. This menu includes various combinations of jet (J) and \(E_{\mathrm{T}}^{\mathrm{miss}}\) triggers (XE) and photon triggers (EM) as shown in Table 4. No prescale values are foreseen for these triggers, whereas the selection of the EM100 trigger is based entirely on the Level-1 (L1) trigger, with no selections envisaged at the Level-2 (L2) trigger or in the event filter. In the following, the trigger efficiency is defined as the ratio of the number of events without any preselection passing a trigger item divided by the total number of events. The total efficiencies for the L1 trigger for the various triggers of this initial menu are summarised in Table 4.

It can be seen, that in addition to the standard SUSY

Figure 1: Typical SUSY decay chain for a neutralino NLSP decaying to a photon and a gravitino.

Figure 2: The g55 event filter trigger efficiency (see text) for the GMSB1 sample as a function of the reconstructed \(p_{\mathrm{T}}\) of the leading photon.

triggers based on jets and \(E_{\rm T}^{\rm miss}\), the photon triggers have very high efficiencies for selecting GMSB1 events and can be used for initial running.
* The second menu investigated here is the standard ATLAS trigger menu foreseen for the stable running at a luminosity of \(\mathcal{L}=10^{33}\,\mathrm{cm}^{-2}\mathrm{s}^{-1}\). In this menu all three trigger levels are used in the selection. The triggers investigated are combinations of jet (j), \(E_{\rm T}^{\rm miss}\) (xE) and photon (g) signatures, see Table 5. Again, no prescale values are foreseen for these items. The trigger efficiencies for the signal at L1, L2 and event filter are summarised in Table 5, where the L2 and event filter efficiencies also contain the efficiencies of the previous levels. It can be seen that for both of the planned running phases the photon triggers are as efficient as the \(E_{\rm T}^{\rm miss}\) and jet triggers for the case of GMSB1 signal events. The efficiency for the g55 photon trigger after the event filter as a function of the reconstructed \(p_{\rm T}\) of the leading photon is shown in Figure 2. As expected, after a steep turn on around 55 GeV a plateau is reached. The integrated efficiency above the threshold of 55 GeV is \(\sim 98\%\).

In summary it can be said that in the GMSB1 scenario the use of photon triggers is possible for initial running conditions, as well as at a higher luminosity. The efficiencies are as high as for the triggers based on jets and \(E_{\rm T}^{\rm miss}\) and can thus provide good redundancy.

#### 3.1.2 Signal selection

At the benchmark point GMSB1, 48.9% (16.4%) of the signal events have one (two) photons with \(p_{\rm T}>20\) GeV in the fiducial acceptance (\(|\eta|<2.5\)) used for photon identification. For the reconstruction of photons a standard cut-based photon selection [43] is used. This is mainly based on variables using information of the first and second samplings of the electromagnetic calorimeter. The photons are required to be isolated and those located in the transition regions between barrel and endcap calorimeters are excluded. No track veto is applied. After a full GEANT4 simulation of the ATLAS detector, the selection efficiency for photons with \(p_{\rm T}>20\) GeV is about 65%.

As background to the signal, events with QCD jets, single gauge boson (W and Z) production and \(t\bar{t}\) production are simulated using the ALPGEN generator. The specific processes are listed in Table 6 and the corresponding integrated luminosities are given for each process. In order to separate the signal from

\begin{table}
\begin{tabular}{|l|c||l|l|} \hline Trigger item & Efficiency & Trigger item & Efficiency \\ \hline
2EM13 & 98.71 \(\pm\) 0.11 & XE70 & 81.39 \(\pm\) 0.39 \\ EM100 & 83.00 \(\pm\) 0.38 & J70+XE30 & 93.64 \(\pm\) 0.25 \\ EM18+XE15 & 98.79 \(\pm\) 0.12 & 2J42+XE30 & 93.98 \(\pm\) 0.24 \\ J100 & 91.43 \(\pm\) 0.28 & 4J23 & 92.27 \(\pm\) 0.27 \\ \hline \end{tabular}
\end{table}
Table 4: Trigger efficiencies and statistical errors for the GMSB1 event sample for (\(\mathcal{L}=10^{31}\,\mathrm{cm}^{-2}\mathrm{s}^{-1}\)).

\begin{table}
\begin{tabular}{|l|c|c|c|} \hline Trigger item & L1 & L1+L2 & L1+L2+EF \\ \hline g55 & 97.18\(\pm\)0.60 & 84.47\(\pm\)1.32 & 80.47\(\pm\)1.44 \\
2g17i & 71.13\(\pm\)1.65 & 55.07\(\pm\)1.81 & 47.91\(\pm\)1.81 \\ j65+xE70 & 80.66\(\pm\)0.40 & 80.63\(\pm\)0.40 & 69.53\(\pm\)0.46 \\
3j65 & 83.63\(\pm\)0.37 & 83.55\(\pm\)0.37 & 83.37\(\pm\)0.37 \\ \hline \end{tabular}
\end{table}
Table 5: Trigger efficiencies and statistical errors for the GMSB1 event sample for (\(\mathcal{L}=10^{33}\,\mathrm{cm}^{-2}\mathrm{s}^{-1}\)).

the Standard Model background a standard preselection for SUSY-like signatures is first performed:

* At least four jets must be found with \(p_{\rm T}>50\) GeV (\(p_{\rm T}>100\) GeV for the leading jet).
* Missing transverse energy \(E_{\rm T}^{\rm miss}>100\) GeV and \(E_{\rm T}^{\rm miss}>20\%\cdot M_{\rm eff}\), where the effective mass \(M_{\rm eff}\) is defined as the scalar sum of \(E_{\rm T}^{\rm miss}\) and the transverse momenta of the four leading jets.

The distributions of \(E_{\rm T}^{\rm miss}\) and \(M_{\rm eff}\) after this selection are shown in Figure 3 for the Standard Model background (histograms) and the signal (open symbols) for an integrated luminosity of 1 fb\({}^{-1}\). No large excess of events is seen over the Standard Model background. However, as shown in Figure 4, a cut on the number of reconstructed photons with \(p_{\rm T}>20\) GeV and \(|\eta|<2.5\) provides an effective way to further suppress the backgrounds. Figure 3 shows the \(p_{\rm T}\) distribution of the leading photon after the initial preselection. Table 7 shows the number of selected events for signal (\(S\)) and background (\(B\)) after requiring 0, 1 or 2 photons passing the cuts described above and either the g55 or the 2g17i trigger. This combination of triggers has a combined efficiency for the signal of \(\sim 85\%\) (\(\sim 99\%\)) before (after) applying these selection cuts. The number of events is normalized to an integrated luminosity of 1 fb\({}^{-1}\). In addition, the signal significance defined as \(Sig=S/\sqrt{B}\) is given in the table. In the calculation of \(Sig\) it is assumed, that there is at least one background event left. With the requirement of two high-energy photons the selection is mainly free from Standard Model background and the significance becomes very large.

\begin{table}
\begin{tabular}{|l|l|l|} \hline Process & & Integrated luminosity (fb\({}^{-1}\)) \\ \hline Top & leptonic & \(\sim 13.4\) \\  & semi-leptonic & \(\sim 3.5\) \\  & hadronic & \(\sim 17.1\) \\ \hline Electroweak & \(Z\to e^{+}e^{-}\) & \(\sim 4.8\) \\ + jets & \(Z\rightarrow\mu^{+}\mu^{-}\) & \(\sim 8.3\) \\  & \(Z\rightarrow\tau^{+}\tau^{-}\) & \(\sim 21.6\) \\  & \(Z\rightarrow\nu\nu\) & \(\sim 9.1\) \\  & \(W\to e\nu\) & \(\sim 3.4\) \\  & \(W\rightarrow\mu\nu\) & \(\sim 4.7\) \\  & \(W\rightarrow\tau\nu\) & \(\sim 3.9\) \\ \hline QCD & multiple jet production & \(\sim 0.03\) \\ \hline \end{tabular}
\end{table}
Table 6: ALPGEN Background samples used in this section. The corresponding integrated luminosities is shown.

Figure 3: Distributions after preselection for 1 fb\({}^{-1}\). Left: Missing transverse energy. Right: Effective mass for signal and Standard Model background.

In addition to the selection criteria listed above, checks were made to see weather a better signal significance can be achieved by requiring an opposite sign same flavour (OSSF) lepton pair, which originates in the squark/gluino decay cascade from a \(\widetilde{\chi}_{2}^{0}\) to \(\widetilde{\chi}_{1}^{0}\) decay via a slepton, as depicted in Figure 1. Here, only electrons and muons are accepted as leptons. The requirement of at least one OSSF lepton pair reduces the number of selected signal and background events. The suppression factor for the signal for the combination of one photon and one OSSF pair is larger than for the combination of two photons. Hence, although the background is reduced to a very low level, just using the requirement of two photons gives the largest significance. Requiring an OSSF pair in addition to two photons just reduces the signal, because the background is already very low.

### GMSB parameter scan with fast simulation

To investigate the discovery potential of the selection described above, over a wider range of the GMSB parameter space, it is necessary to make use of a fast detector simulation to obtain adequate statistics for signal event reconstruction at various points in the parameter space. The computing requirements of the full simulation make it impractical for this study, so for this part of the analysis the fast simulation package ATLFAST [44] has been used instead. ATLFAST performs no detailed simulation of particle interactions with the detector material, but instead parameterizes the detector response. It has two main features relevant to the analysis discussed here:

* every generated particle is reconstructed.
* there is no distinction between electromagnetic and hadronic calorimeter compartments and the energy of a particle is obtained by smearing the energy of the generated particle with a resolution function. No shower development is simulated.

Note that ATLFAST does not simulate either reconstruction inefficiencies nor particle misidentification for any particles.

Figure 5(a) shows the \(M_{\mathrm{eff}}\) distributions of the GMSB1 event sample for full and fast simulation. In the low energy region a small deviation of the fast simulation with respect to the full simulation can be observed, which is due to a slightly higher jet momentum in ATLFAST in the low energy region. However, of more importance for this analysis is the simulation of the photon identification and it is important that the fast simulation provides a reliable modelling. The transverse momentum of the leading photon is

Figure 4: Distributions after preselection for \(1\,\mathrm{fb}^{-1}\): Number of reconstructed photons with \(p_{\mathrm{T}}>20\) GeV and \(|\eta|<2.5\) (left) and transverse momentum of the leading photon for signal and Standard Model background. (right)

shown in Figure 5(b) for full and fast simulation. It can clearly be seen that some significant discrepancies between both simulation approaches exist. This is a result of the photon detection efficiency, which is not included in the fast simulation. The fast simulation assumes a 100% detection efficiency for all truth photons which pass a certain isolation criterion. This effect is taken into account in the analysis by imposing a realistic reconstruction probability on each photon by hand, depending on the transverse momentum of the photon. The corrected \(p_{\mathrm{T}}\) distribution is also shown in Figure 5(b).

In Table 8 the numbers of selected signal events for full and fast simulation are shown and good agreement can be observed after each step of the selection. The level of agreement of the fast simulation with the full simulation is of the order of 10% which is considered to be sufficient for a rough estimation of the discovery potential via a scan of the GMSB model parameters using ATLFAST.

\begin{table}
\begin{tabular}{|r|r||r|r||r|r|r|} \hline N\({}_{\gamma}\) & N\({}_{\mathrm{OSSF}}\) & Signal & \(\sum\) Background & Sig & N\({}_{W}\) & N\({}_{Z}\) & N\({}_{\tilde{t}\tilde{t}}\) \\ \hline
0 & 0 & 1287.4 & 929.6 & 42.3 & 274.4 & 21.0 & 632.8 \\
0 & 1 & 283.6 & 73.0 & 33.2 & 8.7 & 1.4 & 63.0 \\
1 & 0 & 902.9 & 51.7 & 126.1 & 19.5 & 2.0 & 30.1 \\
1 & 1 & 189.1 & 1.4 & 161.4 & 0.2 & 0.0 & 1.2 \\
2 & 0 & 252.9 & 0.1 & 252.9 & 0.0 & 0.0 & 0.1 \\
2 & 1 & 37.0 & 0.0 & 37.0 & 0.0 & 0.0 & 0.0 \\ \hline \end{tabular}
\end{table}
Table 7: Number of selected signal and background events for \(1\,\mathrm{fb}^{-1}\) for different cuts on the number of photons and opposite sign same flavour (OSSF) lepton pairs.

Figure 5: Signal distributions for full and fast simulation: a) effective mass, b) transverse momentum of the leading photon.

\begin{table}
\begin{tabular}{|r|r||r|r|} \hline N\({}_{\gamma}\) & N\({}_{\mathrm{OSSF}}\) & Signal (full) & Signal (fast) \\ \hline
0 & 0 & 1287.4 & 1597.7 \\
1 & 0 & 902.9 & 1029.5 \\
2 & 0 & 252.9 & 275.3 \\ \hline \end{tabular}
\end{table}
Table 8: Number of selected signal events normalised to \(\mathcal{L}=1\,\mathrm{fb}^{-1}\) for full and fast simulation for GMSB1.

In order to estimate the selection efficiency and the discovery potential of the two photon channel in a more model independent way, a scan of some GMSB model parameters has been performed. The mass spectrum and branching fractions of the different GMSB model points have been calculated using ISASUGRA 7.74 [36]. For each point 12500 signal events have been generated using the HERWIG/JIMMY [40, 41]. As discussed above, ATLFAST is used for the detector simulation of the signal with a correction applied to the photon reconstruction efficiency. The estimates for the Standard Model background are taken from the full simulation as described in Section 3.1.2.

For the scan, the SUSY breaking scale parameter \(\Lambda\) has been varied from 60 to 200  in steps of 10 and \(\tan\beta\) has been varied from 2 to 50 in steps of 2. The other model parameters are fixed to \(N_{5}=1\), \(M_{\rm mes}=500\), \({\rm sgn}\mu=+1\) and \(C_{\rm grav}=1\), as for the GMSB1 model point. In this part of the parameter space the neutralino is usually the NLSP, which is most often not the case for larger \(N_{5}\) or larger \(\tan\beta\). For these regions, other channels need to be used to discover GMSB SUSY. These are discussed in Section 5. The discovery potential for the case of different \(C_{\rm grav}\) and hence non-pointing photons is briefly discussed in Section 3.3.

Figure 6 shows the contour lines where the significance reaches \(Sig=5\sigma\) for the default selection cuts as described above for different integrated luminosities. Since it is assumed that there is 1 background event left, these contour lines represent the lines with 5 signal events. In the regions below and left of the lines a \(5\sigma\) discovery can be made with the corresponding amount of data. In the high \(\tan\beta\) region above the solid line no sensitivity is quoted for the two photon channel, since in this region the \(\tilde{\tau}\) is the NLSP and so no significant excess of photons is expected from the SUSY decay chains. Due to the fact that the SUSY cross section decreases with increasing \(\Lambda\), the significance decreases as a function of \(\Lambda\) for a given integrated luminosity. In general the discovery potential in most parts of the GMSB model parameter space is high, giving confidence that GMSB SUSY can be discovered in the two photon channel with early data, if it is realised in nature.

### GMSB3 (non-pointing photon) full simulation studies

If the gravitino mass parameter \(C_{\rm grav}\) is larger than unity, the NLSP will not decay promptly. In the case where the NLSP is a light neutralino, the resulting photons in the final state will not point back to the interaction point and may therefore be reconstructed and triggered with lower efficiency. The reconstruction efficiency is discussed in greater detail in Section 4.1. Here, the standard photon selection will be used to estimate the discovery potential.

Figure 6: \(5\sigma\) discovery potential contour lines for GMSB SUSY in the \(\Lambda\) - \(\tan\beta\) plane for different integrated luminosities.

A suitable model point to study is the GMSB3 point, which has the same parameters as GMSB1, but with \(C_{\rm grav}=55\). The \(\tilde{\chi}_{1}^{0}\) decay length in this point is therefore \(\gamma\beta c\tau\approx 3\) m. Although only 12.4% (0.6%) of the reconstructed events contain one (two) photons with \(p_{\rm T}>20\) GeV in the detector acceptance region, this well exceeds the number of background photons. This suggests that one could also use the above defined selection, which is based on the requirement of two hard photons.

Table 9 shows the trigger efficiencies for the same items listed in Table 5. For the L1 trigger, the main source of inefficiency for the g55 trigger is from neutralino decaying to photons outside the inner-detector volume. The larger the \(C_{\rm grav}\) parameter is, the greater is the number of neutralinos that will decay outside the inner-detector. This effect is more pronounced for the 2g17i trigger, which is optimized for the production of both photons within the inner-detector volume. At L2 trigger and at the event filter, cuts are placed on the shape of the electromagnetic showers, which are less efficient for non-pointing photons due to their wider shower shape in the \(\eta\) direction compared to prompt photons. The small difference in jet trigger efficiencies between GMSB1 and GMSB3 is again due to the difference in the number of photons produced within the inner-detector volume. Photons in the event are treated as jets up to the event filter, so that GMSB1 has effectively a larger number of jets, compared to the GMSB3 sample, which makes a small but significant difference in jet trigger efficiency.

The resulting numbers of selected events for 1 fb\({}^{-1}\) are shown in Table 10. It can clearly be seen that, although the significance, again defined as \(\mbox{\it Sig}=S/\sqrt{B}\), is smaller than in the GMSB1 case, there are enough photons to select a large number of signal events. The difference to the prompt photon case is that with the requirement of an OSSF lepton pair one could obtain a larger significance, which is largest for a combination of one hard photon and one OSSF pair.

### Conclusion of GMSB SUSY with photon signatures

In certain regions of the GMSB parameter space the NLSP is a light neutralino, decaying to a gravitino via the emission of hard photons. These photons can be used to efficiently reject the Standard Model background and to discover GMSB SUSY, if it is realized in nature. Attention must be payed to the fact that the photons might not point back to the interaction point leading to losses in reconstruction and

\begin{table}
\begin{tabular}{|r|r||r|r|r||r|r|r|} \hline N\({}_{\gamma}\) & N\({}_{\rm OSSF}\) & Signal & \(\sum\) Background & Sig & N\({}_{W}\) & N\({}_{Z}\) & N\({}_{\tilde{H}}\) \\ \hline
0 & 0 & 825.2 & 929.6 & 27.1 & 274.4 & 21.0 & 632.8 \\
0 & 1 & 265.2 & 73.0 & 33.2 & 8.7 & 1.4 & 63.0 \\
1 & 0 & 255.8 & 51.7 & 35.7 & 19.5 & 2.0 & 30.1 \\
1 & 1 & 68.6 & 1.4 & 58.6 & 0.2 & 0.0 & 1.2 \\
2 & 0 & 12.5 & 0.1 & 12.5 & 0.0 & 0.0 & 0.1 \\
2 & 1 & 4.7 & 0.0 & 4.7 & 0.0 & 0.0 & 0.0 \\ \hline \end{tabular}
\end{table}
Table 10: Number of selected signal (GMSB3) and background events for 1 fb\({}^{-1}\) for different cuts on the number of photons and opposite sign same flavour (OSSF) lepton pairs.

\begin{table}
\begin{tabular}{|l|r|r|r|} \hline Trigger item & L1 & L1+L2 & L1+L2+EF \\ \hline g55 & 90.19\(\pm\)1.08 & 46.04\(\pm\)1.81 & 36.88\(\pm\)1.75 \\
2g17i & 34.13\(\pm\)1.72 & 17.77\(\pm\)1.39 & 12.87\(\pm\)1.22 \\ j65+xE70 & 80.38\(\pm\)0.56 & 80.24\(\pm\)0.56 & 71.18\(\pm\)0.64 \\
3j65 & 79.80\(\pm\)0.57 & 79.66\(\pm\)0.57 & 79.62\(\pm\)0.57 \\ \hline \end{tabular}
\end{table}
Table 9: Trigger efficiencies and statistical errors for the GMSB3 event sample for (\({\cal L}=10^{33}\) cm\({}^{-2}\)s\({}^{-1}\)).

trigger efficiencies.

## 4 Prospects for neutralino lifetime determination

If GMSB SUSY is discovered, the ATLAS calorimeter can be used to first establish whether the neutralino has a long mean lifetime, and then to quantify it. The calorimeter can be used to both measure the direction and the time of the electromagnetic shower. Both the capabilities can be utilised to determine the mean lifetime of the neutralino.

If the neutralino has a significant decay length, a photon can be observed4) that will not "point-back" to the primary interaction point. This is shown schematically in Figure 7. The neutralino (\(\tilde{\chi}^{0}_{1}\)) travels a significant distance before decaying into a photon (\(\gamma\)) and a gravitino (\(\tilde{G}\)). Due to the finite opening angle between the photon and \(\tilde{G}\), the path taken by the photon does not extrapolate back to the primary interaction point.

Footnote 4): As long as the neutralino decays before the calorimeter.

The first sampling layer can measure the \(\eta\) position (Cluster 1 in Figure 7) whereas the second sampling layer can measure both \(\eta\) and \(\phi\) (Cluster 2 in Figure 7). A vector corresponding to the path of the photon can therefore be constructed in the \(r-z\) plane. Although we can not measure the exact decay point of the neutralino based on these two measurements, we can extrapolate the path of the photon back to the beam axis, and measure the distance between this point and the primary vertex (\(Z^{\prime}\) in Figure 7).

Since the ATLAS calorimeter has a pointing geometry, if a photon enters the calorimeter at a significant angle, the resulting electromagnetic shower can be spread out over a larger number of calorimeter cells. This wider shower-shape can result in issues for photon reconstruction algorithms and identification criteria. The effects of the reconstruction and identification of the non-pointing photons are discussed in Section 4.1.

If the neutralino has a mean lifetime greater than 0.05 ns5), the \(Z^{\prime}\) value associated with the photon can be used to establish that the neutralino has a "long" lifetime. Once this observation has been made, the \(Z^{\prime}\) distance can also be used to measure the mean lifetime. This is discussed in Section 4.2.

Footnote 5): For typical values assumed for the neutralino energy and mass of 200 and 100 GeV respectively, photons with a \(Z^{\prime}\) of at least 1cm from the primary vertex were observed.

The neutralino is a massive particle. This means that photons produced from long-lived neutralinos will arrive at the calorimeter later than prompt photons from the primary vertex. A method which uses the calorimeter timing information to calculate the mean neutralino lifetime is discussed in Section 4.3.

Figure 7: Schematic diagram of a non-pointing photon in the barrel section of the electromagnetic calorimeter. A long lived neutralino can travel a significant distance before decaying into a photon and a gravitino. The gravitino will escape the detector without interacting. A photon produced in this manner can enter the calorimeter at a significantly different angle (\(\eta_{\gamma}\)) than a photon produced at the primary vertex (\(\eta_{1}\)).

### Reconstruction and identification of non-pointing photons

#### 4.1.1 \(\eta\) definitions

Due to the nature of the non-pointing photons, two definitions of \(\eta\) are used in this section. The 'truth \(\eta\)' refers to the \(\eta\) from the particle vector from the Monte Carlo event record (shown as \(\eta_{\gamma}\) in Figure 7). The term 'detector \(\eta\)' refers to the \(\eta\) as measured by constructing a vector from (0,0,0) to the barycenter of the electromgnetic shower(shown as \(\eta_{2}\) in Figure 7).

#### 4.1.2 Photon reconstruction efficiency

The photon reconstruction efficiency is defined as the fraction of photons, produced from the decay of a neutralino, that are reconstructed as a photon candidate. Using information from the Monte Carlo event record, photons are selected to be used in the efficiency calculation if they satisfy the following criteria:

* originate from a neutralino decay occuring inside the outer envelope of the inner detector,
* \(p_{T}>20\) GeV,
* \(|\)detector \(\eta\)\(|<2.5\).

Photons are declared as successfully reconstructed if a photon candidate is found within \(\Delta R<0.2\) of the position of the truth photon in the calorimeter.

The \(z\)-component of the decay length and the momentum of the photon in the GMSB samples, as shown in Figure 8 and 8, depend upon the \(C_{\rm grav}\) parameter of the sample.

The overall efficiency for a photon to be reconstructed in the long-lived neutralino data samples, GMSB2 and GMSB3, is \(88.3\pm 0.2\%\) and \(83.3\pm 0.4\%\) respectively. This efficiency includes the reconstruction of photons which have converted to an electron-position pair. This occurs approximately 30% of the time and is dependent on how much material the photon travels through the inner-detector. This means that a photon from a long-lived neutralino will have a smaller probability of converting than a photon produced at the primary vertex. The reconstruction efficiency of a photon which does not convert, is \(89.3\pm 0.2\%\) for the GMSB2 sample and \(84.2\pm 0.5\%\) for the GMSB3 sample.

The difference in overall reconstruction efficiency measured between the GMSB2 and GMSB3 samples is due to the distribution of neutralino lifetimes in the sample, and hence the proportion of photons which are significantly "non-pointing".

Figure 8: Left: The distributions of the decaylength of the neutralino in the \(z\) direction. Right: The transverse momentum of the photons they produce.

The reconstruction efficiency is measured independently from the sample parameters as a function the variable \(\Delta\eta=\) detector \(\eta\) - truth \(\eta\) as shown in Figure 9.

There is excellent agreement between the two cases. The efficiency is approximately 90% for \(\Delta\eta<0.25\), and falls steadily to 75% for \(\Delta\eta\approx 0.5\). It is clear that the reconstruction efficiency could bias any measured neutralino lifetime distribution. This efficiency distribution is parameterised with an approximation to the top-hat function:

\[R_{\rm eff}(\Delta\eta)=\frac{b}{1+e^{\frac{|\Delta\eta|+a}{c}}}+d \tag{1}\]

with \(a=4.7(6.9)\), \(b=174(229)\), \(c=0.779(1.16)\) and \(d=0.545(0.351)\) for GMSB2 (GMSB3). The GMSB2 fit result is used in Sections 4.2 and 4.3 (due to greater statistics) to account for any bias in the neutralino lifetime determination due to inefficiency.

#### 4.1.3 Study of photon identification efficiency

The dependence of the photon efficiency on the neutralino decay length has been studied for all of the standard photon selection variables [43]. The efficiency for each cut is defined as the fraction of reconstructed photons with \(p_{T}>20\) GeV and \(|\)detector \(\eta|<2.5\) that pass the standard select requirement for the given variable. Only photons that are successfully identified with true photons that come from the decay of a SUSY particle are used.

Figure 10 shows the efficiency of these cuts as a function of the component of the neutralino decay length parallel to the beam axis. From this figure it can be seen that the hadronic leakage (Had/Em) is independent of the neutralino decay length. Of the cuts forming the standard selection from the second sampling layer of the electromagnetic calorimeter, only the ratio of energy in the 3\(\times\)3 / 3\(\times\)7 cells (R33) is shown to be flat with respect to the neutralino decay length. The efficiency of the cuts on the ratio of energy in the 3\(\times\)7 / 7\(\times\)7 cells (R37) and the the lateral width of the shower (weta2) are shown to have a clear dependence on the decay length. These two cuts are removed to form an 'unbiased photon selection' in the second sampling layer.

For the cuts forming the standard cut selection in the first sampling layer of the electromagnetic calorimeter, the fraction of energy (f1) and the cuts on the search for a second minima in the first sampling layer (DeltaE and DeltaEmax2) are shown to be relatively stable with respect to the neutralino decay length. There is however, a significant dependence of the efficiency on the decay length for the fraction of energy outside the shower core (fracm), the shower width in three strips (weta1) and the total width of the shower (wtot). These three cuts are removed to form an 'unbiased photon selection' in the first sampling layer.

Figure 9: Reconstruction efficiency as a function of \(\Delta\eta\) for the GMSB2 and GMSB3 samples.

Table 11 shows the effect on the overall efficiency as the five cuts which have been shown to be dependent on the neutralino decay length cuts are excluded from the standard photon selection to form an 'unbiased photon selection'. For simplicity the cuts are seperated according to which calorimeter sampling layer they are based upon.

The relative effect of loosening cuts on the background is shown in Table 12, which shows the fraction of jets, from a di-jet Monte Carlo data sample, that are reconstructed as photons, that also pass the two different photon selections.

### Projected impact-parameter method for neutralino mean lifetime measurement

The distribution of the photon's projected longitudinal impact parameter \(Z^{\prime}\) arising from GMSB signal events can be used to estimate the mean neutralino lifetime.

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline \multicolumn{4}{|c|}{Standard photon selection} \\  & hadronic & \(2^{\mathrm{nd}}\) sampling & \(1^{\mathrm{st}}\) sampling \\ \hline GMSB1 & \((94.1\pm 0.2)\)\% & \((75.7\pm 0.4)\)\% & \((64.1\pm 0.4)\)\% \\ GMSB2 & \((94.2\pm 0.1)\)\% & \((56.4\pm 0.3)\)\% & \((41.9\pm 0.3)\)\% \\ GMSB3 & \((94.4\pm 0.3)\)\% & \((49.8\pm 0.6)\)\% & \((36.1\pm 0.6)\)\% \\ \hline \hline \multicolumn{4}{|c|}{Unbiased selection} \\  & hadronic & \(2^{\mathrm{nd}}\) sampling & \(1^{\mathrm{st}}\) sampling \\ \hline GMSB1 & \((94.1\pm 0.2)\)\% & \((93.4\pm 0.2)\)\% & \((85.7\pm 0.3)\)\% \\ GMSB2 & \((94.2\pm 0.1)\)\% & \((92.2\pm 0.1)\)\% & \((82.5\pm 0.1)\)\% \\ GMSB3 & \((94.4\pm 0.3)\)\% & \((92.1\pm 0.3)\)\% & \((80.7\pm 0.5)\)\% \\ \hline \end{tabular}
\end{table}
Table 11: Summary of photons identification efficiencies for the three different signal samples. The hadronic, second sampling and first sampling cuts are applied sequentially.

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline  & Hadronic & \(2^{\mathrm{nd}}\) sampling & \(1^{\mathrm{st}}\) sampling \\ \hline Default photon selection & \((3.4\pm 0.1)\)\% & \((0.57\pm 0.06)\)\% & \((0.19\pm 0.03)\)\% \\ Unbiased selection & \((3.4\pm 0.1)\)\% & \((2.7\pm 0.1)\)\% & \((0.70\pm 0.07)\)\% \\ \hline \end{tabular}
\end{table}
Table 12: The fraction of jets reconstructed as photons and passing all photon criteria. The hadronic, second sampling and first sampling cuts are applied sequentially.

Figure 10: Photon identification cut efficiencies as a function of neutralino decay length in Z

A distribution of the intersection points of the \(z\)-axis with the projected photon path is then created for all reconstructed photons. Each intersection point is corrected for the vertex displacement. An exponential function is fitted to the intersection distribution in order to extract the slope parameter which is sensitive to the mean neutralino lifetime. The range for the fit was chosen to be 50 to 500 mm, to remove any possible vertex effects, and to ensure that the decay occured within the volume of the inner-detector.

Plotting the resulting slope parameters versus the mean neutralino lifetime reveals a clear correlation (Figure 11) between the slope parameter and the neutralino lifetime. These results were obtained using a custom-built Monte Carlo program which provides a detailed parameterisation of the response of the transition radiation tracker and the electromagnetic calorimeter. It is envisaged that a calibration curve such as this, created using full simulation, could be used to determine the mean neutralino lifetime from a measurement of the slope of the \(Z^{\prime}\) distribution. In reality this slope will also be a function of the \(\beta\) of the neutralino.

For the GMSB2 data set, a slope of \(-4.35(6)\times 10^{-3}\) was measured and for the GMSB3 data set, a slope of \(-3.8(2)\times 10^{-3}\) was measured. These slopes were obtained before any photon identification cuts were applied. To estimate the effect of bias due to the reconstruction efficiency, a weight (\(=\frac{1}{R_{\mathrm{eff}}(\Delta\eta)}\)) is applied to the events, see Section 4.1.2. By comparing the effect of applying this correction on the resultant \(Z^{\prime}\) slope, a \(-5\times 10^{-5}\) systematic error was obtained. Table 13 shows the values obtained when different photon identification cuts are used.

The results from the GMSB2 and GMSB3 samples shown in Table 13 demonstrate very clearly how the slope of the \(Z^{\prime}\) distribution can be affected by photon identification cuts which are based on width measurements of the electromagnetic shower.

### Calorimeter timing

A comparison has been made of the timing of the electromagnetic shower in the calorimeter, compared to the lifetime of the generated neutralino (in its rest frame). A Gaussian is fitted to this distribution for different bins of true lifetime, and the resultant mean cluster-time per generated neutralino mean lifetime

Figure 11: Fitted slope parameters of the projected intersection distributions versus mean neutralino lifetime from the custom-built Monte Carlo simulation for an integrated luminosity of 30 fb\({}^{-1}\).

is plotted in Figure 12. This fit to this plot is used to calibrate the calorimeter time. It has been shown that this method is robust against photon reconstruction or identification efficiency biases. This is because it is independent of the angle of incidence of the photon on the calorimeter. The arrival time of the photon at the calorimeter is a function of the \(\beta=v/c\) of the neutralino as well as its lifetime.

Using this calibrated calorimeter time, the neutralino lifetime is plotted for each photon. This distribution has the expected exponential shape modified by acceptance and resolution effects. In order to remove these effects, an exponential is fitted between 0.2 and 1 ns. The mean lifetime of the sample (\(\tau\)) was calculated from \(\tau=\frac{1}{slope}\) where \(slope\) is the slope of the exponential fitted.

To calculate the effect of bias due to the reconstruction efficiency, a weight (\(=\frac{1}{R_{\mathrm{eff}}(\Delta\eta)}\)) was applied to the events (see Section 4.1.2). The systematic error on the lifetime determination due to uncertainties on the reconstruction efficiency was determined to be 2%.

To study the effect of the photon identification on this method, the mean lifetime deduced from the slope of the exponential is measured after different identification cuts are applied to the photon sample. These mean lifetimes are shown in Table 14. The large errors on the calculated lifetimes from the GMSB3 sample are due to lack of statistics available for the fit, over the limited range.

In order to obtain estimates for the systematic uncertainty due to the predicted \(\beta\) distribution of the GMSB sample (or an error in the timing calibration), the calibration curve (Figure 12) was scaled up and down by 5% corresponding to the difference in mean \(\beta\) value between the GMSB2 and GMSB3 samples. The effect on the measured mean lifetime determination corresponds to a systematic error of 0.4(2) ns

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline \multicolumn{4}{|c|}{GMSB2: Generated mean lifetime of 3.17 ns} \\ dataset & hadronic & \(2^{\mathrm{nd}}\) Sampling & \(1^{\mathrm{st}}\) Sampling \\ \hline default photon selection & \(-4.35(6)\times 10^{-3}\) & \(-7.00(9)\times 10^{-3}\) & \(-8.3(1)\times 10^{-3}\) \\ unbiased selection & \(-4.35(6)\times 10^{-3}\) & \(-4.39(6)\times 10^{-3}\) & \(-4.54(7)\times 10^{-3}\) \\ \hline \hline \multicolumn{4}{|c|}{GMSB3: Generated mean lifetime of 10.7ns} \\ dataset & hadronic & \(2^{\mathrm{nd}}\) Sampling & \(1^{\mathrm{st}}\) Sampling \\ \hline default photon selection & \(-3.8(2)\times 10^{-3}\) & \(-6.6(2)\times 10^{-3}\) & \(-7.7(3)\times 10^{-3}\) \\ unbiased selection & \(-3.8(2)\times 10^{-3}\) & \(-3.9(2)\times 10^{-3}\) & \(-4.1(2)\times 10^{-3}\) \\ \hline \end{tabular}
\end{table}
Table 13: The slope of the projected-impact-parameter (\(Z^{\prime}\)) distributions of the photon, fitted from 50 to 500 mm and measured in two different fully simulated Monte Carlo samples with different photon identification cuts.

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline \multicolumn{4}{|c|}{GMSB2: Generated mean lifetime of 3.17ns} \\ dataset & hadronic & \(2^{\mathrm{nd}}\) Sampling & \(1^{\mathrm{st}}\) Sampling \\ \hline default photon selection & \(2.9\pm 0.2\) ns & \(1.1\pm 0.07\) ns & \(1.33\pm 0.05\) ns \\ unbiased selection & \(2.9\pm 0.2\) ns & \(2.9\pm 0.2\) ns & \(3.0\pm 0.2\) ns \\ \hline \hline \multicolumn{4}{|c|}{GMSB3: Generated mean lifetime of 10.7ns} \\ dataset & hadronic & \(2^{\mathrm{nd}}\) Sampling & \(1^{\mathrm{st}}\) Sampling \\ \hline default photon selection & \(9\pm 4\) ns & \(3.4\pm 0.7\) ns & \(2.9\pm 0.6\) ns \\ unbiased selection & \(9\pm 4\) ns & \(8\pm 3\) ns & \(19\pm 19\) ns \\ \hline \end{tabular}
\end{table}
Table 14: The mean lifetimes, measured using the calibrated calorimeter time, in two different full simulation Monte Carlo samples with different photon identification cuts. Also shown is the generated mean lifetime of the samples used.

for the GMSB2(3) samples.

In order to obtain estimates for the systematic uncertainty in the mean lifetime determination from the choice of fitting region or a global shift in the timing calibration, the fit range of the exponetial distributions was shifted by 100 ps. A systematic error of 1(10) ns was obtained for the GMSB2(3) samples.

The shape of the observed neutralino lifetime distribution is strongly affected by geometric acceptance and event kinematics. To obtain a lifetime measurement unaffected by these issues, a very limited fitting range has been used. A more accurate fit could be achieved by fitting the entire distribution. A full acceptance correction, including model dependent effects, would then be required to relate this distribution to the mean neutralino lifetime. This work, beyond the scope of this publication, should produce a more accurate measurement of the mean neutralino lifetime.

### Conclusion of the neutralino lifetime determination

Two independent methods for determining the mean neutralino lifetime have been discussed. The two methods are independent with different issues. For the \(Z^{\prime}\) method of Section 4.2, a study using a simple custom-built Monte Carlo program shows that there is a good correlation between the \(Z^{\prime}\) parameter and the mean neutralino lifetime. However, full simulation of a range of lifetime samples will be required to get the correct parameterisation of the relationship. The calorimeter timing study (Section 4.3), shows there is a good correlation between the calorimeter time and lifetime of the associated neutralino. The largest errors from this studies are due to the limited statistics in the range of the measured neutralino lifetime distribution, used for the exponential fit.

In both methods, one has to take care that the biases introduced by the reconstruction and identification of the photons are both measured and reduced, in order to prevent a distortion of the lifetime distribution.

Both of these methods are signal dependent and rely on simulation calibration, either to produce the \(Z^{\prime}\) calibration curve, or the timing calibration. This is because both the \(Z^{\prime}\) value and the arrival time of the photon in the calorimeter are functions of the \(\beta\) of the neutralino as well as its lifetime. One can assume a distribution of \(\beta\) from Monte Carlo simulation (as has been done here), but constraints on the both parameters can in principle be achieved by combining the methods. It is proposed that, if non-pointing photons are observed, a multivariate analysis method could be used to combine information from the calorimeter timing and \(Z^{\prime}\) together with information from the primary vertex and cluster positions and energy to place model-independent constraints on the \(\beta\) and lifetime of the parent of the non-pointing photon.

Figure 12: The measured cluster time as a function of the generated neutralino lifetime, for individual neutralinos in the Monte Carlo samples.

Trigger and reconstruction for searches of long-lived heavy particles

Heavy, charged, long-lived particles are predicted in many models of physics beyond the Standard Model. One example is GMSB where for high \(\tan\beta\) the \(\tilde{\ell}\)  is the NLSP which couples weakly to the gravitino. The signal is a heavy long-lived charged particle with velocity significantly smaller than the speed of light, \(\beta<1\). The momentum (and therefore \(\beta\)) spectrum of these particles is model dependent. Those which have \(\beta\) close to unity are indistinguishable from ordinary muons. Those with \(\beta\) significantly lower than 1 could be identified and their mass determined.

In ATLAS event fragments from different parts of the detector are assiged to a particular bunch crossing (BC) using the BC identifier (BCID). The usual assumption is that the particles traverse the detector at nearly at the speed of light (\(\beta\approx 1\)). Hits from a slower particle may be lost during data collection, or may be marked with the wrong BCID. The implications of low particle speed in the ATLAS trigger and data acquisition design are considered below.

This note does not address the case where the decay length of heavy charged NLSP is such that a significant number of particles will decay inside the tracking volume.

### Datasets used

This analysis is based on a data sample of 10,000 events from the CSC production generated with the characteristics of GMSB point 5: \(\Lambda=30\) TeV, \(M_{m}=250\) TeV, \(N_{5}=3\), \(\tan\beta=5\), \(\mathrm{sgn}(\mu)=+\), \(C_{\mathrm{grav}}=5000\). At this point the squarks and gluinos have masses around 700 GeV, the neutralino has a mass of 114 GeV and the \(\tilde{\tau}\)  and \(\tilde{\ell}\)  have masses of 102 and 100 GeV respectively. The cross-section for this point is 23 pb and the \(\tilde{\tau}\), \(\tilde{e}\)  and \(\tilde{\mu}\)  are co-NLSPs and are produced in the decay \(\tilde{\chi}^{0}\rightarrow\tilde{\ell}^{\pm}\ell^{\mp}\). Because of the small mass difference between the neutralino and the slepton, the \(\tilde{\ell}\)  and lepton are nearly collinear. The \(p_{\mathrm{T}}\)  and \(\beta\) spectra of the sleptons and accompanying leptons are shown in Figure 13.

GMSB5 is a single benchmark point and cannot be taken to represent all the possibilities of long-lived particle production. Some issues that impact our ability to discover long-lived new particles, if they exist, depend on the mass and \(\beta\) spectrum of these particles. In order to make our study less model dependent we also used for this study additional samples of events containing a single \(\tilde{\tau}\)  each, generated at different \(\beta\) with a uniform \(\eta\) distribution between \(\eta=-3\) and \(\eta=+3\).

Split-SUSY events containing long-lived gluinos with masses of 300 GeV and 1000 GeV were also used to assess the efficiency of the slow particle trigger, as discussed below. The generation and simula

Figure 13: Transverse momentum and velocity spectra for sleptons and accompanying leptons from the GMSB5 sample.

tion of these Split-SUSY events is described in Section 6.

For the background study we used single muon events from the CSC production. They were produced at constant \(p_{T}\) with a uniform \(\eta\) distribution, like the single \(\bar{\tau}\) samples. We used cross-section estimates of 1000 pb (200 pb) for muons with \(p_{\mathrm{T}}>40\) GeV (\(>100\) GeV) inside the ATLAS acceptance of \(|\eta|<2.5\)[45].

The simulation of a long-lived heavy sleptons in the ATLAS detector required a special patch to GEANT4 [46].

### Trigger and DAQ issues

When trying to identify slow particles [47, 48] one must pay special attention to the dimensions of ATLAS. Since the detector extends over 20m in length from the interaction point to each detector side and the bunch crossing period is 25ns, this means that particles from three separate bunch crossings can co-exist in the detector at the same time.

As described above, the matching of event fragments from different subdetectors is achieved using the BCID. This is calibrated so that particles originating together at the interaction point and traveling at the speed of light will have the same BCID assigned to them in all detector elements.

When \(\beta\) is sufficiently small, the particle will take longer to reach the detectors (especially those far from the interaction point) and hits may be assigned a wrong BCID and thus not be read-out. Figure 14 shows the efficiency with which slepton hits in the muon trigger chambers are associated to the correct bunch crossing as a function of \(\beta\). This figure was produced using the single \(\bar{\tau}\) events described above. It can be seen that efficiency drops sharply below \(\beta=0.8(0.7)\) in the endcap (barrel). In order to find particles with \(\beta<0.7\) (\(\beta<0.6\)) in the endcap (barrel), ATLAS must collect hits from the following bunch crossing (BC). Fortunately the MDT chambers collect data over a 700 ns interval, and thus hits from many BCs will be present. The RPC and TGC data acquisition can be set up to read out data from \(\pm 7\) and \(\pm 1\) BCs around the triggered BC respectively. The option to read out the information about extra BC, which was originally intended for debugging, must be switched on during routine ATLAS operation if we want to increase our efficiency for long-lived charged particles.

The hits from a slow particle may fall outside the correct BC, either for all trigger stations (e.g. if the particle is very slow and the trigger was produced by another feature in the event) or hits in the low-\(p_{\mathrm{T}}\) stations in the barrel may arrive in the correct BC, but the hits in the outer station may be late. In such a case, even if the \(p_{\mathrm{T}}\) of the particle was high, it would produce a low \(p_{\mathrm{T}}\) trigger.

Figure 14: The efficiency, as a function of \(\beta\), for all slepton hits in the muon trigger chambers to be included in the same BC with fast particles, for the barrel (right)and the endcap (left).

In GMSB5 the two sleptons are produced with different \(\beta\)'s, and since most of the sleptons have high \(\beta\), at least one of the two produced sleptons will have \(\beta>0.7\) in 99% of the events. The level-1 [49] muon trigger efficiency in the correct BC is very high, either from a slepton with high \(\beta\), or from one of the accompanying leptons. Table 15 shows the level-1 trigger efficiencies for GMSB5 events, based on the Level-1 thresholds defined in the standard ATLAS menu for a luminosity of \(10^{33}\).

Nevertheless, a low \(\beta\) slepton, one with good potential for a mass measurement, could arrive to the muon spectrometer, or more likely the outer muon station, in the next BC. In such a case the slow slepton will not be found by the trigger, or be identified as a low \(p_{\rm T}\) muon. In order to identify such a slow particle muon trigger chamber data from the next BC has to be collected.

In Split SUSY, the gluinos are produced directly, and there are few other features in the event. Therefore the \(R\) hadrons themselves must trigger the event. Since both of the \(R\) hadrons may be slow, the muon trigger may correspond to the wrong BC for the central parts of the detector. As a result, other event information such as that from the inner detector may be lost in the previous BC. This problem may be solved by also collecting data from the previous BC in the inner detector, but the feasibility of doing this, from the point of view of increased data volume, has not been investigated in this work. Additional data from the calorimeter is not required in order to find long lived heavy charged particles.

### A L2 trigger for heavy sleptons

At L2 [50], algorithms are activated based on the Region of Interest (RoI) identified at L1. Each algorithm has a reconstruction stage which processes the data from the relevant parts of the subdetectors,

\begin{table}
\begin{tabular}{|l|c|} \hline Trigger label & Description \& Efficiency in GMSB5 \\ \hline \hline MU40 & 95\% \\ xE200 & 63\% \\ EM25i & 46\% \\ \hline \end{tabular}
\end{table}
Table 15: The L1 trigger efficiencies for GMSB5 simulated events for items from the trigger menu for \(\mathcal{L}=10^{33}\)cm\({}^{-}2\)s\({}^{-}1\). The description of the trigger items is in [42]

Figure 15: The \(\beta\) measured for sleptons in the barrel at L2 for different values of true \(\beta\). The error bar represents the fitted sigma of the measured \(\beta\) distribution.

and a hypothesis stage which makes the decision to keep or reject the reconstructed feature. L2 and the Event Filter run in "trigger chains" which define the order in which algorithms are called and the input and output of each processing stage.

The role of the L2 muon trigger is to confirm muon candidates flagged by the L1 and to give more precise physics quantities of the muon candidate.

The L2 muon selection is performed in two stages. The first stage is performed by the muFast algorithm [51], which starts from a L1 muon RoI and reconstructs the muon in the spectrometer, giving a new \(p_{\mathrm{T}}\) estimate. The hypothesis cuts on the estimated \(p_{\mathrm{T}}\) are set so that 90% of the muons with \(p_{\mathrm{T}}\) above the nominal threshold would pass the selection. The resulting trigger element is then passed to the next algorithm.

Track finding in the inner-detector is performed based on the region of interest found by muFast. The muFast candidate and inner-detector tracks then pass to the next algorithm, muComb, which matches an inner-detector track to the muon spectrometer track and refines the \(p_{\mathrm{T}}\) estimate [50].

In the muon barrel, the excellent time resolution (about 3 ns) of the RPC allows measurements of the time of flight (TOF). A method for finding the slepton and measuring its mass at L2 has been developed. We will show that, in the barrel, a slow particle may already be selected effectively at L2. Figure 15 shows the mean value and error of the \(\beta\) reconstructed at the L2 as a function of generated \(\beta\). This figure was produced using the single \(\tilde{\tau}\) events described above.

A selection based only on the \(\beta\) measurement would leave too many muons in the sample. At the hypothesis stage, we select using \(p_{\mathrm{T}}\)(candidate)\(>40\) GeV, \(\beta\)(candidate)\(<0.97\) and \(m\)(candidate)\(>40\) GeV. The mass is calculated from the measured \(\beta\) and the candidate's \(p_{T}\) and \(\eta\) estimated by muFast. Figure 16 show the mass distribution of signal and background resulting from the selection for an integrated luminosity of 500 pb\({}^{-1}\). It can be seen that the signal to background ratio is already good at the L2.

At a luminosity of \(10^{33}\), a slow particle trigger without further trigger selection would produce a rate lower than 1 Hz coming from muons. Further refinement of the slow particle selection using subsequent muon trigger stages can reduce this rate to 0.2 Hz.

The measurement of \(\beta\) for high \(p_{\mathrm{T}}\) muon candidates is already part of the standard ATLAS L2 program MuFast, and a program to make the selection described above is part of the ATLAS L2 trigger.

Measuring \(\beta\) in the muon spectrometer at the second level trigger could be particularly useful for \(R\) hadrons, which have a L2 trigger efficiency of about 50% for a mass of 300 GeV. The efficiency loss comes mainly from events where the \(R\) hadron is neutral in the inner detector (and undergoes charge exchange before the muon spectrometer), which then fail the second stage of the L2 trigger requiring matching between the candidate found in the muon spectrometer and a track in the inner detector. An

Figure 16: Mass distribution of signal and background resulting from the L2 selection for an integrated luminosity of 500 pb\({}^{-1}\). The shaded area is the GMSB5 signal, the dashed line is the muon background, and the full line is the sum.

other source of loss (probably less well simulated) is the assignment of inner detector hits from the charged \(R\) hadron to the incorrect bunch crossing.

If the \(R\) hadron is identified in the muon spectrometer as a slow particle candidate, it could be accepted without the requirement of a matching inner detector track. The slow particle selection at L2 results in an efficiency of 92% to select events with \(R\) hadrons in the barrel. The corresponding muon rate is expected to be completely negligible since all muons have an inner detector track.

The limitations of the L2 slow particle trigger should be noted. Firstly, this selection is performed only in the barrel of the muon spectrometer, where the RPCs are the trigger chambers. The timing information from the endcap is in BC granularity and cannot be used to measure \(\beta\). Secondly, a slow particle which does not produce a RoI in the correct BC will not cause the muFast algorithm to be called, and the selection will not be performed. Therefore, slow particles in the endcap, as well as very slow sleptons in events triggered by other objects such as high \(p_{T}\) leptons, can only be identified offline.

The final trigger decision in ATLAS is made in the event filter, which uses algorithms adapted from the offline reconstruction. As will be shown in the next section, the standard muon reconstruction is not efficient for slow particles; therefore many would be rejected at this stage. The combined trigger efficiency of L2 and the event filter for sleptons with velocity \(\beta=0.6\) is 39%.

To avoid the efficiency loss at the event filter, a specific reconstruction algorithm for slow particles, like the one we describe below for reconstruction, is being implemented at the event filter.

Slow particle candidates found at L2 that do not have a matching inner-detector track (such as charge flipped \(R\)-hadron candidates) should be accepted without further event filter selection. This will increase the combined trigger efficiency of the L2 and the event filter for \(R\) hadrons with a mass of 300 GeV from 25% to 92% in the barrel. The muon rate for this selection is completely negligible since all muons have an inner-detector track, but the effect of cavern background on this selection has not been studied yet.

### Reconstruction of heavy sleptons with the current muon reconstruction packages

In the standard ATLAS reconstruction [52], stable sleptons are expected to be reconstructed as muons. The efficiency to reconstruct slow sleptons is compromised due to the following issues: muons are reconstructed by forming track segments in the three stations of the Muon Spectrometer. Segments in the \(\phi\) direction are found using the trigger chamber data. The data may not be collected if the hits from a slepton are in the next bunch crossing instead of the collision BC. The lack of a \(\phi\) segment hinders the reconstruction of the precision segment in \(\eta\) using the MDT data. Furthermore, the radii of MDT hits

Figure 17: The efficiency to reconstruct sleptons as muons as a function of \(\beta\) for two ATLAS muon reconstruction packages.

are distorted by late arrival of the slepton and may not fit well to a segment.

The efficiency of reconstructing the slepton as a muon depends on the reconstruction technique. Figure 17 shows the reconstruction efficiency for sleptons with the two ATLAS combined reconstruction packages, Staco and Muid which are based on the muon standalone packages MuonBoy and MOORE respectively. It can be seen that reconstruction efficiency starts dropping sharply for \(\beta<0.8\). This indicates that special reconstruction techniques will be required for the slow particles. This is discussed in the next subsection.

### Identifying heavy long-lived particles at reconstruction

Estimating the velocity and mass in the event reconstruction allows us to identify heavy long lived charged particles, as well as to avoid the efficiency losses suffered when reconstructing them as muons. We do this with the MuGirl package [53], which enables us to select candidates also when the segment reconstruction is imperfect. Offline, the velocity can be also determined using the MDTs, the ATLAS precision muon chambers. In the MDT detectors, the hit position is obtained from the particle drift time. The drift distance is calculated assuming the particle passed the chamber with \(\beta=1\), which is wrong for the slow slepton. Minimizing the \(\chi^{2}\) of fit with respect to the time of arrival to the muon detectors yields an estimate of \(\beta\) and of the particle mass. This information is combined with estimates of \(\beta\) from the muon trigger chambers. Figure 18 shows the \(\beta\) resolution and reconstructed mass of sleptons from GMSB5 obtained from the reconstruction with MuGirl.

### Conclusion of strategies for the long-lived heavy particle search

Heavy, long-lived charged particles can be discovered in ATLAS, should they exist. However, this cannot be done effectively using the standard ATLAS muon reconstruction tools. Furthermore, much of the discovery must be done before the analysis stage, in the data acquisition, high level trigger and reconstruction. We have added to the standard ATLAS software components which can identify sleptons effectively.

The efficiency to discover slow long-lived charged particles depends on collecting extra data from the bunch crossing following the one in which the interaction occurred. This is most important for data from the muon trigger chambers, where this possibility is included in the data acquisition design.

For the GMSB5 model, discovery would assured with low integrated luminosity, once the MDT and RPC time calibrations are established. The discovery methods are largely independent of the model

Figure 18: \(\beta\) resolution and reconstructed mass for sleptons from the GMSB5 sample.

characteristics, with discovery for a given integrated luminosity depending primarily on the production cross-section of the slow particles.

## 6 Search strategies for \(R\) hadrons at ATLAS

### Introduction

The presence (or absence) of massive exotic stable hadrons will be an important observable in the search for and quantification of any new physics processes seen at the LHC. Stable exotic coloured particles are predicted in a range of SUSY scenarios (see, for example, Refs. [22, 23, 24, 25, 26, 31]). Such particles could be copiously produced at the LHC and sensitivity to particle masses substantially beyond those excluded by earlier collider searches (\(\lesssim\)200 GeV) [31] could be achieved at ATLAS even with rather modest amounts of integrated luminosity (\(\sim 1\)fb\({}^{-1}\)). This section outlines a strategy for the detection of exotic massive, long-lived hadrons (so-called \(R\) hadrons) formed from either stable gluinos or stops (\(R_{\tilde{g}}\) and \(R_{\tilde{t}}\) hadrons, respectively). As described in section 2.1, the \(R_{\tilde{g}}\) hadrons (\(R_{\tilde{t}}\) hadrons) are considered in the context of a Split-SUSY (stop NLSP/gravitino LSP) scenario. Although this work is performed in the framework of SUSY, the techniques presented here may be used in generic searches for stable heavy exotic hadrons. As in the heavy lepton studies presented in section 4, this work relies on a signature of high-\(p_{T}\) muon-like track, although the distributions presented in this section provide a means of discriminating between lepton and hadron hypotheses for any observed stable massive particle.

This section is organised as follows. First a description is given of the simulation of \(R\) hadrons at ATLAS, including both the event generation and scattering of \(R\) hadrons in matter. Final state observables associated with \(R_{\tilde{g}}\) and \(R_{\tilde{t}}\) hadrons are then presented and it is shown how it may be possible to experimentally distinguish between these two types of particles should a discovery be made of stable massive exotic hadrons. Finally, the discovery potential for \(R_{\tilde{g}}\) and \(R_{\tilde{t}}\) hadrons is presented.

### Physics and detector simulation

#### 6.2.1 Event generation

The leading-order event generator PYTHIA [54] was used to produce samples of pair-produced gluino and stop-antistop events for a range of gluino and stop masses, as summarised in Table 16. Production mechanisms of stops and gluinos are illustrated in Figure 19, which shows leading-order Feynman diagrams. The effects of higher orders, which are important for the jet selection used later in section 6.3.3, are computed within PYTHIA using the parton shower technique.

The processes studied were selected such that they provide conservative estimates of likely rates at the LHC, which depend principally on the mass of the heavy object under study and not other free SUSY parameters.

For the gluino generation a Split-SUSY scenario was used in which squarks masses were set to 4 TeV. To ensure the results presented here are as model-independent as possible, only the PYTHIA sub-process \(gg\to\bar{g}\bar{g}\) was considered whilst neglecting the quark annihilation process \(q\bar{q}\to\bar{g}\bar{g}\), which is sensitive to the squark mass. The former process is anyway the dominant production channel for gluino masses up to \(\sim 1.5\) TeV.

For the stable stop sample, the diagonal production of pairs of the lighter stop state (\(\tilde{t_{1}}\)) were assumed and the following sub-processes modelled: \(gg\to\tilde{t_{1}}\tilde{t_{1}}\;q\bar{q}\to\tilde{t_{1}}\tilde{t_{1}}\). All sparticle masses except that of the \(\tilde{t_{1}}\) quark were set to 4 TeV although, at leading-order, the masses of other sparticles are not relevant for the cross-section calculations [55].

String fragmentation [56] was used to model the momenta of the \(R\) hadrons. A Peterson fragmentation function [57],

\[D(z)\propto\frac{1}{z}(1-\frac{1}{z}-\frac{\epsilon_{\tilde{q}\tilde{g}}}{1-z})^ {-2}\, \tag{2}\]

for which the \(\epsilon\) parameter for the heavy coloured object (\(\epsilon_{\tilde{q}\tilde{g}}\)) has a value extrapolated from its value for \(b\)-quarks (\(\epsilon_{\tilde{q}\tilde{g}}/\epsilon_{b}=m_{b}^{2}/m_{\tilde{q}\tilde{g}}^{2}\)) [58] was used to model the momentum distribution of the \(R\) hadron.

Following hadronisation, and based on calculations of the mass hierarchy of the lowest-lying \(R\)-hadron states [59], around 55% (40%) of the stable \(R_{\tilde{g}}\) (\(R_{\tilde{t}}\)) hadrons are predicted to have zero electric charge. This difference arises principally due to the possible existence of gluino-gluon states, for which the production probability is set to 10% here, and which are treated as mesons when propagating through matter (Section 6.2.2).

To complement the signal samples, various background samples were used, each corresponding to an integrated luminosity of at least \(\sim 1\) fb\({}^{-1}\). The generated and reconstructed number of events, and the equivalent luminosity of each sample is given in Table 17. As the simulated trigger used for this analysis requires a hard muon-like track, only events which could give rise to a high \(p_{T}\)-muon (\(p_{T}>150\) GeV) were simulated. The following processes were considered. Leading-order 2-to-2 QCD processes, which include all quark flavours except top, and which differ in the values of the internal matrix element cut-offs (\(\hat{p}_{T}\)) were generated with PYTHIA, the predictions of which are denoted QCD when discussed in section 6.3.2. In addition, backgrounds arising from diboson (HERWIG [40]) and single boson (PYTHIA) production, denoted electroweak, were produced, again with matrix element cut-offs in order to produce hard muons. A sample of \(t\bar{t}\) pair-production events, termed top, was also prepared using the MC@NLO [60] program.

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline sparticle & **Mass (GeV)** & **Events/fb\({}^{-1}\)** & \(\mathcal{L}\) **(fb\({}^{-1}\))** \\ \hline \(\tilde{g}\) & 300 & \(2.69\times 10^{5}\) & \(3.72\times 10^{-2}\) \\ \(\tilde{g}\) & 600 & \(4.84\times 10^{3}\) & 2.07 \\ \(\tilde{g}\) & 1000 & 138 & 72.5 \\ \(\tilde{g}\) & 1300 & 16.4 & 610 \\ \(\tilde{g}\) & 1600 & 2.12 & \(4.72\times 10^{3}\) \\ \(\tilde{g}\) & 2000 & 0.230 & \(4.35\times 10^{4}\) \\ \(\tilde{t}\) & 300 & \(7.82\times 10^{3}\) & 1.12 \\ \(\tilde{t}\) & 600 & \(1.76\times 10^{2}\) & 35.2 \\ \(\tilde{t}\) & 1000 & 6.4 & \(1.5\times 10^{3}\) \\ \hline \end{tabular}
\end{table}
Table 16: Expected number of gluino and stop pair-production events for 1fb\({}^{-1}\) of integrated luminosity and the equivalent luminosity of signal samples.

Figure 19: Selection of leading-order processes illustrating the production of gluino and stop particles.

#### 6.2.2 Simulation of \(R\)-hadron scattering in matter

A model of \(R\)-hadron scattering [61, 62] recently implemented in Geant4 [63] is used in this work. This is an update of earlier work [59] which, in view of the inherent uncertainties associated with modelling such processes, adopts a pragmatic approach in which the scattering rate is estimated with the geometric cross-section and phase space arguments are used to predict the different 2-to-2 and 2-to-3 reactions. Other approaches to modelling \(R\)-hadron scattering have been proposed, based on Regge phenomenology [24, 25, 64]. These yield predictions of energy loss and scattering cross-sections which are qualitatively similar to those given by the model used here and any differences would not be expected to change the conclusions of this paper.

The typical energy loss per interaction is predicted to be low (around several GeV [61]) since only the light quarks within the \(R\) hadron should participate in interactions with matter, leaving the heavy squark or gluino as a spectator. This implies that the fraction of \(R\) hadrons which would be triggered (\(\beta\raisebox{-3.01pt}{$\,\stackrel{{>}}{{\sim}}\,$}0.6\), see Section 6.3.1) and which would then be stopped during their traversal of the detector is negligible6.

Footnote 6: Although it does not form a part of this work, the possibility of observing the decay of \(R\) hadrons which would be stopped offers a promising and complementary means of searching for \(R\) hadrons at the LHC [65, 66].

In addition to energy loss, another feature of \(R\)-hadron scattering, which has implications for experimental searches, is the possibility of charge and baryon number exchange. Following repeated scattering \(R_{\bar{g}}\) hadrons and \(R_{\bar{t}}\) hadrons not containing an anti-stop should enter the muon system predominantly as baryons. This is due to the occurence of meson-to-baryon conversion processes for which the inverse reaction is suppressed [59]. Anti-baryons, however, would be expected to quickly annihilate in matter and \(R_{\bar{t}}\) hadrons containing anti-stops would thus largely remain as mesons.

The material budget of the part of the ATLAS detector enclosed by the muon system varies as a function of pseudorapidity between 11 and 21 interaction lengths [5, 29], with the calorimeters providing the largest contribution. It is estimated that a \(R_{\bar{g}}\) hadron (\(R_{\bar{t}}\) hadron) will typically undergo 10-20 (7-15)

\begin{table}
\begin{tabular}{|l|r r|r r|} \hline Sample & Dataset ID & Gen. Events & Rec. Events & \(\mathcal{L}\)(fb\({}^{-1}\)) \\ \hline
**QCD**: (PYTHIA) & & & & \\ \hline (140 GeV \(<\hat{p}_{T}<280\)GeV) & 5013 & \(3.125\times 10^{8}\) & 2572 & 0.98 \\ (280GeV \(<\hat{p}_{T}<560\) GeV) & 5014 & \(2.5\times 10^{7}\) & 4800 & 1.12 \\ (560GeV \(<\hat{p}_{T}<1120\) GeV) & 5015 & \(3.5\times 10^{5}\) & 738 & 1.01 \\ (1120GeV \(<\hat{p}_{T}<2240\)GeV) & 5016 & \(5\times 10^{4}\) & 241 & 9.46 \\ (2240GeV \(<\hat{p}_{T}\) & 5017 & \(1\times 10^{4}\) & 42 & 442.29 \\ \hline
**Electroweak** & & & & \\ \hline ZZ (HERWIG) & 5985 & \(2.5\times 10^{4}\) & 53 & 9.82 \\ WW (HERWIG) & 5986 & \(2\times 10^{4}\) & 50 & 1.21 \\ WZ (HERWIG) & 5987 & \(1.5\times 10^{4}\) & 29 & 2.32 \\ \(Z\rightarrow\mu\mu\) (PYTHIA) & 5105 & \(1.3\times 10^{4}\) & 600 & 1.29 \\ \(Z\rightarrow\tau\tau\) (PYTHIA) & 5106 & \(3\times 10^{3}\) & 108 & 9.94 \\ \(W\rightarrow\mu\nu\) (PYTHIA) & 5145 & \(3\times 10^{4}\) & 600 & 0.94 \\ \(W\rightarrow\tau\nu\) (PYTHIA) & 5146 & \(3\times 10^{4}\) & 120 & 7.82 \\ \hline
**Top** & & & & \\ \hline \(t\bar{t}\): (MC@NLO) & 5200 & \(1\times 10^{6}\) & 4065.08 & 0.98 \\ \hline \end{tabular}
\end{table}
Table 17: Background samples used in this work. The number of generated and reconstructed events are shown along with the equivalent integrated luminosity.Event weighting accounts for the non-integer number of generated and reconstructed \(t\bar{t}\) events.

nuclear interactions before reaching the muon system [62]. The difference in scattering rates is due to the smaller number of light valence quarks present in \(R_{\tilde{t}}\) hadrons. Owing to the large number of interactions a substantial rate of events is thus expected in which a \(R\) hadron appears to possess different values of the electric charge in the inner detector and muon system.

While such topologies represent a challenge for track reconstruction software, they also provide observables useful for the discovery and characterisation of \(R\) hadrons, something which is explored in section 6.3. For example, a \(R_{\tilde{g}}\) hadron can reverse the sign of its charge. \(R_{\tilde{t}}\) hadrons [31] can only show this behaviour in the case where an intermediate neutral state oscillates into its anti-particle [67, 68]. Since the expected rates of such are processes are essentially unconstrained by experimental limits on SUSY scenarios, they are not included in the simulation used here. Instead, a conservative, zero oscillation scenario is considered.

### Event selection

#### 6.3.1 Trigger

The selected level 1 trigger is the \(mu\)6 trigger [29], which has been considered in previous studies of \(R\) hadrons at ATLAS as the most promising trigger for this type of work [69]. This trigger is sensitive to the 'classic' stable massive particle signature of a high transverse momentum muon-like track. The trigger efficiency after the level 2 selection for both \(R_{\tilde{g}}\) and \(R_{\tilde{t}}\) hadrons falls from around 30% at masses of several hundred GeV to around 20% at 2 TeV. The variation of efficiency with mass is due to the slowness of the \(R\) hadron. Here, we consider events in which a \(R\)-hadron track in the muon system must be associated with the correct bunch crossing 7. This leads to a rapid fall in efficiency for \(\beta\raisebox{-3.698858pt}{$\stackrel{{<}}{{\sim}}$}0.6\). A gradual decrease in efficiency would therefore naively be expected for increasing \(R\)-hadron mass. After including requirements that the event filter is passed and the muon-like track is well-reconstructed, there is little mass-dependence in the overall efficiency for \(R_{\tilde{g}}\) hadrons (around 10-15%) or \(R_{\tilde{t}}\) hadrons (20-30%). This difference arises due to the stringent track cuts in the event filter which, at low masses (\(\sim 300\) GeV) reject a substantial proportion of tracks which have reversed the sign of their charge, which, as explained in section 6.2.2, occurs only for \(R_{\tilde{g}}\) hadrons. At higher masses, corresponding to higher transverse momentum, the poorer momentum resolution allows more 'charge flippers' to pass. As shown in section 6.3.3 this source of inefficiency has little effect on the discovery potential owing to the large predicted cross-section for low mass \(R_{\tilde{g}}\) hadrons. However, future work could involve the development of triggers which do not rely on linked inner detector-muon chamber tracks. Should such a trigger configuration be introduced which is based on the \(mu\)40 [29] trigger at level 1, this could potentially improve the overall efficiency by a factor of \(2-3\) for \(\beta\raisebox{-3.698858pt}{$\stackrel{{>}}{{\sim}}$}0.6\).

Footnote 7: Section 5 explores possibilities of probing the lower \(\beta\) region

#### 6.3.2 \(R\)-hadron final state observables

Following the trigger selection, reconstructed final state quantities were used to select \(R\)-hadron events and suppress background. A number of variables are presented which were found to provide discrimination between \(R\)-hadron and Standard Model background processes. Since observables associated with \(R_{\tilde{g}}\) hadrons and \(R_{\tilde{t}}\) hadrons are mostly very similar, generally only the \(R_{\tilde{g}}\)-hadron spectra are presented in this section. Where there is a substantial difference in the spectra of the two particle species, separate distributions are shown.

Figure 20 shows the expected transverse momenta distributions, \(\frac{dn}{dp_{T}}\), of muon-like tracks in \(R_{\tilde{g}}\) and \(R_{\tilde{t}}\)-hadron events, for an integrated luminosity of \(1\)fb\({}^{-1}\). Distributions from background events are also shown. As expected, the \(R\)-hadron spectra become harder with larger mass, extending up to \(\sim 1\) TeV at the largest mass values, while the background events are comparatively softer.

The ratio of high and low threshold \(HT/LT\) TRT hit multiplicities is shown in Fig 21 (top left) for \(R_{\tilde{g}}\) hadrons of mass 1000 GeV and muon candidates from background events. The different thresholds correspond to low (\(\sim 200\) eV) and high (\(\sim 6.5\) keV) amounts recorded of ionisation energy for a hit. Owing to the large mass and restricted \(\beta\) range the simulated \(R\)-hadron data peak at lower values of \(HT/LT\) than the background tracks.

Since \(R\) hadrons will typically suffer only several GeV energy loss per interaction through scattering in the calorimeter, it is unlikely they will be associated with a hard calorimeter jet. Figure 21 (top right) shows the distance \(R=(\Delta\eta^{2}+\Delta\phi^{2})^{1/2}\) between a \(R_{\tilde{g}}\)-hadron track and a jet (defined with the \(k_{T}\) algorithm) with \(p_{T}>100\) GeV. Clearly for the \(R\) hadrons, the spectrum is typically larger than around 1, unlike the background sources which peak at lower values. The QCD background peaks around zero since a large proportion of muons in this sample are produced in the decay of heavy quarks. The top distribution peaks at values around 0.4 reflecting the higher jet multiplicity in such events compared to \(R\)-hadron events. The distribution is not shown for the electroweak backgrounds owing to the statistical imprecision of the Monte Sample sample (very few events with high \(p_{T}\) jets arise in the selected kinematic region under study here).

In a leading-order picture, \(R\) hadrons will be produced approximately back-to-back, unlike a number of background sources, as can be seen in Figure 21 (bottom left), which shows the cosine of the angle between two \(R_{\tilde{g}}\)-hadron candidates which both leave hard tracks in the muon system \((\cos\Delta\Phi_{\mu,\mu})\); the \(R_{\tilde{g}}\)-hadron sample peaks strongly at \((\cos\Delta\Phi_{\mu,\mu})\sim-1\). Figure 21 (bottom right) shows the distribution of the cosine of the angle between hard tracks in the inner detector and muon system \((\cos\Delta\Phi_{ID,\mu})\), which, for pair production events, would be expected to display peaks at \(\sim\pm 1\).

As described in section 6.2.2, charge exchange processes can give rise to events in which a linked track is assigned different values of electric charge in the inner detector and muon systems. This is shown in Figure 22 which shows the variable \(\frac{q_{ID}p_{TID}}{q_{\mu}p_{T\mu}}\), where \(q_{ID}\),\(q_{\mu}\), \(p_{T,ID}\), and \(p_{T\mu}\) are the charge as reconstructed in the inner detector and muon system, and the reconstructed transverse momentum in

Figure 20: Distributions of transverse momenta \(\frac{dn}{dp_{T}}\) of hard tracks (\(p_{T}>50\) GeV) as reconstructed in the ID (left) and muon (right) system. The top, middle, and bottom plots show tracks from \(R_{\tilde{g}}\), \(R_{\tilde{t}}\), and background events, respectively. As labelled, \(R\)-hadron spectra are scaled according to \(R\)-hadron mass. The spectra correspond to an equivalent integrated luminosity of 1fb\({}^{-1}\).

the inner detector and muon system, respectively. The gluino distributions show a two peak structure, with the peak at negative values of \(\frac{q_{ID}p_{T}ID}{q_{B}p_{T}}\) arising from charge 'flipping' processes. \(R_{\tilde{t}}\)-hadron spectra indicate a very small rate (several per cent) of candidates with oppositely signed charge in the muon and ID systems which is due to charge misidentification in the muon and ID systems. Both the stop and gluino distributions become broader with increasing mass; this reflects the commensurate increase in \(p_{T}\) and hence degraded resolution of the tracking systems, which has the effect of allowing a greater proportion of charge-'flipping' \(R_{\tilde{g}}\) hadrons to satisfy the event filter.

#### 6.3.3 \(R\)-hadron selection criteria

Using the information presented in section 6.3.2\(R\)-hadron selection criteria were developed following an optimisation procedure [62]. First, no hard muon-like track (\(p_{T}>250\) GeV) can come within a distance \(R<0.36\) of a hard jet (\(p_{T}>100\) GeV). Furthermore a candidate \(R\) hadron must satisfy at least one of the following conditions listed below. For consistency the same selection is applied both for \(R_{\tilde{g}}\) and \(R_{\tilde{t}}\) hadrons though criteria 3-4 are only relevant for \(R_{\tilde{g}}\) hadrons. However, these have a negligible impact

Figure 21: Ratio of the number of high to low threshold hits in the TRT (top left); distance between a \(R\)-hadron candidate and a jet (top right); cosine of the angle between two high \(p_{T}\) tracks in the muon system (bottom left); and cosine of the angle between high \(p_{T}\) tracks in the ID and muon systems (bottom right). Distributions are shown for \(R_{\tilde{g}}\) hadrons of mass 1000 GeV and three background sources.

Figure 22: Distributions of \(\frac{q_{ID}p_{T}ID}{q_{B}p_{T}}\) for \(R_{\tilde{g}}\) (left) and \(R_{\tilde{t}}\) hadrons (right). Predictions for a range of \(R\)-hadron masses are shown.

on the study of the stop discovery potential.

1. The event contains at least one hard muon track with no linked inner detector track. A linked track is defined such that the distance \(R=(\Delta\eta^{2}+\Delta\phi^{2})^{1/2}\) between the measurements in the ID and muon systems is less than 0.1.
2. The event contains two hard back-to-back ID tracks with the TRT hit distribution satisfying \(HT/LT<0.05\). A back-to-back configuration is defined such that the cosine of the angle between the two muon tracks is less than -0.85.
3. The event contains two hard back-to-back (as defined above) like-sign muon tracks.
4. The event contains at least one hard muon track with a hard matching ID track of opposite charge fulfilling the condition \(p_{T,ID}>0.5p_{T\mu}\).

Table 18 shows the acceptance numbers and rates for the various samples. It can be seen that for \(R\)-hadron masses below 1 TeV ATLAS opens up a discovery window with integrated luminosity of the order of 1 fb\({}^{-1}\). For masses above 1 TeV the rate of signal events is small, and is comparable to the expected background rate, so even discovery would be challenging even with larger data-sets.

### Conclusion of \(R\)-hadron search strategies

Stable massive exotic hadrons (\(R\) hadrons) are predicted in a number of SUSY scenarios. By exploiting the signature of a hard penetrating particle which may undergo charge exchange in the calorimeter and seemingly does not fall within a jet, ATLAS will be able to discover \(R\) hadrons for masses below 1 TeV with relatively low amounts of integrated luminosity (\(\sim 1\)fb\({}^{-1}\)).

## 7 Conclusion

Search strategies at ATLAS have been developed for a range of signatures of new physics processes expected within SUSY models. Studies were made of high transverse momentum photons, which may or

\begin{table}
\begin{tabular}{|l l l|} \hline
**Sample** & **Accepted events** & **Rate (Events / fb\({}^{-1}\))** \\ \hline
300 GeV gluino & 235 & \(6.44\times 10^{3}\) \\
600 GeV gluino & 551 & \(2.70\times 10^{3}\) \\
1000 GeV gluino & 774 & 10.7 \\
1300 GeV gluino & 732 & 1.20 \\
1600 GeV gluino & 685 & \(0.147\) \\
2000 GeV gluino & 546 & \(1.26\times 10^{-2}\) \\ \hline
300 GeV stop & 78 & 70.0 \\
600 GeV stop & 134 & 3.9 \\
1000 GeV stop & 170 & 0.1 \\ \hline J5 & 1 & \(0.893\) \\ J8 & 1 & \(2.26\times 10^{-3}\) \\ \(Z\rightarrow\mu\mu\) & 1 & \(0.776\) \\ \hline \end{tabular}
\end{table}
Table 18: Number of events selected for the given samples. Background samples not mentioned here are rejected by the selection.

may not have been produced at the primary collision point, and of slow moving stable massive interacting particles (sleptons and \(R\)-hadrons).

It was shown that with early LHC data, corresponding to an integrated luminosity of around 1fb\({}^{-1}\), ATLAS opens up a discovery window for those SUSY scenarios giving rise to the aforementioned signatures. Although the studies were performed within the framework of SUSY, the techniques used can be applied to generic searches for physics beyond the Standard Model.

## References

* [1] H.P. Nilles, Phys. Rept. **110** (1984) 1.
* [2] H.E. Haber and G.L. Kane, Phys. Rept. **117** (1985) 75-263.
* [3] J. Wess and J. Bagger,,, Princeton, USA: Univ. Pr. (1992) 259 p.
* [4] S.P. Martin, _A supersymmetry primer_, hep-ph/9709356 (1997).
* [5] ATLAS Collaboration, _The ATLAS experiment at the Large Hadron Collider_, paper submitted to JINST.
* [6] ATLAS Collaboration, _ATLAS detector and physics performance. Technical design report_ Vol. 2, CERN-LHCC-99-15 (1999).
* [7] ATLAS Collaboration, _Data-driven determinations of W, Z, and top background to supersymmetry_, this volume.
* [8] ATLAS Collaboration, _Estimation of QCD backgrounds to searches for Supersymmetry_, this volume.
* [9] ATLAS Collaboration, _Prospects for SUSY discovery based on inclusive searches_, this volume.
* [10] L. Alvarez-Gaume, J. Polchinski, and M.B. Wise, Nucl. Phys. **B221** (1983) 495.
* [11] L.E. Ibanez, Phys. Lett. **B118** (1982) 73.
* [12] J.R. Ellis, D.V. Nanopoulos and K. Tamvakis, Phys. Lett. **B121** (1983) 123.
* [13] K. Inoue, A. Kakuto, H. Komatsu and S. Takeshita, Prog. Theor. Phys. **68** (1982) 927.
* [14] A.H. Chamseddine, R. Arnowitt and P. Nath, Phys. Rev. Lett. **49** (1982) 970.
* [15] M. Dine, W. Fischler and M. Srednicki, Nucl. Phys. **B189** (1981) 575-593.
* [16] S. Dimopoulos and S. Raby, Nucl. Phys. **B192** (1981) 353.
* [17] C.R. Nappi and B.A. Ovrut, Phys. Lett. **B113** (1982) 175.
* [18] L. Alvarez-Gaume, M. Claudson and M.B. Wise, Nucl. Phys. **B207** (1982) 96.
* [19] M. Dine and A.E. Nelson, Phys. Rev. **D48** (1993) 1277-1287.
* [20] M. Dine, A.E. Nelson and Y. Shirman, Phys. Rev. **D51** (1995) 1362-1370.
* [21] M. Dine, A.E. Nelson, Y.Nir, Y. Shirman, Phys. Rev. **D53** (1996) 2658-2669.

* [22] N. Arkani-Hamed, S. Dimopoulos, G.F. Giudice and A. Romanino, Nucl. Phys. **B709** (2005) 3-46.
* [23] G.F. Giudice, and A. Romanino, Nucl. Phys. **B699** (2004) 65-89.
* [24] H. Baer and K. Cheung and J.F. Gunion, Phys. Rev. **D59** (1999) 075002.
* [25] A. Mafi and S. Raby, Phys. Rev. **D62** (2000) 035003.
* [26] J.L. Diaz-Cruz, J.R. Ellis, K.A. Olive. and Y. Santoso, JHEP **05** (2007) 003.
* [27] D.E. Acosta and others, Phys. Rev. **D71** (2005) 031104.
* [28] A. Abulencia and others, Phys. Rev. Lett. **99** (2007) 121801.
* [29] ATLAS Collaboration, _ATLAS detector and physics performance. Technical design report_ Vol. 1, CERN-LHCC-99-15 (1999).
* [30] D.E. Acosta, and others, Phys. Rev. Lett. **90** (2003) 131801.
* [31] M. Fairbairn and others, Phys. Rept. **438** (2007) 1-63.
* [32] ATLAS Collaboration, _Supersymmetry searches with ATLAS_, this volume.
* [33] Richter-Was, Elzbieta and Froidevaux, Daniel and Poggioli, Luc, _ATLFAST 2.0 a fast simulation package for ATLAS_ Atlas Note ATL-PHYS-98-131.
* [34] S. Dimopoulos, S.D. Thomas and J.D. Wells, Nucl. Phys. **B488** (1997) 39-91.
* [35] S.P. Martin, Phys. Rev. **D55** (1997) 3177-3187.
* [36] F. Paige, S. Protopopescu, H. Baer and X. Tata, _ISAJET 7.69: A Monte Carlo event generator for p, anti-p p, and e+ e- reactions_ hep-ph/0312045, 2003.
* [37] W. Beenakker, R. Hopker, M. Spira and P.M. Zerwas, Nucl. Phys. **B492** (1997) 51-103.
* [38] W. Beenakker and others, Phys. Rev. Lett. **83** (1999) 3780-3783.
* [39]_Prospino2_, [http://www.ph.ed.ac.uk/](http://www.ph.ed.ac.uk/) tplehn/prospino/.
* [40] Corcella, G. and others, JHEP **01** (2001) 010.
* [41] J. Butterworth, J. Forshaw and M. Seymour, Z. Phys. **C72** (1996) 637-646.
* [42] ATLAS Collaboration, _The ATLAS trigger for early running_, this volume.
* [43] ATLAS Collaboration, _ATLAS photon identification algorithms and their performances_, this volume.
* [44] Cavalli, D and Costanzo, D and Dean, S and D Internal report.
* [45] Boos, E. and others, Nucl. Instrum. Meth. **A534** (2004) 250.
* [46] Agostinelli, S. and others, Nucl. Instrum. Meth. **A506** (2003) 250-303.
* [47] Tarem, S. and Bressler, S. and Duchovni, E. and Levinson, L., _Can ATLAS avoid missing the long lived stau?_, Atlas note ATL-PHYS-PUB-2005-022, 2005.

* [48] Tarem, S. and Bressler, S. and Nomoto, H. and Dimattia, A., _Trigger and Reconstruction for a heavy long lived charged particles with the ATLAS detector_, Atlas note ATL-PHYS-PUB-2008-001, 2008.
* [49] ATLAS Level-1 Trigger Group, Level-1 Technical Design Report, ATLAS TDR 12, 1998.
* [50] ATLAS Collaboration, _ATLAS High-Level Trigger, Data Acquisition and Controls Technical Design Report_, ATLAS TDR-016 (2003).
* [51] A. Di Mattia et al., _A Level-2 trigger algorithm for the identification of muons in the ATLAS Muon Spectrometer_, Atlas notes ATL-DAQ-CONF-2005-005, CERN-ATL-DAQ-CONF-2005-005, 2005.
* [52] ATLAS Collaboration, _Muon reconstruction and identification performance in ATLAS: studies with simulated Monte Carlo samples_, this volume.
* Muon identification in ATLAS from the inside out, Nuclear Science Symposium Conference Record, 2006. IEEE Volume 1, May 2007, Pages 617
* [54] T. Sjostrand, S. Mrenna and P. Skands, JHEP **05** (2006) 026.
* [55] Beenakker, W. and Kramer, M. and Plehn, T. and Spira, M. and Zerwas, P. M., Nucl. Phys. **B515** (1998) 3-14.
* [56] Andersson, B and Gustafson, G. and Ingelman, G. and Sjostrand, T., Phys. Rept. **97** (1983) 31.
* [57] Peterson, C. and Schlatter, D. and Schmitt, I. and Zerwas, Peter M., Phys. Rev. **D27** (1983) 105.
* [58] Heister, A. and others, Phys. Lett. **B512** (2001) 30-48.
* [59] A.C. Kraan, Eur. Phys. J. **C37** (2004) 91-104.
* [60] S. Frixione and B.R. Webber, (2006).
* [61] R. Mackeprang and A. Rizzi, Eur. Phys. J. **C50** (2007) 353-362.
* [62] R. Mackeprang, Stable Heavy Hadrons in ATLAS, Ph.D. thesis, Niels Bohr Institute, Copenhagen University, 2007.
* [63] Allison, J. and others, IEEE Trans. Nucl. Sci. **53** (2006) 270.
* [64] Y.R. De Boer, A.B. Kaidalov, D.A. Milstead and O.I. Piskounova, (2007).
* [65] Arvanitaki, A. and Dimopoulos, S. and Pierce, A. and Rajendran, S. and Wacker, Jay G., Phys. Rev. **D76** (2007) 055007.
* [66] Abazov, V. M. and others, Phys. Rev. Lett. **99** (2007) 131801.
* [67] S.J. Gates Jr. and O. Lebedev, Phys. Lett. **B477** (2000) 216-222.
* [68] U. Sarid and S.D. Thomas, Phys. Rev. Lett. **85** (2000) 1178-1181.
* [69] Kraan, A. C. and Hansen, J. B. and Nevski, P., Eur. Phys. J. **C49** (2007) 623-640.