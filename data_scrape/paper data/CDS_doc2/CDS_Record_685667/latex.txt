###### Abstract

This paper presents the design and prototype testing of an analog pipeline readout module suitable for reading out fast calorimeters at the large hadron collider. The design has been driven by the readout requirements of the ATLAS electromagnetic liquid argon calorimeter and the ATLAS trigger design parameters. The module is based on switched capacitor array chips.

D.M. Gingrich\({}^{1}\), J.C. Hewlett, L. Holm, S.L. Mullin, J.L. Pinfold, J.R. Schaapman

_Centre for Subatomic Research, University of Alberta, Edmonton, AB, Canada_

S. A. Kleinfelder

_Lawrence Berkeley Laboratory, University of California, Berkeley, CA, USA_

E. Auge

_LAL, Orsay, France_

## 1 Introduction

The 25 ns bunch-crossing interval at the large hadron collider (LHC) puts stringent requirements on the readout and trigger systems of the experiments. The latency of the ATLAS [1] level one trigger will be 2 \(\mu\)s and hence data must be stored locally in pipelines until a level one trigger accept. For the ATLAS electromagnetic calorimeter, the signals will be continuously sampled at the bunch-crossing frequency of 40 MHz, and the capability of reading out samples from multiple bunch crossings per triggered event must exist. The readout system must also simultaneously transfer fully digitized event data to the level two trigger and data acquisition systems with no dead-time, at the mean level one trigger rate of 100 kHz. The entire readout system must have a greater than 15-bit dynamic range with an 11-12 bit accuracy, and a timing resolution sufficient to uniquely identify the bunch crossing. In addition, the system must be compact, reliable, have low power requirements, low cost, and be radiation hard in the LHC environment. We describe prototype tests of an analog pipeline readout module that meets these requirements.

Pipeline Readout Module

A digitization rate at the bunch-crossing frequency of 40 MHz with a greater than 15-bit dynamic range will be difficult to achieve. The digital pipeline approach offers a simple and flexible architecture but suffers from the lack of an available 40 MHz high precision analog-to-digital converter (ADC), which is affordable in terms of both cost and power. However, a digitization rate of only 100 kHz is possible by storing the data in analog form until a level one trigger accept. This analog pipeline approach greatly reduces the bandwidth compared to a digital approach and allows the possibility of multiplexing many channels into a single ADC.

### Switched Capacitor Array Chip

The switched capacitor array approach to pipelining analog detector signals offers low cost, low power, and high density, while providing fast sampling speeds, wide dynamic range, and a high degree of flexibility. The technique has been successfully implemented in the ZEUS experiment [2].

We use the switched capacitor array (SCA) chip originally designed at the Lawrence Berkeley Laboratory [3]. The SCA memory is subdivided into 16 parallel channels of 256 sample-and-hold cells (capacitors) per channel. Each of the 16 channels has a dedicated analog input which is connected to a bus distributing the input signal to the 256 cells. Each sample-and-hold cell consists of a complementary CMOS transmission gate and a 0.7 pF double-polysilicon capacitor. An externally supplied reference voltage is applied to the bottom plate of all capacitors. The voltage stored on each sample-and-hold capacitor then corresponds to the difference between the input signal from a given channel at the time its sample-and-hold switches are closed and the applied reference voltage. The reference voltage can be adjusted to shift the baseline for better level matching. During the readout sequence each sampling capacitor is placed in the feedback path of an op-amp with one op-amp per channel.

The SCA chip is an externally addressed analog memory. An address decoder turns on and off the sample-and-hold switches using a break-before-make action. This insures that no charge sharing between subsequently engaged capacitors can occur. The sample-and-hold cells in a given channel can be addressed in any order and charge can simultaneously be stored in one capacitor while being retrieve from a different capacitor in the same channel. These characteristics allow dead-time free operation of the pipeline. The high density 1.2 \(\mu\)m double-metal CMOS process that is used to make the SCA chip is also suitable for the inclusion of other integrated circuits that could perform on-chip preamplification, signal shaping, range selection, analog multiplexing, analog-to-digital conversion, etc..

### Readout Module Design

Our readout module design uses a dual-range scheme with SCA chips, including analog multiplexing, and followed by commercial ADCs. To obtain the required greater than 15-bit dynamic range, the signals from the calorimeter preamplifiers will be split into two gain scales and processed by shapers with a greater than 12-bit dynamic range before being sampled at 40 MHz. This scheme effectively doubles t he number of pipeline channels but relaxes the digitization requirements to allow the use of commercial ADCs. Pulse shaping is required to preserve the advantages of the calorimeter speed and to minimize the effects of pile-up from crossings near in time. The calorimeter samples are stored in analog form, and only digitized after receipt of a level one trigger accept, leading to an available digitization time of 10 \(\mu\)s on average. Before digitization the appropriate gain scale is chosen by comparing the high gain signal with a reference voltage. We envision multiplexing 16 channels into 12-bit 10 MHz ADCs and digitizing five samples per channel. By multiplexing the analog output before digitization, the number of ADCs, and hence, board space and power requirements will be reduced. After digitization the ADC converted data and SCA addresses, inserted by a data formatter, are transmitted to the level two trigger and data acquisition systems over an optical fiber. A schematic diagram of 16 channels of the readout module design is shown in figure 1. The timing, control logic, and level one trigger connections are not shown.

## 3 Prototype Testing

A prototype readout module for tests with the RD3 liquid argon accordion calorimeter [4] at the SPS in CERN was designed. The main objective of these tests was to obtain a 12-bit resolution.

We build five 6U VME readout modules and a wire-wrapped pipeline controller board for tests in September of 1993. Each prototype readout module occupied two slots in the VME crate, with one PC board allocated to the analog functions and one to the digital circuitry. Since the test beam from the SPS could not provide the energy range that will occur at the LHC, we did not implement the dual-range readout scheme. Furthermore, since the RD3 shapers process 24 calorimeter cells and the SCA chips contained 16 channels, we put two SCA chips on each analog board and used only 12 of the 16 channels on each chip. A future application specific integrate circuit version of the shaper will process eight channels, and hence allow all channels of the SCA chips to be utilized and higher density analog pipeline boards to be laid out. Following the two SCA chips on each analog pipeline board were a set of amplifiers and sample-and-hold circuits which allowed the 24 channels to be multiplexed into 12 12-bit ADCs running at 1 MHz. A total of 10 samples per channelwere read out per event for test purposes. It is envisioned that in the final design the analog multiplexing circuits would be integrated onto the SCA chips. The digital board contained the required multiplexing to dump the converted ADC data from a total of 24 channels and the SCA capacitor address into two first-in-first-out (FIFO) memories on each board. The FIFOs were subsequently read out along the VMEbus by a FIC processing board.

The following two sub-sections present the results obtained during the RD3 prototype test of September 1993 and test-bench results obtained in Alberta after circuit-board improvements. A \(\Delta\eta\times\Delta\phi=0.216\times 0.08\) full-depth region of the calorimeter was instrumented with 120 channels of pipeline electronics. We ignored 1.7% of the channels in the following analysis; one dead channel and one very inefficient channel.

### Noise and Linearity Studies

During the RD3 tests we read out a total of 10 time samples per channel for each triggered event. While one would expect no variation in gain with the different time samples, we found a small gain increase over the samples and a totally un-usable first sample. We accounted for this gain variation due to a trivial specification error in the chip fabrication and ignored the first time sample. The following results include an average over the remaining time samples after an appropriate correction for the gain increase has been applied.

Figure 1: Schematic diagram of 16 channels of the readout module design. The timing, control logic, and level one trigger connections are not shown.

In order to achieve a 12-bit dynamic range the pedestal variation of each of the storage capacitors in a channel must be less than one part in 4096 of the full scale voltage range. A channel operating with a full scale range of 2.5 V would then require less than 0.61 mV of pedestal variation per capacitor.

In the RD3 tests we measure an average rms variation in the pedestal for each capacitor of about 1.2 mV. Figure 2 shows the rms pedestal variation per capacitor for four different channels in the system. We determined the noise per capacitor to be 0.73 mV incoherent over the channels and 0.31 mV coherent over the channels. A negligible coherent noise over the capacitors in a given channel was observed. After circuit-board improvements (mainly lowering the digital addressing logic level) we measured the rms noise per capacitor to be \((0.61\,0\pm 0.006)\) mV, where the error is statistical only. We estimate approximately 0.2 mV rms noise due to the ADC along and approximately 0.5 mV rms noise due to system without the SCA chip.

The above noise values allow us to deduce that the resolution of the system is 11-12 bit. Results also indicate that to obtain a 12-bit resolution we must store the pedestal value for each capacitor in the system, rather than the more appealing prospect of having one pedestal value per channel. The long-term stability of the system is very good and we

Figure 2: Pedestal variation (rms noise) per capacitor for four different channels in the system.

measured a shift in pedestal per capacitor of less than 0.3 mV over two and one half days of running.

The linearity of the system was measure. We varied the voltage of a high precision pulser over the full input voltage range and measured the mean and rms number of ADC counts. We fit the resulting data to a straight line and expressed the residuals as a percentage of the full scale. The linearity of the system is better than 0.3% and is shown in figure 3 over the full voltage range.

### Electron Energy Reconstruction

As a quick test to determined that the readout system was functioning correctly, we scanned for pulses above pedestal in all the instrumented calorimeter cells, and plotted the pulse positions and the sum of the pulse heights. Figures 4 shows the position of the pulses in the three calorimeter depths for the two electron beam energies of 100 GeV and 180 GeV. The rapidity (to the right) and azimuthal (to the left) directions in the lego plots are in units of cell number. Figure 5 show the sum of the pulse heights for the two electron beam energies of 100 GeV and 180 GeV. No corrections or calibration have been applied and the pulse height sum is in arbitrary ADC units.

Figure 3: Percentage full scale difference from linearity over the full voltage range.

Figure 4: Pulse positions in the three calorimeter depths for the two electron beam energies. The rapidity axis (to the right) and azimuthal axis (to the left) are in units of cell number.

Figure 5: Sum of the pulse heights for the two electron beam energies. No corrections or calibration have been applied and the pulse height sum is in arbitrary ADC units.

To reconstruct the electron energy we summed the energy in a nonet of cells centred on the electron impact point. A nonet was formed by finding the cell in the first calorimeter depth with the highest energy deposit and summing this energy along with the eight cells surrounding it. From the positions of the cells in the front depth, the energy in the corresponding nine cells in the middle depth and six cells in the back depth were included in the total energy sum. A nonet thus corresponded to summing 24 calorimeter cells in total. This cluster size typically contains only 94% of the shower but has the advantage, compared to a larger size cluster (5\(\times\) 5 cells), of contributing 40% less electronic and pile-up noise [5]. We expected a total noise when using a nonet of about 13.4 ADC counts per time sample. The energy distribution in a nonet from pedestal runs was observed to have a gaussian shape with a sigma of 12.4 ADC counts. This corresponded to 960 MeV in the RD3 calorimeter. The timing is not very sensitive to noise and hence we assume that the noise for reconstructing the electron energy using multiple time samples is not so different from the noise using a single time sample. After correcting for calorimeter non-uniformities and implementing a time correction, we obtained an energy resolution of 1.15% for 180 GeV electrons, (0.8% using the standard track-and-hold readout system of the RD3 calorimeter), and an energy resolution of 1.66% for 100 GeV electrons.

The channel-to-channel timing was known to better than 1 ns. We were not able to make an un-biased estimate of the timing of each channel because the shape of the signal varied between the channels. This was probably due to cross-talk. If we ignored this problem and corrected for the cross-talk between the middle and back calorimeter depths, the timing difference between the front and middle plus back depths of the calorimeter was found to be 0.5 ns for 180 GeV electrons. This time difference is not effected by a biased estimate of the channel timing. If we were able to obtain an un-biased estimate of the channel timing, then we would estimate the timing precision to be 0.35 ns. This estimate was obtained by measuring the timing of the channels with respect to each other using test pulse events. We conclude that the 120 channels were synchronous to better than 1 ns.

## 4 Pipeline Control Module

Dead-time free performance of the pipeline readout system can be obtained by allowing simultaneous read and write operations, and the ability to write to non-sequential locations in the SCA. For a 2 \(\mu\)s level one trigger latency and a 40 MHz bunch-crossing frequency, 80 pipeline storage cells per channel are required. If data were stored in sequentially located storage cells we would encounter an amount of dead-time dependent on the number of storage cells per channel and the time required to readout each sample. By keeping track of the state of SCA addresses, we can obtain dead-time free operation provided the level one trigger accepts do not fluctuate too high above the mean 100 kHz rate.

The management of storage cell addresses and hence control of the SCA chip can be performed by an address list processor (ALP) circuit on the pipeline control module. The ALP circuit manages a list of all possible SCA storage location addresses, tagging them as empty, pending level one trigger decision, or pending readout. In essence, the ALP circuit substitutes movement of analog data (stored signal) for digital data (address of stored signal).

A block diagram of the ALP design is shown in figure 6 and is a considerable simplification of that in reference [6]. The presence of a given address in a given FIFO indicates

Figure 6: Block diagram of address list processor design.

the state of the corresponding capacitor storage location in the SCA. With each bunch crossing, an address moves from the free list (write FIFO) to the pending level one trigger list (read-delay FIFO). The write FIFO contains a list of all available addresses in the SCA which can be written to. From the read-delay FIFO, addresses may move back onto the free list (trigger reject) or onto the pending readout list (read FIFO) (trigger accept). With a level one trigger accept and a known latency, the appropriate addresses from the read-delay FIFO are placed into the read FIFO where they are queued for readout. The read FIFO buffers readout requests during the readout of prior events. Once read out the address is placed into a read-complete FIFO and then back into the pool of free addresses in the write FIFO after receiving the next level one trigger decision.

If each FIFO is the maximum size (the maximum number of SCA storage locations), then the number of address in each can expand or contract arbitrarily with no risk of overflow. If the list of free storage locations ever becomes empty it means that the SCA is full, and an error occurred. A reset signal clears all FIFOs except for the free list, which is primed with all available addresses. Simulations indicate that dead-time free operation can be obtained when reading out five samples for each level one trigger accept if the readout time per sample does not exceed 2 \(\mu\)s.

## 5 System Architecture

In specifying the readout architecture we have paid attention to minimizing the amount of electronics on the detector, dividing the system into sub-systems, allowing convenient monitoring and calibration, transmitting from the detector only the information for events accepted by the level one trigger, using several samplings for each channel in each selected event, and performing zero-suppression and reconstruction of the energy as soon as possible.

We have used a working model for the ATLAS electromagnetic calorimeter which consist of three longitudinal sections (front, middle, and back). The \(\eta\)-\(\phi\) segmentation consists of 51200 cells in the front and middle sections each, with 25600 cells in the back section. Hence there are a total of 128000 cells to be read out from the barrel and end-caps of the electromagnetic calorimeter. Trigger towers will be formed by combining 16 front, 16 middle, and 8 back calorimeter cells.

While maintenance issues have led to the desire to place as little of the electronics as possible inside the detector, noise considerations necessitate that the liquid argon preamplifiers and calibration circuits be located inside the cryostat, mounted directly on the calorimeter. We envision front-end electronics mounted near the detector, while remote electronics could sit in an electronics room 30-50 m away connected by optical fibers. Because of the large dynamic range, we disfavour the possibility of sending shaped analogsignals from the detector to the electronics room over long links.

### Front-End Electronics

The front-end electronics is responsible for forming the level one trigger sums, storing the analog signals until a level one trigger accept, and digitizing the accepted events. Each pipeline readout board will be responsible for 64 calorimeter cells and hence 2000 pipeline readout boards will comprise the system. We will allocate six boards to the front, six boards to the middle, and three boards to the back calorimeter sections. There will be a total of 15 pipeline boards per front-end crate and hence the entire front-end system will consist 134 crates.

The 64 calorimeter cells per board (128 shaper channels) will require eight 16-channel SCA chips to be mount on each pipeline readout board. This will require eight 12-bit 10 MHz ADCs and 4 200 Mbit/s optical fibers from the pipeline readout boards to the digital processing boards in the remote electronics. We hope to use standard VME 6U high and 30 cm deep boards.

We envision one local pipeline controller per crate. The ALP circuit will provide the write and read addresses to all the SCA chips in the crate. The controller will receive from the ATLAS timing, trigger, and control distribution system [7] the 40 MHz LHC clock, the level one trigger decision, the event number, and trigger type. The analog pipeline boards will receive the set of fast timing signals from the crate pipeline controller. The timing of these signals should be stable to 0.5 ns with respect to the LHC bunch-crossing time. For the synchronization of the front-end electronics we will install a programmable delay on the write address and on its 40 MHz strobe for each memory chip. We foresee a programmable delay at the input of each pipeline controller board for the trigger decision signal.

Each front-end crate of 960 calorimeter channels maps onto 24 level one trigger towers. The low gain signals from the shapers are summed in groups of 16 on each pipeline board dedicated to the front and middle calorimeter sections, and summed in groups of eight on those boards dedicated to the back section. Hence, 72 analog signals are sent to a trigger summation board in each crate which is responsible for summing the corresponding front, middle, and back sums to form the 24 trigger towers. These signals will either be digitized by flash ADCs in the front-end crate or sent via 24 optical fibers to a remote flash-ADC system.

We envision putting a calibration controller board in each front-end crate to control the calibration system for that crate. The calibration system must be able to inject calibration pulses with a programmable amplitude and time of arrival. The charge injection system must be able to exercise the full dynamic range of the readout.

In summary, each front-end crate will contain 15 pipeline readout boards, one trigger summation board, one local pipeline controller, and one calibration controller.

### Remote Electronics

The remote electronics is responsible for the digital processing, and interfaces to the level two trigger and data acquisition systems. Each digital processing board will receive synchronous signals at 10 MHz over 32 optical fibers from eight pipeline readout boards. The processing boards will contain the required amount of CPUs to perform the pulse reconstruction, zero-suppression, and data formatting functions. The results from the processing boards will be sent to an event buffer board in each crate where the data will be available to the level two trigger and data acquisition systems. We estimate sending data from the event buffer boards over 1 Gbyte/s optical fibers. The remote electronics comprises a total of 250 digital processing boards sitting in 21 VME crates (12 boards per crate).

## 6 Radiation Damage Tests

Although the location of the front-end boards will be in relatively low radiation areas (approximately 10 krad/year), it is essential to know the effects of radiation on the board components. We plan to make a series of radiation damage tests using proton, electron, and pion beams. Proton tests will be performed in the PS beam at CERN during the second week in June, 1994 and electron tests in the LIL beam the following week. Future radiation damage tests with pion beams are foreseen at PSI or TRIUMF. The 1.2 \(\mu\)m double-metal CMOS process is intrinsically radiation hard, but if problems are encounter the SCA chip could be redesigned using the HARRIS process.

## 7 Summary

Based on SCA chips, we have designed a readout module that is capable of input rates in excess of 40 MHz, can store data over 256 LHC bunch crossings, operates at a 100 kHz readout rate, and is capable of achieving a greater than 15-bit dynamic range, using a dual-range scheme. We have built prototype readout modules and a controller board for tests with the RD3 electromagnetic liquid argon accordion calorimeter at the SPS. The main objectives of these tests were to study the noise of the system and obtain a 12-bit dynamic range. The resulting noise studies and resolution were presented. Further prototype studies performed in Alberta have lead to circuit modifications and suggested SCA chip improvements. The results indicate that an analog pipeline readout system meeting the ATLAS requirements can be built using our modules. In addition, a prototype design of a dead-time free control module, a preliminary design of a readout architecture, and a plan for radiation damage tests were presented.

We acknowledge useful discussions with a group [8] at the Nevis Laboratory working on a similar readout system.

## References

* [1] D.M. Gingrich _et al._, ATLAS Collaboration, "ATLAS Letter of Intent for a General-Purpose pp Experiment at the Large Hadron Collider at CERN", CERN/LHCC/92-4.
* [2] A. Caldwell _et al._, "Design and implementation of a high precision readout system for the ZEUS calorimeter", Nucl. Instr. and Meth. **A321** (1992) 356-364.
* [3] S.A. Kleinfelder, M. Levi & O. Milgrome, "Test results of a 90 MHz integrated circuit sixteen channel analog pipeline for SSC detector calorimetry", Nucl. Phys. B (Proc. Suppl.) **23A** (1991) 382; LBL preprint # 30222.
* [4] B. Aubert _et al._, RD3 Collaboration, "Performance of a liquid argon electromagnetic calorimeter with a cylindrical accordion geometry", Nucl. Instr. and Meth. **A325** (1993) 116-128; RD3 Collaboration, CERN/DRDC/90-31, CERN/DRDC/91-21, CERN/DRDC/92-40.
* [5] A. Cravero & F. Gianotti, "Uniformity of response and energy resolution of a large scale prototype of the barrel accordion calorimeter", ATLAS Internal Note CAL-no-33, RD3 Note 54, 11 April 1994.
* [6] S.A. Kleinfelder, M. Levi & O. Milgrome, "Toward a 62.5 MHz analog virtual pipeline integrated data acquisition system", LBL preprint #29608.
* [7] B.G. Taylor, "Timing, trigger and control distribution for LHC detectors", Rev. 1.3, 1 Feb. 1994.
* [8] A. Gara, J.A. Parsons & W. Sippach, "High Rate Precision Calorimetry Readout", Presented at the Fourth Annual Conference on Electronics for Future Colliders, May 11-12, 1994, LeCroy Corporation.