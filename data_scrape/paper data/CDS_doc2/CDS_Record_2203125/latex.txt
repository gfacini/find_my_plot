[MISSING_PAGE_EMPTY:1]

## 1 Introduction

This note documents the identification of _prompt photons_ produced at LHC proton-proton (\(pp\)) collisions and observed by the ATLAS experiment. Prompt photons are defined as photons not originating from hadron decays. There are several known physics mechanisms in Standard Model (SM) that may produce such photons, such as parton-parton scattering (\(qg,q\bar{q}\to\gamma+X\), \(gg,q\bar{q}\to\gamma\gamma\)), QED radiation, Higgs boson decays (\(H\to\gamma\gamma\)). Moreover, several theories beyond the Standard Model foresee interactions with final states containing one or more photons.

The selection of prompt photons is affected by a large reducible background, originated by hadronic jets, produced with dominant cross-sections: this background will be referred to as "_background photons_", and may be due to photons originated from hadronic decays, or to hadrons wrongly identified as photons. For this reason, a careful identification of photon candidates is necessary. The precise measurement of the photon identification efficiency is performed using data-driven methods, as the description of the photon interaction with the material is not precise enough to accurately determine the photon efficiency from simulation alone. In ATLAS there are currently three data-driven methods to estimate the photon identification efficiency, that cover different ranges of transverse energy (\(E_{\mathrm{T}}\)), with partial overlaps.

* **Radiative Z boson decays** -- This method relies on the use of a pure photon sample selected from radiative decays of the \(Z\) boson, \(Z\to\ell^{+}\ell^{-}\gamma\), and allows a precise measurement in the low \(E_{\mathrm{T}}\) region. In this analysis, the \(e^{+}e^{-}\gamma\) and \(\mu^{+}\mu^{-}\gamma\) channels are initially treated independently. As the results of the two channels give consistent results, they are subsequently combined.
* **Electron extrapolation** -- An electron sample from \(Z\to e^{+}e^{-}\) decays is used to obtain a pure sample of electromagnetic showers from data. Showers developed by electrons are similar to those by photons: their differences are taken from the simulation, and applied to observed showers from electrons to describe those produced by photons. Due to the \(Z\) decay kinematics, this method covers an intermediate \(E_{\mathrm{T}}\) range.
* This method exploits photons reconstructed in collision data, which are contaminated by hadronic background. The isolation of reconstructed photons is used as a discriminating property in order to extract the sample purity before and after the photon identification. This method has the advantage of covering a very large \(E_{\mathrm{T}}\) range.

A detailed description of photon identification, used for data collected during the LHC "Run-I", is given in a previous publication [1]. This document reviews the basic concepts and provides updated results from the first year of the LHC Run-II data taking. In Section 2, the photon reconstruction and identification are briefly reviewed, the data set collected during \(pp\) collisions in 2015 is described, together with the simulated samples used in the analyses; the corrections applied to the simulations are also mentioned. Section 3 describes the three data-driven methods used to measure the photon identification efficiency, with the related systematic uncertainties. The results are discussed in Section 4, and compared among themselves and with the corrected simulations.

## 2 Data selection and simulation

### Photon reconstruction and identification

The ATLAS experiment is described in detail elsewhere [2]. The reconstruction and identification of photons are briefly summarized here, and a full description can be found in [1]. The reconstruction of photons relies on measurements of electromagnetic showers in the electromagnetic calorimeter (ECAL). Rectangular clusters of ECAL cells are used as seeds for electron and photon reconstruction, requiring little or no energy deposit in the hadronic calorimeter (HCAL). Furthermore, tracks reconstructed in the inner detector, with loose angular match with ECAL clusters, are collected. If an ECAL cluster has no associated tracks, it is considered as an "unconverted photon". In case the cluster is matched to a pair of oppositely-charged tracks, collinear at the production vertex and compatible with electrons in the transition radiation tracker detector (TRT),the cluster is considered as a "converted photon". Since the detection of conversion track pairs becomes inefficient at large conversion radius, also a cluster matched to one track can be considered as converted photon: to discriminate from electrons produced at interaction point, the track must have no hits in the innermost layer of the pixel detector.

Prompt photons are separated from background photons in the ATLAS experiment by means of selections on quantities describing the shape and properties of the associated electromagnetic showers and by requiring them to be isolated from other particles in the event.

Typically, background photons are accompanied by a sizable surrounding hadronic activity, and therefore by a poor isolation.The isolation is defined based on the transverse energy flow in a cone around the direction of the photon candidate, within an angular distance \(\Delta R=\sqrt{(\eta-\eta^{\gamma})^{2}+(\phi-\phi^{\gamma})^{2}}\). The transverse energy flow can be characterized by two quantities: (_i_) \(E_{\mathrm{T}}^{\mathrm{iso}}\), as the sum of transverse energies of topological clusters [3] in the calorimeters, after subtracting the energy deposited by the photon candidate and the contribution from underlying event and pile-up; (_ii_) \(p_{\mathrm{T}}^{\mathrm{iso}}\), by summing the transverse momenta of all the tracks with transverse momentum above 1 GeV and having a distance of closest approach to the primary vertex along the beam axis of less than 3 mm, and excluding the tracks associated to photon conversions. The isolation requirements imposed in these analyses are \(E_{\mathrm{T}}^{\mathrm{iso}}<0.065\cdot E_{\mathrm{T}}\) and \(p_{\mathrm{T}}^{\mathrm{iso}}<0.05\cdot E_{\mathrm{T}}\), in a cone with an opening \(\Delta R<0.2\).

Hadrons reconstructed as photons release a substantial portion of energy in the HCAL and produce a broader transverse energy deposit in the ECAL. Background photons from hadron decays are typically pairs of genuine photons close to each other, that may be recognized to some extent by exploiting the fine granularity of the first layer ("strips") of the ECAL. The _photon identification_ (ID) is achieved by imposing requirements on _discriminating variables_ (DV) describing the energy fraction released in the HCAL and the shower shape in the ECAL, both in its second sampling layer and in the "strips". There are two levels of ID. The _loose_ ID level exploits the DVs only in the HCAL and in the ECAL second sampling layer, providing a highly efficient selection with fair background rejection, typically used for the trigger and for background studies. The _tight_ ID level exploits the full granularity of the ECAL, including the fine segmentation of the first sampling layer, and applies tighter requirements also on the DVs used by the loose ID. In all cases, the requirements on the DVs are tuned separately for unconverted and converted photons, in several pseudorapidity regions. A summary of the DVs used by the loose and tight photon identification algorithms is given in Table 2, in the Appendix.

The fiducial acceptance for photon reconstruction and identification is defined by the pseudorapidity (\(\eta\)) regions where the ECAL depth is enough to contain the whole photon shower and the segmentation of theECAL strips is fine enough to allow the rejection of neutral hadrons. Specifically, \(|\eta|<1.37\) is required in the ECAL barrel and \(1.52<|\eta|<2.37\) in the ECAL endcaps.

All the analyses are performed independently for unconverted and converted photons. Moreover, to account for the material distributions in front of the ECAL, four \(|\eta|\) regions are treated separately: \([0.00;0.60]\), \([0.60;1.37]\), \([1.52;1.81]\), \([1.81;2.37]\).

### Collision data and simulated samples

Events were recorded in 3.2 fb\({}^{-1}\) of proton-proton collisions at a center-of-mass energy of \(\sqrt{s}=13\) TeV during the 2015 data taking. Events are considered only if recorded when the entire ATLAS detector was fully operational.

Events containing at least one photon must pass at least one of several single photon triggers, with requirements on the DVs weaker than those used for the loose ID, and with \(E_{\mathrm{T}}\) thresholds varying from 10 to 140 GeV1. In this way, a good coverage with high statistics is ensured over a wide \(E_{\mathrm{T}}\) range. Events containing leptons must satisfy the lowest unprescaled single-lepton triggers, with an \(E_{\mathrm{T}}\) threshold of 24 GeV, or di-electron (di-muon) triggers with an \(E_{\mathrm{T}}\) threshold of 15 GeV (14 GeV).

Footnote 1: Triggers with lower thresholds were pre-scaled as soon as the instantaneous luminosity increased, to maintain the trigger rate at an sustainable level.

The analyses also use simulated Monte Carlo (MC) samples:

* photon+jet events (\(\gamma\)-jet) generated by Pythia8[4, 5], with photon \(E_{\mathrm{T}}\) in the range \([17;1500]\) GeV: used to model the photon properties;
* dijet-like events, containing both photon+jet and dijet events in realistic proportions, generated by Pythia8, with jet filter thresholds between 17 and 55 GeV: used to model the hadronic background;
* \(Z\rightarrow\ell^{+}\ell^{-}\gamma\) decays (where \(\ell=e,\mu\)) generated by Sherpa[6]: used to model the signal in the "radiative \(Z\)" method;
* \(Z\rightarrow\ell^{+}\ell^{-}\) decays generated by Powheg+Pythia[7, 8]: used for the "electron extrapolation" method and for cross-checks in the "radiative \(Z\)" method;
* \(Z(\rightarrow\ell^{+}\ell^{-})+\mathrm{jet}\) generated by Sherpa: used to model the hadronic background in the "radiative \(Z\)" method.

All samples needed to model the signal are generated with high statistics. Photon+jet simulations are performed in bins of the photon \(E_{\mathrm{T}}\): up to \(E_{\mathrm{T}}=800\) GeV each simulation contains 2 million or 1 million events, while for larger \(E_{\mathrm{T}}\), up to 3 TeV, each slice contains 100 000 events. Simulated samples for \(Z\rightarrow\ell^{+}\ell^{-}\) and \(Z\rightarrow\ell^{+}\ell^{-}\gamma\) contain respectively 20 million and 5 million events, for each lepton flavour.

Signal samples have also been simulated with a different description of the detector geometry, to assess the systematic effects due to a mismodelling of the materials. These samples include additional material, compared to the nominal one, both in the tracking detector and directly in front of the calorimeter.

All samples are generated with underlying event and pile-up. The interaction of the particles in the final state with the detector material is simulated with Geant4[9], the detector response is simulated, and the events are processed through the full ATLAS reconstruction [10].

In order to improve the description of the photon DVs, corrections are applied to the simulated values, by applying a shift to each of them, whose value is optimised separately for unconverted and converted photons, and as a function of the pseudorapidity. The general procedure is to select photons from data and compare their DVs distributions to those from the simulation. Photons with \(E_{\mathrm{T}}<25\) GeV are selected from radiative \(Z\to\ell^{+}\ell^{-}\gamma\) decays (more details are provided in Section 3.1), while those with \(E_{\mathrm{T}}\geq 25\) GeV are obtained from reconstructed photons passing the tight ID and the isolation requirements, in events selected by a single-photon trigger. An example of such procedure is displayed in Figure 1. More figures on this procedure (Figures 12-13) are shown in the Appendix, for both converted and unconverted photons, in the four pseudorapidity intervals.

## 3 Data-driven efficiency measurements

### Radiative photons from \(Z\to\ell^{+}\ell^{-}\gamma\) decays

Radiative \(Z\to\ell\ell\gamma\) decays are selected by placing kinematic requirements on the dilepton pair, on the invariant mass of the three particles in the final state, and on the quality requirements on the two leptons. Muon candidates are formed from tracks reconstructed both in the Inner Detector and in the muon spectrometer, with transverse momentum larger than 10 GeV and absolute pseudorapidity less than 2.4. For the electrons, stronger selection criteria are applied, to avoid the possibility of an electron to be misidentified as a photon. Electrons are required to have \(p_{\mathrm{T}}\geq 10\) GeV and \(|\eta|\leq 1.37\) or \(1.52\leq|\eta|\leq 2.47\), and to satisfy the identification criteria based on tracking and transition radiation information from the Inner Detector, shower shape variables computed from the lateral and longitudinal profiles of the energy deposited in the EM calorimeter, and track-cluster matching quality. For both electron and muon candidates, the longitudinal impact parameter, \(|z_{\mathrm{PV}}|\), with respect to primary vertex and transverse impact parameter significance, \(|d_{0}|/\sigma_{d_{0}}\), are required to satisfy \(|z_{\mathrm{PV}}|\leq 10\) mm and \(|d_{0}|/\sigma_{d_{0}}\leq 10\). The photon selection is performed separately for converted and unconverted candidates, which are required to be in the ECAL fiducial acceptance and to have transverse energy larger than 10 GeV. The photon candidates have to satisfy the object quality and photon cleaning requirements in order to reject misidentified electrons as photons and clusters affected by cells with read-out problems. Photon candidates are required to pass

Figure 1: Two examples of shower-shape variables for unconverted photons: the black points are for the photons from \(Z\to\ell^{+}\ell^{-}\gamma\) events from data, the red histogram for the photons from \(Z\to\ell^{+}\ell^{-}\gamma\) event from simulation before applying the shift, and the blue histogram after applying the shift.

the isolation criteria described in Section 2.1. The same isolation criteria are also applied to electron and muon candidates. The \(Z\to\ell\ell\gamma\) candidates are selected by requiring two opposite-sign charged leptons of the same flavour satisfying the previous criteria. An angular separation \(\Delta R\geq 0.2\) between the photon and each of the two leptons is required to avoid contamination on the photon cluster. The two-dimensional distribution of \(\ell\ell\) vs \(\ell\ell\gamma\) invariant masses is shown in Figure 2, for the selected events in data passing the previous criteria.

The sample is dominated by \(Z\)+jet background events in which the jet is misreconstructed as a photon. These events, which have a cross section about three orders of magnitude higher than \(\ell\ell\gamma\) events, have \(m_{\ell\ell}\approx m_{\mathrm{Z}}\) and \(m_{\ell\ell\gamma}\geq m_{\mathrm{Z}}\), while final-state radiation \(Z\to\ell\ell\gamma\) events have \(m_{\ell\ell}\leq m_{\mathrm{Z}}\) and \(m_{\ell\ell\gamma}\approx m_{\mathrm{Z}}\). In order to reduce the \(Z\)+jet background, the requirements of 40 GeV \(\leq m_{\ell\ell}\leq\) 83 GeV and 83 GeV \(\leq m_{\ell\ell\gamma}\leq\) 100 GeV are applied. The efficiency of photon tight identification is evaluated from the selected photon sample and measured as the fraction of selected photons (probes) that pass the tight identification criteria:

\[\varepsilon_{\mathrm{ID}}=\frac{N_{probes,tight}}{N_{probes}} \tag{1}\]

The residual background contamination from \(Z\)+jet events is estimated through a maximum-likelihood (template) fit to \(m_{\ell\ell\gamma}\) after the cut on it. The data are fit to a sum of the photon and the background contributions. The photon and background distributions ("templates") are extracted from the \(Z\to\ell\ell\gamma\) and \(Z\)+jet simulations, corrected to take into account data-MC differences in the lepton efficiencies, and in the photon and lepton energy scales and resolutions. The signal and background yields are determined from the data by maximizing the likelihood. The photon purity for 10 GeV \(\leq E_{\mathrm{T}}\leq\) 20 GeV is estimated from the template fit using \(Z+\gamma\) and \(Z\)+jet SHERPA samples. In the signal region (83 GeV \(\leq m_{\ell\ell\gamma}\leq\) 100 GeV) the purity is about 91.6% in the \(\mu\mu\gamma\) channel and 92.7% in the \(ee\gamma\) channel. The sample purity is accounted for, when computing the identification efficiency.

A closure test has been performed, applying the analysis to a simulated sample, containing \(Z\rightarrow\ell\ell\gamma\) and \(Z\)+jet events in realistic proportions: the difference between the ID efficiency computed by the analysis, and that computed directly on genuine photons from the simulation, is about 4.5% (5.5%), for converted (unconverted) photons and it has been taken into account as a systematic uncertainty. Additional uncertainties, arising from material modeling and alternative MC event generators, have been considered. In the first case distorted geometry MC sample has been used, where the detector geometry is simulated with more material in front of the ECAL. Subtraction of background events with templated fit method has been obtained with the use of templates extracted from the distorted geometry MC instead of the nominal one. One more MC-related uncertainty, due to the choice of event generator, arises from deviation in the MC predictions of the background. Uncertainty estimation is similar to the one described earlier: background subtraction in data with template fit method is redone with extraction of templates from alternative MC event generator Powheg+Pythia instead of nominal one (Sherpa).

The differences with respect to the nominal results are treated as additional systematic uncertainties.

### \(e\rightarrow\gamma\) extrapolation

The similarity between the electromagnetic showers induced by isolated electrons and photons in the ECAL is exploited to extrapolate the expected photon distributions of the DVs. The photon identification efficiency is thus estimated from the distributions of the same variables in a pure and large sample of electrons with \(E_{\mathrm{T}}\) between 30 GeV and 100 GeV obtained from \(Z\to ee\) decays, using a "tag-and-probe" method. Events are selected if they contain two opposite-sign electrons in the ECAL fiducial acceptance, with \(p_{\mathrm{T}}\geq 25\) GeV, at least seven hits in the silicon detectors, one hit in the pixel detector, and the invariant mass \(70\) GeV \(\leq m_{ee}\leq 110\) GeV. The "tag" electron is required to match the trigger object within a cone with \(\Delta R\leq 0.15\) and to pass the tight electron identification requirement. Both electrons have to satisfy the isolation criteria, as described in Section 2.1. The background contamination of the electron "probes" is determined from the \(m_{ee}\) spectrum of the selected events, using a template whose normalization is extracted from events with \(m_{ee}\geq 120\) GeV, and whose shape is obtained from events in which the probe electron candidate fails both isolation and loose identification requirements. The differences between the photon and electron distributions of the DVs are studied using simulated samples of prompt photons and electrons from \(Z\to ee\) decays, separately for converted and unconverted photons. For most DVs, the difference between showers is more sizable between electrons and unconverted photons, than for converted photons, because the latter are actually two electron showers overlapped. An exception is the azimuthal width (\(R_{\phi}\)) of the shower, that is affected more for converted photons, due to the opposite bendings of the two tracks in the magnetic field. To reduce such differences, a mapping technique based on the Smirnov transform is used for both converted and unconverted photons. For each shower shape variable \(x\), the cumulative distribution functions (CDF) of simulated electrons (CDF\({}_{e}(x)\)) and photons (CDF\({}_{\gamma}(x)\)) are calculated. The transform \(f(x)\) is defined such that CDF\({}_{e}(x)=\) CDF\({}_{\gamma}(f(x))\). By applying the appropriate transform for each DV, the electron sample can be transformed into a sample of objects with photon-like shower shapes. In Figure 3 this process is illustrated for the shower shape \(R_{\phi}\). More figures showing the Smirnov transform are shown in the Appendix (Figures 14-15).

However, as the process is applied to each DV independently, the correlations between shower shapes are preserved from the source sample, which introduces some intrinsic uncertainty to the method. These effects are assessed by comparing the efficiency measured from a pure sample of simulated photons to the efficiency measured from a simulated electron sample after applying the Smirnov transforms. The difference between the efficiencies extracted from the two samples is treated as a systematic uncertainty.

Figure 3: Diagram illustrating the process of Smirnov transform for \(R_{\phi}\). This discriminating variable was chosen due to its distribution, particulary different between electrons and unconverted photons. The pdf in each sample (top-left plot) is used to calculate the respective CDF (top-right plot). From the two CDFs, the Smirnov transform can be derived (bottom-left plot). Applying the transform leads to an \(R_{\phi}\) distribution of the transformed electrons, which well reproduces the photon distribution (bottom-right plot).

For both converted and unconverted photons, it is about 1%. An additional source of systematic uncertainty may come from the modelling of the shower shape distributions and correlations in the photon and electron simulations used to extract the mappings. The largest uncertainties in the distributions of the discriminating variables originate from limited knowledge of the material in front of the calorimeter. The extraction of the mappings is repeated using MC with distorted geometry. The difference between the efficiencies obtained using the nominal and the distorted is about 2% (4%) for converted (unconverted) photons. Also the effect of a possible background contamination in the selected electron probes in data is taken into account as an additional systematic uncertainty.

### Matrix method

An inclusive sample of photon candidates is selected using single photon triggers by requiring at least one photon candidate in the ECAL fiducial acceptance and with 20 GeV \(\leq E_{\mathrm{T}}\leq\) 1500 GeV. Only the photons passing the isolation requirements described in Section 2.1 are retained. The distribution of the track isolation of selected candidates, computed in a cone \(\Delta R<0.4\) (as opposed to \(\Delta R<0.2\) described in Section 2.1), is used to discriminate between prompt and background photon candidates, before and after applying the tight identification criteria.

In the following, \(N_{\mathrm{all}}\) and \(N_{\mathrm{pass}}\) are the total number of photon candidates in the selected sample ("all" sample) and in the sample of candidates passing the tight identification criteria ("pass" sample), respectively, while \(N_{\mathrm{all}}^{\mathrm{iso}}\) and \(N_{\mathrm{pass}}^{\mathrm{iso}}\) are the number of candidates in the "all" and "pass" samples that pass the track isolation requirement. The quantities \(\varepsilon_{\mathrm{all}}^{\mathrm{S(B)}}\) and \(\varepsilon_{\mathrm{pass}}^{\mathrm{S(B)}}\) are the track isolation efficiencies for prompt (background) photons in the "all" and "pass" samples. The yields of prompt (S) and background (B) photons in the "all" and "pass" samples, respectively \(N_{\mathrm{all}}^{\mathrm{S}}\), \(N_{\mathrm{all}}^{\mathrm{B}}\), \(N_{\mathrm{pass}}^{\mathrm{S}}\), \(N_{\mathrm{pass}}^{\mathrm{B}}\), are obtained by solving a system of four equations:

\[N_{\mathrm{all}} =N_{\mathrm{all}}^{\mathrm{S}}+N_{\mathrm{all}}^{\mathrm{B}} \tag{2}\] \[N_{\mathrm{pass}} =N_{\mathrm{pass}}^{\mathrm{S}}+N_{\mathrm{pass}}^{\mathrm{B}}\] (3) \[N_{\mathrm{all}}^{\mathrm{iso}} =\varepsilon_{\mathrm{all}}^{\mathrm{S}}\cdot N_{\mathrm{all}}^{ \mathrm{S}}+\varepsilon_{\mathrm{all}}^{\mathrm{B}}\cdot N_{\mathrm{all}}^{ \mathrm{B}}\] (4) \[N_{\mathrm{pass}}^{\mathrm{iso}} =\varepsilon_{\mathrm{pass}}^{\mathrm{S}}\cdot N_{\mathrm{pass}}^{ \mathrm{S}}+\varepsilon_{\mathrm{pass}}^{\mathrm{B}}\cdot N_{\mathrm{pass}}^{ \mathrm{B}} \tag{5}\]

The identification efficiency \(\varepsilon^{\mathrm{ID}}=N_{\mathrm{pass}}^{\mathrm{S}}/N_{\mathrm{all}}^{ \mathrm{S}}\) is thus:

\[\varepsilon_{\mathrm{ID}} = \frac{\varepsilon_{\mathrm{pass}}-\varepsilon_{\mathrm{pass}}^{ \mathrm{B}}}{\varepsilon_{\mathrm{pass}}^{\mathrm{S}}-\varepsilon_{\mathrm{pass }}^{\mathrm{B}}}\cdot N_{\mathrm{pass}} \tag{6}\] \[\frac{\varepsilon_{\mathrm{all}}-\varepsilon_{\mathrm{all}}^{ \mathrm{B}}}{\varepsilon_{\mathrm{all}}^{\mathrm{S}}-\varepsilon_{\mathrm{all }}^{\mathrm{B}}}\cdot N_{\mathrm{all}}\]

where \(\varepsilon_{\mathrm{pass(all)}}=N_{\mathrm{pass(all)}}^{\mathrm{iso}}/N_{ \mathrm{pass(all)}}\) is the fraction of tight (all) photon candidates in data that satisfy the track isolation criteria.

The prompt-photon track isolation efficiencies (\(\varepsilon_{\mathrm{all}}^{\mathrm{S}}\) and \(\varepsilon_{\mathrm{pass}}^{\mathrm{S}}\)) are estimated from simulated prompt-photon samples. The differences between the prompt track isolation efficiencies calculated with these samples and those with additional material are treated as systematic uncertainties.

The background-photon track isolation efficiencies (\(\varepsilon_{\rm all}^{\rm B}\) and \(\varepsilon_{\rm pass}^{\rm B}\)) are estimated from control samples enriched with background photons, selected by reversing the tight selection on the variables computed from the energy in the cells of the first ECAL layer, also called "narrow strip variables": \(F_{\rm side}\), \(\omega_{s,3}\), \(\Delta E\), \(E_{\rm ratio}\). Since in such samples no candidates pass the tight cuts by construction, in order to obtain \(\varepsilon_{\rm pass}^{\rm B}\), a "relaxed tight" criterion is defined, consisting of the candidates which fail at least one of the requirements on the narrow strip variables, but pass the rest of the selection in the tight identification definition. Due to the very small correlation (few %) between the track isolation and the narrow strip variables, the background-photon track isolation efficiency is similar for photons satisfying tight or relaxed tight criteria. The differences between the track isolation efficiencies for background photons passing the tight or the relaxed tight criteria are estimated from simulations and included in the systematic uncertainties. The contamination from prompt photons in the background enriched samples is accounted for in this procedure by using as an additional input the fraction of signal events passing or failing the relaxed tight requirements, as determined from the prompt-photon simulation. The fraction of prompt photons in the background control samples decreases from about 20% to 0.1%, with increasing photon transverse momentum. The whole procedure is tested on a simulated sample of \(\gamma\)+jet and dijet events, and the difference between the true track isolation efficiency for background photons and the one estimated with this procedure is taken as a systematic uncertainty. The typical relative uncertainty in the background-photon track isolation efficiency is 3-5%. An additional systematic uncertainty, due to the use of the prompt-photon simulation to estimate the fraction of signal photons in the background control regions, is estimated by calculating these fractions using alternative MC samples based on a detector simulation with a conservative estimate of additional material in front of the calorimeter. The distorted material relative uncertainty is about 1% below 30 GeV and less than 0.1% at higher \(E_{\rm T}\). The total systematic uncertainty decreases with the transverse energy. It reaches 5-6% below 40 GeV, and 1% at higher \(E_{\rm T}\) where the contribution of this method is the most important.

As an example, Figure 4 shows the track isolation efficiencies for prompt and background unconverted photons, with \(|\eta|\leq 0.6\), in the "all" and "pass" samples, together with the corresponding efficiencies measured in data, for photons passing or failing the tight ID criteria. The track isolation criteria for background photons decreases with \(E_{\rm T}\), since the candidates with larger transverse energy are produced from more energetic jets, which are characterized by a large number of tracks near the photon candidates.

The final result is obtained by multiplying the measured efficiency by a correction factor to take into

Figure 4: Track isolation efficiencies for unconverted photon candidates. Errors include statistical and systematic uncertainties. Left: candidates passing the tight identification criteria. Right: candidates in the inclusive sample. In the last \(E_{\rm T}\) bin, both \(\varepsilon_{\rm pass}^{\rm B}\) and \(\varepsilon_{\rm all}^{\rm B}\) are equal to 0.

account the preselection of the sample using different photon triggers, which already apply some loose requirements to the photon discriminating variables. The correction factor is computed, using the \(\gamma\)+jet simulated sample, as the ratio between the tight identification efficiency for all reconstructed photons and that for photons that were used to trigger the event2.

Footnote 2: The effect of this factor on the ID efficiency ranges from -2% to -0.1%, decreasing towards high \(E_{\mathrm{T}}\).

## 4 Results

### Efficiencies measured in data

The identification efficiency measurements obtained from the three data-driven methods, discussed in the previous sections, are compared in Figures 5-6. In the overlapping \(E_{\mathrm{T}}\) regions, the \(\varepsilon_{\mathrm{ID}}\) values are consistent with each other within the uncertainties. Relatively large fluctuations of the radiative \(Z\) decay measurements are observed, due to their large statistical uncertainties.

The photon identification efficiency increases from 53-64%(47-61%) for unconverted (converted) photons at \(E_{\mathrm{T}}\approx 10\) GeV to 88-92% (96-98%) for \(E_{\mathrm{T}}\geq 100\) GeV.

Figure 5: Comparison of the data-driven mesurements of the identification efficiency for unconverted photons as function of \(E_{\mathrm{T}}\) in the region 10 GeV \(\leq E_{\mathrm{T}}\leq 1500\) GeV, for the four pseudorapidity intervals. The uncertainty bars represent the sum in quadrature of the statistical and systematic uncertainties estimated in each method.

### Comparison with the simulation

In this section the results of the data-driven efficiency measurements are compared to the identification efficiencies predicted in the simulation. Prompt photons produced in photon+jet events have different kinematic distributions inside each eta region, with respect to photons originating in radiative \(Z\) boson decays. Moreover, the latter are always well isolated, while the former have a significant contribution from fragmentation. After the isolation requirement, the difference in identification efficiency between the two cases is small. Nonetheless, to account for such a difference, the efficiency measured in data with radiative \(Z\) boson decays is compared to the prediction from simulated \(Z\to\ell\ell\gamma\) events (Figures 7-8), while the efficiencies measured in data with the electron extrapolation and the matrix method are compared to the predictions from simulated photon+jet events (Figures 9-10).

No significant differences are observed between data-driven measurements and the simulations. The difference between the simulation and the data-driven measurements is taken into account by computing data-to-MC efficiency ratios, also referred to as scale factors (SF).

The SF are computed independently for each method and then combined. The data-to-MC efficiency ratios are shown in the bottom plots of Figures 7 to 10. Because of their good agreement and of the independence of the data samples, the SF as function of \(E_{\mathrm{T}}\) are combined into a single result in the overlapping regions. The combination is performed indipendently in each \(p_{\mathrm{T}}\) bin, in each pseudorapidity

Figure 6: Comparison of the data-driven measurements of the identification efficiency for converted photons as function of \(E_{\mathrm{T}}\) in the region 10 GeV \(\leq E_{\mathrm{T}}\leq\) 1500 GeV, for the four pseudorapidity intervals. The uncertainty bars represent the sum in quadrature of the statistical and systematic uncertainties estimated in each method.

region, and separately for unconverted and converted photons, using the Best Linear Unbiased Estimate (BLUE) technique [11]. The combined values are displayed in Figure 11, as a function of \(E_{\mathrm{T}}\), separately for unconverted and converted photons, and in different \(\eta\) regions.

Most SF values are close to unity. This confirms that the simulation, with the applied corrections, provides a good description of the photon shower shapes in the collision data. In analyses with photons in final state, the combined scale factors are then applied to simulated photons as weights to provide an even better description of the identification efficiency.

Table 1 lists the statistical uncertainties and all the sources of systematic uncertainties, arising from: the background modelling/subtraction; the description of the detector material/geometry in the simulation; the residual discrepancies in closure tests; the identification of conversions; the usage of a different generator for photon simulation.

\begin{table}
\begin{tabular}{l l l l l l} \hline \hline  & & \multicolumn{4}{c}{\(E_{\mathrm{T}}\) range [GeV]} \\ \cline{3-6}  & & 10–30 & 30–100 & 100–1500 \\ \hline \multirow{3}{*}{Unconverted \(\gamma\)} & Total & 1.4\%–18.5\% & 0.3\%–1.4\% & 0.4\%–4.2\% \\  & Statistics & 1.2\%– 2.4\% & 0.1\%–0.8\% & 0.4\%–1.9\% \\  & Systematics & 0.6\%–18.5\% & 0.2\%–1.3\% & 0.1\%–3.9\% \\ \cline{2-6}  & Background & 0.4\%– 6.7\% & 0.0\%–1.2\% & 0.0\%–0.4\% \\  & Material & 0.3\%– 8.5\% & 0.0\%–1.0\% & 0.1\%–3.9\% \\  & Non-closure & 0.0\%–12.3\% & 0.0\%–0.3\% & - \\  & Conversion & - & 0.0\%–0.1\% & - \\  & Generator & 0.0\%– 9.8\% & - & - \\ \hline \multirow{3}{*}{Converted \(\gamma\)} & Total & 1.9\%–30.8\% & 0.1\%–1.2\% & 0.5\%–2.0\% \\  & Statistics & 1.1\%– 5.8\% & 0.1\%–0.8\% & 0.4\%–1.9\% \\  & Systematics & 1.6\%–30.5\% & 0.1\%–1.2\% & 0.1\%–0.8\% \\ \cline{2-6}  & Background & 0.6\%–16.3\% & 0.0\%–0.8\% & 0.0\%–0.1\% \\  & Material & 0.5\%–16.5\% & 0.0\%–0.9\% & 0.1\%–0.8\% \\  & Non-closure & 0.0\%–15.6\% & 0.0\%–0.3\% & 0.0\%–0.0\% \\  & Conversion & - & 0.0\%–0.0\% & - \\  & Generator & 0.0\%–15.0\% & - & - \\ \hline \hline \end{tabular}
\end{table}
Table 1: Ranges of total uncertainty on the data-to-MC photon identification efficiency ratios and breakdown of the different sources of uncertainty for unconverted and converted photons, in three bins of transverse energy, giving the minimum and maximum values in the four pseudorapidity regions. A dash indicates that a particular systematic uncertainty is not applied in that \(E_{\mathrm{T}}\) range.

## 6 Summary

Figure 7: Comparison of the radiative Z boson data-driven efficiency measurements of unconverted photons to the \(Z\to\ell\ell\gamma\) simulation as function of \(E_{\rm T}\) in the region \(10\leq E_{\rm T}\leq 80\) GeV, in the four pseudorapidity intervals. The bottom panels show the ratio of the data-driven results to the MC predictions (“scale factor”, SF). The uncertainty bars represent the sum in quadrature of the statistical and systematic uncertainties.

Figure 8: Comparison of the radiative Z boson data-driven efficiency measurements of converted photons to the \(Z\to\ell\ell\gamma\) simulation as function of \(E_{\rm T}\) in the region \(10\leq E_{\rm T}\leq 80\) GeV, in the four pseudorapidity intervals. The bottom panels show the ratio of the data-driven results to the MC predictions (“scale factor”, SF). The uncertainty bars represent the sum in quadrature of the statistical and systematic uncertainties.

## 6 Conclusions

Figure 9: Comparison of the electron extrapolation and matrix method data-driven efficiency measurements of unconverted photons to the respectively prompt-photon MC predictions as function of \(E_{\mathrm{T}}\) in the region \(20\leq E_{\mathrm{T}}\leq 1500\) GeV, in the four pseudorapidity intervals. The bottom panels show the ratio of the data-driven results to the MC predictions (“scale factor”, SF). The uncertainty bars represent the sum in quadrature of the statistical and systematic uncertainties.

Figure 10: Comparison of the electron extrapolation and matrix method data-driven efficiency measurements of converted photons to the respectively prompt-photon MC predictions as function of \(E_{\mathrm{T}}\) in the region \(20\leq E_{\mathrm{T}}\leq 1500\) GeV, in the four pseudorapidity intervals. The bottom panels show the ratio of the data-driven results to the MC predictions (“scale factor”, SF). The uncertainty bars represent the sum in quadrature of the statistical and systematic uncertainties.

Figure 11: Data-to-MC efficiency ratios (SF) from the combination of the three measurements described in the text, for unconverted (top) and converted (bottom) photons, in the four pseudorapidity intervals. The uncertainty bars represent the sum in quadrature of the statistical and systematic uncertainties.

## 5 Conclusions

The strategy to measure the photon identification efficiency, developed by ATLAS during the LHC Run-I as described in [1], has been repeated for the data collected during 2015 at \(\sqrt{s}=13\) TeV, with an integrated luminosity of \(3.2\) fb\({}^{-1}\). Three independent analyses have been pursued to measure the photon identification efficiency: using photons from radiative \(Z\to\ell\ell\gamma\) decays; extrapolating to photons the shower shape properties observed for electrons from \(Z\to ee\) decays; directly measuring the efficiency on samples of reconstructed photons, after determining and subtracting the hadronic background with a technique based on track isolation. The results for each analysis are obtained for unconverted and converted photons separately, and in four pseudorapidity regions. The three analyses cover different kinematic ranges, and in the overlapping regions provide compatible results. Such results are combined, to provide scale factors to be applied to the simulated photons.

## Appendix

Table 2 lists the shower shape variables used for photon identification.

\begin{table}
\begin{tabular}{l l l|c c} \hline \hline Category & Description & Name & _loose_ & _tight_ \\ \hline \hline Acceptance & \(|\eta|<2.37\), with \(1.37<|\eta|<1.52\) excluded & – & \(\bullet\) & \(\bullet\) \\ Hadronic leakage & Ratio of \(E_{\rm T}\) in the first sampling layer of the hadronic & \(R_{\rm had_{1}}\) & \(\bullet\) & \(\bullet\) \\  & calorimeter to \(E_{\rm T}\) of the EM cluster (used over the range \(|\eta|<0.8\) or \(|\eta|>1.37\)) & & & \\  & Ratio of \(E_{\rm T}\) in the hadronic calorimeter to \(E_{\rm T}\) of the EM cluster (used over the range \(0.8<|\eta|<1.37\)) & \(R_{\rm had}\) & \(\bullet\) & \(\bullet\) \\ EM Middle layer & Ratio of \(3\times 7\)\(\eta\times\phi\) to \(7\times 7\) cell energies & \(R_{\eta}\) & \(\bullet\) & \(\bullet\) \\  & Lateral width of the shower & \(w_{\eta_{2}}\) & \(\bullet\) & \(\bullet\) \\  & Ratio of \(3\times 3\)\(\eta\times\phi\) to \(3\times 7\) cell energies & \(R_{\phi}\) & & \(\bullet\) \\ EM Strip layer & Shower width calculated from three strips around the strip with maximum energy deposit & \(w_{s\,3}\) & & \(\bullet\) \\  & Total lateral shower width & \(w_{s\,{\rm tot}}\) & & \(\bullet\) \\  & Energy outside the core of the three central strips but within seven strips divided by energy within the three central strips & \(F_{\rm side}\) & \(\bullet\) \\  & Difference between the energy associated with the second maximum in the strip layer and the energy reconstructed in the strip with the minimum value found between the first and second maxima & \(E_{\rm ratio}\) & \(\bullet\) \\  & Ratio of the energy difference associated with the largest and second largest energy deposits to the sum of these energies & & \\ \hline \hline \end{tabular}
\end{table}
Table 2: Discriminating variables used for _loose_ and _tight_ photon identification.

Figures 12 and 13 show the distribution of \(R_{\eta}\) and \(w_{s\,3}\) in data and in the simulation, before or after applying the corrections described in Section 2.1. With respect to the Figure 1 in the text, here the distributions are shown separately for both unconverted and converted photons, and for different pseudorapidity regions.

Figures 14 and 15 show the effect of the Smirnov transform for variables \(w_{s\,3}\) and \(R_{\phi}\), for both unconverted and converted photons. As explained in Section 3.2, for most DVs the difference is more sizable between electrons and unconverted photons, than for converted photons, because the latter are actually two electron showers overlapped: this is visible in Figure 14. An important exception comes from \(R_{\phi}\), where the two tracks from converted photons open apart in the plane transverse to the beam axis, due to the bending in the magnetic field, thus providing a wider shower than for electrons and unconverted photons: the effect is visible in Figure 15.

Figure 12: Shift correction applied to the simulated \(R_{q}\) discriminating variable, to match the observed distribution: for unconverted and converted photons, and for different pseudo-rapidity regions.

Figure 13: Shift correction applied to the simulated \(w_{x3}\) discriminating variable, to match the observed distribution: for unconverted and converted photons, and for different pseudo-rapidity regions.

## 6 Conclusions

Figure 14: Smirnov transform on variable \(w_{s\,3}\), for unconverted and converted photons.

## 6 Conclusions

Figure 15: Smirnov transform on variable \(R_{\phi}\), for unconverted and converted photons.

## References

* [1] ATLAS Collaboration, _Measurement of the photon identification efficiencies with the ATLAS detector using LHC Run-1 data_, (2016), arXiv: 1606.01813 [hep-ex].
* [2] ATLAS Collaboration, _The ATLAS experiment at the CERN Large Hadron Collider_, JINST **3** (2008) S08003.
* [3] W. Lampl et al., _Calorimeter Clustering Algorithms : Description and Performance_, (2008), url: [https://cds.cern.ch/record/1099735](https://cds.cern.ch/record/1099735).
* [4] T. Sjostrand, S. Mrenna, P. Z. Skands, _A Brief Introduction to PYTHIA 8.1_, Comput. Phys. Commun. **178** (2008) 852, arXiv: 0710.3820 [hep-ph].
* [5] T. Sjostrand, S. Mrenna, P. Z. Skands, _PYTHIA 6.4 Physics and Manual_, JHEP **0605** (2006) 026, arXiv: hep-ph/0603175 [hep-ph].
* [6] T. Gleisberg et al., _Event generation with SHERPA 1.1_, JHEP **0902** (2009) 007, arXiv: 0811.4622 [hep-ph].
* [7] S. Frixione, P. Nason and C. Oleari, _Matching NLO QCD computations with Parton Shower simulations: the POWHEG method_, JHEP **0711** (2007) 070, arXiv: 0709.2092 [hep-ph].
* [8] S. Alioli et al., _A general framework for implementing NLO calculations in shower Monte Carlo programs: the POWHEG BOX_, JHEP **1006** (2010) 043, arXiv: 1002.2581 [hep-ph].
* a simulation toolkit_, Nucl. Instrum. Methods A **506** (2003) 250.
* [10] ATLAS Collaboration, _The ATLAS simulation infrastructure_, Eur. Phys. J. C **70** (2010) 823, arXiv: 1005.4568 [physics.ins-det].
* [11] A. Valassi, _Combining correlated measurements of several different physical quantities_, Nucl. Instrum. Meth. A **500** (2003) 391.