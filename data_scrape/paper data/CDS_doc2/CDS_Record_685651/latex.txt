**ATLAS Internal Note CAL-NO-037**

**24 March1994**

**Using GEANT Mixtures for the Precise Simulation of Particle and Jet Response, and Particle Fluxes, in ATLAS**

Michael Shupe

University of Arizona

March 24, 1994

**Abstract**

A mixture level GEANT description of a collider experiment such as ATLAS reduces the number of volumes by one to two orders of magnitude by comparison with a detailed, 'electrode level', description of the same experiment. There is a corresponding gain in the speed with which the simulation runs, in part because the behavior of a detailed description cannot be reliably modelled without using lower cuts. Mixture descriptions of sensitive volumes such as calorimeter modules require tuning, both for response and fluctuations. Traditionally this tuning is done in an _ad hoc_ fashion, but in this paper we describe how to tune mixtures methodically. We discuss the types of studies where mixture descriptions excel, and suggest how mixtures might be smoothly incorporated into DICE.

**Overview of Mixture Techniques**

In the spectrum of GEANT simulations, a-mixture level description achieves a level of realism intermediate between parameterizations and detailed absorber and electrode level descriptions. Sensitive detector volumes, such as EM calorimeter modules, hadronic modules in barrel and endcap, forward calorimeter modules, tracking chambers, and muon chambers, are represented as homogeneous mixtures of the component materials, such as lead, copper, liquid-krypton, liquid-argon, scintillator, G10, silicon, etc. The mixtures are further decomposed into lists of elements, proportioned by weight, before defining the GEANT mixtures via GSMXT. This elemental decomposition is not necessary for many types of investigations, but is crucial when doing low energy neutron flux calculations.

The advantage of this approach is in computation speed. Depending on the cuts applied, such a simulation typically runs one to two orders of magnitude faster than a detailed simulation. An associated technique employed to reduce the number of GEANT volumes is to define all modules as single GEANT volumes and then compute the energy deposits (digitizations) in individual cells in 'user' software in the routine GUSTEP. For example, the ATLAS EM barrel accordion would be treated as one'module' (actually two because of the sampling fraction break), the hadronic scintillating barrel as one module, the EM endcap accordion (Spanish Fan) as one module, etc. D0 and H1 both use this technique to speed up the computations (in D0,the summing is done both at cell and tower level, where is it called'software caltowers'). This subdivision of volume and cell sums also has the advantage of allowing the calculation of calorimeter energy centroids with and without segmentation, so that the effects of \(\eta\)-\(\phi\) segmentation on electromagnetic shower, hadronic shower, and jet resolution may be investigated.

Mixtures have the disadvantage that they do not correctly model the resolutions or \(e/h\) response of sensitive calorimeter volumes. Electromagnetic energy is perfectly measured and resolved, both in EM showers, and as a component of hadronic showers. Hadronic energy has nuclear binding losses correctly modelled, as well as the fluctuations due to this particular source, but sampling fractions and their fluctuations are not present in mixtures in this component either. In any technique involving mixtures, sampling fractions and fluctuations, \(e/mip\) ratios, and other effects leading to non-compensation, must be put in following the summing of energy in individual volumes or cells. In a later section we describe how to tune mixtures reliably.

**History and Context**

The University of Arizona, as collaborators on the GEM experiment, used these mixture methods to calculate the single particle and jet response of the GEM calorimeter as the design evolved. This was one of several levels of calculation employed by GEM, and in the end, the full spectrum of methods was needed. Early on, various GEM institutions had separate detailed GEANT simulations for individual components of GEM: central tracker designs, EM accordion modules, hadronic calorimeter modules, forward calorimeter modules, muon chambers, etc. Many of these detailed descriptions propogated into an overall detailed description of GEM, known as SIGEM. With all subsystems described at detailed level, this simulation ran too slowly for many of the studies which had to be done. In addition, it was very difficult to keep SIGEM current or to do design tradeoff studies because of the complexity of the description and the logistics of incorporating design changes.

SIGEM ended up being very useful ultimately when used 'in parts', for central tracker studies, muon resolution and acceptance calculations, and neutron fluences. But in addition a whole spectrum of other tools was needed. The crucial problem is that the interesting physics at the LHC frequently involves rare signals sitting on top of rare fluctuations in some large cross section background. This implies the need for high statistics, which rules out full event simulation for most processes in a detailed GEANT simulation of the whole detector. But whatever alternatives are employed must still accurately characterize the rare fluctuations.

The mixture level description plays a role in this by allowing an accurate calculation of the effects of detector transition regions and mechanical structures on electrons and jets. It is inadequate for calculating a process such as Higgs decaying to \(\gamma\gamma\), but it excels in calculating the jet response at all \(\eta\) to very high statistics. The tails of the jet response (both low and high) affect many physics processes, and the high statistics are needed to develop the weighting procedures needed to recover linearity and resolution for jets.

Jet studies are one of several areas where mixture level calculations are useful. Most neutron fluence and detector dose studies are done at mixture level. This may be done through separate calculations with other packages and geometry descriptions, such as stand-alone Fluka with its combinatorial geometry. But it is also convenient to stay within the GEANT geometry description, and use the GCALOR interface to do neutron and low energy photon flux calculations.

An additional area where the mixture description found use in GEM was in deriving single particle response functions over the whole range of \(\eta\). Again, the high level of detail in detector transitions and structures made these realistic, and the speed of the description allowed high statistics to be accumulated. These'smearing' functions, complete with tails, were part of a collection of fast parameterization routines describing the response of GEM subsystems, called 'GEMFAST.' GEMFAST was the only route by which it was possible to achieve the required statistics on many of the physics benchmark processes included in the technical design report.

**Tuning Mixtures and Calculating the Energy Response**

Mixtures used for calorimetry will correctly model hadronic shower fluctuations due to binding energy losses, neutrinos, and other physical processes, but will otherwise act as fully sampling detectors. As a result the mixtures will not model sampling fraction or sampling frequency effects, and will thus get resolutions, \(e/h\) and \(e/mip\) wrong. Traditionally, experiments such as D0 have applied correction factors to the electromagnetic and hadronic energy to match testbeam results, and have at the same time applied smearing factors to match the same data.

What we have done differently starting in GEM is to make the response corrections in TWO STEPS. First, energies observed in the mixture volumes are adjusted to give the response of a _perfectly compensating detector_. Then they are corrected by the appropriate \(e/h\) for the given detector to simulate the _realistic response_.

The multiplier used in the first step is found by doing separate GEANT runs with a large shower-containing block of the mixture under investigation. Pion showers deposit electromagnetic and hadronic energy in the volume. All of the EM energy is visible (\(E_{EM}\)), and some fraction of the hadronic energy is visible (\(E_{hadvis}\)). These appear in GUSTEP as DESTEP. From energy conservation, one can solve for the total hadronic energy (\(E_{hadtot}=E_{pion}-E_{EM}\)), and find the factor by which one needs to multiply the hadronic energy to simulate a _compensating full-sampling_ detector: \(E_{hadtot}/E_{hadvis}\). From here on we shall refer to this as the "boost factor.' The boost factor is found by averaging over many showers, so that applying it event to event gives a distribution which is centered on the incident pion energies (i.e. is calibrated), but has the fluctuations characteristic of nuclear binding losses and neutrino losses in this mixture. It turns out that this boost is only weakly dependent on material. An illustration from GEM calorimetry shows that it is rather close to 2.0 for all materials:

EM accordion-Pb/liq krypton 2.22 EM accordion-Cu/liq argon 2.00 Fine hadronic-Pb/liq krypton 2.01 Fine hadronic-Cu/liq argon 2.00 Outer hadronic-Cu/scint 2.00 Forward hadronic-W/liq argon 1.94

The \(e/h\) factor applied in the second step may be found, in descending order of preference, by (a) using test beam data, and/or (b) detailed GEANT simulations, and/or (c) guessing. As test beam data become available, (a) should be used. In most cases, separate detailed GEANT studies will have been done of the various calorimeter modules, so method (b) may be used. In method (b), the \(e/h\) may be calculated during the detailed simulation of pion showers by keeping track of the EM energy in the module (\(E_{EM}\)), the total hadronic energy in the module (\(E_{hadtot}\)), the EM energy sampled in liquid argon gaps, scintillator, etc. (\(E_{EMsamp}\)), and the sampled hadronic energy (\(E_{hadsamp}\)). These are accumulated for enough showers to make statistical error negligible. Then \(e/h\) is simply the ratio \((E_{EMsamp}/E_{hadsamp})/(E_{EM}/E_{hadtot})\). Typical \(e/h\) factors used in previous GEM simulations for the example mixtures above are:

EM accordion-Pb/liq krypton 1.8 EM accordion-Cu/liq argon 1.8 Fine hadronic-Pb/liq krypton 1.6 Fine hadronic-Cu/liq argon 1.8 Outer hadronic-Cu/scint 1.2 Forward hadronic-W/liq argon 1.4

There are several advantages to this two step approach. The boost factor is intrinsic to the behavior of the GEANT mixture, so the calculation may be done 'once and for all.' What results is the response of a perfectly compensating, fully sampling detector, which in itself is interesting, and may be used as a basis for comparison to see what penalty is being paid for by lack of compensation. The second factor may be gotten from various sources, and as testbeam results become available it may be improved, and the simulations rerun. (If the event energy sums are written to disk before any correction factors are applied, rerunning the simulation is unnecessary.) One remaining nuisance, of course, is that in testbeam data the experimentally measured quantity is \(e/\pi\), and one must fit to a selection of incident energies to extract \(e/h\).

Note that one could have been more realistic by multiplying the electromagnetic energy by \(e/mip\) times the \(dE/dx\) weighted sampling fraction, and the hadronic energy by the \(dE/dx\) weighted sampling fraction alone, but the current method takes all these into account and leaves the electromagnetic energy calibrated. This makes quick scanning of the results less confusing, and amounts to nothing more than an arbitrary choice of scale-a calibration constant applying to the whole detector.

These two response factors correct the magnitude of the response, but do not provide the right smearing. The EM and hadronic energies will under-go fluctuation due to the sampling fraction and frequency. These additional smearing factors, like the \(e/h\) factor, must be measured in a testbeam, deduced from detailed GEANT simulation, or guessed. The additional subtlety here is that the smearing observed in the hadronic energy in a testbeam is the convolution, in quadrature, of the fluctuations in nuclear binding losses, and the fluctuations due to sampling. So to avoid 'oversmearing', one must take the experimental number and subtract the nuclear binding fluctuations seen in the simulation, in quadrature, to derive the additional smearing factor. In the GEM example list above, the following stochastic term ('samp') and constant term smearing factors were applied:

\begin{tabular}{l c c c}  & Esamp & Hsamp & Const \\ EM accordion-Pb/liq krypton &.06 &.60 &.004 \\ EM accordion-Cu/liq argon &.075 &.60 &.004 \\ Fine hadronic-Pb/liq krypton &.16 &.60 &.02 \\ Fine hadronic-Cu/liq argon &.16 &.60 &.02 \\ Outer hadronic-Cu/scint &.16 &.60 &.02 \\ Forward hadronic-W/liq argon &.40 &.80 &.04 \\ \end{tabular}

The stochastic term smearing is applied separately to the EM and hadronic components, then after summing these two, the constant term s-mearing is applied. To be sure that the procedures implied by the discussion above are clear, we summarize the steps applied to energy sums in the mixture simulation:

1. Sum EM and hadronic energy in each volume (cell) separately. (Write the event to disk if all the following are to be done in post-processing.)

2. Apply the hadronic energy boost factor needed to offset the nuclear binding losses.

**3.** Multiply the hadronic energy in each volume (cell) by the appropriate detector-dependent factor \(1/(e/h)\).

4. Fluctuate the EM component by the stochastic term smearing arising primarily from the sampling fraction, and the hadronic component by the corresponding hadronic stochastic term.

5. Add the two components and fluctuate by the constant term.

All of the above arguments are general and may be applied to any GEANT simulation employing mixtures in calorimeters.

**Mixture Simulations at the University of Arizona**

Up to the present, the geometry description used first for GEM, and now for ATLAS, is what is sometimes referred to as a '2D' description, with complete symmetry in \(\phi\). All volumes are described as TUBE or CONE shapes with no cracks. These shapes are used for calorimeter sensitive volumes, cryostat walls, beam structures, major structural members, central tracking chambers, and muon chambers. Many of these reduce to cylinders or 'washers' by changing dimensions of the basic TUBE shape. No provision is made for misalignment: the detector is perfect in this description. In reality the ATLAS EM calorimeter has no \(\phi\) cracks, but the hadronic calorimeter sections may have cracks, and provision will be made in future studies for inserting inter-module gaps. Some versions of ATLAS forward calorimetry have cracks, and this will be the subject of ongoing study.

The Arizona simulation may be run with or without segmentation, or with both cases at the same time for comparison. Much can be learned by using volumes without segmentation, summing all energy deposits in every step in each sensitive volume to form global \(E_{z}\), \(E_{y}\), and \(E_{z}\). One may scan an electron, pion, muon, or geantino gun in eta and learn a great deal about the single particle response function and the sources of fluctuation. This approach will not include segmentation effects, but it will correctly simulate the effects of dead materials, edges, thin sections of the calorimeter, etc.

In order to include segmentation, calorimeter cells are realized in software within the GUSTEP routine, and many possible segmentation types (projective, pseudo-projective, and non-projective) have been implemented. Electromagnetic and hadronic energy sums are maintained separately so that they may be independently corrected and smeared, as described above. With segmentation included, more realistic investigations, such as the effects of pileup on jet finding and resolution, become possible.

The Arizona mixture simulation initializes by reading an ASCII file to describe the GEANT geometry and materials. In effect, this geometry file drives the sequence of calls to the GEANT routines such as GSVOLU and GSPOS, and establishes the whole geometry tree. It is written in a simple format of keywords and named variables. The variables are all defined at the top of the file, and there is a section of derived variables as well. There is also a structure of conditional flags which allows several options to exist within the same description file. The whole description is very compact and may be quickly modified. The framework also has a postscript file output to verify the geometry setup.

A mixture routine receives lists of materials from this geometry file, and accepts as input mixtures specified by weight, volume, or atomic abundances. The action of this mixture maker is successive. For example, once a mixture such as 'CABLEMIX3' is defined, it may become the component of some mixture later in the table. In the end all mixtures are reduced to their elemental abundances by weight before introduction to GSMIXT. In this way the proper abundances are present for neutron fluence calculations using GCALOR.

### Mixtures in DICE

We are not proposing that the above utilities employed in the Arizona simulation framework should be incorporated into DICE. But we do feel that the experience of other running and proposed collider experiments shows that a whole spectrum of detector descriptions, of varying degrees of detail, are needed to deal with design options and the need for very high statistics in some of the physics benchmarks.

One simple step in this direction would be to give DICE the capability to use a mixture description in place of each component which currently has a complex detailed description. For example, one control file switch might cause the barrel EM accordion to be treated as a mixture, another, the hadronic barrel calorimeter, etc. A given user might throw all these switches at once to do global \(E_{t}\) calculations or neutron fluence studies, for example. Or if the user is focussing on the optimization of one subsystem, that one subsystem could be left as a detailed description while all others were treated as mixtures. The effort to install this feature could be spread around if those responsible for the DICE frame worried only about the switch implementation and standards for passing the mixture level information, while the authors of the subsystem detailed geometries set up the 'envelopes' and materials lists for the mixture descriptions of the corresponding subsystems.

This proposal does not go all the way to implementing a parameterized description as an additional option for each subsystem. Such parameterizations involve considerably more effort if they are to characterize the rare fluctuations properly. But having this intermediate capability in DICE would facilitate a number of important calculations.

**Summary**

This paper is a bit peculiar in that it has two different purposes. One has been to document the mixture methods used in the Arizona framework simulations of ATLAS particle response, fluence, and dose; jet resolution; and missing \(E_{t}\) calculations. And at the same time it is a proposal to supplement DICE with mixture option switches so that some studies might be done to higher statistics than is currently possible. We hope that we have not confused the reader too much in forming this mixture of topics.