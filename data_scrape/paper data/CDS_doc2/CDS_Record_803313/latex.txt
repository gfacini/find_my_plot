# The Simulation of the ATLAS Experiment: Present Status and Outlook

A. Rimoldi, University of Pavia & INFN, Italy, A.Dell'Acqua, M. Gallas, A.Nairz, CERN, Geneva, Switzerland, J. Boudreau, V.Tsulaia, University of Pittsburgh, USA, D. Costanzo, LBL, USA

###### Abstract

The simulation program for the ATLAS experiment is presently operational in a full OO environment. This important physics application has been successfully integrated into ATLAS's common analysis framework, ATHENA. In the last year, following a well stated strategy of transition from a GEANT3 to a GEANT4-based simulation, a careful validation programme confirmed the reliability, performance and robustness of this new tool, as well as its consistency with the results of previous simulation. Generation, simulation and digitization steps on different sets of full physics events were tested for performance. The same software used to simulate the full the ATLAS detector is also used with testbeam configurations. Comparisons to real data in the testbeam validate both the detector description and the physics processes within each subcomponent. In this paper we present the current status of ATLAS GEANT4 simulation, describe the functionality tests performed during its validation phase, and the experience with distributed production during a recent ATLAS data challenge.

## 1 Introduction

The GEANT4 Simulation for the ATLAS detector is a new tool implemented in the ATLAS common framework (ATHENA) [1]; it replaces the GEANT-3 based simulation, which played the major role in ATLAS in the past 10 years. The deployment of the new simulation [2], and its first extensive use in production was completed this Year (2004). The ATLAS collaboration has been using GEANT3 since the collaboration was formed and during these years the description of both the ATLAS geometry and the simulation of detector response have been considerably refined.

The new simulation was implemented with the same accuracy and level of detail as the previous one, if not more, and follows all of the developments in the most recent construction phase of the detector. The performance and robustness tests presented here were initially carried out time prior to a large-scale production of simulated events for the second data challenge (DC2), and were repeated as the project evolved in order to continuously monitor the performance of the simulation. During the data challenge itself, we processed single particle events (electrons, muons, pions) with incident energy ranging between 1 GeV and 2 TeV using the full ATLAS geometry, in the entire geometrical acceptance, in addition to minimum-bias events within a pseudorapidity (\(\eta\)) range (\(|\eta|\)\(<\)6), H(130) ZZ\({}^{*}\)_4l, Z_ee, Z_uu, Z_xt, \(di\)-\(jet\) events (p\({}_{\rm f}\)(hard)\(>\)17 GeV), SUSY/SUGRA events, in the same range of \(\eta\). The total production consisted of more than 10\({}^{7}\) events. Memory consumption and CPU usage was monitored at runtime; the results are presented below.

## 2 The ATLAS Simulation Project

### The Simulation data flow

Input for Simulation comes from event generators after a particle filtering stage. Data objects representing Monte Carlo truth information from the generators was read by simulation and processed.

Hits produced by the simulation can be directly processed by the digitization algorithm and transformed into Raw Data Objects (RDO). Alternatively they can be sent to the pile-up algorithm and then passed either to the digitization for RDO production or to the 3-level trigger chain for the final Event Filter selections.

### Present Status of the GEANT4-based Simulation

The GEANT4-based simulation was developed in a full OO environment since the year 2000; it is completely written in C++ and is very detailed. Dynamic loading and action-on-demand are extensively used. At the time of this note most of the desired functionality is present. Interactivity is provided by the use of the Python scripting language, which was recently adopted as a replacement for the old macro-files structure. All recent developments provide backward compatibility.

The development of the ATLAS simulation program started as a standalone exercise in a standalone framework, but since 2002 it has been embedded in the ATLAS standard framework (ATHENA). Now it is fully operational both for the full experiment and for testbeampurposes, using the same software. The POOL facility is adopted for input/output.

### The validation process

The long history of validation started during early preproduction tests (2001) and Data Challenges (2003-2004). After a short ramp-up with failures at about the 10% level in single particle jobs (30% failures in physics processes) the detector simulation became extremely stable, with high performance and proven reliability.

The validation procedures evolved over many years, starting in 2002 with Data Challenge preproduction and continuing in subsequent years with DC (0, 1, 2). Initial tests involving small and simple (e.g. single particle) events developed over time into more detailed tests on larger and more complicated events. DC2 (2004) is the first data challenge to be based entirely upon GEANT4. It is used for large scale physics analyses, as well as tests of the computing model, calibration and alignment. 12 million full events were fully simulated over four months with only one job crashing in production. At NorduGrid, a total sample of more than 3.5 millions events (1 million full Z_e^e-e events) was processed in 35K different jobs without a single reported failure.

Since 2001 a wide and detailed set of tests of GEANT4 physics, including comparisons with the previous GEANT3-based simulation was also performed for all the ATLAS detector components. Extensive comparisons with beam test data confirmed the reliability of this tool: the agreement data-simulation is now \(\sim\)1%. More room for refinements and fine tuning is still open.

## 11 AN OVERVIEW OF THE ATLAS DETECTOR

The ATLAS detector consists of four main subdetectors (Fig. 1):

* the inner detector (ID) for the measurement of momentum and impact parameter of charged particles.
* the calorimeter system, for measurement of particle and jet energies, consisting of a liquid argon (LAr) electromagnetic and hadronic system in the endcap, and a liquid argon electromagnetic calorimeter plus a scintillating tile colorimeter in the barrel region.
* the muon spectrometer for muon identification and momentum measurement, consisting of high precision drift tubes for tracking, and a set of two subsystems of trigger chambers: resistive plate chambers (RPC) and thin gap chambers (TCG).
* A magnet system for bending of charged particles for momentum measurements.

The ATLAS subdetectors are all simulated in detail. In the 1D, a detailed implementation for the three technologies (Pixel, Silicon and TRT) is in place. For each of them detailed descriptions of the final layout (the complete detector for the experiment) and initial layout (the one installed at first day of collisions) are implemented. Comparisons on performance of different configurations are possible at hit level (Fig. 2). The detector response is tuned on testbeam results and used to feed the ATLAS simulation.

Figure 1: The ATLAS detector in an opened 3-D view

Figure 3: LAr barrel electromagnetic calorimeter

Figure 2: - Hits comparisons in the TRT detector for initial/final layout vs. pseudorapidity

The calorimeter simulation is very detailed for each component (barrel and forward calorimeters, both electromagnetic and hadronic). Fig. 3 and 4 show a 3-D view of the LAr accordion calorimeter and the forward calorimeters. Extensive tests are being done to investigate and optimize the physics content of GEANT4 and the geometry for reducing the memory consumption at runtime. Parameterization studies are also under way, to further optimize the performance.

The muon spectrometer, which is the outermost detector of ATLAS, is carefully simulated in order to reproduce not only all the detector details but also its peculiar asymmetries. A final/initial layout switch, as in the case of the ID, is implemented for comparisons of performance and check of the predictions of the earliest discoveries at experiment start-up. Source of primary numbers is NOVA [3] for all subdetectors. All functionality for handling event pileup is in place but the final implementation of full background is still under development and expected shortly.

## 11 The ATLAS Testbeam

In the last years an extensive program of tests, in a beam line, of all the components of a true and complete sector of ATLAS was performed. A detailed simulation of the setup was developed, reproducing a complete sector of ATLAS detector. All ancillary detectors, magnets and dead material along the beam line were added in the simulation, and a broad set of comparisons with data were performed for all the technologies, giving us confidence in the simulation of both the detector description and the physics of the complete tool.

Testbeam simulation uses the same software as the full experiment. A 3D view of the implemented geometry is shown in Fig. 5.

## 11 The Detector Digitization

The digitization of GEANT4 hits in ATLAS is performed subdetector-by-subdetector. It can be run on pregenerated, persistified hits or in a full chain that includes simulation. His persistified using POOL can be read by the pile-up procedure. The Pythia generator is used to produce minimum bias events.

Digitization in ATLAS is now fully functional and free of memory leaks. We expect extensive validation work through comparisons with data from testbeam 2004: all assumptions such as resolution, smearing, etc. should be revisited and finalized. The full Monte Carlo Truth navigation should be finalized and tested, and occupancy studies should be carried out.

## 11 The Simulation Validation in Preproduction

Preliminary simulation validation started at the end of 2003 and comparisons with Geant3 using common event samples and with the same geometry were performed. Hits and digits for all the Atlas subdetectors were collected. We ran jobs in parallel using the LSF batch and Castor facility at CERN and outside. We measured at different event/run phases the performance and memory usage. The generated samples are the following:

* Single particle at different energies
* SUSY events
* H_4 leptons, Z_2leptons(e, mu,tau)
* dijets
* minimum bias events

We initially observed a failure rate of \(\sim\)10% for single particle jobs and 30% in physics events, where many problems arose. We corrected geometry problems, physics problems (GEANT4 physics lists) and our final failure is numerically around 0%, excluding AFS or Castor problems. All jobs now run reliably to the end.

The hit size is less than a factor of 1.5 of that GEANT3 (700Kb for G3 with 900KB G4), while the execution time is \(\sim\)1.5 times that of G3.

Figure 4: Forward electromagnetic and hadronic calorimeters

Figure 5: The ATLAS combined testbeam, 2004 setup

[MISSING_PAGE_FAIL:4]