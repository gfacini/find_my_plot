# Test Beam Results on the Atlas First-Level Endcap Muon Trigger System

T. MAENO

CERN

1211 Geneva 23, Switzerland

E-mail:

Tadashi.Maeno@cern.ch

K.NAGANO, M. IKENO, O. SASAKI

KEK, Tsukuba, Japan

S. TSUJI, R. ICHMIYA, H. KURASHIGE

Kobe University, Kobe, Japan

D. LELLOUCH, L. LEVINSON, G. MIKENBERG, A. ROICH

The Weizmann Institute of Science, Rehovot, Israel

A. HAREL, R. LIFSHITZ, N. LUPU, S. SCHWARZMANN, S. TAREM

Technion, Haifa, Israel

Y. BENHAMMOU, E. ETZION

Tel Aviv University, Tel Aviv, Israel

C. FUKUNAGA, K.TOSHIMA

Tokyo Metropolitan University, Tokyo, Japan

Y. FUJII, Y. KATAOKA, H. SAKAMOTO, K. SHIBUYA

ICEPP. University of Tokyo, Tokyo, Japan

N. TAKADA

Shinshu University, Matsumoto, Japan

T. SAKUMA

Tokyo University of Agriculture and Technology, Tokyo, JapanThe ATLAS endcap muon trigger system uses custom integrated circuits and electronic modules. It will provide fast trigger information at the LHC bunch-crossing rate of 40 MHz to be used in making the first-level trigger decision. A prototype of the system has been constructed and mounted on Thin Gap Chambers. We have tested the system using a 180 GeV muon beam in the CERN SPS H8 beam line. The SPS provided bunched-beam with 25 ns structure, which allowed us to check the system performance under conditions very similar to the ATLAS experiment, before proceeding to the mass-production phase. We will present results on the evaluation of the system performance.

## 1 Introduction

The ATLAS Thin Gap Chamber (TGC) is dedicated to trigger muons in the endcap region and to measure the azimuthal coordinate not measured by the precision muon drift chambers. The TGC trigger system will provide fast trigger information for the first-level trigger decision at the LHC bunch-crossing rate of 40 MHz [1]. The trigger information is fed into the Muon Central Trigger Processor Interface (MUCTPI) that calculates the muon candidate multiplicity before the muon trigger signals are sent to the central trigger processor (CTP). The TGC system also reads out all hits and trigger data and sends them as formatted events to the central ATLAS readout system at the Level-1 accept rate of up to 100kHz.

We have constructed the TGC electronics system, which uses three ASICs [2] and custom electronics modules, and completed a vertical slice test in the laboratory in 2002. In September 2003, we have tested the system using a 180 GeV muon beam in the CERN SPS H8 beam line. The SPS provided bunched-beam with 25 ns structure, which allowed us to check the system performance under conditions very similar to the ATLAS experiment, before proceeding to the mass-production phase. In this test beam the TGC system was integrated in the ATLAS central trigger system and the overall test beam DAQ system. We used the TGC detector control system (DCS) [3] for the control of the chamber and electronics. We will present results on the evaluation of the system performance in the test beam. A prototype database was used to record running conditions.

## 2 Overview of TGC Trigger System

The TGCs give eight measurement layers. In front of TGC, there are air-core toroidal magnets that produce the magnetic fields for \(\mathrm{p_{T}}\) measurements. Amplifier- Shaper- Discriminator boards [4] are attached directly to TGC chambers to digitize the TGC signals, and send them to Patch-panel ASICs (PP ASICs). Service patch panel (SPP), that fans out the Timing Trigger and Control(TTC) signals, is also attached to TGC chambers. PP ASICs synchronize signals to identify bunch crossing before sends them to Slave Board ASICs (SLB ASICs). SLB ASICs perform local coincidence to identify muon candidates with \(\mathrm{p_{T}}\)\(\geq\) 6 GeV/c, and outputs \(\mathrm{r}\) and \(\mathrm{\Delta r}\) (\(\mathrm{\phi}\) and \(\mathrm{\Delta\phi}\)) information for each candidate. The PP ASICs and SLBs are mounted together on a PS board. The output signals from SLBs are fed into a Hi-pT board, which is installed in an HS crate and is about 15m away from the corresponding PS board. Hi-pT ASICs (HpT ASICs) are mounted on the Hi-pT board. A HpT ASIC combines information from two or three SLB ASICs in order to find muon candidates with \(\mathrm{p_{T}}\)\(\geq\) 20 GeV/c. HpT ASICs compress the output information and sends it to the Sector Logic (SL) with serial data transmission. The SL is installed in the off-detector part and makes global \(\mathrm{r\phi}\)-coincidence to identify muon candidates in the two dimensional space. At maximum two highest \(\mathrm{p_{T}}\) muon candidates per trigger sector (72 sectors/side) are selected after successful \(\mathrm{r\phi}\)-coincidence, and the information is sent to the MUCTPI. Functionalities and design concept of the three main ASICs (PP, SLB and HpT ASIC) have been discussed in [5].

The readout information is also processed in the SLB ASICs, each of which implements pipeline buffers to store data during the process time of the first-level trigger. At every level-1 accept signal, SLB ICs serialize data and send them to the Star Switch (SSW). One SSW receives data from up to 18 SLB ASICs and sends them to Readout Driver (ROD). The ROD gathers all data from an octant, formats them into an event record that is sent to the ATLAS central DAQ (ROS). Events are also sent to a local processor for consistency checking and monitoring.

## 3 Test Beam Setup

CERN SPS provided a bunched-beam with 25ns time structure during two periods, in May and September 2003. Seven layers of TGC (one triplet and two doublets) were setup to make a realistic experimental configuration that is almost the same as the final one for the ATLAS endcap muon detection system. One TGC triplet was installed in front of the monitoring drift tubes (MDT) that will be used to measure muon tracks precisely in the ATLAS detector. Two TGC doublets were mounted behind the MDT.

For this test beam setup, we used two PS boards and one SPP. A DCS board was mounted on each PS board, providing control functions for the PS boards and chambers. These DCS boards were connected via CAN bus to a control station PC in the H8 counting room. The Hi-pT and SSW modules were installed in a VME 9Ucrate (HS crate) and put in the vicinity of the triplet. The PS boards and the HS crate were connected with 10m cables. The ROD and SL were put in the H8 electronics hut together with the MUCTPI and ROS. Also a PC running database software was used to record the running conditions such as thresholds, HV and DAQ/trigger parameters.

## 4 Results

We have measured trigger efficiency with a scan over PP ASIC delay parameters. Figure 1 shows that we can maximize trigger efficiency and bunch-crossing identification performance by adjusting the delay parameters. Although the highest efficiency was about 96%, 3% of it is owing to the dead space from chamber supports in the test beam setup and about 1% is estimated to come from some spurious triggers from the scintillation counter, such as cosmic rays. Trigger efficiency was then estimated as 99.7% maximum after the corrections. And we measured the muon beam profile in the two dimensional space. Data were taken under the condition of 15ns delay of the triplet PP ASIC and 30ns gate width. Both chambers gave a beam profile with root mean square of about three channels.

The self-consistency of the TGC system was checked by comparing the trigger output with the corresponding simulation result with the same input hits. Then we analyzed the combined run data to check consistency with other sub-detector data. Figure 2 shows comparison of trigger P\({}_{\rm T}\) range bits stored in the TGC and MUCTPI data fragments. We can see clear correlation in this figure. Therefore, it is confirmed that the TGC system was synchronized with other ATLAS components and worked correctly in the global ATLAS system. We also checked the consistency with MDT data.

Figure 1: Trigger efficiency versus delay parameter of PP ASIC.

Figure 2: Comparison of trigger P\({}_{\rm T}\) range bits stored in the TGC and MUCTPI data.

## 5 Conclusions

The functionality of the TGC trigger system has been tested with a 180GeV muon beam at CERN SPS H8 beam line. Both trigger- and readout-chain were operated well, and integration with the ATLAS central trigger system and the test beam DAQ system was smooth. The TGC system ran together with other ATLAS sub-detectors successfully. We have analyzed the combined run data and observed clear consistency with other sub-detector data. That is the first evidence that the TGC system is able to work correctly in the overall ATLAS system.

## Acknowledgments

We would like to acknowledge the CERN SPS and H8 beam line crew for giving us 25ns structured beam constantly during the test. We are grateful to ATLAS TGC construction group and in particular M. Ishino and Y. Arataki for their advice and support for the TGC operation in the beam time. We would like to express our gratitude to N. Ellis, T. Kondo and T. Kobayashi for their support and encouragement throughout the test. We are grateful to T. Wengler, P. Amaral, Ph. Farthouat and P. Gallno for their MUCTPI and TTC system integration, B. Di Girolamo and F.Cerutti for their beam time management, L. Pontecorvo for the beam and beam trigger, and Central ATLAS DAQ team for their help in the DAQ system integration.

## References

* [1] ATLAS Level-1 Trigger group, ATLAS First Level Trigger Technical Design Report CERN/LHCC/98-14 (1998)
* [2] K.Hasuko, et.al., Proc. the 6th Electronics for LHC Experiments (2000) 328
* [3] S. Tarem, et. al., Proc. the 8th Workshop on Electronics for LHC Experiments (2002) 411
* [4] O.Sasaki and M.Yoshida, IEEE Trans. Nucl. Sci., **46** (1999) 1871
* [5] H.Kano, et al., Proc. the 6th Electronics for LHC Experiments, 2000, 486