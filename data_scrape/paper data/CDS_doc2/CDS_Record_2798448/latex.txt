[MISSING_PAGE_EMPTY:1]

## 1 Introduction

The discovery of the Higgs boson (\(H\)) by the ATLAS and CMS collaborations [1; 2] opened a vast programme of Standard Model (SM) precision measurements and new avenues for probing beyond the Standard Model (BSM) physics models. All current measurements of the Higgs boson spin and couplings [3; 4; 5; 6; 7] are so far consistent with the SM predictions [8; 9; 10; 11; 12; 13].

The production of a pair of Higgs bosons (\(HH\)) is a rare process in the SM. At the LHC, \(HH\) can be produced via the Higgs trilinear self-coupling and the destructively interfering top-quark loop through the dominant gluon-gluon fusion (ggF) process. In the SM, the trilinear self-coupling strength (\(\lambda^{\rm SM}_{HHH}\)) is related to the Higgs boson mass (\(m_{H}\)) and the vacuum expectation value of the Higgs field (\(v\)) by \(\lambda^{\rm SM}_{HHH}=\frac{m_{H}^{2}}{2v^{2}}\). Measurements of this parameter would provide constraints on the shape of the Higgs potential and would allow the verification of the electroweak symmetry breaking mechanism of the SM. The existence of an extended scalar sector or the presence of new dynamics at higher energy scales could modify the effectively measured value of the trilinear self-coupling strength \(\lambda_{HHH}\).

Experimental studies of final states arising from \(HH\) production can be used to set constraints on \(\lambda_{HHH}\). The SM production cross-section of Higgs boson pairs is about 1000 times smaller than that of single Higgs bosons. The \(HH\) production through the dominant ggF process has a predicted cross-section \(\sigma^{\rm SM}_{\rm ggF}=36.7^{+6\%}_{-23\%}\) (scale + \(m_{\rm top}\)) \(\pm\) 3.0% (\(\alpha_{s}\) + PDF) fb at next-to-next-to-leading order (NNLO) in \(\alpha_{s}\) for \(m_{H}=125\) GeV and \(\sqrt{s}=14\) TeV [14; 15; 16; 17; 18], where scale + \(m_{\rm top}\) is related to the uncertainties arising from the choice of renormalization scheme and scale of the top-quark mass, and \(\alpha_{s}\) + PDF refers to the strong coupling constant and parton distribution functions. The sub-dominant vector boson fusion (VBF) process has a predicted cross-section \(\sigma^{\rm SM}_{\rm VBF}=2.06^{+0.03\%}_{-0.04\%}\) (scale) \(\pm\) 2.1% (\(\alpha_{s}\) + PDF) fb for \(m_{H}=125\) GeV and \(\sqrt{s}=14\) TeV [19; 20; 21; 22; 23]. The non-resonant \(HH\) production rate is very sensitive to anomalous couplings in BSM scenarios [19].

A major upgrade of the LHC is planned to be completed by 2027, resulting in the High Luminosity LHC (HL-LHC). The goal of the HL-LHC is to accumulate 3000 fb\({}^{-1}\) and potentially up to 4000 fb\({}^{-1}\) of \(pp\) collision data at \(\sqrt{s}=14\) TeV over about a decade. To achieve such high integrated luminosities, peak instantaneous luminosities will range from \(5\times 10^{34}\) cm\({}^{-2}\)s\({}^{-1}\) (baseline) up to \(7.5\times 10^{34}\) cm\({}^{-2}\) s\({}^{-1}\) (ultimate), representing an increase by an approximate factor of 4 compared to the typical luminosities of Run 2. This corresponds to an average pileup of 140 to 200 \(pp\) collisions per bunch crossing. Therefore, optimising object reconstruction and identification performance for precision measurements constitutes a challenge in this harsh environment. Based on previous projections, it is expected that the Higgs boson trilinear self-coupling can be measured to a precision of 50% at the HL-LHC by combining results from both ATLAS and CMS [24]. Previous ATLAS prospects for the search of non-resonant \(HH\) production using a statistical combination of the \(b\bar{b}b\bar{b}\), \(b\bar{b}\gamma\gamma\) and \(b\bar{b}\tau^{+}\tau^{-}\) final states can be found in Ref. [25]. This note presents updated ATLAS studies of \(HH\) production in the \(b\bar{b}\tau^{+}\tau^{-}\) final state at the HL-LHC, assuming a total integrated luminosity of 3000 fb\({}^{-1}\). This channel combines a sizeable branching fraction \(\mathcal{B}(HH\to b\bar{b}\tau^{+}\tau^{-})=7.3\%\)[26] with moderate contamination from the multi-jet and \(t\bar{t}\) backgrounds, making it one of the most sensitive channels for \(HH\) searches.

The extrapolation of the Run 2 \(HH\to b\bar{b}\tau^{+}\tau^{-}\) analysis results [27; 28] to estimate the sensitivity of this channel to the \(HH\) cross-section and to the Higgs boson self-coupling modifier \(\kappa_{\lambda}\) (\(\kappa_{\lambda}\equiv\lambda_{HHH}/\lambda^{\rm SM}_{HHH}\)) at the HL-LHC are presented here. The Run 2 \(HH\to b\bar{b}\tau^{+}\tau^{-}\) results yielded an observed (expected) 95% confidence level (CL) upper limit on the cross-section of non-resonant \(HH\) production that includes the contributions from the ggF and VBF processes of 135 (114) fb, and a 95% CL upper limit of 4.65 (3.87)on the SM \(HH\) production signal strength \(\sigma_{\rm ggF\ +\ VBF}/\sigma^{\rm SM}_{\rm ggF\ +\ VBF}\). Assuming an observed signal strength of zero, the Higgs boson self-coupling was constrained at 95% CL to \([-2.4,9.2]\) (\([-2.0,9.0]\)). When compared to the results obtained with 36 fb\({}^{-1}\) of Run 2 data, these results profit from improved object reconstruction and identification [29, 30, 31, 32, 33], more sophisticated multivariate methods [32, 33] and new background estimation techniques. One of the main motivations for this updated projection is to include the improvements in object reconstruction and identification from the Run 2 \(HH\to b\bar{b}\tau^{+}\tau^{-}\) results and evaluate their effect on the \(HH\) sensitivity at the HL-LHC. It is assumed that the performance degradation arising from the higher number of pileup interactions will be mitigated by new developments [34, 35] exploiting the future highly segmented ATLAS detector subsystems [36, 37, 38].

## 2 Run 2 Analysis

The Run 2 \(HH\to b\bar{b}\tau^{+}\tau^{-}\) results are based on \(pp\) collision data at \(\sqrt{s}=13\,\mathrm{TeV}\), collected with the ATLAS detector at the LHC during 2015-2018 [27, 28]. Data samples corresponding to an integrated luminosity of \(139.0\pm 2.4\) fb\({}^{-1}\)[39, 40] are used in the analysis. Selected data events are required to have all relevant components of the ATLAS detector in good working condition. The recorded events contain an average of 34 simultaneous inelastic \(pp\) collisions per bunch crossing. The contributions from misidentified \(\tau_{\rm had\-vis}\) (fake-\(\tau_{\rm had\-vis}\)) originating from quark- and gluon-initiated jets are estimated using data-driven methods for major backgrounds. Monte Carlo (MC) simulated events are used to model the non-resonant \(HH\) signal production and the SM background production. The MC processes are passed through the full ATLAS detector simulation [41] based on Geant 4 [42].

The non-resonant ggF \(HH\) signal sample is generated at next-to-leading order (NLO) with finite top-quark mass using PowhegBox v2 [43] and the PDF4LHC15 [44] NLO PDF set. The non-resonant VBF \(HH\) samples are produced with MadGraph5_aMC@NLO v2.7.3 [45] at leading order (LO) using the NNPDF3.0NLO [46] PDF set. Both the ggF and VBF samples are showered with Pythia 8.244 [47, 48, 49] using the A14 tune [50, 51] and the NNPDF2.3LO PDF set [52]. To evaluate uncertainties on the signal modelling originating from the parton shower, samples showered with Herwig 7.1.3 [53] instead of Pythia 8.244 are used.

Predictions for ggF \(HH\) assuming \(\kappa_{\lambda}\neq 1\) are obtained from the SM signal sample using the reweighting procedure described in Ref. [54]. The event weights for this procedure are derived in two steps, described in the following. First, linear combinations of three samples produced assuming \(\kappa_{\lambda}=0,1,20\) are performed according to their LO cross-sections to construct predicted distributions of the invariant mass of the \(HH\) system (\(m_{HH}\)) for numerous \(\kappa_{\lambda}\) values. Afterwards, the contents of the bins of the \(m_{HH}\) distributions for these \(\kappa_{\lambda}\) values are divided by the content of the same bin of the \(m_{HH}\) distribution for \(\kappa_{\lambda}=1\) to define the event weights in dependence of \(m_{HH}\). For validation, as well as evaluation of the uncertainties related to the method, a ggF \(HH\) sample assuming \(\kappa_{\lambda}=10\) is used. For VBF \(HH\), no such event weights are available. Instead, non-SM samples with \(\kappa_{\lambda}=0,2,10\) are used following a similar procedure in order to obtain the VBF templates. The samples with \(\kappa_{\lambda}=1,2,10\) are linearly combined according to their LO cross-sections to make predictions for arbitrary \(\kappa_{\lambda}\) values, and the additional sample for \(\kappa_{\lambda}=0\) is used for validation and uncertainty estimation. The simulation of background samples is unchanged with respect to Ref. [27] and described in the following.

Top-quark pairs (\(t\bar{t}\)) and single top-quark production in the \(Wt\)-, \(s\)- and \(t\)-channels are simulated using PowhegBox v2 and the NNPDF3.0NLO PDF set. The events are interfaced to Pythia 8.230 [49] for the parton shower and hadronisation with the A14 set of tuned parameters and the NNPDF2.3LO PDF set.

Events containing \(W\) or \(Z\) bosons produced in association with jets, diboson and \(t\bar{t}Z\) processes are simulated using Sherpa 2.2.1[55]. The \(t\bar{t}W\) processes are simulated with Sherpa 2.2.8[55]. The NNPDF3.0NNLO PDF set is used in conjunction with dedicated parton shower tuning developed by the Sherpa authors in these processes.

Single Higgs boson processes are simulated using Powheg Box v2 and the NNPDF3.0NLO PDF set. The simulated ggF and VBF single Higgs boson events are interfaced to Pythia 8.212 for parton shower and hadronisation using the AZNLO tune [56] together with the CTEQ6L1 PDF set [57]. For the Higgs boson production in association with a pair of top-quarks (\(t\bar{t}H\)) the events are interfaced to Pythia 8.230 for the parton shower and hadronisation with the A14 set of tuned parameters and the NNPDF2.3LO PDF set.

Events are selected in three separate signal regions (SRs), targeting the fully-hadronic and the semi-leptonic decay modes of the \(\tau\)-lepton pair, labeled \(\tau_{\text{had}}\tau_{\text{had}}\) and \(\tau_{\text{lep}}\tau_{\text{had}}\) respectively. Events in the \(\tau_{\text{had}}\tau_{\text{had}}\) SR are selected using a combination of single- (STT) and di-\(\tau_{\text{had-vis}}\) triggers (DTT), and are required to have two \(\tau_{\text{had-vis}}\) with opposite charge. An electron and muon veto is applied to ensure orthogonality with the \(\tau_{\text{lep}}\tau_{\text{had}}\) channel. Events in the \(\tau_{\text{lep}}\tau_{\text{had}}\) channel are split into two separate SRs depending on whether they pass a single-lepton trigger (SLT) or a lepton plus \(\tau_{\text{had-vis}}\) trigger (LTT). Both categories of events are required to have exactly one electron or muon and one \(\tau_{\text{had-vis}}\) with opposite charge. Events in all SRs are required to have \(m_{\tau\tau}^{\text{MMC}}>60\) GeV1 and exactly two \(b\)-tagged jets in addition to any trigger-dependent requirements. A control region (CR) targeting events with two electrons or two muons of opposite charge and an invariant mass in the interval \([75\text{ GeV},110\text{ GeV}]\), and exactly two \(b\)-tagged jets, is included to control the background process of \(Z\) bosons produced in association with two jets initiated by \(b\) or \(c\) quarks. This process is referred to as \(Z\)+HF in the following. In the \(Z\)+HF CR, the \(b\)-tagged jets are required to have an invariant mass outside the interval \([40\text{ GeV},210\text{ GeV}]\) to avoid overlap with other analyses targeting \(H\to b\bar{b}\) decays.

Footnote 1: The invariant mass of the \(\tau\)-lepton pair (\(m_{\tau\tau}^{\text{MMC}}\)) is estimated using the Missing Mass Calculator (MMC) [58].

In the offline \(\tau_{\text{lep}}\tau_{\text{had}}\) event selection, a \(\tau_{\text{had-vis}}\) with transverse momentum (\(p_{\text{T}}\)) of at least 20 GeV is required in the SLT category, while \(p_{\text{T}}>30\) GeV is required in the LTT category. Depending on the data-taking period, the electron (muon) that passes the SLT category is required to have \(p_{\text{T}}^{e}>25\) GeV or \(p_{\text{T}}^{e}>27\) GeV (\(p_{\text{T}}^{\mu}>21\) GeV or \(p_{\text{T}}^{\mu}>27\) GeV). If the event fails the SLT, then the LTT is checked. The LTT category requires either an electron with \(p_{\text{T}}^{e}>18\) GeV or a muon with \(p_{\text{T}}^{\mu}>15\) GeV. In the \(\tau_{\text{had}}\tau_{\text{had}}\) event selection, the offline \(p_{\text{T}}\) thresholds for the \(\tau_{\text{had-vis}}\) range between 100 GeV and 180 GeV for the STTs, and are 40 GeV (30 GeV) for the (sub-)leading \(\tau_{\text{had-vis}}\) for the DTTs. In events passing single-object triggers, the two leading \(b\)-tagged jets have to pass minimum \(p_{\text{T}}\) thresholds of 45 and 20 GeV, respectively. Some of the multi-object triggers used in this analysis require the presence of a jet in addition to the \(\tau\)-lepton decay products. In events that pass these, the leading jet \(p_{\text{T}}\) threshold is increased to 80 GeV to ensure a uniform selection efficiency. There are also triggers that require the presence of two additional jets. In events selected by such triggers, the \(p_{\text{T}}\) threshold on the sub-leading \(b\)-jet is increased to 45 GeV.

The main sources of background are from top-quark, \(Z\)+jets, \(W\)+jets, diboson, single Higgs boson and multi-jet production. Depending on the source, the background contamination is estimated using data-driven or simulation-based techniques, or a combination of both. A reconstructed \(\tau_{\text{had-vis}}\) in these background events can originate either from a \(\tau_{\text{had}}\) decay (true-\(\tau_{\text{had-vis}}\)), or from a misidentified quark- or gluon-initiated jet (fake-\(\tau_{\text{had-vis}}\)). Processes that contribute the most to background events with fake-\(\tau_{\text{had-vis}}\) are \(t\bar{t}\) and multi-jet production. In \(t\bar{t}\) events, fake-\(\tau_{\text{had-vis}}\) typically originate from quark-initiated jets from the top-quark decay. In multi-jet events, both quark- and gluon-initiated jets are a source for fake-\(\tau_{\text{had-vis}}\) candidates. Simulated event samples are used to model background events containing true-\(\tau_{\text{had-vis}}\) and events with an electron or a muon misidentified as a \(\tau_{\text{had-vis}}\). Events with fake-\(\tau_{\text{had-vis}}\) in \(tt\) and multi-jet production are estimated from techniques relying on both simulated events and data. The modelling of events with fake-\(\tau_{\text{had-vis}}\) from the other smaller backgrounds is performed using simulation. The normalisations of simulated \(t\bar{t}\) and \(Z\)+HF backgrounds are determined from data in the likelihood fits of signal and control regions.

Dedicated multivariate discriminants are introduced in each SR to separate \(HH\) signal from background events. Variables which provide good discrimination and are minimally correlated are used as inputs to the training. The variables selected in each channel differ, reflecting the different background compositions. In the \(\tau_{\text{lep}}\tau_{\text{had}}\) SRs, neural networks (NNs) are used while a boosted decision tree (BDT) is used in the \(\tau_{\text{had}}\tau_{\text{had}}\) category.

The Run 2 analysis is mainly limited by statistical uncertainties on the data distributions in the SRs. Nonetheless, other sources of uncertainty are also taken into account. To account for the limited statistical precision of the simulated event samples, a simplified version of the Beeston-Barlow method [59] is used, in which only the combined uncertainty for all processes in a single bin is considered. In addition, both theoretical and experimental uncertainties are taken into account for the considered signal and background samples. Considered sources of theoretical uncertainty are the assumed Higgs boson branching ratios to \(b\)-quarks and \(\tau\) leptons [26], the top-quark mass scheme and missing higher-order QCD terms in the cross-section calculation, and uncertainties related to PDFs, \(\alpha_{s}\), and parton shower settings. The considered sources of experimental uncertainty are the various selection efficiencies for all included final-state objects, as well as uncertainties in the momentum scale and resolution estimation. Moreover, uncertainties on the measured integrated luminosity of the dataset as well as corrections of the pileup distributions are included. For signal distributions with \(\kappa_{\lambda}\neq 1\), additional uncertainties are considered to reflect possible differences between the reweighting method and simulation. Changes in the uncertainties on cross-section and detector acceptance depending on the assumed \(\kappa_{\lambda}\) value are also taken into account.

## 3 Extrapolation Procedure

The statistical framework based on the profile likelihood ratio [60] deployed for the Run 2 results [27; 28] is extended to assess the expected HL-LHC sensitivity to a SM (ggF + VBF) \(HH\) signal in the \(b\bar{b}\tau^{+}\tau^{-}\) final state. In general, the strategy of previous studies [25] is adopted. The extrapolation procedure takes into account the output of multivariate algorithms that are used as final discriminants for the signal extraction. The statistical framework is then employed to produce modified multivariate output distributions for signal and background representing an integrated luminosity of 3000 fb\({}^{-1}\) and intermediate target luminosities, under various extrapolation assumptions for the uncertainties. These distributions are further used to set upper limits on the signal strength applying the \(CL_{S}\) method [61]. The expected discovery significance assuming a SM \(HH\) signal and constraints to \(\kappa_{\lambda}\) are also presented.

The Run 2 distributions for signal and background are first scaled by a uniform multiplicative factor, defined as the ratio of the target luminosity of 3000 fb\({}^{-1}\) to the luminosity of the Run 2 result. The performance of the ATLAS detector in the HL-LHC era is expected to remain at least as good as that of Run 2. In particular, studies with an updated ATLAS Inner Tracker layout at the HL-LHC confirm a similar expected performance in the \(b\)-tagging efficiency [35].

The increase in centre-of-mass energy from \(\sqrt{s}=13\) TeV to \(\sqrt{s}=14\) TeV is accounted for by scaling the number of expected signal and background events by the ratio of the corresponding production cross-sections. The \(HH\) signal and the single-Higgs boson background cross-sections are all scaled following the recommendations from the LHC Higgs Working Group [24, 62]. For the remaining backgrounds, a factor of 1.18 is applied to account for the cross-section increase arising from the enhanced gluon-luminosity, following the same assumptions as in previous projections [25]. In the Run 2 analysis, the normalisation of simulated \(Z\)+HF backgrounds are determined from data in the likelihood fits, yielding factors depending on the assumed signal hypothesis. To reflect this, a representative normalisation factor of 1.37 is taken into account in the extrapolation procedure. The normalisation factor for \(t\bar{t}\) is consistent with unity, hence no additional scaling is applied for this process. Table 1 summarises the scaling factors for the SM \(HH\) signal and background processes.

In the Run 2 analysis, a simultaneous binned maximum-likelihood fit based on the MVA output distributions in the \(\tau_{\rm had}\tau_{\rm had}\), \(\tau_{\rm lep}\tau_{\rm had}\) SLT, and \(\tau_{\rm lep}\tau_{\rm had}\) LTT event categories, and on the \(m_{\ell\ell}\) distribution in the \(Z\)+HF CR. The \(t\bar{t}\) and \(Z\)+HF background normalisations are free parameters in the fit, and are primarily constrained by the \(Z\)+HF CR. Additionally, the background-like MVA output bins in the \(\tau_{\rm lep}\tau_{\rm had}\) SRs also help constrain the \(t\bar{t}\) normalisation. The uncertainty on the normalisations is incorporated in the fit as nuisance parameters for the \(Z\)+HF and the \(t\bar{t}\) backgrounds.

In the Run 2 analysis, the binning schemes for the MVA output distributions used in the likelihood fit were chosen to minimise the number of bins, while also maximising the retained expected sensitivity, and ensuring the stability of the fit and the validity of the asymptotic approximation [60]. The binning schemes start from finely-binned histograms, and bins are iteratively merged starting from the most signal-like MVA bins until the following channel-dependent criteria are fulfilled. In the \(\tau_{\rm had}\tau_{\rm had}\) channel, the bins are required to satisfy \(\sigma_{b}^{\rm MC}<0.5f_{s}+1\%\), where \(\sigma_{b}^{\rm MC}\) is the relative MC statistical uncertainty in the background estimate and \(f_{s}\) is the fraction of signal in the bin. In the \(\tau_{\rm lep}\tau_{\rm had}\) channel, the bins are required to satisfy \(10f_{s}+5f_{b}>1\), where \(f_{s}\) and \(f_{b}\) are the fractions of signal and background in the bin, respectively. Bins in all channels are required to contain at least 5 expected background events to ensure that the asymptotic approximation is valid. The binning criteria for the extrapolation are kept the same, but the binning itself changes due to the scaling of expected signal and background events. Therefore, the statistical sensitivity improves beyond what is expected from just an increase in cross-section and luminosity.

The systematic uncertainties are updated according to the latest baseline recommendations for HL-LHC projection studies [62]. All theoretical systematic uncertainties, as well as \(b\)-jet and \(c\)-jet tagging uncertainties, are reduced by a factor of two. For the light-jet tagging, the Run 2 uncertainties are

\begin{table}
\begin{tabular}{l c}
**Process** & **HL-LHC Scale Factor** \\ \hline \hline
**Signal** & \\ ggF \(HH\) & 1.18 \\ VBF \(HH\) & 1.19 \\ \hline
**Backgrounds** & \\ ggF \(H\) & 1.13 \\ VBF \(H\) & 1.13 \\ \(WH\) & 1.10 \\ \(ZH\) & 1.12 \\ \(ttH\) & 1.21 \\ Others & 1.18 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Summary of HL-LHC scale factors for the SM \(HH\) signal and background processes to account for the increase in centre-of-mass energy from \(\sqrt{s}=13\) TeV to \(\sqrt{s}=14\) TeV.

maintained. Uncertainties on \(\tau_{\text{had-vis}}\) selection efficiencies are removed when the statistical component dominates, and the uncertainties related to the \(\tau_{\text{had-vis}}\) energy scale calibration are kept at their Run 2 values. The fake-\(\tau_{\text{had-vis}}\) uncertainties are also kept unchanged with respect to their Run 2 values. For electrons and muons, the Run 2 uncertainties on the selection efficiencies are maintained. The same applies for the jet energy scale, the jet energy resolution and \(E_{\text{T}}^{\text{miss}}\). The uncertainty on the integrated luminosity of the full HL-LHC dataset is taken as 1%, corresponding to a reduction by 0.6 compared to its Run 2 value. The MC statistical uncertainties are neglected under the assumption that the statistics will increase significantly in line with the data luminosity, as assumed in previous studies [25]. Similarly, the uncertainty assigned to the \(\kappa_{\lambda}\) reweighting method is omitted in the baseline uncertainty scenario. This is based on the assumption that, with increased computing power, dedicated samples for different values of \(\kappa_{\lambda}\) can be produced in the future. Table 2 summarises the scaling factors for the relevant sources of systematic uncertainty as discussed above.

Finally, in addition to this baseline scenario, other extrapolation assumptions for the uncertainties are considered. In the most conservative scenario, all uncertainties are kept at their Run 2 values. To estimate the effect of the theoretical uncertainties reduction, a scenario with theory uncertainties scaled by a factor of 0.5 while keeping all other uncertainties at their Run 2 values is considered. Similarly, the impact of neglecting MC statistical uncertainties while keeping all other uncertainties unchanged with respect to Run 2 is also investigated. For the final and most optimistic extrapolation, all systematic uncertainties, including the MC statistical uncertainties, are neglected.

## 4 Results

In this section, the main results are presented for the combined fit over all regions. The SR distributions entering the fit are shown in Appendix A.

\begin{table}
\begin{tabular}{l c}
**Source** & **HL-LHC Scale Factor** \\ \hline \hline
**Experimental Uncertainties** & \\ \hline \hline Luminosity & 0.6 \\ \hline Electrons and muons efficiency & 1.0 \\ \hline \(b\)-jet tagging efficiency & 0.5 \\ \(c\)-jet tagging efficiency & 0.5 \\ Light-jet tagging efficiency & 1.0 \\ \(\tau_{\text{had-vis}}\) efficiency (statistical) & 0.0 \\ \(\tau_{\text{had-vis}}\) efficiency (systematic) & 1.0 \\ \(\tau_{\text{had-vis}}\) energy scale & 1.0 \\ Fake-\(\tau_{\text{had-vis}}\) estimation & 1.0 \\ Jet energy scale and resolution, \(E_{\text{T}}^{\text{miss}}\) & 1.0 \\ \(\kappa_{\lambda}\) reweighting & 0.0 \\ \hline \hline
**Theoretical Uncertainties** & 0.5 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Summary of HL-LHC scale factors for relevant systematic uncertainties defining the baseline scenario.

### \(Hh\) Signal Strength

Under the baseline HL-LHC uncertainty scenario and assuming SM kinematics for the signal, the extrapolation based on the full Run 2 dataset analysis leads to an upper limit on the \(HH\) signal strength at 95% CL of 0.71 times the SM prediction with respect to the background-only hypothesis. The previous extrapolation in this channel [25], which was based on the partial 36.1 fb\({}^{-1}\) Run 2 dataset [63], yielded a limit of 0.99 times the SM prediction. This constitutes an improvement of 28%, which can be attributed to updated reconstruction and identification algorithms, as well as analysis design methods. Similarly, the signal significance is now projected to be 2.8\(\sigma\) at the HL-LHC, while it reached 2.1\(\sigma\) in the previous extrapolation.

A summary of the SM signal strength limits for different uncertainty scenarios is given in Table 3. While the Run 2 analysis is mostly dominated by statistical uncertainties, the HL-LHC result is expected to depend more strongly on the understanding of systematic limitations, especially those on the theoretical predictions. Aside from the MC statistical uncertainties, which are expected to reduce over time, they are found to be the leading uncertainties in the projection results. Reducing them will become increasingly important for the sensitivity to \(HH\) production in the \(b\bar{b}\tau^{+}\tau^{-}\) channel. The following theoretical uncertainties were found to have the largest impact on the obtained signal strength limit in the baseline fit. The leading one is an ad-hoc uncertainty of 100% in the Run 2 analysis and 50% in the baseline uncertainty scenario, assigned to the ggF production of single Higgs bosons. It is introduced to account for the difficulty in modelling this process in association with jets initiated by \(b\) or \(c\) quarks. The sub-leading uncertainty is the detector acceptance uncertainty of single top-quark production related to the interference between the \(Wt\) and \(t\bar{t}\) processes. The third leading uncertainty is the uncertainty on the ggF \(HH\) production cross-section arising from variations of the QCD scales and the top-quark mass scheme.

Figure 1 presents the SM \(HH\) production signal strength limits at 95% CL and signal significance as a function of the integrated luminosity for different uncertainty scenarios. The integrated luminosity spans from 1000 fb\({}^{-1}\) to 3000 fb\({}^{-1}\) at \(\sqrt{s}=14\) TeV.

### Constraints on \(\kappa_{\lambda}\)

Two different approaches to constrain \(\kappa_{\lambda}\) are presented in the following. For both of them, all Higgs boson couplings except for the trilinear self-coupling are assumed to be SM-like. The first method is a scan of the cross-section limits, repeating the procedure employed for the SM result quoted in the previous section. The 95% CL limit at each investigated \(\kappa_{\lambda}\) value is compared to the \(\kappa_{\lambda}\)-dependent theoretical prediction of

\begin{table}
\begin{tabular}{c|c|c|c} \hline \hline Uncertainty Scenario & 95\% CL Upper Limit & Significance [\(\sigma\)] & Signal Strength Precision \\ \hline No syst. unc. & 0.49 & 4.0 & 0.27 \\ Baseline & 0.71 & 2.8 & 0.39 \\ Run 2 syst. unc. & 1.37 & 1.5 & 0.69 \\ MC stat. unc. neglected & 0.99 & 2.2 & 0.51 \\ Theoretical unc. halved & 1.07 & 1.7 & 0.58 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Comparison of the projected 95% CL upper limits on the \(HH\) production signal strength, the signal significance and the signal strength precision for different uncertainty scenarios at an integrated luminosity of 3000 fb\({}^{-1}\), assuming SM kinematics for the signal.

the total \(HH\) production cross-section [17] to define the constraints on \(\kappa_{\lambda}\), comparing each \(\kappa_{\lambda}\) hypothesis to the background-only hypothesis.

The results of this cross-section scan are shown in Figure 2 for the baseline uncertainty scenario, and the obtained 95% CL constraints on \(\kappa_{\lambda}\) are summarised in Table 4 for all considered scenarios. The minimum of the cross-section limit for \(\kappa_{\lambda}\approx 2\) is due to an increase in the average \(m_{HH}\) value. The destructive interference in the ggF process reduces the contribution from events in the low region of the \(m_{HH}\) spectrum, thus increasing the signal acceptance and selection efficiency [28]. Therefore, given a similar upper limit on the number of measured signal events in the signal-enriched bins of the MVA classifier distributions, the cross-section limit is lower in this region.

Using the baseline uncertainty scenario, the predicted 95% CL constraint on \(\kappa_{\lambda}\) is \([1.7,5.4]\). The \(\kappa_{\lambda}\) values outside of this interval are expected to be excluded at 95% CL by the HL-LHC measurement in the \(b\bar{b}\tau^{+}\tau^{-}\) channel if they are not realised in nature. In particular, the SM prediction of \(\kappa_{\lambda}=1\) can be excluded under the background-only hypothesis.

Additionally, the signal significance above the background-only hypothesis in dependence of \(\kappa_{\lambda}\) is shown in Figure 3. Under the baseline uncertainty scenario, evidence (\(>3\sigma\)) for \(HH\) production can be found at the

\begin{table}
\begin{tabular}{c c} \hline \hline Uncertainty Scenario & Cross-Section Scan 95\% CL Constraints \\ \hline No syst. unc. & \([2.4,4.5]\) \\ Baseline & \([1.7,5.4]\) \\ Run 2 syst. unc. & \([0.6,6.5]\) \\ MC stat. unc. neglected & \([1.3,5.9]\) \\ Theoretical unc. halved & \([0.9,6.2]\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Projected 95% CL constraints on \(\kappa_{\lambda}\) for different uncertainty scenarios at an integrated luminosity of 3000 fb\({}^{-1}\). The constraints are obtained from cross-section scans comparing different \(\kappa_{\lambda}\) signal hypotheses to the background-only hypothesis.

Figure 1: Expected 95% CL upper limit on the \(HH\) production signal strength (a) and signal significance (b) as a function of the integrated luminosity between 1000 fb\({}^{-1}\) and 3000 fb\({}^{-1}\) for different uncertainty scenarios.

HL-LHC if \(\kappa_{\lambda}<0.8\) or \(\kappa_{\lambda}>6.3\). If \(\kappa_{\lambda}<-0.6\) or \(\kappa_{\lambda}>7.8\), \(HH\) production can be observed (\(>5\sigma\)).

The sensitivity to \(\kappa_{\lambda}\) is also assessed from direct likelihood scans. The shapes and normalisations of the \(HH\) signal distributions, as well as the normalisations of the single Higgs boson production background distributions, are parameterised in dependence of \(\kappa_{\lambda}\) following the method described in Refs. [64, 65]. In order to allow for shape variations of the signal with \(\kappa_{\lambda}\), signal templates for three different \(\kappa_{\lambda}\) values are included in the fit. The chosen templates are \(\kappa_{\lambda}=0,1,20\) for ggF \(HH\) and \(\kappa_{\lambda}=1,2,10\) for VBF \(HH\). These are combined to obtain signal distributions for arbitrary values of \(\kappa_{\lambda}\), using the same linear combination method as that employed for deriving the weights of the signal \(\kappa_{\lambda}\) reweighting method [54] described in Section 2. In the likelihood scans, the signal and background predictions assuming different \(\kappa_{\lambda}\) hypotheses are compared to an Asimov dataset [60] constructed under the SM hypothesis of \(\kappa_{\lambda}=1\).

Figure 3: Projected signal significance above the background-only hypothesis as a function of \(\kappa_{\lambda}\) for different uncertainty scenarios at an integrated luminosity of 3000 fb\({}^{-1}\). The vertical line indicates the SM hypothesis of \(\kappa_{\lambda}=1\).

Figure 2: Projected 95% CL upper limit on the non-resonant \(HH\) production cross-section as a function of \(\kappa_{\lambda}\) when compared to the background-only hypothesis, assuming the baseline uncertainty scenario and an integrated luminosity of 3000 fb\({}^{-1}\).

The results of the likelihood scan for different uncertainty scenarios are shown in Figure 4(a). Aside from the minimum at \(\kappa_{\lambda}=1\), which appears by design of the scan, the likelihood curves feature a second minimum at \(\kappa_{\lambda}\approx 6\). This is due to an increase in the \(HH\) production cross-section and a simultaneous decrease in signal acceptance and selection efficiency for \(\kappa_{\lambda}\approx 6\) compared to \(\kappa_{\lambda}=1\), leading to similar signal yields in the signal-enriched bins of the MVA classifier distributions in these cases.

A summary of the \(1\sigma\) and \(2\sigma\) confidence intervals (CIs) on \(\kappa_{\lambda}\) obtained from the likelihood scans is given in Table 5. While the cross-section scan tests the sensitivity to \(HH\) production assuming individual \(\kappa_{\lambda}\) values, the likelihood scan quantifies the separation power between the hypotheses \(\kappa_{\lambda}=1\) and \(\kappa_{\lambda}\neq 1\). Assuming the baseline uncertainty scenario and an observed value of \(\kappa_{\lambda}=1\), the \(b\bar{b}\tau^{+}\tau^{-}\) channel is projected to be able to constrain \(\kappa_{\lambda}\) to the \(1\sigma\) CI \([0.3,1.9]\cup[5.2,6.7]\) at the HL-LHC. Compared to the interval obtained in the previous projection, the size of the extrapolated \(1\sigma\) CI is improved by \(28\%\). To demonstrate the sensitivity to \(\kappa_{\lambda}\) in the \(\tau_{\text{lep}}\tau_{\text{had}}\) and \(\tau_{\text{had}}\tau_{\text{had}}\) channels, likelihood scans including only the respective signal regions of each channel have been performed, assuming the baseline uncertainty scenario. The results are shown in Figure 4(b). Using only the \(\tau_{\text{lep}}\tau_{\text{had}}\) signal regions, a \(1\sigma\) CI of \(\kappa_{\lambda}\in[-0.4,7.8]\) is obtained, while for the \(\tau_{\text{had}}\tau_{\text{had}}\) channel the result is \(\kappa_{\lambda}\in[0.2,2.0]\cup[5.1,6.8]\).

Additional likelihood scans to assess the sensitivity to \(\kappa_{\lambda}\) assuming a true value of \(\kappa_{\lambda}=0\) are presented in Appendix B.

Figure 4: Negative logarithm of the likelihood ratio comparing different \(\kappa_{\lambda}\) hypotheses to an Asimov dataset constructed under the SM hypothesis of \(\kappa_{\lambda}=1\). Figure (a) shows a comparison of the sensitivity to \(\kappa_{\lambda}\) under different uncertainty scenarios in the combined fit over all analysis regions. Figure (b) compares the sensitivity of the combined fit to the fits in individual channels, assuming the baseline uncertainty scenario.

## 5 Conclusion

The HL-LHC will allow to study processes with small cross-sections, such as \(HH\) production, in greater detail. This note presents a projection of the current sensitivity to the \(HH\) production rate and the self-coupling modifier \(\kappa_{\lambda}\) in the \(b\bar{b}\tau^{+}\tau^{-}\) decay channel. Under the baseline uncertainty scenario and assuming SM kinematics for the signal, the 95% CL upper limit on the \(HH\) signal strength is projected to be at 0.71 times the SM prediction with respect to the background-only hypothesis assuming an integrated luminosity of \(3000\,\mathrm{fb}^{-1}\) and \(\sqrt{s}=14\) TeV. The signal significance is extrapolated to \(2.8\sigma\), and assuming a true value of \(\kappa_{\lambda}=1\), the self-coupling modifier is constrained to the \(1\sigma\) CI \([0.3,1.9]\cup[5.2,6.7]\). If no \(HH\) signal is found at the HL-LHC, the value of \(\kappa_{\lambda}\) is expected to be constrained to \([1.7,5.4]\) at 95% CL.

The results present a clear improvement with respect to previous HL-LHC projection studies in this channel. This is mainly due to improved object reconstruction and identification as well as the overall design of the analysis. Finding evidence for \(HH\) production in the \(b\bar{b}\tau^{+}\tau^{-}\) decay channel at the HL-LHC is an achievable goal, considering the large expected dataset together with the ATLAS detector upgrades that are designed to mitigate the effects of increased pileup. The main limitations to the sensitivity are then found to stem from theoretical uncertainties and the limited size of simulated event samples.

\begin{table}
\begin{tabular}{c c c} \hline \hline Uncertainty Scenario & Likelihood Scan \(1\sigma\) CI & Likelihood Scan \(2\sigma\) CI \\ \hline No syst. unc. & \([0.5,1.6]\) & \([0.1,2.5]\cup[4.5,6.5]\) \\ Baseline & \([0.3,1.9]\cup[5.2,6.7]\) & \([-0.3,7.4]\) \\ Run 2 syst. unc. & \([-0.2,7.3]\) & \([-1.2,8.3]\) \\ MC stat. unc. neglected & \([0.0,2.2]\cup[4.9,7.1]\) & \([-0.8,8.0]\) \\ Theoretical unc. halved & \([0.0,2.9]\cup[4.2,7.1]\) & \([-0.8,7.9]\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Projected \(1\sigma\) and \(2\sigma\) CIs on \(\kappa_{\lambda}\) for different uncertainty scenarios at an integrated luminosity of \(3000\) fb\({}^{-1}\). The limits are obtained from the likelihood scans comparing different \(\kappa_{\lambda}\) signal hypotheses to the SM hypothesis \(\kappa_{\lambda}=1\).

[MISSING_PAGE_EMPTY:13]

[MISSING_PAGE_FAIL:14]

## References

* [1] ATLAS Collaboration, _Observation of a new particle in the search for the Standard Model Higgs boson with the ATLAS detector at the LHC_, Phys. Lett. B **716** (2012) 1, arXiv: 1207.7214 [hep-ex] (cit. on p. 2).
* [2] CMS Collaboration, _Observation of a new boson at a mass of 125 GeV with the CMS experiment at the LHC_, Phys. Lett. B **716** (2012) 30, arXiv: 1207.7235 [hep-ex] (cit. on p. 2).
* [3] ATLAS Collaboration, _Measurements of Higgs boson production and couplings in diboson final states with the ATLAS detector at the LHC_, Phys. Lett. B **726** (2013) 88, arXiv: 1307.1427 [hep-ex] (cit. on p. 2).
* [4] ATLAS Collaboration, _Study of the spin and parity of the Higgs boson in diboson decays with the ATLAS detector_, Eur. Phys. J. C **75** (2015) 476, arXiv: 1506.05669 [hep-ex] (cit. on p. 2).
* [5] CMS Collaboration, _Evidence for the direct decay of the \(125\) GeV Higgs boson to fermions_, Nature Phys. **10** (2014) 557, arXiv: 1401.6527 [hep-ex] (cit. on p. 2).
* [6] CMS Collaboration, _Measurement of the properties of a Higgs boson in the four-lepton final state_, Phys. Rev. D **89** (2014) 092007, arXiv: 1312.5353 [hep-ex] (cit. on p. 2).
* [7] CMS Collaboration, _Measurement of Higgs boson production and properties in the \(WW\) decay channel with leptonic final states_, JHEP **01** (2014) 096, arXiv: 1312.1129 [hep-ex] (cit. on p. 2).
* [8] F. Englert and R. Brout, _Broken Symmetry and the Mass of Gauge Vector Mesons_, Phys. Rev. Lett. **13** (1964) 321 (cit. on p. 2).
* [9] P. Higgs, _Broken symmetries, massless particles and gauge fields_, Physics Letters **12** (1964) 132 (cit. on p. 2).
* [10] P. W. Higgs, _Broken Symmetries and the Masses of Gauge Bosons_, Phys. Rev. Lett. **13** (1964) 508 (cit. on p. 2).
* [11] P. W. Higgs, _Spontaneous Symmetry Breakdown without Massless Bosons_, Phys. Rev. **145** (1966) 1156 (cit. on p. 2).
* [12] G. S. Guralnik, C. R. Hagen and T. W. B. Kibble, _Global Conservation Laws and Massless Particles_, Phys. Rev. Lett. **13** (1964) 585 (cit. on p. 2).
* [13] T. W. B. Kibble, _Symmetry Breaking in Non-Abelian Gauge Theories_, Phys. Rev. **155** (1967) 1554 (cit. on p. 2).
* [14] B. D. Micco, M. Gouzevitch, J. Mazzitelli and C. Vernieri, _Higgs boson potential at colliders: Status and perspectives_, Reviews in Physics **5** (2020) 100045, issn: 2405-4283, url: [https://www.sciencedirect.com/science/article/pii/S2405428320300083](https://www.sciencedirect.com/science/article/pii/S2405428320300083) (cit. on p. 2).
* [15] D. Y. Shao, C. S. Li, H. T. Li and J. Wang, _Threshold resummation effects in Higgs boson pair production at the LHC_, JHEP **07** (2013) 169, arXiv: 1301.1245 [hep-ph] (cit. on p. 2).
* [16] D. de Florian and J. Mazzitelli, _Higgs pair production at next-to-next-to-leading logarithmic accuracy at the LHC_, JHEP **09** (2015) 053, arXiv: 1505.07122 [hep-ph] (cit. on p. 2).
* [17] M. Grazzini et al., _Higgs boson pair production at NNLO with top quark mass effects_, JHEP **05** (2018) 059, arXiv: 1803.02463 [hep-ph] (cit. on pp. 2, 9).
* [18] J. Baglio et al., _\(gg\to HH\) : Combined uncertainties_, Phys. Rev. D **103** (2021) 056002, arXiv: 2008.11626 [hep-ph] (cit. on p. 2).