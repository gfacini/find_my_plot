###### Abstract

A design for part of the second level of a three level trigger scheme for ATLAS is described. The units needed to provide the system are discussed and plans for demonstrations summarised.

**ATLAS Internal Note DAQ-NOTE-21**

**30 November 1994**

**Local processing for a farm-based second level trigger at LHC**

John Strong

Royal Holloway, University of London

Egham, Surrey TW20 0EX, UK

## 1 Introduction

The trigger systems for experiments at the Large Hadron Collider (LHC) must meet the challenge of reducing an initial interaction rate of up to \(10^{9}\) Hz to a rate which can be written to storage media for off-line analysis. For the ATLAS experiment [1] it is proposed to use a three stage trigger system. Simulation work indicates that the first level trigger should provide a rate reduction to about 40 kHz. The design goal for the second level is to accept an input rate of at least \(10^{5}\) Hz and reduce this to \(10^{3}\) or less.

## 2 The second level trigger

The second level trigger must retain all 'interesting' physics events and those required for calibration, while rejecting the rump of the high-rate processes which pass the first level. Events passed to the second level will closely resemble good triggers and can only be rejected by performing analyses not possible at level 1.

Second level trigger processing may be divided into several stages. Data for analysis must be moved to a processor and then analysed to produce features (e.g. tracks parameters). Related features from different sub-detectors (e.g. a track and a calorimeter cluster) can then be combined and finally information from different areas of the detector evaluated to provide an overall decision. Because it operates on a limited volume of the data, feature extraction is a local operation and global data access is not required.

Considerable benefits in data transfer and processing rates arise if information from the first trigger level can be used to guide level two. Only data from regions of interest (RoIs) in sub-detectors need be moved and processed. The first level trigger can provide these pointers by indicating the position of all significant energy deposits in the calorimeter and high energy tracks in the muon chambers.

In ATLAS, data will be moved to buffers off the detector after the first level trigger. The latency of the second level trigger is determined by the capacity of these buffers which must hold the data during the level two decision time. It is estimated that a total buffer capacity of 1 GB will be needed for each millisecond of latency at a Level 1 rate of 100 kHz. Latency of a few milliseconds is, therefore, not a problem.

## 3 Local and global processing

A latency of several milliseconds means that programmable devices can be considered as the processing units in a second level trigger. The trigger discussed here is based on a continuation of the work on a local/global architecture described at the Aachen workshop on LHC [2]. Features extraction is performed in the local part of the architecture and feature combining and topological assessment is performed in the global area.

It is assumed that digitised data from the front-end electronics arrives at the second level buffers (T2 buffers) on links operating at about 1 Gbit/s to limit the number of buffers. For a buffer with 1 MB of memory about one thousand events can be stored which allows a second level latency of up to 10 ms.

The information from one sub-detector is spread across many buffers but the data corresponding to one RoI is limited to only a few. For a calorimeter with three electromagnetic layers of granularity 0.025 by 0.025 (\(\Delta\eta,\,\Delta\phi\)) and four hadronic layers of 0.05 by 0.05, with data from 324 (18x18) cells connected to one buffer, the data for a RoI would spread over four buffers in each layer at most (see Fig. 1)

For feature extraction the RoI data from all layers must be collected into one processor and the network shown in Fig. 1 is sufficient for this task. One link unit concentrates the data from one tower and another provides the mesh connection which routes the data to the appropriate feature extractor (FeX).

Table 1 shows the basic parameters for a calorimeter, table 2 gives the trigger rates and table 3 the rates at various points in the system for the architecture shown in Fig. 1.

\begin{table}
\begin{tabular}{|l|l|} \hline calorimeter & 252x252 cells/layer \\ e.m.cell size & 0.0249x0.0238 \\ e.m. layers & 3 \\ hadronic layers & 4 \\ T1 cell size & 4x4 e.m. cells \\ trigger cells & 3969 \\ buffer coverage & 324 (18x18) cells \\ buffers & 784 (4x196) \\ crates (T2bc) & 49 (784/16) \\ \hline \end{tabular}
\end{table}
Table 1: Basic calorimeter parameters

Figure 1: Local processor network for a calorimeter

An estimate, using a simplified monte carlo, of the number of RoIs from the Level 1 trigger gives a mean value of about two [3]. However, five RoIs is used to provide a reasonable safety margin.

An estimate, using a simplified monte carlo, of the number of RoIs from the Level 1 trigger gives a mean value of about two [3]. However, five RoIs is used to provide a reasonable safety margin.

This arrangement where it is assumed that each FeX is a small processor farm.

## 4 Demonstrations

Based on a commercial board using the TMS320C40 DSP, a T2 buffer with 100 MB/s data input acceptance has been built and tested. It will be used this summer in a test beam at CERN as part of a minimal test of the architecture described above. The link unit and feature extractors will be similar DSPs. The global network wil consist of a small SCI ring and Alpha single board computers. The results obtained will allow comparison with modelling studies [4] and the development of modelling techniques.

## 5 References

[1]. ATLAS Letter of Intent. CERN/LHCC 92-4

[2]. D. Crosetto et al.: A local/global architecture for level 2 calorimeter triggers. LHC Workshop, Aachen, 1990

[3]. D. Johnson and J. Strong.: A study of a calorimeter based trigger system using single electron and two jet events. ATLAS CAL-NO-030 October 1993

[4]. Z. Hajduk et al. : Modelling of local / global architectures for the second level trigger at the LHC experiment. Proc. of this conference.

\begin{table}
\begin{tabular}{|l|l|} \hline between routers & 3.5 MB/s/link \\ into FeX & 14 MB/s \\ FeX event rate & 10.2 kHz \\ Link units & 294 \\ Link boards & 74 (49 in T2bc) \\ FeX (farms) & 49 \\ FeX boards & 49 \\ Crates & 4 \\ \hline \end{tabular}
\end{table}
Table 4: Rates for Fig. 2

\begin{table}
\begin{tabular}{|l|l|} \hline from T2 buffer & \(\sim\)1 MB/s \\ into FeX & \(\sim\)3.5 MB/s \\ FeX event rate & 2.6 kHz \\ Link units & 392 \\ Link boards & 98 (49 in T2bc) \\ FeX (farms) & 196 \\ FeX boards & 98 \\ Crates & 8 \\ \hline \end{tabular}
\end{table}
Table 3: Rates for Fig 1.

Figure 2: Local processor network with added stage of data concentration