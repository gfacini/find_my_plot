Improving Inspections

Rosemary Candlin, _Edinburg University_

1 March 1996

## 1 Introduction

These thoughts have arisen from reading two books -- "Software Inspection" by Tom Gilb and Dorothy Graham [1], and, to a lesser extent 'A Discipline of Software Engineering" by Watts Humphrey [2]. In each case, they propose a method for improving the process of software development, so that, over time, better quality code is produced more quickly. More information and discussion of the same topic can be found on the Web under the heading of "Formal Technical Reviews" [3]. We have had a certain amount of practical experience in the MOOSE project, but this has been confined to code inspections. The purpose of this note is to evaluate our inspection procedures against the recommendations in Gilb and Graham (which are also largely those followed by some major firms who have put up information on the Web).

The Gilb and Graham book seems to be directed at _groups_ who want to introduce inspections into their software development process. It is probably aimed largely at the group leader, since management backing is essential for success. The book describes the reasons for introducing inspections (or, as they put it, Inspection) into an organization. The authors provide detailed descriptions of the phases of an inspection, the documents that are required, the roles of the various people involved, and the actions to be taken. There are also several quite detailed case studies of the experience of introducing inspections in various firms.

The authors make the point strongly that _everything_ should be inspected: requirements specifications, designs and user documentation, as well as code. In fact the greatest benefits are obtained by inspecting the "upstream" documents, and when this is working well, very few faults are found in the code. Inspections work on two levels. Firstly and obviously, the document being inspected is improved in quality. But beyond that, data obtained from an inspection can be used to improve the whole _process_ of software development (or of any other product, come to that). For example, statistics of the types of faults that are found can suggest reasons why certain faults occur, and indicate improvements like better training for programmers or clearer documentation. The benefits of a quantitative approach are felt over a period of time: better estimates of development costs can be made, resulting in better planning and control of the current and future projects.

The Humphrey book has a different intention: it is aimed at the _individual_ software engineer who wantsto upgrade his personal skills, and who might be working in an environment where nobody necessarily takes much interest in anything except the finished product. However, much, if not most, of this material is relevant for group working. There are some quite useful suggestions, like design notations or checklists for finding programming faults. The control of the software development process is more formally statistical than in Gilb and Graham, and is probably only appropriate in the context of an organization where a dedicated, long term quality control group exists.

## 2 Benefits

Gilb and Graham give quite a lot of statistics to support the benefits to be expected from systematic inspections. Roughly, one might expect a reduction in development time of 2550%, including the time spent on inspections. For code that has been successfully compiled but not run, fault detection at inspection varies from 50-80% of faults. The rest were found at testing or during running. They estimate that the time taken to find a fault during inspection, testing and operation is in the ratio of approximately 1: 10: 100.

They also make the point that it is not possible to run tests on documents produced in the early stages of the software development process, like test plans and designs. Inspection is thus particularly valuable in ensuring that defects do not get propagated to downstream documents where they are more difficult to detect and require more time to correct.

## 3 The Inspection Process

The Inspection Process recognizes five distinct steps discussed below.

### Entry

The input to an inspection is at least one source document and a product document, and rules which are to be used to check that the product is consistent with the source. The source document and the rules will have been previously used by the developer in the course of implementing the product. There are _entry criteria_ to be satisfied before an inspection can begin: the source document(s) must have successfully "exited" an inspection, and the product document must look as though it is in a fit state to be inspected, as determined by a quick evaluation from the _inspection leader_. The first criterion is to ensure that mistakes don't get propagated further; the second is to avoid wasting inspectors' time.

I think our code inspection was deficient at this point. We did not have a "source document" to check against, so we did not know what the code was _supposed_ to do. Our checking was therefore primarily devoted to looking at internal consistency, with an implicit assumption that inspectors knew what the application was all about and could therefore check whether the code was correct. However, it was not easy to go from an overview understanding of the aims of the software down to the details of a particular piece of programming. I think this may have been why we found rather few major errors: we didn't have any kind of design specification to check against.

Also, the quality of the documents we were supplied with left something to be desired. We would have saved quite a bit of time if the product document had been sent back to the author to check that it was consistent with the style rules before submitting it for inspection.

**Suggested Action.** Produce design specification in some appropriate notation as quickly as possible. Pay attention to the quality of all documents required for an inspection, and postpone the inspection until all the input is considered to be acceptable.

### Checking

It is not necessary that all inspectors check for the same faults -- it may help to have different inspectors looking at different aspects of the document ("specialized inspections"). For example, one inspector may look for errors in loops, while another checks that comments include information according to the style rules. Experience will show what are cost-effective ways of dividing up the work (whether it is worth having several inspectors checking the same thing, for example).

It will usually be helpful to provide a checklist of faults to look for. These are fairly obvious for code inspections (Humphrey provides a list for C++ programs): non-terminating loops, incorrect parameters for a function call, dangling pointers, overflow risks etc.

Gilb and Graham quote statistics that show that the optimum rate of checking is about a page an hour (yes, they say that everybody is surprised)! This does not mean that an inspector spends an hour just looking at a page. Time must be allowed for inspectors to read and understand the source documents and rule sets,and perhaps to read some background references that set the product document in context.Experience shows that the rate of finding defects falls off for large documents.

Our own experience suggests that we tried to do too much too quickly. Inspectors should concentrate on finding major faults, which are violations of the source document or which would cause run-time failure, and not spend too much time on minor faults. We, on the other hand, found mostly minor faults, like violations of the style rules dealing with naming conventions or spelling mistakes in comments. Since all inspectors tended to notice the same faults, the overall use of inspectors' time seems rather poor.

**Suggested Action**. Consider providing a checklist, and give the responsibility of checking individual items to specific inspectors. Have more frequent inspections with smaller documents. And provide source documents to check the product against!

### Exit

It is not expected that perfection will be achieved at the end of an inspection, but it should be possible (based on the inspection metrics) to judge the quality of an inspection. Things which should arouse suspicion are: too fast a rate of checking, too high a ratio of minor to major faults, or differences between the reporting rates of different checkers. Reasonable values for these metrics should become available as the project proceeds (for the first iteration, historic data will have to be used, for example, taken from this book). An estimate of remaining faults should be made for the exited document. This gives an indication of the error rate to be expected downstream.

**Suggested Action**. We should be able to do this with the metrics we currently collect. We need to be able to track changes as our inspection procedure develops over time.

### After the Inspection

The procedure of fixing up the document is more or less what we do. The inspection leader passes over the complete list of issues that have been raised by the inspectors. These may be genuine faults or queries that the inspectors feel should be clarified. The inspection leader has to be satisfied that all points will be dealt with satisfactorily. It may be that one or more errors are shown up in the _source documents_. In a formal environment this involves a "change request" to whoever is responsible for the source, but there may be wider repercussions. For example, a code inspection may throw up an error in the design specification, but this may have arisen because of a contradiction in the requirements specification.

**Suggested Action**. Our post- inspection procedure seems to conform fairly closely to that recommended. However, we have encountered occasional problems where it has not been possible to resolve a disagreement between the author and an inspector. We also need to set up a procedure for modifying existing documents, checking for consistency in updating, and informing interested parties about the changes. This is all a question of overall project management which should be addressed at some point.

### Brainstorming

This is seen as a short meeting following the logging meeting. In our context, it would be carried out by email correspondence over a period of perhaps a day. Anyone involved in an inspection can make a suggestion for improving the _inspection process_, not the inspection product, based on their own experience, or on statistics of frequent faults. This may be an addition or clarification of a rule, a new item on a checklist, a different format or notation for a source document, a different amount of work to check etc etc. Rules may also be dropped if they turn out to be unnecessary or inappropriate.

**Suggested Action**. It would be useful to do this. I have no doubt that people would be very free with their opinions, and the difficulty would be to adjudicate between them. It would be necessary to ensure that suitable action was taken after the suggestions had been accepted. This is probably a case where we would need some management structure, with decisions vested in some particular person to ensure that accepted proposals are carried through.

## 4 Roles

The roles people play are pretty similar to what we are used to, except that what we have been used to thinking of as the "moderator" (the original IBM title) now becomes the very much more powerful and crucial figure of the "Inspection Leader". Glib and Graham devote 81 pages to describing what this character has to do! I will just mention some of the things that are involved.

* The IL must be formally trained and certified. (How is this done? By going to a 5-day training course run by Tom Gilb). Once inspection is established in a company, existing inspection leaders can take responsibility for training new ones.
* The IL has an important management role in controlling the actual operation of the inspection. He does not initiate it, but he decides if a document is ready to be inspected, selects the inspectors and controls the overall timing. He also has to generate enthusiasm and makes sure that everyone has a say, but not too much.
* The IL is responsible for choosing appropriate source documents for a particular inspection. He may construct specific checklists (not necessarily the same for each checker, if checkers are assigned specialized roles). He divides up the work into suitable chunks and allocates it to the checkers.
* The IL sets objectives (eg type of faults, checking rates) and ensures that checkers achieve them. He obtains metrics of the inspection process.
* The IL conducts the "brainstorming" meeting and takes action to implement accepted improvements.

?From this, it can be seen that a great deal of the success of inspections in general hangs on the inspection leader, who must not only be technically qualified, but also be powerful enough to make decisions affecting others in the group who are not not necessarily themselves involved in, or sympathetic to, inspections. It is therefore important to have management backing, and it is recommended that there should be short educational sessions to inform managers of the benefits of systematic inspection.

**Suggested Action**. None. This is for the future-- we need more experience ourselves before we can do much about overall management issues.

## 5 Problems

Traditionally, inspections are carried out in face-to-face meetings with the author present.

Certain problems are likely to arise and require firmnessandtacton the part of the inspection leader

* the author feels threatened and gets upset
* some inspectors hog the proceedings
* inspectors may feel they are under evaluation by more senior members of the group
* discussion gets off the point and the meeting drags on

These problems are non-existent, or greatly reduced with our conventions. Inspections are carried out anonymously by email, and the inspectors are decoupled from each other and from the author. The only disadvantage as far as I can see, is that we do not find the extra defects that may only occur to inspectors actually during a meeting (it is estimated that these may account for about 10 % of the total).

The more serious problem is the question of why, in spite of all its vaunted benefits, companies give up on inspection. This seems to be for two reasons. First, inspections aren't carried out correctly and they seem to be a lot of overhead for little or no benefit. Second, management may be unsupportive. The case studies all show that there has to be an enthusiast (a "champion") with real power to arrange training, allow time for organizing inspections and to give tangible credit to those participating. There is a discussion under FAQs on [3] which throws some light on these problems.

## 6 Where does OO come in?

There is nothing specifically OO in any of this: in principle, these techniques could be applied with any software development method, although I think it is implicit that software must proceed in definite stages, with the input to a given stage coming from the output of the previous stage. Backtracking is clearly envisaged, since there is the possibilty of having to edit source documents as the result of an inspection.

## 7 Documents for Code Inspection

This is not a proposal for how things should be done in the future: it is a retrospective suggestion for what we might have done at our previous inspections of Eiffel code. The reason for putting more work into what looks like wasted effort (because that code is likely to be superseded) is that we have a concrete, rather than a hypothetical, situation. Many of us have been through the "inspection experience"; we know what we found difficult in this particular case, and are therefore in a better position to evaluate changes in procedure. However, I would hope that we would be able to generalize from our particular experience and build on it in the future. Most of the ideas in this section have been taken from Gilb and Graham [1].

Why do we want to have inspections at all? There is no point in having them if they just make extra work, but the experience in many serious, money-making organizations is that inspection saves both time and money, because it enables code of a given quality to be produced more quickly. In our context, we should not actually lose money if someone had to find a fault at run-time in a supposedly correct program, but it would be a severe hold-up and waste of someone's time. However, benefits are only obtained with _efficient_ inspection procedures, and, as I suggested above, I am not entirely convinced that our inspections make good use of inspectors' time.

Experience from industry suggests that it is much more cost-effective to inspect documents early in the life cycle than to inspect code. However, we are familiar with what is involved in code inspections so, for us, it seems a good idea to start from there, and to think how we could do it more effectively. I have suggested above some changes in procedure that would be helpful, but what I want to concentrate on in this section is the input data to the checking phase.

I think we might work backwards. We know that we must end up with code, and we now have some feeling for what a code inspection involves. We could start by working out what input documents would have been useful. For example, I would have liked to see information like the following for each function or routine: explanation of the role of the parameters, precondition, what the function does and the post-condition. In addition, I want to know what is supposed to happen if the precondition is not satisfied, or if there is some invalid input during execution. All these are things that should be decided before writing the code and would be the output of a previous design step. If we had had this information we would have had something definite check the code against.

We can go back another step and think where this source document would come from. It could not be produced until the class interfaces had been defined. We would also need some document describing policies about error handling. If we worked backwards in this way, we could make sensible choices about notation, because it would probably turn out that some were more convenient than others from the point of view of checking the documents downstream.

To simplify the problem, I assume that code inspection will deal with a set of class definitions (as was actually the case for our own inspections), not with more complicated programs written using class objects. So any individual inspector will be provided with the source code for a set of classes to be checked, more or less in isolation. The "more or less" is in fact one of the problems, because a method in one class may refer to objects of classes which are not in the current inspection, and chasing after the extra definitions is one of the good ways of ading to an inspector's burden.

I also assume some things about the inspectors. They will be familiar with the programming language, at least at the reading level, but will not necessarily be familiar with the rationale for the design. They therefore need to be explicitly provided with enough information to check that the proposed classes satisfy the design objectives. It saves everyone's time if this information is assembled by one person, before the inspection starts, in one or more documents that are handy for subsequent checking.

I now want to make some suggestions about the "source documents" for a code inspection. "Source" in this case means the documents which define the properties which the "product" must have (in this case the "product" is in fact "source code"--confusingly). These document(s) will be derived from the output of one or more preceding stages in the design process. Ideally, they should themselves have been inspected, but since we are working backwards, we shall have to make do with what may be rather poor quality input. We have to realise that the code inspection may throw up errors in the source as well as the product.

## 8 Information Required By Inspectors

We need some sort of life cycle model, so that we can see outputs from one phase feeding into the next, and I think we will have to be a bit more formal about this at some time in the future. I think the traditional,rather coarse, breakdown into architectural and detailed design is unlikely to be helpful, and I have just invented a few phases for the purpose of this exercise, so that I can see where the data that I want for checking code is going to come from.

More work obviously needs to be done on defining a suitable software development sequence for our own situation.

1. **User Requirements Definition** These state what the user wants from the system, and the need to satisfy requirements will permeate all subsequent system development. The question raised here is the extent to which we shall be conscious of the the content of the user requirements specification at the stage where we implement code. Briefly, important general requirements are that (1) the reconstruction program should find events with a certain probability, and (2) that the code should be easy to maintain. The first requirement implies that a future class decomposition must be suitable for writing the kinds of programs that one wants to, and is something that should be checked at an early stage in the software development process. However, it does not need to be considered explicitly at the design-to-code phase, since the class specifications would have been already been checked. We are not (or should not) be concerned with checking overall class design at the the stage where we are inspecting code. Maintainabilty is however still in many respects a property of the code which is independent of the particular design chosen. It affects things like identifier names, comments, and textual layout. We acknowledge the need by providing style rules, but it might be useful to realize than some of the rules could refer also to documents produced at an earlier stage in the life cycle (we might wish to keep consistent naming conventions throughout design and coding, for example). We could therefore think of these naming rules as something that is constructed at a very early stage in software development. However, coding rules which refer to particular programming languages should not feature at this stage.
2. **Deciding on a High-Level Design** A number of alternative class decompositions may be proposed and checked for programming usability, by trying out use scenarios. The various utility classes should be established. There needs to be some cost-benefit analysis for prefering one design rather than another. This looks quite difficult to do, but never mind for the moment -- at the end, we should have named classes, and some kind of entity-relation diagram to show how they interact. This whole phase needs a lot more attention, but from our point of view here, it is not directly relevant since its output feeds into the next phase, which is a bit more cut and dried.
3. **Defining Class Services** This is the stage at which methods are assigned to classes, so that classes become self-contained modules offering services to others. There may need to be some rethink of the overall class decomposition, because it may turn out that classes are too entangled, so there might well be some cycling between this and the previous stage. We need criteria for establishing if a design is satisfactory (again, not easy), but we will assume that it can be done, and that we can emerge with the description of the interface that each class presents. This is information that is immediate input for the code inspection. Details of what might be included are presented in the next section.
4. **Deciding on Class Implementations** At this stage we specify _how_ a class provides its services and describe what goes on behind the scenes of the interface. It is now a question of specifying particular solutions, rather than properties, and alternatives should be explored and evaluated (different algorithms, different I/O formats etc) in a language-independent way. The final design is also required for the code inspection.
5. **Coding** It is important to understand that code is produced in conformity with designs that have already been accepted (ideally!). So when we do a code inspection we are _not_ evaluating a design, we are _not_ evaluating a solution to achieving the properties specified for the design, but we _are_ checking that the code maintains the properties as the interfaces specification and that it achieves its results by means of the specified solutions. In addition, of course, we have to do what we have already been doing: look out for violations of style and coding rules, and check that there are no faults that could lead to run-time failure.

## 9 Documents

There are a number of practical suggestions about rules in T. Gilb and D. Graham "Software Inspection". One idea that seems good to me is to split up rules to cover different aspects of inspection, and to to have a number of shortest sets of rules (preferably no more than a single page) which can be used for different types of inspection. Thus we can have rules for documents in general (that each should have a title, date and author, for example) and rules for particular types of documents (that all class specifications should state the class invariant on the line below the class header). As mentioned above, the source documents for a code inspection of class definitions might be: class interface specifications, the corresponding implementation specifications, rules of various kinds and possibly checklists. I don't want to get into details of notation at this point, but probably textual versions are as convenient as anything for the subsequent checking of code. The suggestions below are a first step at identifying what might be included in these documents (the order isn't necessarily the best possible)

### Class Interface Specifications

* Name of class
* Comment to explain the role class objects play
* Parent classes
* Parent methods redefined
* State variables that need to be known by user
* names and types of parameters, precondition, comment to describe effect of calling the method, postcondition

This specification should have been produced _before_ any particular solutions were implemented. It may look rather like Eiffel or C++, but it will contain less implementation detail so that it will be easier to understand the general principles of a design. The specification is language-independent, though as you can see,it will be close to some individual parts of the actual program code.

### Class Implementation Specifications

* Name of class
* General comments about implementation decisions and reasons (eg performance, future flexibility)
* Any ancillary constants or state variables that are declared purely for implementation purposes and which should not be visible across the interface.
* Hidden methods
* For each such method a comment or pseudocode description of what the method or function does.

Again, there may be criticism that this is all very close to code and that one might just as well go straight there. I don't think I agree with that-- if you look at an algorithm in pseudocode it is usually a lot shorter because you can omit declarations and say things like "select element which is closest to point (x,y,z)" which are cumbersome to express in a programming language. On the other hand, it is very useful for a checker (or a maintainer) to see that this is what a chunk of code is supposed to be doing.

### Design Metrics

There is now well-established set of metrics which are useful for evaluating the quality of object oriented code. However, there are some practical suggestions in Lorenz and Kidd [4]. They produce guidelines for acceptable values for such metrics as: number of public methods, total number of methods, class hierarchy level, number of calls of methods from other classes etc. They base their choice on values derived from previous projects (largely in Smalltalk, though some in C++) and for applications which are very different in nature to ours. The purpose of their metrics is largely to define the extent to which classes are loosely coupled and manageable to develop and maintain.

Some of the metrics could be used at earlier stages in the design process and would be useful there. Some could only be estimated after the code was written - largely the ones which are concerned with method size. The suggested values are not rules, which cannot be broken. Rather they are to be considered as guidelines which pinpoint places where it might be advantageous to reconsider the design.

### Rules relevant for code inspections

We need to ensure that the code conforms to the general standards for documents, that it conforms to the approved standards for program code (irrespective of language), and that it conforms to standards for the particular language used for implementation. Here are some suggested, mostly partial, rule sets. I assume that standard formats are defined in some document where they can be referenced (in practice, templates could be edited into product documents). The details aren't fixed, of course, but I have made specific proposals for the sake of having something concrete.

All Documents Rules
1. The document shall start with a header consisting of a unique document identifier, the document type (eg rule set, interface specification), author(s) and date in a standard format(defined in...).

2. The document identifier shall consist of a string, followed by a tag followed by an integer version number of the form string.tag.n
3. Apart from technical notations, the document shall be in English.
4. The document shall be free of grammatical and spelling errors.
5. The document shall be free of internal contradictions.

### Class Interface Specification Rules

1. The document shall conform to "All Documents"
2. The document shall contain the specification for a single class.
3. The document identifier shall have the same string part as other design documents referring to the same class, and the tag "iface".
4. Identifier names shall correspond to names used on the corresponding entity-relation diagrams(or whatever notation is used for this design phase)
5. The information described in the "Class Interface Specifications" document shall be recorded in the standard format (defined in...)
6. The document shall conform to "All Documents"
7. The document identifier shall have the same string part as other design documents referring to the same class, and the tag "impl".
8. Identifier names shall correspond to names used on the corresponding entity-relation diagrams (or whatever notation is used for this design phase)
9. The information described in the "Class Interface Specifications" document shall be recorded in the standard format (defined in...)
10. The document shall contain the specification for a single class.
11. The document identifier shall have the same string part as other design documents referring to the same class, and the tag "impl".
12. Identifier names shall correspond to names used on the corresponding entity-relation diagrams (or whatever notation is used for this design phase) and to those used in the corresponding class interface specification.
13. The information described in the "Class Implementation Specifications" document shall be recorded in the standard format (defined in...)
14. The document shall conform to "All Documents"
15. The name of the programming language shall be added to the header.
16. The document shall contain the code required to define a single class.
17. The document identifier shall have the same string part as the design documents for this class and the tag "code".
18. Names of identifiers shall be the same as on the design documents for this class, unless this rule is overridden in the "Language Coding Rules".
19. The following data from the "Class Interface Specification" shall appear in the program at the places designated:* the class description and the class invariant as comments immediately after the class header.
* the preconditions and postconditions, if they are executable, at the beginning and end of each public method. If they are not executable, they should appear as comments at these points.
7. The execution of a method for which the precondition is satisfied on entry will result in the postcondition being true on exit.
8. Successful execution of any public method will leave the class invariant unchanged.
9. Checks shall be made for invalid input values during the execution of any method and action taken according to its implementation specification.
10. Each method shall be implemented according to its description in its implementation specification.
11. All comments shall be consistent with the actual implementation.

Language Coding Rules These are things like not using pointer arithmetic etc. I don't think I want to make any more suggestions about them, except to assume that they will exist!

## 10 Source Documents for Input to Code Inspection

We are now in a position to make some concrete proposals about what documents a code inspector will get for class implementation inspectors The product document(s), as on that occasion, will be a number of individual class source code files. The source documents will be

* All the rules sets above plus the detailed documents they reference (style rules etc)
* The interface and implementation specifications for the classes that are being inspected.
* The interface specifications for class objects that are "mentioned" the code. These objects might be class attributes, parameters to methods or local variables. We don't need to know about their implementations, but we do need to be able to check if their methods are called correctly, and to know what they are supposed to do. In principle, this information could be obtained automatically by parsing the source code, but in any case it would be quite a time saver if it were collected up before the inspection started.

In addition, we should perhaps consider providing checklists. These should not duplicate the rules, because inspection should involve going through the code and checking that no rule is violated. We could start with the relevant rules sets and then see if there were some additional useful hints that would be useful for specific inspections. Suggested values for design metrics might be supplied in a checklist.

## 11 Conclusions

This paper contains suggestions for tightening up and extending inspections. In particular, an improved checking procedure is suggested for class code inspections. This is based on checking code against design specifications which are split into two documents: the first contains the class interface specification, and the second specifies how the class methods are to be implemented. The structure of these two documents is outlined. Their availability should make inspection a more systematic process, since an inspector is provided with a specific set of rules to check. Furthermore, inspectors should find it easier to understand the purpose of the code, and are less likely to be side-tracked into irrelevant problems.

The work of the author should also be assisted by having the design specifications to work from. By the time the code comes to be written, arguments for and against particular solutions will have been resolved, and there will be a much clearer idea of what has to be produced. Obviously, choosing the right level of detail for the design specifications is very important. From the point of view of studying alternative designs, one wants sufficient implementation detail to be able to evaluate questions of efficiency. On the other hand, too much detail makes specifications very long, and it is difficult to get an overview of the effect of executing a method. We should expect to learn by experience what is most useful for us.

This paper has only addressed the question of what are useful documents for our code inspections. It doesn't deal with the problem of how the design specifications are produced in the first place. However, it is hoped that making some concrete proposals for a single stage in the software development process will be a first step towards seeing what needs to be done earlier on.

## References

* [1] T. Gilb and D. Graham, _Software Inspection_, Addison-Wesley, 1993.
* [2] W. Humphrey, _A Discipline of Software Engineering_, Addison-Wesley, 1995.
* [3] The WWW Formal Technical Review Archive, http:www.ics.hawaii.edu/%7Ejohnson/FTR/
* [4] M. Lorenz and J. Kidd, _Object-Oriented Metrics_, Prentice-Hall Object-Oriented Series, 1994.