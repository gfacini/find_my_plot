# **Atlas Note**

**Statistical Combination of Several Important Standard Model Higgs Boson Search Channels.**

The ATLAS Collaboration1

Footnote 1: This note prepared by C. Adam Bourdaroís, A. Ahmad, J. Alison, C. Anastopoulos, A. Armbruster, S. Asai, G. Azuelos, M. Baak, O.K. Baker, F. Barreiro, M. Beckingham, N. Benekos, N. Berger, P. Bernat, B. Brelier, S. Burdin, M. Campanelli, L. Carminati, V. Cavasinni, F. Cerutti, X. Chen, C. Collard, G. Cowan, K. Cranmer, T. Dai, N. de Groot, J. del Peso, M. Delmastro, P.A. Delsart, R. Di Nardo, A. Di Simone, T. Donszelmann, A. D’Orazio, F. Dudziak, M. Ohrssen, Y. Fang, M. Fanti, S.M. Farrington, D. Fassouliotiis, L. Fayard, A. Firan, P. Fleischmann, L.R. Flores Castillo, G. Gaycken, D. Goldin, R. Goncalo, M. Groh, E. Gross, J. Grosse-Knetter, M. Heldmann, A. Hoecker, J. Hoffman, S. Horvat, P.J. Hsu, D. Joffe, M. Kado, S. Kaiser, M. Kaneda, J. Kanzaki, A. Kasmi, R. Kehoe, N. Kerschen, H. Kim, T. Koffas, I. Koletsou, O. Kortner, C. Kourkoumelis, H. Kroha, B. Laforge, T. Lagouri, S. Laplace, L. La Rotonda, K.J.C. Leney, B. Lenzi, D. Levin, X. Li, Z. Liang, H. Liu, K. Loureiro, Y. Malek, L. Mandelli, C.L. Manet, J.F. Marchand, R. Mazzini, B.R. Mellado Garcia, E. Menoni, M. Moch, S. Mohrdieck-Moock, J. Monk, F. Monticelli, N. Mser, R. Nicolaidou, K. Nikolopoulos, A. Nisati, G. Nunes Hanninger, G. Ordonez, E. Pagansi, Y. Pan, A. Patwa, V. Perez Reale, M. Plamondon, L. Poggioli, F. Polci, K. Prokofiev, J. Purdham, J. Qian, W. Quayle, M. Rast, D. Rebuzzi, Z. Ren, A. Robert, S. Rosati, I. Rottlander, D. Rousseau, C. Ruwiedel, F. Sarri, M. Schmitz, M. Schumacher, E. Solfaroli Camillocci, J. Strandberg, R. Stroynowski, J. Tanaka, F. Tarrade, G.F. Tartarelli, R. Thun, J. Tojo, I. Tsukerman, S. Tsuno, G. Unal, C. Valderanis, D. Varouchas, T. Venturelli, T. Vickey, O. Vitells, I. Vivarelli, E. von Toerne, C. Weiser, N. Wermes, A. Wilson, S.L. Wu, H. Yang, J. Yu, J. Yuan, S. Xella, S. Yamamoto, Z. Zenonos, Z. Zhao, H. Zhu.

###### Abstract

The ATLAS Collaboration1

Footnote 1: This note is part of CERN-OPEN-2008-020. This version of the note should not be cited: all citations should be to CERN-OPEN-2008-020.

_This note is part of CERN-OPEN-2008-020. This version of the note should not be cited: all citations should be to CERN-OPEN-2008-020._In this note we describe statistical procedures for combination of results from independent searches for the Higgs boson. Here only the Standard Model Higgs is considered, although the methods can easily be extended to non-standard Higgs models as well as to other searches. The methods are applied to Monte Carlo studies of four important search channels: \(H\rightarrow\tau^{+}\tau^{-}\), \(H\to W^{+}W^{-}\to eV\mu\nu\), \(H\rightarrow\gamma\gamma\) and \(H\to ZZ^{(*)}\rightarrow\) 4 leptons. The statistical treatment relies on a large sample approximation that is expected to be valid for an integrated luminosity of at least 2 fb\({}^{-1}\). Results are presented for the expected statistical significance of discovery and expected exclusion limits.

Introduction

Higgs searches will exploit a number of statistically independent decay channels. One wishes to combine all of the information from them to provide a single measure of the significance of a discovery or limits on Higgs production. The approach taken in this paper is based on frequentist statistical methods, where effects of systematic uncertainties are incorporated by use of the profile likelihood ratio.

The statistical procedures used for establishing discovery and setting limits are described in Section 2. These methods are very general and can be applied to the combination of results of essentially any search that will be carried out at the LHC. Section 3 summarizes the four search channels for the Standard Model Higgs boson considered in this note: \(H\to\tau^{+}\tau^{-}\), \(H\to W^{+}W^{-}\to e\nu\mu\nu\), \(H\to\gamma\gamma\) and \(H\to ZZ^{(*)}\to 4\) leptons.

The statistical treatment requires knowledge of the distribution of a test statistic based on the profile likelihood ratio. To determine these distributions by Monte Carlo so as to establish discovery at a high level of significance would require an enormous amount of simulated data, which is not practical at present. Therefore the distributions have been estimated using the functional form expected to hold in the large sample limit. Investigations shown in Section 3 indicate that this approximation should be reliable for an integrated luminosity above 2 fb\({}^{-1}\).

In Section 4 we show the result of the combination. For different values of the integrated luminosity and hypothesized Higgs mass, we present the signal significance expected assuming the Standard Model Higgs production rate, as well as expected upper limits on the Higgs production cross section, under the hypothesis of no Higgs signal.

The channels considered here focus on the search for a Higgs boson in the low-mass range. It is planned to include other channels in the future, e.g., further final states from the W\({}^{+}\)W\({}^{-}\) and \(ZZ\) modes. This will improve sensitivity especially at higher Higgs mass values.

## 2 Statistical methods

In this section we describe the general statistical model and likelihood function, first for a single channel and then generalized to multiple channels. In Section 2.2 we give the procedure used to establish discovery based on a frequentist significance test, where the effects of systematic uncertainties are incorporated by use of the _profile likelihood ratio_. Section 2.3 covers the corresponding methods for setting limits. For both discovery and exclusion one requires the sampling distribution of the statistic used in the test; this is described in Section 2.4. Section 2.5 discusses a series of approximations used to determine expected values of the discovery significance and exclusion limits.

The approach taken in this note is to carry out tests for discovery and exclusion for fixed values of the Higgs mass \(m_{H}\). In principle the entire procedure is then repeated for all masses, resulting in limits on or a measurement of \(m_{H}\). In practice, an interpolation is made between finite steps in \(m_{H}\).

### The statistical model and likelihood function

First we consider the case of a single search channel. The measurement results in a set of numbers of events found in kinematic regions where signal could be present. These typically correspond to a histogram of a variable such as the mass of the reconstructed Higgs candidate, with the numbers of entries denoted by \(\vec{n}=(n_{1},\ldots,n_{N})\). In some cases one may consider a histogram with only one bin, i.e., the measured outcome is simply a number of candidate events found. The number of entries in bin \(i\), \(n_{i}\), is modeled as a Poisson variable with mean value

\[E[n_{i}]=\mu L\epsilon_{i}\sigma_{i}\mathcal{B}+b_{i}\equiv\mu s_{i}+b_{i}\, \tag{1}\]where \(L\) is the integrated luminosity, \(\epsilon_{i}\), \(\sigma_{i}\) and \(\cal{B}\) are the signal efficiency, Higgs cross section, and branching ratio, and \(b_{i}\) is the expected number of background events. Here \(\mu\) is a signal strength parameter defined such that \(\mu=0\) corresponds to the absence of a signal; \(\mu=1\) gives the signal rate \(s_{i}\) expected from the Standard Model. If we consider a fixed Higgs mass \(m_{H}\), the only parameter of interest is \(\mu\). All other adjustable parameters needed to specify the model are called _nuisance parameters_.

In principle the expected background values \(b_{i}\) can be predicted using Monte Carlo models for Standard Model processes. In the measurements considered here, however, the systematic uncertainty in the Standard Model prediction is in many cases quite large, and this would severely limit the sensitivity of the search. Therefore data regions where one expects only a very small amount of signal (_control regions_) are used to constrain the background in the signal region (see also below).

For the \(i\)th bin of a histogram of a discriminating variable \(x\), the expected signal and background can be written

\[s_{i} = s_{\rm tot}\int_{\rm bin\,}f_{s}(x;\vec{\theta}_{s})\,dx\;, \tag{2}\] \[b_{i} = b_{\rm tot}\int_{\rm bin\,}f_{b}(x;\vec{\theta}_{b})\,dx\;, \tag{3}\]

where \(s_{\rm tot}\) and \(b_{\rm tot}\) are the total expected numbers of events in the histograms, \(f_{s}(x;\vec{\theta}_{s})\) and \(f_{b}(x;\vec{\theta}_{b})\) are the probability density functions (pdfs) of \(x\) for signal and background, and \(\vec{\theta}_{s}\) and \(\vec{\theta}_{b}\) represent sets of _shape parameters_.

The parametric forms of the pdfs \(f_{s}(x;\vec{\theta}_{s})\) and \(f_{b}(x;\vec{\theta}_{b})\) are determined from Monte Carlo simulations or data control samples. In the following we will use \(\vec{\theta}=(\vec{\theta}_{s},\vec{\theta}_{b},b_{\rm tot})\) to refer to all of the nuisance parameters. The signal normalization \(s_{\rm tot}\) here is not an adjustable parameter, but rather is fixed equal to the Standard Model prediction.

In addition to the measured histogram \(\vec{n}\), some search channels also make use of a set of subsidiary measurements \(\vec{m}=(m_{1},\ldots,m_{M})\) in control regions where one expects mainly background events. These can be modeled as being Poisson distributed with mean values

\[E[m_{i}]=u_{i}(\vec{\theta})\;, \tag{4}\]

where the \(u_{i}\) are calculable quantities depending on a set of parameters, at least some of which are the same as those entering into the predictions for \(s_{i}\) and \(b_{i}\) above. In practice the subsidiary measurements are constructed so as to provide information on the background normalization \(b_{\rm tot}\) and sometimes also on its shape.

If the measurement is based on counting events in a given kinematic region, i.e., without using the shape of a distribution, in the formalism above the histograms have a single bin. The value \(s=s_{\rm tot}\) is then the Standard Model prediction for the signal and \(b=b_{\rm tot}\) is the (unknown) expected background. There are then no shape parameters, and \(b\) itself plays the role of \(\vec{\theta}\) as the single nuisance parameter. In this case the subsidiary measurement \(m\) is made in a control region where signal is absent (or can to good approximation be neglected), and has an expectation value

\[E[m]=u=\tau b\;, \tag{5}\]

where \(\tau\) is a scaling constant whose value can be estimated from a Monte Carlo simulation.

The likelihood function is the product of Poisson probabilities for all bins:

\[L(\mu,\vec{\theta})=\prod_{j=1}^{N}\frac{(\mu s_{j}+b_{j})^{n_{j}}}{n_{j}!}e^{ -(\mu s_{j}+b_{j})}\ \prod_{k=1}^{M}\frac{u_{k}^{m_{k}}}{m_{k}!}e^{-u_{k}}\;. \tag{6}\]Equivalently the log-likelihood is

\[\ln L(\mu,\vec{\theta})=\sum_{j=1}^{N}\left(n_{j}\ln(\mu s_{j}+b_{j})-(\mu s_{j}+ b_{j})\right)\ +\ \sum_{k=1}^{M}\left(m_{k}\ln u_{k}-u_{k}\right)+C\, \tag{7}\]

where \(C\) represents terms that do not depend on the parameters and thus can be dropped. Here and in (6) the parameters \(\vec{\theta}\) enter through Eqs. (2), (3), and (4).

In the case where the presence of signal in the histogram \(\vec{n}\) gives a peak sitting on a smooth background, one does not need a subsidiary measurement \(\vec{m}\). Rather, as long as the number of parameters in the models for the signal and background distributions is smaller than the total number of bins measured, one can determine the strength parameter \(\mu\) from the histogram \(\vec{n}\) alone. Here the regions away from the peak (the sidebands) play the role of the subsidiary measurement by providing information on the background level. Of course if an additional subsidiary measurement is available, this will improve the accuracy of the background determination, which will increase the sensitivity of the analysis.

In the case of several independent search channels, the method described above is generalized in a straightforward manner. For each channel \(i\) there is a likelihood function \(L_{i}(\mu,\vec{\theta}_{i})\). Its general form is given by Eq. (6), except that all quantities carry an additional index \(i\) to label the channel except the global strength parameter \(\mu\), which is assumed to be the same for all channels. Since the channels are statistically independent, the full likelihood function is given by the product

\[L(\mu,\vec{\theta})=\prod_{i}L_{i}(\mu,\vec{\theta}_{i})\, \tag{8}\]

where \(\vec{\theta}\) here represents all of the nuisance parameters.

Systematic uncertainties are effectively included in the analysis through the nuisance parameters \(\vec{\theta}\). The model must be sufficiently flexible, i.e., it must contain enough parameters, so that for at least some point in its parameter space it can be regarded as representing the truth. One must exercise some restraint in achieving this, however, as an increasing number of nuisance parameters leads to a decrease in sensitivity to the parameters of interest. Some of the components of \(\vec{\theta}\) may be common among different channels, e.g., parameters relating to uncertainty in the integrated luminosity. These then represent a common (correlated) systematic uncertainty.

As an example, consider the signal efficiency \(\varepsilon\) that enters in the relation between the cross section and expected number of signal events. Suppose the efficiency has been estimated to have a value \(\hat{\varepsilon}\) and systematic uncertainty \(\sigma_{\hat{\varepsilon}}\). To incorporate this uncertainty into the model, we can regard the measured value \(\hat{\varepsilon}\) as a random variable whose true value \(\varepsilon\) is treated as a nuisance parameter. For the pdf \(f_{\varepsilon}(\hat{\varepsilon};\varepsilon,\sigma_{\hat{\varepsilon}})\) one could use, e.g., a Gaussian distribution centred about \(\varepsilon\), or for a quantity such as the efficiency which must lie in the range \(0\leq\varepsilon\leq 1\) one could use a pdf that automatically satisfies this constraint (e.g., a beta distribution). For whatever choice is deemed appropriate, the likelihood (6) is multiplied by \(f_{\varepsilon}(\hat{\varepsilon};\varepsilon,\sigma_{\hat{\varepsilon}})\), evaluated with the best estimate \(\hat{\varepsilon}\), and the parameter \(\varepsilon\) is included in the set of nuisance parameters \(\vec{\theta}\).

To test a hypothesized value of \(\mu\) we construct the profile likelihood ratio,

\[\lambda(\mu)=\frac{L(\mu,\hat{\vec{\theta}})}{L(\hat{\mu},\hat{\vec{\theta}}) }. \tag{9}\]

Here \(\hat{\vec{\theta}}\) in the numerator denotes the value of \(\vec{\theta}\) that maximizes \(L\) for the specified \(\mu\), i.e., it is the conditional maximum-likelihood estimator (MLE) of \(\vec{\theta}\) (and thus is a function of \(\mu\)). The denominator is the maximized (full) likelihood function, i.e., \(\hat{\mu}\) and \(\hat{\vec{\theta}}\) are the MLEs. The presence of the nuisance parameters broadens the profile likelihood ratio as a function of \(\mu\) relative to what one would have if their values were fixed. This reflects the loss of information about \(\mu\) due to the systematic uncertainties.

The likelihood ratio (9) and procedures for incorporating systematic uncertainties applied here differ somewhat from those used for the searches carried out at LEP. Some of these differences are discussed further in Appendix A.

From the definition of the profile likelihood ratio one can see that \(0\leq\lambda\leq 1\), with \(\lambda(\mu)=1\) implying good agreement between the data and the hypothesized value of \(\mu\). Equivalently it is convenient to work with the quantity

\[q_{\mu}=-2\ln\lambda(\mu)\, \tag{10}\]

so that high values of \(q_{\mu}\) correspond to poor agreement between the data and the hypothesized \(\mu\). The statistic \(q_{\mu}\) will have a sampling distribution \(f(q_{\mu}|\mu^{\prime})\). Here \(\mu\) refers to the strength parameter used to define the statistic \(q_{\mu}\), entering in the numerator of the likelihood ratio, and \(\mu^{\prime}\) is the value used to define the data generated to obtain the distribution (i.e., the 'true' value). For the special case \(\mu^{\prime}=\mu\) and for a sufficiently large data sample, the pdf \(f(q_{\mu}|\mu)\) approaches a limiting form related to the chi-square distribution, discussed further in Section 2.4. For \(\mu^{\prime}\neq\mu\), the distribution of \(q_{\mu}\) is shifted to higher values, reflecting the decreased agreement between the data generated with \(\mu^{\prime}\) and the hypothesis tested by \(q_{\mu}\), as indicated in Fig. 1. The two cases of particular interest are \(\mu=0\), the background-only hypothesis, and \(\mu=1\), the hypothesis of background plus signal present at the Standard Model rate.

The level of compatibility between data that give an observed value \(q_{\mu,\text{obs}}\) for \(q_{\mu}\) and a hypothesized value of \(\mu\) is quantified by giving the \(p\)-value

\[p_{\mu}=\int_{q_{\mu,\text{obs}}}^{\infty}f(q_{\mu}|\mu)\,dq_{\mu}. \tag{11}\]

This is the probability, under the assumption of \(\mu\), of seeing data with equal or greater incompatibility, as measured by \(q_{\mu}\), relative to the data actually obtained. This is illustrated in Fig. 1, where the shaded area indicates the \(p\)-value of the hypothesized \(\mu\). The figure also indicates the median value of \(q_{\mu}\) under the assumption of a different value of the strength parameter \(\mu^{\prime}\) used to generate the data. For \(\mu\) and \(\mu^{\prime}\) values that are increasingly different, the median \(\text{med}[q_{\mu}|\mu^{\prime}]\) moves further to the right. An observed value of \(q_{\mu}\) at this median would give a correspondingly small \(p\)-value for \(\mu\).

### Establishing discovery

To establish discovery we try to reject the \(\mu=0\) (background-only) hypothesis, i.e., that there is no Higgs signal present. To do this we use the statistic \(q_{0}=-2\ln\lambda(0)\). One expects to find a low value of \(\lambda(0)\) (high \(q_{0}\)) if the data include signal. Here even though one is testing the hypothesis that the Higgs does not exist, the definition of \(q_{0}\) depends on the hypothesized Higgs mass \(m_{H}\). It enters through the denominator of the likelihood ratio (9), which contains the maximum-likelihood estimator \(\hat{\mu}\) for the strength of a Higgs signal at the mass \(m_{H}\). By defining the test statistic in this way one maximizes the

Figure 1: Illustration of the determination of the \(p\)-value of a hypothesized value of \(\mu\). The left-hand curve indicates the pdf of \(q_{\mu}\) for data generated with the same value of \(\mu\) as was used to define the statistic \(q_{\mu}\); this is used to determine the \(p\)-value of \(\mu\), shown as the shaded region. The right-hand curve indicates the pdf of \(q_{\mu}\) for data generated with a different value of the strength parameter, \(\mu^{\prime}\).

probability of rejecting the \(\mu=0\) hypothesis if the Higgs boson exists at the specified mass. This search procedure is then carried out for all values of \(m_{H}\) (in practice an interpolation is carried out between finite steps in \(m_{H}\)).

A given data set will result in an observed value \(q_{0,\rm obs}\) of \(q_{0}\). The level of compatibility between the data and the no-Higgs hypothesis is quantified by giving the \(p\)-value

\[p_{0}=\int_{q_{0,\rm obs}}^{\infty}f(q_{0}|0)\,dq_{0}. \tag{12}\]

This is the probability, under the assumption of \(\mu=0\) (background only), of seeing data as signal-like or more so relative to the data actually obtained. A small value is interpreted as evidence against \(\mu=0\), i.e., a discovery of the signal.

One can define the _significance_ corresponding to a given \(p\)-value as the number of standard deviations \(Z\) at which a Gaussian random variable of zero mean would give a one-sided tail area equal to \(p\). That is, the significance \(Z\) is related to the \(p\)-value by

\[p=\int_{Z}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}\,dx=1-\Phi(Z)\, \tag{13}\]

where \(\Phi\) is the cumulative distribution for the standard (zero mean, unit variance) Gaussian. Equivalently one has

\[Z=\Phi^{-1}(1-p)\, \tag{14}\]

where \(\Phi^{-1}\) is the quantile of the standard Gaussian (inverse of the cumulative distribution). In (13) and (14) the subscript \(0\) was dropped as these relations hold for all \(p\)-values, not only those of the \(\mu=0\) hypothesis. The relation between \(Z\) and \(p\) is illustrated in Fig. 2.

A significance of \(Z=5\) corresponds to \(p=2.87\times 10^{-7}\). For a sufficiently large data sample, one would obtain a \(p\)-value of \(0.5\) for data in perfect agreement with the expected background. With the definition of \(Z\) given above, this gives \(Z=0\). If the data fluctuate below the expected background, \(Z\) becomes negative.

Note that according to the definition (14), a \(p\)-value of \(0.05\) corresponds to \(Z=1.64\). This should not be confused with a \(1.96\sigma\) fluctuation of a Gaussian variable that gives \(0.05\) for the two-sided tail area.

The significance of a discovery \(Z\) depends on the data obtained. To quantify our ability to discover a hypothesized signal in advance of seeing the data, we report the _median_ significance under the assumption that the signal is present at the Standard Model rate, \(\mu=1\). Since \(Z\) is a monotonic function of \(p_{0}\), and \(p_{0}\) is also a monotonic function of \(q_{0}\), we have for the median significance,

\[Z_{\rm med}=\Phi^{-1}(1-p_{0_{\rm med}})=\Phi^{-1}(1-p_{0}(q_{0_{\rm med}})). \tag{15}\]

This can be obtained from the median value of \(q_{0}\) found using data generated under the assumption of \(\mu=1\).

Figure 2: Illustration of the correspondence between the significance \(Z\) and a \(p\)-value.

A complete evaluation of the median significance is computationally difficult, as it requires a large number of repeated simulations of the full set of experimental outputs and determination of \(Z(q_{0})\) from the combination of all channels. Therefore in this note we have used the approximate methods described in Section 2.5, which allow one to estimate quickly the median significance.

### Setting limits

In addition to establishing discovery by rejecting the \(\mu=0\) hypothesis, we can consider the alternative hypothesis of some non-zero \(\mu\) and try to reject it. A \(p\)-value is computed for each \(\mu\), and the set of \(\mu\) values for which the \(p\)-value is greater than or equal to a fixed value \(1-\mathrm{CL}\) form a confidence interval for \(\mu\), where typically one takes a _confidence level_\(\mathrm{CL}=95\%\). The upper end of this interval \(\mu_{\mathrm{up}}\) is the upper limit (i.e., \(\mu\leq\mu_{\mathrm{up}}\) at \(95\%\) CL).

To compute the \(p\)-value for a hypothesized \(\mu\) we first consider again the test statistic \(q_{\mu}=-2\ln\lambda(\mu)\) as initially defined in (9) and (10). For purposes of computing limits, we introduce a modification to this definition as described below.

If the data are incompatible with the hypothesized \(\mu\), one expects a large value of \(-2\ln\lambda(\mu)\), i.e., \(\lambda(\mu)\) close to zero. If a data set generated according to the hypothesis \(\mu\) gives a large value of \(-2\ln\lambda(\mu)\), this can be the result of either an upward or downward fluctuation in \(\hat{\mu}\) relative to \(\mu\). This is illustrated in the scatterplot of \(\hat{\mu}\) versus \(-2\ln\lambda(\mu)\) shown in Fig. 3(a), which is from a toy Monte Carlo study with \(\mu=0.8\). The projection of the points on the \(\hat{\mu}\) axis is shown in Fig. 3(b). Note that \(\hat{\mu}\geq 0\) is imposed; the reasons for and consequences of this requirement are discussed in Section 2.4.

For purposes of setting an upper limit, however, we want to determine the smallest \(\mu\) such that there is a fixed small probability (one minus the confidence level) to find data as compatible with that value of \(\mu\) or less, relative to the degree of compatibility found with the real data. Therefore the data with upward fluctuations in \(\hat{\mu}\) are not counted when computing the \(p\)-value, because they would be compatible with some larger \(\mu\). Therefore for purposes of computing limits we redefine \(q_{\mu}\) to be2

Footnote 2: Equivalently, one could retain the definition \(q_{\mu}=-2\ln(L(\mu,\hat{\theta})/L(\hat{\mu},\hat{\theta}))\) by placing an upper bound on \(\hat{\mu}\) equal to \(\mu\), i.e., by imposing \(0\leq\hat{\mu}\leq\mu\). In this way, when \(\hat{\mu}=\mu\) then one has \(q_{\mu}=0\) just as in the case of discovery when testing \(\mu=0\).

\[q_{\mu}=\left\{\begin{array}{cl}-2\ln\lambda(\mu)&\hat{\mu}\leq\mu\,\\ 0&\text{otherwise}.\end{array}\right. \tag{16}\]

The distribution of the new \(q_{\mu}\) thus corresponds to the lower branch only of the U-shaped scatterplot shown in Fig. 3(a).

Using the new definition (16), the \(p\)-value is given by the integral of \(f(q_{\mu}|\mu)\) from the observed value \(q_{\mu,\mathrm{obs}}\) to infinity as in Eq. (11) and as illustrated in Fig. 1. The \(p\)-value is computed in this manner for all values of \(\mu\), and the upper limit \(\mu_{\mathrm{up}}\) at 95% confidence level is the largest value of \(\mu\) for which the \(p\)-value is at least 0.05.

The result can be summarized by giving the upper limit on \(\mu\) as a function of the Higgs mass \(m_{H}\). Specifically, if we can reject the hypothesis \(\mu=1\) at a certain confidence level, then the corresponding value of \(m_{H}\) is regarded as excluded for a Standard Model Higgs. The lowest mass value not excluded is the lower limit \(m_{\mathrm{lo}}\).

One is also interested in the median limit under the assumption that there is no Higgs. As in the case of the discovery significance, a full calculation of the median limit is difficult as it requires a large number of repeated simulations based on the full profile likelihood ratio. For purposes of this note, therefore, we use the approximation techniques described in Section 2.5.

### Sampling distribution of the likelihood ratio

To determine the \(p\)-values required for both discovery and exclusion we need the sampling distribution, assuming data generated according to a given value of \(\mu\), of the statistic \(q_{\mu}\), i.e., \(f(q_{\mu}|\mu)\). For the case of discovery significance we use \(q_{0}=-2\ln\lambda(0)\), and for setting limits we use \(q_{\mu}=-2\ln\lambda(\mu)\) for \(\hat{\mu}\leq\mu\) and \(q_{\mu}=0\), otherwise.

To claim discovery we require \(p\)-values for \(\mu=0\) down to around \(10^{-7}\), and therefore to do this with a Monte Carlo simulation requires an extremely large number of simulated measurements. In practice this is only carried out for simple test cases. Even for setting limits at 95% confidence level, it is often not practical to use Monte Carlo.

Under a set of regularity conditions and for a sufficiently large data sample, _Wilks' theorem_ says that for a hypothesized value of \(\mu\), the pdf of the statistic \(-2\ln\lambda(\mu)\) approaches the chi-square pdf for one degree of freedom [2]. More generally, if there are \(n\) parameters of interest, i.e., those parameters that do not get a double hat in the numerator of the likelihood ratio (9), then \(-2\ln\lambda(\mu)\) asymptotically follows a chi-square distribution for \(n\) degrees of freedom. A proof and details of the regularity conditions can be found in standard texts such as [3].

In the searches considered here, the data samples are generally large enough to ensure the validity of the asymptotic formulae for the likelihood-ratio distributions. In our case, however, the distributions are modified because of constraints imposed on the expected number of events.

Usually when searching for a new type of particle reaction one regards the mean number of events contributed to any bin from any source, signal or background, to be greater than or equal to zero. In some analyses it could be meaningful to consider a new effect that suppresses the expected number of events, e.g., the presence of a new decay channel could mean that the number of decays to known channels is reduced. Here, however, we will regard any contribution to an expected number of events as non-negative.

Assuming only non-negative event rates, the maximum-likelihood estimators for the parameters are constrained, e.g., \(\hat{\mu}\geq 0\). As a consequence, if the observed number of events is below the level predicted by the background alone, then the maximum of the likelihood occurs for \(\mu=0\), i.e., negative \(\mu\) is not allowed. We can consider the effect of having \(\hat{\mu}=0\) on the distribution of \(q_{\mu}\) for two cases: \(\mu=0\) and \(\mu>0\).

For \(\mu=0\), i.e., when computing the discovery significance, if \(\hat{\mu}=0\) one has (see (9)),

\[\lambda(0)=\frac{L(0,\hat{\frac{\hat{\theta}}{\theta}})}{L(\hat{\mu},\hat{ \frac{\theta}{\theta}})}=\frac{L(0,\hat{\frac{\hat{\theta}}{\theta}})}{L(0, \hat{\frac{\theta}{\theta}})}=1\, \tag{17}\]since \(\hat{\mu}=0\) and therefore \(\hat{\hat{\bar{\theta}}}=\hat{\bar{\theta}}\). The statistic \(q_{0}=-2\ln\lambda(0)\) is therefore equal to zero. This can be seen in the scatterplot of \(q_{0}\) versus \(\hat{\mu}\) in Fig. 4(a). Figure 4(b) shows the corresponding \(q_{0}\) distribution with the peak visible at \(q_{0}=0\). The superimposed curve is a chi-square distribution multiplied by one half, corresponding to the half of the events with \(\hat{\mu}>0\).

From Fig. 4(b) one can see that except for the spike at \(q_{0}=0\) (when \(\hat{\mu}=0\)), the pdf of \(q_{0}\) can be well approximated by the chi-square pdf. Assuming a fraction \(w\) for the cases with \(\hat{\mu}>0\) one has the pdf

\[f(q_{0}|0)=wf_{\chi_{1}^{2}}(q_{0})+(1-w)\delta(q_{0})\;. \tag{18}\]

In the usual case where upward and downward fluctuations of \(\hat{\mu}\) are equally likely we have \(w=1/2\). The \(p\)-value of the background-only hypothesis given an observation \(q_{0,\text{obs}}\) greater than zero is therefore

\[p=\int_{q_{0,\text{obs}}}^{\infty}wf_{\chi_{1}^{2}}(q_{0})\,dq_{0}=w(1-F_{ \chi_{1}^{2}}(q_{0,\text{obs}}))\;, \tag{19}\]

where \(F_{\chi_{1}^{2}}\) is the cumulative chi-square distribution for one degree of freedom.

The second case to consider is \(\mu>0\), e.g., when one wants to set an upper limit on \(\mu\). Under the hypothesis \(\mu\), one obtains \(\hat{\mu}>\mu\) and \(\hat{\mu}\leq\mu\) with approximately equal probability. Figure 5 shows the distributions of \(q_{\mu}\) for both cases \(\hat{\mu}>\mu\) and \(\hat{\mu}\leq\mu\) obtained from the scatterplot Fig. 3(a), from a Monte Carlo study with \(\mu=0.8\).

From Fig. 5(a) one can see that for \(\hat{\mu}>\mu\), the data follow the chi-square pdf quite accurately. This portion of the distribution is ignored, however, when setting upper limits on \(\mu\), because of the modified definition of \(q_{\mu}\) (20) used for limits,

\[q_{\mu}=\left\{\begin{array}{ll}-2\ln\lambda(\mu)&\hat{\mu}\leq\mu\;,\\ 0&\text{otherwise}\,.\end{array}\right. \tag{20}\]

Suppose now \(\hat{\mu}\leq\mu\) with a probability \(w\); in practice this is close to one half. (Note for the case of \(q_{0}\), \(w\) is the probability of \(\hat{\mu}>\mu\). The different definitions of \(w\) are used so as to give similar forms for \(f(q_{0}|0)\) and \(f(q_{\mu}|\mu)\).) Thus for \(\hat{\mu}>\mu\) one has from (20) \(q_{\mu}=0\), and therefore the distribution has a delta function at \(q_{\mu}=0\) with weight \(1-w\). The pdf of \(f(q_{\mu}|\mu)\) can therefore be written

\[f(q_{\mu}|\mu)=wf(q_{\mu}|\mu,\hat{\mu}\leq\mu)+(1-w)\delta(q_{\mu})\;. \tag{21}\]

where \(f(q_{\mu}|\mu,\hat{\mu}\leq\mu)\) is the conditional pdf for \(q_{\mu}\) given \(\hat{\mu}\leq\mu\).

Figure 4: (a) Scatterplot of \(\hat{\mu}\) versus \(q_{\mu}\) from a Monte Carlo study with \(\mu=0\); (b) the distribution of \(q_{0}\) (see text).

For \(\hat{\mu}\leq\mu\), one may sometimes find \(\hat{\mu}\) equal to zero, i.e., the lower edge of the allowed range, as can be seen in the scatterplot of \(\hat{\mu}\) versus \(q_{\mu}\) shown in Fig. 3(a). Although for the case \(\mu=0\) this gave a peak at \(q_{0}=0\), here it gives

\[\lambda(\mu)=\frac{L(\mu,\hat{\hat{\theta}})}{L(\mu,\hat{\hat{\theta}})}=\frac {L(\mu,\hat{\hat{\theta}})}{L(0,\hat{\theta})}\, \tag{22}\]

which in contrast to (17) is not equal to unity. The effect of having \(\hat{\mu}=0\) on the distribution of \(q_{\mu}\) is therefore more complicated than was the case for \(q_{0}\).

In general for \(\hat{\mu}\leq\mu\), the distribution of \(q_{\mu}\) falls off more steeply than the chi-square distribution. This is seen in Fig. 5(b). Therefore a \(p\)-value based on the chi-square formula will be larger than the true \(p\)-value, and the corresponding significance \(Z\) will be smaller. The upper limits obtained for \(\mu\) are therefore larger, i.e., a smaller set of \(\mu\) values is excluded.

If \(\mu\) is sufficiently large, then \(\hat{\mu}\) is very rarely pushed to zero and \(f(q_{\mu}|\mu,\hat{\mu}\leq\mu)\) approaches a chi-square distribution for one degree of freedom. For purposes of the present study, the chi-square approximation is adequate, but gives somewhat conservative limits. That is, we take the distribution of \(q_{\mu}\) to be

\[f(q_{\mu}|\mu)=wf_{\chi_{1}^{2}}(q_{\mu})+(1-w)\delta(q_{\mu}) \tag{23}\]

and use \(w=0.5\). One has therefore the same pdf for \(q_{\mu}\) using the modified definition (20) as was found in (18) for \(q_{0}\) based on the original definition, \(q_{0}=-2\ln\lambda(0)\).

To summarize the result above, the pdf of \(q_{\mu}\) can be approximated by a mixture of a chi-square pdf for one degree of freedom with weight \(w\) and a delta function at zero with weight \(1-w\). This holds both for discovery (\(\mu=0\)) and setting limits (\(\mu>0\)).

Consider now the variable

\[u=\sqrt{q_{\mu}}=\sqrt{-2\ln\lambda(\mu)}\, \tag{24}\]

which has the pdf

\[f(u)=\Theta(u)w\sqrt{\frac{2}{\pi}}e^{-u^{2}/2}+(1-w)\delta(u)\, \tag{25}\]

Figure 5: Distributions of \(-2\ln\lambda(\mu)\) for (a) \(\hat{\mu}>\mu\) and (b) \(\hat{\mu}\leq\mu\). The superimposed curves are chi-square distributions for one degree of freedom normalized to half the number of entries in the original distribution (see Fig. 3(a)).

where \(\Theta(u)=1\) for \(u\geq 0\) and is zero otherwise. The second term in (25) follows from the fact that the values \(q_{0}=0\) and \(u=0\) occur with equal probability, \(1-w\). Furthermore if a variable \(x\) follows the standard Gaussian distribution, then one can show \(x^{2}\) follows a chi-square distribution for one degree of freedom. Therefore if \(x^{2}\) follows a \(\chi^{2}\) distribution, then \(\sqrt{x^{2}}\) follows a Gaussian scaled up by a factor of two for \(x>0\) so as to have a total area of unity.

The \(p\)-value of the hypothesis \(\mu\) for a non-zero observation \(q_{\mu,\mathrm{obs}}\) is therefore

\[p=P(q_{\mu}\geq q_{\mu,\mathrm{obs}})=P(u\geq\sqrt{q_{\mu,\mathrm{obs}}})=2w \int_{\sqrt{q_{\mu,\mathrm{obs}}}}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-u^{2}/2} \,du=2w(1-\Phi(\sqrt{q_{\mu,\mathrm{obs}}})). \tag{26}\]

Combining this with Eq. (14) for the significance \(Z\) gives

\[Z=\Phi^{-1}(1-2w(1-\Phi(\sqrt{q_{\mu,\mathrm{obs}}}))). \tag{27}\]

In the usual case where the weights of the chi-square and delta-function terms are equal, i.e., \(w=1/2\), Eq. (27) reduces to to the simple formula

\[Z=\sqrt{q_{\mu,\mathrm{obs}}}. \tag{28}\]

### Approximate methods

To determine the discovery significance or to set limits using a given data set, one must carry out the global fit described above. For this one needs first to combine the likelihood functions for the individual channels into the full likelihood function containing a single strength parameter \(\mu\), and use this to find the profile likelihood ratio. It is possible, however, to find approximate values for the _median_ discovery significance and limits in a way that only requires as input the separate profile likelihood ratio values from each of the channels. This is very useful especially in the planning phase of a search that combines multiple channels.

The procedure relies on two separate approximations. First, we estimate the median value of the profile likelihood ratio \(\lambda(\mu)\) by evaluating the likelihood function with a single, artificial data set in which all statistical fluctuations are suppressed, as described in Section 2.5.1. Second, to determine the significance values from the likelihood ratios, we use the asymptotic form of the distribution of \(-2\ln\lambda(\mu)\) valid for sufficiently large data samples. This is described in Section 2.5.2, and its validity is checked for the individual channels in Section 3. Here the limitations of the approximation are investigated and for one case where it is found to be insufficiently accurate (the discovery significance for the channel \(H\to W^{+}W^{-}\) plus no jets), an alternate procedure is followed.

#### 2.5.1 Approximation for the median likelihood ratio

To find the median discovery significance and limits, the median likelihood ratios \(\lambda_{i}(\mu)\) are first found for each channel separately, and then combined to give the full median likelihood ratio. One can estimate the median \(\lambda_{i}(\mu)\) by the value of the likelihood ratio evaluated with a single artificially constructed data set, in which all statistical fluctuations are suppressed and the data values \(\vec{n}\) and \(\vec{m}\) are replaced by their expectation values for a given integrated luminosity and a hypothesized strength parameter \(\mu_{\mathrm{A}}\). We refer to this as an 'Asimov' data set.3) It replaces having to simulate a large number of experiments from which one would determine the median.

As before, \(\mu_{A}=0\) is the background only hypothesis and \(\mu_{\rm A}=1\) corresponds to background plus signal present at the Standard Model rate. The median referred to thus pertains to what one would obtain with a large number of experiments generated under the assumption of \(\mu_{\rm A}\). The approximation is in fact more accurate if one uses noninteger values for numbers of events in the log-likelihood (the factorial terms are in any case absent) so that the Asimov likelihood \(L_{A}\) is found by substituting

\[n_{j} = \mu_{A}s_{j}+b_{j} \tag{29}\] \[m_{k} = u_{k}\;, \tag{30}\]

into the likelihood function (6) for each channel. Here for \(s_{j}\), \(b_{j}\) and \(u_{k}\), one needs in principle the expectation values, i.e., these quantities should have no statistical errors. In practice they are estimated using a Monte Carlo sample corresponding to an integrated luminosity substantially larger than what is considered for the data. The numbers of signal and background events are then scaled to the desired luminosity. The other nuisance parameters such as shape parameters are estimated as would be done with any other data set; we refer below to the resulting values as \(\widetilde{\theta}_{\rm A}\). Because the Asimov data set has no statistical fluctuations, the \(\widetilde{\theta}_{\rm A}\) are simply the values one would derive from a very large Monte Carlo data sample.

The estimate of the median likelihood ratio used for the \(i\)th channel is therefore

\[\lambda_{A,i}(\mu)=\frac{L_{A,i}(\mu,\hat{\tilde{\theta}})}{L_{A,i}(\mu,\hat{ \tilde{\theta}})}\approx\frac{L_{A,i}(\mu,\hat{\tilde{\theta}})}{L_{A,i}(\mu_{ \rm A},\bar{\theta}_{\rm A})}\;, \tag{31}\]

where \(L_{A,i}\) denotes the likelihood function (6) evaluated with the Asimov data values (29) and (30). The approximation used for the final step in (31) exploits the fact that ML estimate of \(\hat{\mu}\) is very close to the input value \(\mu_{A}\) when the likelihood function is constructed using the Asimov data set.

Note that if the likelihood functions for the individual channels were to be constructed with data containing statistical fluctuations rather than with the artificial Asimov data, then the ML estimate of the strength parameter, \(\hat{\mu}\), would in general be different for each channel. The full likelihood function (8) used for the combination, however, contains a single global \(\mu\). We can now exploit the fact that for the Asimov data one has \(\hat{\mu}\approx\mu_{\rm A}\) for all of the channels and thus obtain the median likelihood ratio for the combination as the product of the individual \(\lambda_{A,i}(\mu)\),

\[\lambda_{A}(\mu)=\prod_{i}\lambda_{A,i}(\mu)\;. \tag{32}\]

Monte Carlo studies show that Eq. (32) provides an excellent approximation to the median value one would find from data generated with \(\mu_{\rm A}\) as the strength parameter.

For purposes of quantifying how likely we are to discover the Higgs if it exists, we report the significance obtained from the \(p\)-value of \(\mu=0\) with an Asimov data set that corresponds to \(\mu_{A}=1\),

\[\lambda_{s+b}(0)=\prod_{i}\frac{L_{s+b,i}(0,\hat{\tilde{\theta}})}{L_{s+b,i} (1,\bar{\theta}_{\rm A})}\;. \tag{33}\]

Here the subscript \(s+b\) refers to the Asimov data set; the argument \(0\) denotes the value of \(\mu\) being tested. That is, Eq. (33) approximates what one would obtain with data generated with signal and background for the median value of \(\lambda(0)\), which is used to test the background-only (\(\mu=0\)) hypothesis. Equation (33) provides the median \(q_{0\rm med}=-2\ln\lambda_{s+b}(0)\), and from this the \(p\)-value and significance \(Z\) are found using equation (15).

To determine the limits on \(\mu\) that we expect to set if the Higgs does not exist (or is beyond our reach), we find the \(p\)-value of a hypothesized \(\mu\) using the likelihood ratio \(\lambda(\mu)\) based on Asimov data for background only (\(\mu_{\mathrm{A}}=0\)),

\[\lambda_{b}(\mu)=\prod_{i}\frac{L_{b,i}(\mu,\hat{\bar{\theta}})}{L_{b,i}(0,\bar {\theta}_{\mathrm{A}})}. \tag{34}\]

That is, \(\lambda_{b}(\mu)\) approximates the median value of \(\lambda(\mu)\) one would obtain from data generated according to the background-only hypothesis. The value of \(\lambda_{b}(\mu)\) is used to determine the median \(q_{\mu_{\mathrm{med}}}\), which is used to find the median \(p\)-value, \(p_{\mu_{\mathrm{med}}}\). This is computed for all \(\mu\) and the point where \(p_{\mu_{\mathrm{med}}}=0.05\) gives the 95% CL upper limit.

Because \(\hat{\mu}\approx\mu_{\mathrm{A}}\) holds for each channel individually when using Asimov data, it is possible to determine the values of the likelihood ratio entering into (32) separately for each channel, which simplifies greatly the task of estimating the median significance that would result from the full combination. It should be emphasized, however, that the discovery significance or exclusion limits determined from real data require one to construct the full likelihood function containing a single parameter \(\mu\), and this must be used in a global fit to find the profile likelihood ratio.

Furthermore, some systematic errors, e.g., the uncertainty in the integrated luminosity, are common to all channels and correspond to a common nuisance parameter. When using Asimov data, the values of such parameters will be fitted to the same values in all channels. Thus the correlations between common systematics are taken into account just as they would be in a global fit of all channels.

A limitation of the procedure with Asimov data is that it only provides an estimate of the median likelihood ratio. To obtain an uncertainty band on the expected (median) discovery and exclusion sensitivities as a function of \(m_{H}\) one would have to simulate a large number of experiments.

#### 2.5.2 Approximate relation between likelihood ratio and significance

To compute the \(p\)-values we need the distribution \(f(q_{\mu}|\mu)\) of \(q_{\mu}=-2\ln\lambda(\mu)\). For a sufficiently large data sample the pdf of \(q_{\mu}\) takes on a well defined limiting form related to the chi-square distribution, as discussed in Section 2.4. Assuming this form, the \(p\)-value of the hypothesis \(\mu\) is found to be

\[p_{\mu}\approx 1-\Phi(\sqrt{q_{\mu}})\, \tag{35}\]

and the significance \(Z\) is given by the formula

\[Z=\Phi^{-1}(1-p_{\mu})\approx\sqrt{-2\ln\lambda(\mu)}. \tag{36}\]

For estimating the median discovery significance we use equations (35) and (36) together with the equation (33), the likelihood ratio based on Asimov data containing signal and background. To find the median limit on \(\mu\), we use again equations (35) and (36) but with the likelihood ratio based on Asimov background data only, equation (34).

The validity of this approximation is investigated for each channel by generating distributions of \(q_{\mu}\) for \(\mu=0,1\) using a fast Monte Carlo simulation and comparing the resulting histograms with the expected asymptotic form. These comparisons are shown in Section 3.

### Consequences of testing many Higgs mass values

The statistical significance of a potential discovery is quantified by giving the \(p\)-value of the no-Higgs hypothesis, i.e., the probability, under the assumption of background only, that that one would see data with equal or less compatibility with this hypothesis relative to the data obtained. Finding this probability below a specified threshold (e.g., the \(5\sigma\) threshold, or \(p<2.87\times 10^{-7}\)) corresponds to claiming discovery of a Higgs boson.

The approach taken in this analysis is to compute the \(p\)-value of the no-Higgs hypothesis separately as a function of the Higgs mass. The threshold \(p\)-value is thus the false discovery rate for Higgs boson of a given mass. Further one should also estimate the probability, under the assumption of background only, that this \(p\)-value will fall below the discovery threshold for _any_ mass within the range considered. By searching for the Higgs within a broad range of hypothetical masses, one increases the probability of observing what appears to be a signal at some mass, and so the effective significance of the discovery is reduced. In HEP this is sometimes referred to as the "look-elsewhere effect".

To first approximation the effective increase in the false-discovery rate is given by the number of statistically separate mass ranges explored. If a certain data set would give a \(p\)-value of \(m_{\rm H}\) below the discovery threshold, then the same data would in general also indicate discovery for other masses very close by. Roughly speaking, the mass range in which a given data set would indicate discovery is set by the mass resolution for the Higgs candidate. So the factor by which the \(p\)-value is inflated is given by the mass range explored divided by the average mass resolution. Monte Carlo studies can be used to validate and refine this approximation; this approach is planned for future analyses.

An alternative to considering fixed Higgs masses is to treat both the strength parameter \(\mu\) and the Higgs mass \(m_{\rm H}\) as free parameters in the likelihood ratio. For example, to establish discovery one computes the \(p\)-value of the no-Higgs hypothesis. As before, this is the probability, under the assumption of no Higgs, of finding data with equal or lesser compatibility with \(\mu=0\) relative to the data obtained. In contrast to the fixed-mass case, however, "less compatible" here means having a lower likelihood ratio for any allowed value of the Higgs mass; the lowest value comes when the denominator contains the fitted maximum-likelihood estimator \(\hat{m}_{\rm H}\). In practice the fitted value of the Higgs mass is restricted to lie within a stated range. This has been done for the Higgs searches using the \(\gamma\gamma\)[4] and \(\rm W^{+}W^{-}\)[5] channels, with the aim of extending this method to a combination of all channels.

## 3 Combination of Higgs search channels

In this section a brief description of each of the four search channels is given. For each channel, the method used to obtain the likelihood ratio is described, and values of the test variable \(q_{\mu}\) as defined by Eq. (10) for discovery and by Eq. (16) for limits are tabulated for several values of the integrated luminosity \(L\) and Higgs mass \(m_{\rm H}\). For the discovery sensitivity where one tests \(\mu=0\), the median value of \(q_{0}\) is given under the assumption of \(\mu=1\); for exclusion sensitivity, the median of \(q_{1}\) is given under the assumption of \(\mu=0\).

In addition, for each channel we show distributions of \(q_{\mu}\) under the assumption of \(\mu\) for the two cases \(\mu=0\) and \(\mu=1\). For the approximations used in this note to be valid, these should be close to the asymptotic form described in Section 2.4. This limiting form for the distribution \(f(q_{\mu}|\mu)\) is a mixture of a delta function at \(q_{\mu}=0\) and a chi-square distribution for one degree of freedom, where each component has equal weight. We refer to this as a \(\frac{1}{2}\chi_{1}^{2}\) distribution. For the case of \(\mu=0\) we compare directly the Monte Carlo distribution of \(q_{0}\) with the \(\frac{1}{2}\chi_{1}^{2}\) distribution and the delta-function term at \(q_{0}=0\) is clearly visible. For \(\mu=1\) we show the equivalent comparison but for reasons of convenience only the events with \(\hat{\mu}\leq\mu\) are shown, i.e., the events with \(\hat{\mu}>\mu\) that contribute to the delta function at \(q_{1}=0\) are left off. That is, for exclusion it is the conditional pdf \(f(q_{1}|\mu=1,\hat{\mu}\leq 1)\) that is compared to a chi-square distribution for one degree of freedom; there is no delta function term.

All channels use data driven background estimation methods. This way, the uncertainties in the background shape and normalization are treated within the framework of the profile likelihood as nuisance parameters. Using control samples the effect of many uncertainties like energy scales and fake rates on the background estimate can be constrained by the control samples. Uncertainties on the signal efficiency do not affect the discovery sensitivity which is testing the presence or absence of a signal; however, this is not the case for exclusion sensitivity. As one would expect, uncertainty in the signal efficiency does reduce the exclusion sensitivity. This uncertainty was incorporated into the profile likelihood calculation by adding an extra term to the likelihood function for every channel as described in Section 2.1: a Gaussian relating the nominal efficiency estimated in an auxiliary measurement, the true efficiency, and the uncertainty of that auxiliary measurement.

### \(H\to\gamma\gamma\)

Details on the \(H\to\gamma\gamma\) channel are given in Ref. [4]. We perform an unbinned maximum-likelihood fit to extract the signal and background event yields by using the diphoton invariant mass, \(m_{\gamma\gamma}\), as a discriminating variable. The \(H\to\gamma\gamma\) distribution of \(m_{\gamma\gamma}\) forms a Gaussian peak with tails to lower values from photon energy losses before the calorimeter. It is well modelled by a _Crystal Ball_ function. The signal probability density function, \(p_{H}(m_{\gamma\gamma})\), is given by

\[p_{H}(m_{\gamma\gamma})=N\cdot\left\{\begin{array}{ll}\exp\left(-t^{2}/2 \right)\,,&\mbox{for $t>-\alpha$}\,,\\ \left(n/|\alpha|\right)^{n}\cdot\exp\left(-|\alpha|^{2}/2\right)\cdot\left(n/ |\alpha|-|\alpha|-t\right)^{-n}\,,&\mbox{otherwise}\,,\end{array}\right. \tag{37}\]

where \(t=(m_{\gamma\gamma}-m_{H}-\delta m_{H})/\sigma(m_{\gamma\gamma})\), \(N\) is a normalisation parameter, \(m_{H}\) is the Higgs boson mass, \(\delta m_{H}\) is an offset and \(\sigma\) represents the diphoton invariant mass resolution. The non-Gaussian tail is parametrised by \(n\) and \(\alpha\). We include an additional, broader Gaussian term in Eq. 37 to improve the description of the tails of the distribution. Within a sufficiently narrow mass window, the background of \(m_{\gamma\gamma}\) is modeled by an exponential distribution with a single slope parameter \(\xi\).

The resulting median profile likelihood ratios for discovery, \(\lambda(\mu=0)\) (using toy \(s+b\) Monte Carlo experiments and taking the median of the \(\lambda(\mu=0)\) distribution ) are given in Table 1 for a few Higgs masses at some given luminosities.

The distribution of the test statistic \(q_{0}\) under the null background only hypothesis, for \(m_{H}=120\) GeV with an integrated luminosity of 2 and 10 fb\({}^{-1}\), is shown in Fig. 6. A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed, showing the validity of the asymptotic approximation.

The median profile likelihood ratio for exclusion, \(-2\ln\lambda(\mu)\) (using toy background-only Monte Carlo experiments and taking the median of the \(\lambda(\mu)\) distribution) is given in Table 2 for a few Higgs masses at several integrated luminosities and for a signal strength \(\mu=1\), corresponding to a Standard Model Higgs Boson.

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline L & \multicolumn{4}{c}{\(m_{H}\) (GeV)} \\ (fb\({}^{-1}\)) & 115 & 120 & 130 & 140 \\ \hline
1 & 0.35 & 0.55 & 0.75 & 0.67 \\
2 & 0.75 & 1.07 & 1.45 & 0.95 \\
5 & 1.95 & 2.95 & 3.65 & 2.55 \\
10 & 3.95 & 5.86 & 7.35 & 5.05 \\
30 & 11.85 & 17.72 & 21.99 & 15.05 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Median values of \(-2\ln\lambda(\mu)\) (evaluated at \(\mu=0\)) obtained from fits to simulated data generated with \(H\to\gamma\gamma\) signal plus background (\(\mu=1\)) for several values of the Higgs mass and integrated luminosity.

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline L & \multicolumn{4}{c}{\(m_{H}\) (GeV)} \\ \(({\rm fb}^{-1})\) & 115 & 120 & 130 & 140 \\ \hline
1 & 0.72 & 0.73 & 0.91 & 0.67 \\
2 & 0.97 & 1.21 & 1.39 & 0.97 \\
5 & 2.11 & 2.59 & 3.13 & 2.23 \\
10 & 3.55 & 4.87 & 5.71 & 4.04 \\
30 & 8.47 & 10.50 & 11.63 & 9.00 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Median values of \(-2\ln\lambda(\mu)\) (evaluated at \(\mu=1\)) obtained from \(H\to\gamma\gamma\) background-only (\(\mu=0\)) simulated data for several values of the Higgs mass and integrated luminosities.

Figure 6: The distribution of the test statistic \(q_{0}\) (for \(H\to\gamma\gamma\)), under the null background only hypothesis, for \(m_{H}=120\) GeV with an integrated luminosity of 2 (a) and 10 (b) fb\({}^{-1}\). A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed.

[MISSING_PAGE_EMPTY:18]

background is determined using the same variation of the background parameters. It was found that the median \(p\)-value of the background-only hypothesis, with the median computed under assumption of the \(s+b\) hypothesis, is very similar to the original case where the QCD shape parameters are not varied and the \(\frac{1}{2}\chi_{1}^{2}\) distribution is used.

For the combination of results for discovery (i.e., testing \(\mu=0\)), we have used the \(p\)-values as described above for the case of the \(H+0j\) channel. The same variation of QCD WW parameters was also investigated for the case of exclusion (i.e., testing \(\mu>0\), and in particular \(\mu=1\)), and it was done as well for the \(H+2j\) channel. In those studies, however, the distributions, under the assumption of \(\mu\), of the test statistic \(q_{\mu}\) were found to agree quite well with the expected \(\frac{1}{2}\chi_{1}^{2}\) distribution, even after the parameter variation. Therefore for these cases we have based the combination of results on the asymptotic approximations for the \(q_{\mu}\) distributions (as done in this paper for the other Higgs channels).

To simplify the comparison with the other channels, the median \(p\)-values of the background-only (\(\mu=0\)) hypothesis for the \(H+0j\) channel were converted into effective values of the variable \(q_{0}=-2\ln\lambda(0)\) according to \(q_{0}=Z^{2}=\left(\Phi^{-1}(1-p)\right)^{2}\). These are given in Table 3 for several Higgs masses and integrated luminosities.

The median profile likelihood ratio for exclusion, \(\lambda(\mu)\) (using background-only MC experiments and taking the median of the \(\lambda(\mu)\) distribution), is given in Table 4 for several Higgs masses and integrated luminosities for the signal strength \(\mu=1.0\), corresponding to a SM Higgs Boson.

The distribution of the statistic \(q_{1}\) for \(\hat{\mu}\leq 1\) under the \(s+b\) hypothesis is shown in Fig. 9 for \(m_{H}=150\) GeV and for an integrated luminosity of 2 and 10 fb\({}^{-1}\). A \(\chi_{1}^{2}\) distribution is superimposed, showing the

\begin{table}
\begin{tabular}{c|c c c c c c c} \hline \hline \(L\) & & & & \(m_{H}\) (GeV) & & & \\ (fb\({}^{-1}\)) & 130 & 140 & 150 & 160 & 170 & 180 & 190 \\ \hline
1 & 1.64 & 4.30 & 9.56 & 16.52 & 15.39 & 7.37 & 3.17 \\
2 & 2.87 & 8.60 & 19.36 & 34.67 & 30.58 & 13.73 & 5.63 \\
5 & 6.55 & 20.15 & 42.77 & 74.39 & 63.58 & 31.54 & 13.54 \\
10 & 11.52 & 33.27 & 70.67 & 113.33 & 103.44 & 51.06 & 22.78 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Median values of \(-2\ln\lambda(\mu=0)\) obtained from \(H+0j\) fits using data simulated under the assumption of signal plus background (\(\mu=1\)) for several values of the Higgs mass and integrated luminosity.

Figure 8: The distribution of the test statistic \(q_{0}\) for \(H+0j\to WW+0j\), under the background-only hypothesis, with the same fixed QCD WW shape parameters used at both the generator and the fit level, for \(m_{H}=150\) GeV and for an integrated luminosity of 10 fb\({}^{-1}\) (a) with the same shape parameters for event generation and fitting; (b) with altered shape parameters. A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed.

validity of the asymptotic approximation.

#### 3.2.2 \(H+2j\)

The \(H+2j\) analysis uses a two-dimensional fit based on the transverse mass and the output of a Neural Network, which takes as input several kinematic variables related to the jet activity in the event. The fit is performed simultaneously in signal-enriched and background-enriched regions distinguished by lepton angular variables, which are nearly uncorrelated to the jet variables used in the Neural Network.

The median profile likelihood ratios for discovery, \(-2\ln\lambda(\mu=0)\) (using toy \(s+b\) MC experiments and taking the median of the \(\lambda(\mu=0)\) distribution), are given in Table 5 for several Higgs masses and integrated luminosities.

The distribution of the statistic \(q_{0}\) under the background-only hypothesis is shown in Fig. 10 for \(m_{H}=150\) GeV and for an integrated luminosity of 2 and 10 fb\({}^{-1}\). A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed, showing the validity of the asymptotic approximation.

The median profile likelihood ratio for exclusion, \(-2\ln\lambda(\mu)\) with \(\mu=1\), where the median is computed using background-only MC data, is given in Table 6 for several Higgs masses and integrated luminosities.

The distribution of the test statistic \(q_{1}\) for \(\hat{\mu}\leq 1\) under the \(s+b\) hypothesis is shown in Figures 11 for \(m_{H}=150\) GeV with an integrated luminosity of 2 and 10 fb\({}^{-1}\). A \(\chi_{1}^{2}\) distribution is superimposed, showing the validity of the asymptotic approximation.

\begin{table}
\begin{tabular}{c|c c c c c c c} \hline \hline \(L\) & \multicolumn{8}{c}{\(m_{H}\) (GeV)} \\ (fb\({}^{-1}\)) & 130 & 140 & 150 & 160 & 170 & 180 & 190 \\ \hline
1 & 1.37 & 3.93 & 8.69 & 14.83 & 14.23 & 7.26 & 3.26 \\
2 & 2.57 & 7.47 & 15.59 & 25.20 & 23.65 & 12.91 & 5.84 \\
5 & 5.85 & 15.26 & 30.05 & 45.60 & 41.13 & 25.41 & 12.02 \\
10 & 10.01 & 24.69 & 45.24 & 62.13 & 57.69 & 37.42 & 20.03 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Median values of \(-2\ln\lambda(\mu=1)\) obtained from \(H+0j\) fits using simulated background-only (\(\mu=0\)) data for several values of the Higgs mass and integrated luminosity.

\begin{table}
\begin{tabular}{c|c c c c c c c} \hline \hline \(L\) & \multicolumn{8}{c}{\(m_{H}\) (GeV)} \\ (fb\({}^{-1}\)) & 130 & 140 & 150 & 160 & 170 & 180 & 190 \\ \hline
1 & 0.37 & 0.75 & 1.31 & 2.29 & 2.44 & 1.99 & 0.95 \\
2 & 0.87 & 2.49 & 5.06 & 8.18 & 7.74 & 3.85 & 1.90 \\
5 & 1.40 & 3.13 & 5.86 & 9.58 & 9.90 & 7.89 & 4.59 \\
10 & 2.80 & 6.56 & 10.72 & 16.14 & 16.62 & 13.94 & 8.74 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Median values of \(-2\ln\lambda(\mu)\) for \(\mu=1\) obtained from \(H+2j\) fits to simulated background-only (\(\mu=0\)) data for several values of the Higgs mass and integrated luminosity.

Figure 10: The distribution of the test statistic \(q_{0}\) (for \(H+2j\to WW+2j\)), under the null background only hypothesis, for \(m_{H}=150\) GeV and for an integrated luminosity of 2 (a) and 10 (b) \(fb^{-1}\). A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed.

\begin{table}
\begin{tabular}{c|c c c c c c c} \hline \hline \(L\) & \multicolumn{8}{c}{\(m_{H}\) (GeV)} \\ (fb\({}^{-1}\)) & 130 & 140 & 150 & 160 & 170 & 180 & 190 \\ \hline
1 & 0.39 & 0.89 & 1.61 & 2.73 & 2.89 & 1.85 & 1.23 \\
2 & 0.70 & 1.75 & 3.22 & 5.34 & 5.67 & 3.66 & 2.07 \\
5 & 2.01 & 5.29 & 8.87 & 14.20 & 14.58 & 9.22 & 5.71 \\
10 & 3.82 & 9.14 & 16.56 & 26.35 & 26.05 & 16.68 & 9.93 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Median values of \(-2\ln\lambda(\mu)\) for \(\mu=0\) obtained from \(H+2j\) fits to simulated data with signal plus background (\(\mu=1\)) for several values of the Higgs mass and integrated luminosity.

### \(H\to\tau^{+}\tau^{-}\)

The sensitivity of the ATLAS detector to a Higgs boson produced via Vector Boson Fusion and decaying to tau leptons has been investigated [6].

Two tau decay channels are considered: \(ll\) and \(lh\). Although there are several neutrinos in the event, it is possible to reconstruct the \(\tau^{+}\tau^{-}\) invariant mass, \(m_{\tau\tau}\), by making the collinear approximation, in which the decay products of the \(\tau\) are assumed to be collinear with the \(\tau\) direction in the laboratory frame. After other event selection criteria are imposed, the spectrum of \(m_{\tau\tau}\) is used to extract the signal. Particular care has been given to the incorporation of uncertainty in both the rate and shape for the signal and backgrounds.

A data-driven background estimation technique has been established for the major backgrounds. Each technique has been developed to address the aspects of the background estimation which are most relevant for the analysis: the shape of the \(m_{\tau\tau}\) tail from the irreducible \(Z\to\tau\tau\), the fake tau contribution in the \(lh\)-channel, and the normalization of the QCD backgrounds.

In addition to the \(m_{\tau\tau}\) spectrum from the \(Z\to\tau\tau\) and QCD control samples, a track multiplicity distribution is used to constrain the fraction of QCD events in the \(lh\)-channel. This likelihood term is denoted \(L_{track}(r_{QCD},r_{tau})\), where \(r_{tau}\) (\(r_{QCD}\)) denotes the fraction of real taus (fakes from jets) in the sample. The track multiplicity distribution for the QCD jets is modelled from samples of QCD di-jets that produce tau candidates.

The shape of the \(m_{\tau\tau}\) distribution for signal and \(Z\to\tau\tau\) events is dictated by the resolution of \(\not{E}_{T}\) and the kinematics of the collinear approximation. The parameterization of \(m_{\tau\tau}\) for the signal and \(Z\to\tau\tau\) background are based on the kinematics of the collinear approximation and reproduces an asymmetric distribution with non-Gaussian tails. This distribution is dependent on the overall width width, \(\sigma_{H/Z}\), and a mean, \(m_{H/Z}\).

A \(Z\to\tau\tau\) control sample is used to constrain the mean, \(m_{Z}\), and the overall width of the distribution, \(\sigma_{Z}\), which are the only free parameters in the \(Z\to\tau\tau\) background model. The error bars in the control sample were scaled to 10% to account for the 10% shape uncertainty in the \(\mu\to\tau\) rescaling method.

The shapes for \(W+\)jets and \(t\bar{t}\) are very similar and are modelled with a single distribution. A conservative 50% error is applied to each bin in the combined QCD (i.e., \(t\bar{t}\) and \(W+\)jets) control sample to reflect uncertainty in how this shape changes as the remainder of the analysis cuts are applied.

Figure 11: The distribution of the test statistic \(q_{1}\) for \(\not{\mu}\leq 1\) under the \(s+b\) (\(\mu=1\)) hypothesis (for \(H+2j\to WW+2j\)), for \(m_{H}=150\) GeV with an integrated luminosity of (a) \(2\,\mathrm{fb}^{-1}\) and (b) \(10\,\mathrm{fb}^{-1}\). A \(\chi_{1}^{2}\) distribution is superimposed.

The shape of the QCD background was parametrized with the following equation:

\[L_{QCD}(m_{\tau\tau}|a_{1},a_{2},a_{3})={\cal N}\left(\frac{1}{m_{\tau\tau}+a_{1} }\right)^{a_{2}}m_{\tau\tau}^{a_{3}}. \tag{38}\]

The form is motivated by a competition between the parton distribution functions and the matrix element. In the \(lh\)-channel, the normalization of the backgrounds with fake taus can be constrained by using the track multiplicity method described above. We apply a conservative 50% systematic on this fraction.

By fitting the \(m_{\tau\tau}\) spectrum to a model that accurately describes the signal and various backgrounds it is possible to directly incorporate uncertainty in the background shape and take advantage of the shape of the signal within the mass window. We utilize the profile likelihood ratio as our test statistic. The likelihood function corresponding to the simultaneous fit is simply a product of the likelihoods from the individual measurements:

\[L(data|\mu,m_{H},\nu) = L_{track}(\mbox{track multiplicity}|r_{QCD})\times L_{Z}(\mbox{Z +jets control}|m_{Z},\sigma_{Z}) \tag{39}\] \[\times L_{QCD}(\mbox{QCD control}|a_{1},a_{2},a_{3})\] \[\times L_{s+b}(\mbox{signal candidates}|\mu,m_{H},\sigma_{H},m_{Z}, \sigma_{Z},r_{QCD},a_{1},a_{2},a_{3}),\]

where the \(a_{i}\) are the parameters used to parametrize the QCD background and \(\nu\) represents all nuisance parameters of the model: \(\sigma_{H},m_{Z},\sigma_{Z},r_{QCD},a_{1},a_{2},a_{3}\).

The data-driven background estimation methods described above have been developed so that uncertainty in the background shape and normalization are included directly into the significance calculation. Because the discovery criterion is simply testing the presence or absence of the signal, it is not sensitive to some of the sources of systematic uncertainty. In contrast, measurement and exclusion of \(\sigma(pp\to qqH)\times BR(H\to\tau\tau)\) are sensitive to the uncertainty on the signal selection efficiency. Both experimental and theoretical sources of uncertainty on the signal efficiency have been evaluated. The jet energy scale uncertainty dominates in this channel, and a signal efficiency uncertainty of 18% was used when estimating the exclusion sensitivity.

The median profile likelihood ratios for discovery, \(\lambda(\mu=0)\) (using the Asimov data sets with \(\mu_{A}=1\)), are given in Table 7 for a few Higgs masses at some given luminosities. The distribution of the test statistic \(q_{0}\) under the null background only hypothesis, for \(m_{H}=130\) GeV with an integrated luminosity of 2 and 10 fb\({}^{-1}\), is shown in Figure 12. A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed, showing the validity of the asymptotic approximation.

The resulting median profile likelihood ratio for exclusion, \(\lambda(\mu)\) (using the Asimov data sets, \(\mu_{A}=0\)), is given in Table 8 for a few Higgs masses at some given luminosities and signal strength \(\mu=1.0\) corresponding to a Standard Model Higgs Boson.

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline L & \multicolumn{4}{c}{\(m_{H}\) (GeV)} \\ (fb\({}^{-1}\)) & 110 & 120 & 130 & 140 \\ \hline
1 & 0.59 & 0.88 & 0.72 & 0.46 \\
2 & 1.18 & 1.74 & 1.40 & 0.89 \\
5 & 2.91 & 4.43 & 3.34 & 2.08 \\
10 & 5.81 & 8.23 & 6.37 & 3.91 \\
30 & 17.2 & 23.6 & 17.6 & 10.6 \\ \hline \hline \end{tabular}
\end{table}
Table 7: Median values of \(-2\ln\lambda(\mu=0)\) obtained from \(H\to\tau^{+}\tau^{-}\) simulated data generated with signal plus background (\(\mu=1\)) for several values of the Higgs mass and integrated luminosity.

Figure 12: The distribution of the test statistic \(q_{0}\) for \(H\to\tau^{+}\tau^{-}\) under the null background-only hypothesis, for \(m_{H}=130\,\)GeV with an integrated luminosity of 2 (a) and 10 (b) fb\({}^{-1}\). A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed. Figures (c) and (d) show \(1-F(q_{0})\) where \(F(q_{0})\) is the corresponding cumulative distribution. The small excess of events at high \(q_{0}\) is statistically compatible with the expected curves, as can be seen by comparison with the dotted histograms that show the 68.3% central confidence intervals for \(p=1-F(q_{0}|0)\). The lower dotted line at \(2.87\times 10^{-7}\) shows the \(5\sigma\) discovery threshold.

The distribution of the test statistic \(q_{1}\) for \(\hat{\mu}\leq 1\) under the \(s+b\) hypotheses for \(m_{H}=130\,\mathrm{GeV}\) with an integrated luminosity of 2 and 10 fb\({}^{-1}\) is shown in Figures 13. A \(\chi_{1}^{2}\) distribution is superimposed, showing the validity of the asymptotic approximation.

### \(H\to ZZ^{(*)}\to 4l\)

Details of the \(H\to ZZ^{(*)}\to 4l\) channel can be found in Ref. [7]. The main challenge of this channel for what concerns statistical analysis is its relevance over a very wide mass range (from \(m_{H}\) around 120 GeV up to 700 GeV), over which the shapes and cross sections of both signal and background show considerable variations.

While in principle it would be possible to divide the mass range in different regions and use separate models for each of them, using a unique background model for the whole phase space is a better approach, since it allows to estimate discovery and exclusion significance at any mass, without having to worry about boundaries between different models. This will be needed of course when the analysis is performed using real data, where \(m_{H}\) is unknown.

The main background after event filtering in this channel is the irreducible \(ZZ\to 4l\) process. Reducible backgrounds such as \(Zb\bar{b}\to 4l+X\) or \(t\bar{t}\) give a negligible contribution to the overall shape, with the only exception of the \(m_{H}=120\,\mathrm{GeV}\) case, where \(Zb\bar{b}\to 4l+X\) modifies the background shape in the low mass region, and it must therefore be taken into account.

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline L & \multicolumn{5}{c}{\(m_{H}\,(\mathrm{GeV})\)} \\ (fb\({}^{-1}\)) & 110 & 120 & 130 & 140 \\ \hline
1 & 0.64 & 0.71 & 0.52 & 0.32 \\
2 & 1.31 & 1.41 & 1.03 & 0.64 \\
5 & 3.30 & 3.42 & 2.52 & 1.56 \\
10 & 6.93 & 7.79 & 7.18 & 3.48 \\
30 & 15.3 & 16.6 & 12.8 & 8.48 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Median values of \(-2\ln\lambda(\mu=1)\) obtained from \(H\to\tau^{+}\tau^{-}\) background-only (\(\mu=0\)) simulated data for several values of the Higgs mass and integrated luminosities.

The irreducible background has been modelled using a combination of Fermi functions which are suitable to describe both the plateau in the low mass region and the broad peak corresponding to the second Z coming _on shell_. The chosen model is described by the following function:

\[\frac{p0}{(1+e^{\frac{p0-M_{ZZ}}{p^{3}}})(1+e^{\frac{M_{ZZ}-p8}{p^{3}}})}+\frac{ p1}{(1+e^{\frac{p2-M_{ZZ}}{p^{3}}})(1+e^{\frac{p4-M_{ZZ}}{p^{3}}})}\,. \tag{40}\]

The first plateau, in the region where only one of the two Z bosons is _on shell_, is modelled by the first term, and its suppression, needed for a correct description at higher masses, is controlled by the \(p8\) and \(p9\) parameters. The second term in the above formula accounts for the shape of the broad peak and the tail at high masses. This function can describe with a negligible bias the ZZ background shape with good accuracy over the full mass range.

As already mentioned, the \(Zb\bar{b}\) contribution is relevant only when searching for very light Higgs bosons (in this study, only \(m_{H}=120\,\mathrm{GeV}\)). In this case, an additional term is added to the ZZ continuum, with a functional form similar to the second part of equation 40. For what concerns signal modelling, a simple Gaussian shape has been used for \(m_{H}\leq 300\,\mathrm{GeV}\), while a relativistic Breit-Wigner formula was needed to properly describe the big tails arising at higher values of the Higgs mass.

In the fits to determine the profile likelihood ratio, \(m_{H}\) is fixed to the hypothesized value, while \(\sigma_{H}\) is allowed to float in a \(\pm 20\%\) range around the value obtained from the signal Monte Carlo distributions. All the parameters describing the background shape are floating within sensible ranges. Given the complexity of the model involved, the fit can from time to time get trapped into local minima. While there is no easy way to avoid this problem, the fake measurements obtained in this case are easy to distinguish from the correct ones, and a repetition of the fit from a different starting point is enough to solve the problem.

The resulting median profile likelihood ratios for discovery, \(-2\ln\lambda(\mu=0)\), with the median computed using toy \(s+b\) MC data (i.e., with \(\mu=1\)), are given in Table 9 for several values of the Higgs mass and integrated luminosity.

The distribution of the test statistic \(q_{0}\) under the null background-only hypothesis, for \(m_{H}=200\) GeV with an integrated luminosity of 2 and \(10\,\mathrm{fb}^{-1}\), is shown in Fig. 14. A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed, showing the validity of the asymptotic approximation.

The resulting median profile likelihood ratio for exclusion, \(\lambda(\mu)\) (using toy background-only MC experiments and taking the median of the \(\lambda(\mu)\) distribution), is given in Table 10 for several Higgs masses and luminosities using a signal strength \(\mu=1.0\) corresponding to a Standard Model Higgs boson.

The distribution of the test statistic \(q_{1}\) for \(\hat{\mu}\leq 1\) under the \(s+b\) hypothesis for \(m_{H}=200\) GeV with an integrated luminosity of 2 and \(10\,\mathrm{fb}^{-1}\) is shown in Figures 15. A \(\chi_{1}^{2}\) dist

\begin{table}
\begin{tabular}{c|c c c c c c c c c c c} \hline \hline L & \multicolumn{10}{c}{\(m_{H}\) (GeV)} \\ (\(\mathrm{fb}^{-1}\)) & 120 & 130 & 140 & 150 & 160 & 165 & 180 & 200 & 300 & 400 & 500 & 600 \\ \hline
1 & 0.22 & 1.20 & 3.98 & 5.35 & 1.65 & 0.49 & 0.86 & 6.86 & 5.20 & 3.55 & 0.88 & 0.31 \\
2 & 0.44 & 2.40 & 7.96 & 10.7 & 3.30 & 0.98 & 1.71 & 13.7 & 10.4

\begin{table}
\begin{tabular}{c|c c c c c c c c c c c c} \hline \hline L & \multicolumn{10}{c}{\(m_{H}\) (GeV)} \\ (fb\({}^{-1}\)) & 120 & 130 & 140 & 150 & 160 & 165 & 180 & 200 & 300 & 400 & 500 & 600 \\ \hline
1 & 0.16 & 0.93 & 2.25 & 3.12 & 1.23 & 0.39 & 0.51 & 4.86 & 2.86 & 2.36 & 0.87 & 0.28 \\
2 & 0.33 & 1.85 & 4.50 & 6.22 & 2.4 & 0.75 & 1.90 & 9.64 & 5.68 & 4.69 & 1.74 & 0.56 \\
5 & 0.83 & 4.60 & 11.2 & 15.4 & 6.09 & 2.28 & 4.74 & 23.5 & 14.0 & 11.6 & 4.32 & 1.39 \\
10 & 1.60 & 9.14 & 22.0 & 30.3 & 12.1 & 3.86 & 5.05 & 45.2 & 27.3 & 22.7 & 8.57 & 2.77 \\
30 & 4.78 & 26.8 & 63.0 & 85.3 & 35.1 & 11.4 & 14.7 & 105 & 74.1 & 63.0 & 24.9 & 8.22 \\
60 & 8.90 & 51.7 & 117 & 155 & 66.9 & 22.3 & 28.0 & 174 & 129 & 113 & 47.6 & 16.1 \\ \hline \hline \end{tabular}
\end{table}
Table 10: Median values of \(-2\ln\lambda(\mu=1)\) obtained from \(H\to ZZ^{(\ast)}\to 4l\) simulated data generated with background only (\(\mu=0\)) for several values of the Higgs mass and integrated luminosity.

Figure 14: The distribution of the test statistic \(q_{0}\) (for \(H\to 4l\)), under the null background only hypothesis, for \(m_{H}=200\) GeV with an integrated luminosity of 2 (a) and 10 (b) fb\({}^{-1}\). A \(\frac{1}{2}\chi_{1}^{2}\) distribution is superimposed. Figures (c) and (d) show \(1-F(q_{0})\) where \(F(q_{0})\) is the corresponding cumulative distribution. The small excess of events at high \(q_{0}\) is statistically compatible with the expected curves, as can be seen by comparison with the dotted histograms showing the 68.3% central confidence intervals for \(p=1-F(q_{0}|0)\). The lower dotted line at \(2.87\times 10^{-7}\) shows the \(5\sigma\) discovery threshold.

showing the validity of the asymptotic approximation.

### Limitations of the approximations used

The distributions shown in Sections 3.1 through 3.4 show varying levels of agreement between the asymptotic chi-square form and the results of Monte Carlo simulations. For the \(WW\) (0 jet) channel (Fig. 8), the discrepancy in the distribution of \(q_{0}\) is very large, and this is understood to arise from the special manner in which the systematic uncertainties for this channel were treated. The distribution of \(q_{0}\) for the \(WW\) (0 jet) channel therefore does not use the asymptotic formula. This is the only channel for which the approximation was not applied.

For other cases such as the distribution of \(q_{1}\) for the \(H\to\gamma\gamma\) channel shown in Fig. 7, the Monte Carlo distribution falls off significantly faster than the chi-square curve. This means that the significance with which one excludes the tested hypothesis will be less when estimated from the chi-square curve, leading to conservative limits. As the integrated luminosity increases, one expects to the asymptotic formula to become more accurate.

In some of the distributions such as that of \(q_{0}\) for the \(H\to ZZ^{(*)}\to 4l\) channel shown in Fig. 14, the Monte Carlo simulation indicates a slight excess over the chi-square curve in the tail region. The level of the excess is not statistically significant in the part of the distribution that can be meaningfully assessed given the amount of Monte Carlo data available (out to \(q_{0}\) between around 9 to 16, i.e., to the level of a 3 to 4\(\sigma\) discovery). At present it is not practical to verify directly that the chi-square formula remains valid to the 5\(\sigma\) level (i.e., out to \(q_{0}=25\)). Thus the results on discovery significance presented here rest on the assumption that the asymptotic distribution is a valid approximation to at least the 5\(\sigma\) level.

The validation exercises carried here out indicate that the methods used should be valid, or in some cases conservative, for an integrated luminosity of at least 2 fb\({}^{-1}\). At earlier stages of the data taking, one will be interested primarily in exclusion limits at the 95% confidence level. For this the distributions of the test statistic \(q_{\mu}\) at different values of \(\mu\) can be determined with a manageably small number of events. It is therefore anticipated that we will rely on Monte Carlo methods for the initial phase of the experiment.

Figure 15: The distribution of the test statistic \(q_{1}\) for \(\hat{\mu}\leq 1\) under the \(s+b\) hypothesis (for \(H\to 4l\)), for \(m_{H}=200\) GeV with an integrated luminosity of (a) 2 fb\({}^{-1}\) and (b) 10 fb\({}^{-1}\). A \(\chi_{1}^{2}\) distribution is superimposed.

Results of the combination

### Combined discovery sensitivity

The full discovery likelihood ratio for all channels combined, \(\lambda_{s+b}(0)\), is calculated using Eq. 33. This uses the median likelihood ratio of each channel, \(\lambda_{s+b,i}(0)\), found either by generating toy experiments under the \(s+b\) hypothesis and calculating the median of the \(\lambda_{s+b,i}\) distribution or by approximating the median likelihood ratio using the Asimov data sets with \(\mu_{A,i}=1\). Both approaches were validated to agree with each other. The discovery significance is calculated using Eq. 36, i.e., \(Z\approx\sqrt{-2\ln\lambda(0)}\), where \(\lambda(0)\) is the combined median likelihood ratio.

The resulting significances per channel and the combined one are shown in Fig. 16 for an integrated luminosity of \(10\) fb\({}^{-1}\).

The median discovery significance as a function of the integrated luminosity and Higgs mass is shown colour coded in Fig. 17. The full line indicates the \(5\sigma\) contour. Note that the approximations used do not hold for very low luminosities (where the expected number of events is low) and therefore the results below about \(2\) fb\({}^{-1}\) should be taken as indications only. In most cases, however, the approximations tend to underestimate the true median significance.

### Combined exclusion sensitivity

The full likelihood ratio of all channels used for exclusion for a signal strength \(\mu\), \(\lambda_{b}(\mu)\), is calculated using Eq. 34 with the median likelihood ratios of each channel, \(\lambda_{b,i}(\mu)\), calculated, either by generating toy experiments under the \(b\)-only hypothesis and calculating the median of the \(\lambda_{b,i}\) distribution or approximating the median likelihood ratio using the Asimov data sets with \(\mu_{A,i}=0\). Both approaches were checked to agree with each other. A signal strength \(\mu=1\) corresponds to the Standard Model Higgs boson.

Any exclusion of \(\mu(m_{H})\) smaller than 1 corresponds to an exclusion of a Standard Model Higgs boson with a mass \(m_{H}\). To probe the median sensitivity for excluding a Standard Model Higgs boson we follow Eq. 35 and calculate the corresponding \(p\)-value for \(\mu=1\), \(p_{1}\) for a given luminosity at a given Higgs mass. A \(p\)-value of 0.05 corresponds to a significance (Eq. 36) of 1.64. The resulting \(p_{1}\) for the various channels as well as for the combination, for a luminosity of \(2\) fb\({}^{-1}\), are shown in Fig. 18. Note that any \(p\)-value below 0.05 indicates an exclusion. We therefore conclude that with a luminosity of \(2\) fb\({}^{-1}\) ATLAS has the median sensitivity to exclude a Standard Model Higgs boson heavier than 115 GeV

Figure 16: The median discovery significance for the various channels and the combination with an integrated luminosity of \(10\) fb\({}^{-1}\) for (a) the lower mass range (b) for masses up to 600 GeV.

at the 95% Confidence Level. This can also be seen from Fig. 19, which shows the luminosity required to exclude a Higgs boson with a mass \(m_{H}\) at a given confidence level from the combination of the four channels explored in this note.

The sharp increase in the required luminosity for lower \(m_{H}\) seen in Fig. 17 reflects the decrease in sensitivity to the Higgs when using only the set of channels considered here. Further developments will increase the sensitivity in this region. For example, improved analysis methods for the \(H\to\gamma\gamma\) channel are described in Ref. [4], including a separation of the events into those with zero or two accompanying jets. Additional final states such as \(t\overline{t}H\) with \(H\to b\overline{b}\) will help somewhat, although the contribution to the sensitivity will be small because of the large uncertainties in the background.

For the \(WW\) channel, the present study includes only the \(e\nu\mu\nu\) decay mode, but it is planned to

Figure 17: Significance contours for different Standard Model Higgs masses and integrated luminosities. The thick curve represents the \(5\sigma\) discovery contour. The median significance is shown with a colour according to the legend. The hatched area below \(2~{}\mathrm{fb}^{-1}\) indicates the region where the approximations used in the combination are not accurate, although they are expected to be conservative.

Figure 18: The median \(p\)-value obtained for excluding a Standard Model Higgs Boson for the various channels as well as the combination for (a) the lower mass range (b) for masses up to 600 GeV.

include \(evev\), \(\mu\nu\mu\nu\) and \(qql\nu\) as well. The \(ZZ^{(*)}\) channel here only includes \(Z\) decays to \(ee\) and \(\mu\mu\), but in future analyses \(qq\nu\nu\) will be included. The additional \(WW\) and \(ZZ^{(*)}\) modes have been found to have sensitivity for a high-mass Higgs. Finally, combination with the results from ATLAS with those of CMS will of course result in an overall increase in sensitivity.

## 5 Conclusions

The procedure for combination of search results based on the profile likelihood ratio has been applied to a study of the search for the Standard Model Higgs boson using four search channels: \(H\to\tau^{+}\tau^{-}\), \(H\to W^{+}W^{-}\to ev\mu\nu\), \(H\to\gamma\gamma\) and \(H\to ZZ^{(*)}\to 4\) leptons. The combination method is very general and can be applied to essentially any search that will be carried out at the LHC.

The study here has not exploited all of the search channels that will be investigated and therefore the current estimates of the sensitivity can be regarded as conservative. For example, using further decay modes in the \(ZZ\) and \(WW\) channels will provide additional sensitivity especially for a Higgs boson in the higher mass range.

The studies have exploited a series of useful approximations that allow one to determine the median discovery and exclusion sensitivities from a combined fit in a manner that only requires separate input ingredients from the individual channels. The determination of the significance for a given (e.g., real) data set, however, will require a simultaneous fit of all of the channels.

It is not practical at present to generate enough Monte Carlo data to verify directly that the tail of the profile likelihood distribution is well described to the level required for discovery at the \(5\sigma\) level, corresponding to an upper tail area of \(2.87\times 10^{-7}\). The estimates of discovery significance presented here therefore rely on the assumption that the large-sample approximation used remains valid out to this level.

The validation studies shown in Section 3 indicate that the approximations used should be reasonably accurate or lead to conservative limits for an integrated luminosity of at least 2 fb\({}^{-1}\). For the earlier

Figure 19: The expected luminosity required to exclude a Higgs boson with a mass \(m_{H}\) at a confidence level given by the corresponding colour. The hatched area below 2 fb\({}^{-1}\) indicates the region where the approximations used in the combination are not accurate, although they are expected to be conservative.

stages of the experiment it is expected that one will need to rely on Monte Carlo methods, which should be feasible for exclusion limits at the 95% confidence level.

The profile likelihood ratio treats systematic errors by associating the uncertainties with adjustable (nuisance) parameters. Other methods for treating systematic uncertainties can also be considered. Using Bayesian methods, for example, one would associate a prior probability density with the nuisance parameters. We plan to develop and use this and other approaches in parallel with the profile likelihood method for searches at the LHC.

The study presented in this paper provides the discovery significance for a Higgs boson of a specific mass. That is, the traditional discovery threshold \(p\)-value of \(2.87\times 10^{-7}\) corresponding to a 5\(\sigma\) effect for a given hypothesized Higgs mass refers to the false discovery rate for a Higgs of that mass. The false discovery rate for a Higgs of _any_ mass is higher, and several approaches are being pursued to quantify this (the so-called 'look-elsewhere effect'). The most mature of these methods involves using a simultaneous fit of the Higgs mass \(m_{\rm H}\) and the strength parameter \(\mu\) (or equivalently the Higgs production rate), as has been discussed in the studies of \(H\to\gamma\gamma\)[4] and \(H\to W^{+}W^{-}\)[5].

To summarize, the studies based on the four channels considered in this note confirm the good discovery and exclusion sensitivities already shown in the ATLAS Technical Design Report (TDR) [10]. Furthermore the results here are based on better knowledge and a more realistic simulation of the detector than what is described in the TDR. Because of the approximations used, the present studies are valid only for luminosities above \(2\,\mathrm{fb}^{-1}\). With a luminosity of \(2\,\mathrm{fb}^{-1}\) the expected (median) sensitivity is at the 5\(\sigma\) level or greater for discovery of a Higgs boson in the mass range between 143 and 179 GeV, and the expected upper limit at 95% confidence level on the Higgs mass is 115 GeV.

## Appendix A Comparison with procedures used at LEP

In this appendix we compare the procedures described in the present analysis with those used in searches carried out at LEP. More details on these methods be found in [8]. The important differences involve the definition of the test statistic used and the treatment of systematic uncertainties. In addition, the LEP analyses adopted a special procedure to prevent spurious exclusion due to a downward fluctuation of the number of events (the CL\({}_{s}\) method, see below).

In the LEP Higgs searches, a hypothesized value of the Higgs mass \(m_{H}\) was tested by constructing the statistic

\[Q=\frac{L_{s+b}}{L_{b}}=\frac{L(\mu=1)}{L(\mu=0)}\;, \tag{41}\]

where as before \(b\) (\(\mu=0\)) represents the background-only hypothesis and \(s+b\) (\(\mu=1\)) refers to background plus signal at the rate predicted by the Standard Model. For convenience the equivalent logarithmic variable \(q=-2\ln Q\) was used.

The sampling distribution of \(Q\) was determined by Monte Carlo simulation. The Monte Carlo was also used to incorporate systematic errors by sampling values of the corresponding nuisance parameters from pdfs that reflected their uncertainties. That is, one effectively integrated the product of the likelihood and prior pdfs for the nuisance parameters.

For a give observed value \(q_{\rm obs}=-2\ln Q_{\rm obs}\), the \(p\)-values for the \(s\) and \(s+b\) hypotheses were determined as

\[p_{s+b} = \int_{q_{\rm obs}}^{\infty}f(q|s+b)\,dq\equiv{\rm CL}_{s+b}\;, \tag{42}\] \[p_{b} = \int_{-\infty}^{q_{\rm obs}}f(q|b)\,dq\equiv 1-{\rm CL}_{b}\;. \tag{43}\]Having determine the \(p\)-values, the LEP analyses then based exclusion of the \(s+b\) hypothesis not on the \(p\)-value of \(s+b\) but rather on the ratio \(\rm CL_{s}\), defined as

\[\rm CL_{s}=\frac{\rm CL_{s+b}}{\rm CL_{b}}=\frac{p_{s+b}}{1-p_{b}}\;. \tag{44}\]

The signal-plus-background hypothesis was said to be excluded at confidence level \(\rm CL=1-\alpha=0.95\) if one finds

\[\rm CL_{s}<\alpha\;. \tag{45}\]

Since \(\rm CL_{b}\leq 1\), one has \(\rm CL_{s}\geq\rm CL_{s+b}\). Therefore the \(\rm CL_{s}\) method will not exclude as large a region of parameter space as that based on the signal-plus-background \(p\)-value (\(\rm CL_{s+b}\) method). As the \(\rm CL_{s+b}\) method was designed to provide an interval that brackets the true value of the parameter with a probability of at least \(1-\alpha\), the \(\rm CL_{s}\) limit must cover the true parameter with a greater probability; it is in this sense conservative. The \(\rm CL_{s}\) method was devised so as to avoid the problem where a downward fluctuation in the number of background events can lead to exclusion of the Higgs mass considered, even for hypothesized mass values where one does not expect to be sensitive to Higgs production [9].

In contrast, in the present analysis we test a hypothesized value of the strength parameter \(\mu\) using

\[q_{\mu}=-2\ln\frac{L(\mu,\frac{\hat{\Xi}}{\hat{\theta}})}{L(\hat{\mu},\hat{ \Xi})}\;, \tag{46}\]

as described in Section 2. With this definition, the sampling distribution of the test statistic \(f(q_{\mu}|\mu)\) approaches a well defined form related to the chi-squared distribution for a sufficiently large data sample. The ability to exploit this approximate form is very useful as the relevant \(p\)-value for a \(5\sigma\) discovery is \(2.87\times 10^{-7}\), and therefore to determine this from Monte Carlo would require an extremely large number of simulated experiments. At LEP this was not a crucial issue as the statistical treatment focused primarily on exclusion limits at \(95\%\) CL, not on discovery at the \(5\sigma\) level.

Systematic uncertainties here have been incorporated using the profile likelihood, rather than with the integrated likelihoods used at LEP. For the uncertainties most relevant to the analyses at the LHC, the broadening of the likelihood function obtained by both procedures is similar. It is the profile likelihood ratio and not the ratio of integrated likelihoods, however, that approaches the chi-squared form in the large sample limit in accordance with Wilks' theorem.

The \(\rm CL_{s}\) method has not been applied in the present analysis but studies of its application to searches in ATLAS are ongoing.

A final difference with the LEP procedures concerns the definition of significance \(Z\). Here we have defined its relation to the \(p\)-value as the number of standard deviations of a Gaussian variable that would give a one-sided tail area of \(p\), as described in Section 2.1. A significance of \(Z=5\) corresponds to \(p=2.87\times 10^{-7}\). The LEP Higgs group defined this relation using a two-sided fluctuation of a Gaussian variable, i.e., a \(5\sigma\) significance corresponded to \(p=5.7\times 10^{-7}\).

## References

* [1] Isaac Asimov, _Franchise_, in _Isaac Asimov: The Complete Stories, Vol. 1_, Broadway Books, 1990.
* [2] S.S. Wilks, _The large-sample distribution of the likelihood ratio for testing composite hypotheses_, Ann. Math. Statist. **9** (1938) 60-2.