# **Atlas Note**

ATL-PHYS-PUB-2009-000

**Measurement of Missing Tranverse Energy**

The ATLAS Collaboration1

Footnote 1: This note prepared by J. Abdallah, S. Asai, E. Barberio, D. Casadei, D. Cavalli, X. Chen, M. Consonni, L. Courneyea, K. Cranmer, R. Djilkibaev, E. Dobson, R. Duxfield, L. Flores Castillo, A. Gibson, A. Gupta, N. Kanaya, E. van der Kraaij, Y. Ishizawa, R. Lafaye, R. McPherson, B. Meirose, B. Mellado, S. Menke, A. Mincer, H. Okawa, S. Padhi, F. Paige, A. Phan, C. Pizio, J. Poveda, R. Prabhu, S. Resconi, M. Rijpstra, G. Rosenbaum, A. Schwartzman, A. Shibata, R. Teuscher, D. Tovey, I. Trigger, G. Usai, J. Valls, M. Vreeswijk, L. Zhao, S.L. Wu, S. Yamamoto, and A. Yurkewicz

_This note is part of CERN-OPEN-2008-020. This version of the note should not be cited: all citations should be to CERN-OPEN-2008-020._

**Abstract**

This note discusses the overall ATLAS detector performance for the reconstruction of the missing transverse energy, \(\not{E}_{\rm T}\). Two reconstruction algorithms are discussed and their performance is evaluated for a variety of simulated physics processes which probe different topologies and different total transverse energy regimes. In addition, effects of fake \(\not{E}_{\rm T}\) resulting from instrumental effects and from false reconstructions are investigated. Finally, studies with first data, corresponding to an integrated luminosity of 100pb\({}^{-1}\), are suggested which can be used to assess and calibrate the \(\not{E}_{\rm T}\) performance at the startup of data taking.

Introduction

A very good measurement of the missing transverse energy, \(\not{E}_{\rm T}\), is essential for many physics studies in ATLAS. Events with large \(\not{E}_{\rm T}\) are expected to be the key signature for new physics such as supersymmetry and extra dimensions. A good \(\not{E}_{\rm T}\) measurement in terms of linearity and resolution is also important for the reconstruction of the top-quark mass from \(t\bar{t}\) events with one top quark decaying semileptonically. Furthermore, it is crucial for the efficient and accurate reconstruction of the Higgs boson mass when the Higgs boson decays to a pair of \(\tau\)-leptons.

This Note describes the overall performance of the \(\not{E}_{\rm T}\) measurement in ATLAS. The performance is checked using fully simulated Monte Carlo (MC) samples in different physics channels with differences in event topology and kinematics range. Events with no true \(\not{E}_{\rm T}\) as well as events with a true \(\not{E}_{\rm T}\), \(\not{E}_{\rm T}^{\rm True}\), due to particles unseen in the detector as neutrinos or lightest supersymmetric particles, ranging from \(\sim 20\) to \(\sim 500\) GeV are used.

An important requirement on the measurement of \(\not{E}_{\rm T}\) is to minimize the impact of limited detector coverage, finite detector resolution, presence of dead regions and different sources of noise that produce fake \(\not{E}_{\rm T}\), \(\not{E}_{\rm T}^{\rm Fake}\). The ATLAS calorimeter coverage extends to large pseudorapidity angles to minimize the impact of high energy particles escaping in the very forward direction. Even so, there are inactive transition regions between different calorimeters that produce \(\not{E}_{\rm T}^{\rm Fake}\). Dead and noisy readout channels in the running detector, if present, will also produce \(\not{E}_{\rm T}^{\rm Fake}\). Such \(\not{E}_{\rm T}^{\rm Fake}\) sources can significantly enhance the background from QCD multi-jet events in supersymmetry searches or the background from \(Z\to\ell\ell\) events accompanied by high-\(p_{\rm T}\) jets in Higgs boson searches when the Higgs boson decays into two leptons and neutrinos.

The calorimeter plays a crucial role in the \(\not{E}_{\rm T}\) measurement and an important first step of the \(\not{E}_{\rm T}\) measurement is the suppression of noise in the calorimeter. Section 2 describes the techniques used for noise suppression in calorimeters. The two \(\not{E}_{\rm T}\) reconstruction algorithms used in ATLAS, Cell-based and Object-based, are described in detail in Sections 2.2 and 2.3. The overall performance of the \(\not{E}_{\rm T}\) measurement in ATLAS is reported in Section 3. Any mis-measurement in the event, due to finite resolution or acceptance of the detector or due to instrumental effects related to dead or noisy channels, will degrade the \(\not{E}_{\rm T}\) measurement. Such sources of \(\not{E}_{\rm T}\), that can lead to large values of fake \(\not{E}_{\rm T}\), are studied in Section 4. Section 5 introduces the \(\not{E}_{\rm T}\) algorithm for the ATLAS triggers and describes its performance. Finally, Section 6 describes techniques in different physics channels that can be used with the very first ATLAS data to validate the \(\not{E}_{\rm T}\) measurement and determine the \(\not{E}_{\rm T}\) scale in-situ.

## 2 The algorithms for \(\not{E}_{\rm T}\) reconstruction in ATLAS

The transverse missing energy in ATLAS is primarily reconstructed from energy deposits in the calorimeter and reconstructed muon tracks. Apart from the hard scattering process of interest, many other sources, such as the underlying event, multiple interactions, pile-up and coherent electronics noise, lead to energy deposits and/or muon tracks. Classifying the energy deposits into various types (e.g. electrons or jets) and calibrating them accordingly is the essential key for an optimal \(\not{E}_{\rm T}\)measurement. In addition, the loss of energy in dead regions and readout channels make the \(\not{E}_{\rm T}\) measurement a real challenge.

There are two algorithms for \(\not{E}_{\rm T}\) reconstruction in ATLAS that emphasize different aspects of energy classification and calibration.

The Cell-based algorithm starts from the energy deposits in calorimeter cells that survive a noise suppression procedure. The cells can be calibrated using global calibration weights depending on their energy density. This procedure will be robust already at initial data taking because it does not rely on other reconstructed objects. In a subsequent step, the cells can be calibrated according to the reconstructed object they are assigned to. Corrections are applied for the muon energy and for the energy lost in the cryostats.

The Object-based algorithm starts from the reconstructed, calibrated and classified objects in the event. The energy outside these objects is further classified as low \(p_{\mathrm{T}}\) deposit from charged and neutral pions and calibrated accordingly.

The noise suppression in the calorimeter is common for the Cell- and Object-based algorithm and is described below, followed by a detailed description of the algorithms.

### Calorimeter noise suppression

The electronics noise alone in the \(\approx 200\)k readout channels of the ATLAS calorimeter contributes about \(13\GeV\) to the width of the \(\not{E}_{\mathrm{T}}\) distribution. Especially in events that do not have large \(\not{E}_{\mathrm{T}}\), such as in \(Z\to\tau\tau\) used for an in-situ determination of the \(\not{E}_{\mathrm{T}}\) scale (Section 6.2), the noise suppression is of crucial importance.

For the \(\not{E}_{\mathrm{T}}\) measurement, two noise suppression methods have been studied so far. Both require knowledge of the width of the noise distribution, \(\sigma_{\mathrm{noise}}\), which can be either purely electronics noise or a combination of electronics and pile-up noise.

**Standard Noise Suppression Method.** The first method is based on only using calorimeter cells with energies larger than a threshold, generally corresponding to a certain number of \(\sigma_{\mathrm{noise}}\). The threshold is optimized for \(\not{E}_{\mathrm{T}}\) resolution, the scale of \(\not{E}_{\mathrm{T}}\), the total transverse energy in the calorimeters, \(\Sigma\not{E}_{\mathrm{T}}\), and for the highest \(p_{\mathrm{T}}\) jet to be close to the case without noise simulation. Two cases are studied: a symmetric threshold (\(|E_{\mathrm{cell}}|>n\times\sigma_{\mathrm{noise}}\)) and an asymmetric one (\(E_{\mathrm{cell}}>n\times\sigma_{\mathrm{noise}}\)). A symmetric threshold with \(n=2\) for all calorimeters is generally used.

**Noise Suppression using TopoClusters.** The second method only uses cells in 3-dimensional topological calorimeter clusters [1, 2], hereafter called TopoClusters. A TopoCluster is reconstructed starting from a seed cell with an absolute energy value \(|E_{\mathrm{cell}}|>4\sigma_{\mathrm{noise}}\) to which neighbors with \(|E_{\mathrm{cell}}|>2\sigma_{\mathrm{noise}}\) are added. Finally the cells at the boundary are required to have \(|E_{\mathrm{cell}}|>0\sigma_{\mathrm{noise}}\). The cells that constitute the TopoCluster are hereafter called TopoCells. This set of thresholds, referred to as \(4/2/0\), is optimized to suppress electronics noise as well as pile-up from minimum bias events, while keeping the single pion efficiency as high as possible.

As a result of the large energy density of electromagnetic showers, the \(\pi^{0}\) reconstruction efficiency is high (close to 100% for energies \(>4\) GeV) for the \(4/2/0\) configuration. On the other hand, the reconstruction efficiency for charged pions is very sensitive to the parameters of the TopoClusters. For example, changing the cuts on neighbors from \(4/2\) to \(6/3\), the \(\pi^{\pm}\) efficiency significantly decreases for TopoClusters with \(E<4\) GeV. This sensitivity highlights the importance of a good modeling of the noise level from first data.

In \(Z\to\nu\bar{\nu}\) events simulated with electronics noise, the \(\not{E}_{\mathrm{T}}\) resolution degrades by only \(3\,\%\) for the 4/2/0 configuration as compared to the same events without noise added. Also, the TopoCluster algorithm performs better in terms of linearity and resolution of the \(\not{E}_{\mathrm{T}}\) measurement, compared to the standard noise suppression method. Therefore Cell- and Object-based \(\not{E}_{\mathrm{T}}\) algorithms apply the noise suppression method based on TopoClusters with configuration \(4/2/0\).

### Cell-based \(\not{E}_{\mathrm{T}}\) reconstruction

The Cell-based \(\not{E}_{\mathrm{T}}\) reconstruction includes contributions from transverse energy deposits in the calorimeters, corrections for energy loss in the cryostat and measured muons:

\[\not{E}_{x,y}^{\mathrm{Final}}=\not{E}_{x,y}^{\mathrm{Calo}}+\not{E}_{x,y}^{ \mathrm{Cryo}}+\not{E}_{x,y}^{\mathrm{Muon}}. \tag{1}\]

In the following, the three terms in the above equation, referred to as calorimeter, cryostat and muon terms, are described in some detail.

#### 2.2.1 The \(\not{E}_{\rm T}\) calorimeter term

As described in the previous section, the first step is to select calorimeter cells that belong to reconstructed TopoClusters to minimize the impact of noise.

The \(x\) and \(y\) components of the calorimeter \(\not{E}_{\rm T}\) term are calculated from the transverse energies measured in TopoCells:

\[\not{E}_{x,y}^{\rm{Calo}}=-\sum_{\rm{TopoCells}}E_{x,y}. \tag{2}\]

The total transverse energy in the calorimeters, \(\not{E}_{\rm T}\), is calculated from the scalar sum of \(E_{\rm T}\) of all TopoCells:

\[\Sigma\not{E}_{\rm T}{}^{Calo}=\sum_{\rm{TopoCells}}E_{\rm T}. \tag{3}\]

The straightforward result, obtained by using the electromagnetic calibration for all cells, gives a large shift in the \(\not{E}_{\rm T}\) scale of about 30% with respect to \(\not{E}_{\rm T}^{\rm{True}}\) (see Section 3).

This result illustrates the necessity of developing a dedicated calibration scheme to reduce the systematic shift of the \(\not{E}_{\rm T}\) scale and optimize its resolution. This goal is achieved in several steps according to the cell classification. The classification depends on whether the energy deposits in the calorimeter are electromagnetic or hadronic in nature and whether they are associated with high \(p_{\rm T}\) particles.

To classify energy deposits, schemes to calibrate hadronic showers such as 'H1-like' calibration or 'Local-Hadronic' calibration [3] utilize the energy density in a cell. Electromagnetic showers tend to have higher energy densities as compared to hadronic showers. The 'Local-Hadronic' calibration scheme uses further information related to shape and depth of the calorimetric shower to classify a TopoCluster. The next step in the cell-based \(\not{E}_{\rm T}\) reconstruction is to globally calibrate all calorimeter cells using the 'H1-like' or 'Local-Hadronic' calibration schemes. As can be seen in the performance section, this already gives a very good \(\not{E}_{\rm T}\) performance. The final refinement step of the calibration using the association of cells with reconstructed objects is described in Section 2.2.4. It improves the linearity and the resolution particularly for events containing electrons (Section 3).

#### 2.2.2 The \(\not{E}_{\rm T}\) muon term

The \(\not{E}_{\rm T}\) muon term is calculated from the momenta of muons measured in a large range of pseudorapidity, defined by \(|\eta|<2.7\):

\[\not{E}_{x,y}^{\rm{Muon}}=-\sum_{\rm{RecMuons}}E_{x,y}. \tag{4}\]

In the region \(|\eta|<2.5\) only good-quality muons in the muon spectrometer with a matched track in the inner detector are considered. The matching requirement reduces considerably contributions from fake muons, sometimes created from high hit multiplicities in the muon spectrometer in events with very energetic jets. For higher values of the pseudorapidity (\(2.5<|\eta|<2.7\)), outside the fiducial volume of the inner detector, there is no matched track required and the muon spectrometer is used alone.

The muon momentum measured by the muon spectrometer is taken in the two cases. Energy lost in the calorimeter is already included in the calorimeter term. No \(p_{\rm T}\) threshold cut is applied to reconstructed muons. Apart from the loss of muons outside the acceptance of the muon spectrometer (\(|\eta|>2.7\)), there is a loss of muons in other regions (see Section 4.1) due to limited coverage of the muon spectrometer. The muons reconstructed from the inner detector and calorimeter energy deposits could be used to recover these events, but they are not yet used here.

As can be seen in the performance section, the \(\not{E}_{\rm T}\) resolution is only marginally affected by the muon term, due to the good identification efficiency and resolution of the ATLAS muon system. However, unmeasured, badly measured or fake muons can be a source of large fake \(\not{E}_{\rm T}\) (see Section 4).

#### 2.2.3 \(\not\!\!E_{\rm T}\) cryostat term

The thickness of the cryostat between the LAr barrel electromagnetic calorimeter and the tile barrel hadronic calorimeter is about half an interaction length where hadronic showers can lose energy. The \(\not\!\!E_{\rm T}\) reconstruction recovers this loss of energy in the cryostat using the correlation of energies between the last layer of the LAr calorimeter and the first layer of the hadronic calorimeter. A similar correction for the end-cap cryostats is applied. This correction is called the cryostat term when used for jet energy correction [3]. It is defined as follows:

\[\not\!\!E_{x,y}^{\rm Cryo}=-\sum_{\rm recJets}E\,jet_{x,y}^{\rm Cryo}, \tag{5}\]

where all reconstructed jets are summed in the event, and

\[E\,jet^{\rm Cryo}=w^{\rm Cryo}\sqrt{E_{\rm EM3}\times E_{\rm HAD}}, \tag{6}\]

where \(w^{\rm Cryo}\) is a calibration weight (determined together with the cell calibration weights in the H1-like calibration) and \(E_{\rm EM3}\) and \(E_{\rm HAD}\) are the jet energies in the third layer of the electromagnetic calorimeter and in the first layer of the hadronic calorimeter, respectively. The cryostat correction turns out to be non-negligible for high-\(p_{\rm T}\) jets. It contributes at the level of \(\sim 5\%\) per jet with \(p_{\rm T}\) above \(500\) GeV.

#### 2.2.4 Refined calibration of the \(\not\!\!E_{\rm T}\) calorimeter term

The final step is the refinement of the calibration of cells associated with each high-\(p_{\rm T}\) object. Calorimeter cells are associated with a parent reconstructed and identified high-\(p_{\rm T}\) object, in a chosen order: electrons, photons, muons, hadronically decaying \(\tau\)-leptons, \(b\)-jets and light jets. Refined calibration of the object is then used in \(\not\!\!E_{\rm T}\) to replace the initial global calibration cells. The calibration of these objects is known to higher accuracy than the global calibration, enabling to improve the \(\not\!\!E_{\rm T}\) reconstruction.

The calorimeter cells are associated with the reconstructed objects through the use of an association map. This map is filled starting from the reconstructed/identified objects in the chosen order, navigating back to their component clusters and back again to their cells. If a cell belongs to several kinds of reconstructed objects, only the first association is included in the map, i.e. the overlap removal is done at cell level. This avoids double counting of cells in the \(\not\!\!E_{\rm T}\) calculation. If a cell belongs to more than one object of the same kind, all associations are included in the map and the geometrical weight of the cells, accounting for the sharing of energy of cells owned by two different TopoClusters, is also included to avoid double counting.

Attention has to be paid to the calibration of cells inside different objects. For example, for electrons/photons, the final cluster-level calibration (which can be propagated back to the cell-level) corrects for upstream material, longitudinal leakage and out-of-cone energy. The last correction should not be applied in the \(\not\!\!E_{\rm T}\) calculation because the contribution of cells outside objects already accounts for it. In a similar way, for \(\tau\) lepton decays and for jets, the overall scale factors which correct the energy for physics effects like final state radiation, fragmentation or the underlying event as well as for the effects due to the clustering algorithm are not applied in the calculation of \(\not\!\!E_{\rm T}\), because they also contain the out-of-cluster correction.

All TopoCells, even if not associated with any high-\(p_{\rm T}\) reconstructed object, are used in the \(\not\!\!E_{\rm T}\) calculation. They are calibrated using the global calibration scheme. The importance of the energy deposits of these low energy particles for the \(\not\!\!E_{\rm T}\) calculation is shown in Fig. 1. The shift in the absolute value of the reconstructed \(\not\!\!E_{\rm T}\) increases by about \(1\) GeV while the resolution is degraded by a factor \(\sim 1.25\).

Once the cells are associated with categories of objects as described above, the contribution to \(\not{E}_{\rm T}\) is calculated as follows:

\[\not{E}_{x,y}^{\rm{Calo}}=\not{E}_{x,y}^{\rm{RefCalib}}=-(\not{E}_{x,y}^{\rm{ RefEle}}+\not{E}_{x,y}^{\rm{RefFtau}}+\not{E}_{x,y}^{\rm{Refbjets}}+\not{E}_{x,y}^{\rm{ Reflets}}+\not{E}_{x,y}^{\rm{RefMuo}}+\not{E}_{x,y}^{\rm{RefOut}}), \tag{7}\]

where each term is calculated from the negative of the sum of calibrated cells inside a specific object and \(\not{E}_{x,y}^{\rm{RefFout}}\) is calculated from the cells in TopoClusters which are not included in the reconstructed objects. In the following the final \(\not{E}_{\rm T}\) calculation obtained from Equation (1) with \(\not{E}_{x,y}^{\rm{Calo}}=\not{E}_{x,y}^{\rm{RefCalib}}\) will be referred to as \(\not{E}_{\rm T}^{\rm{RefFinal}}\).

### Object-based \(\not{E}_{\rm T}\) reconstruction

The motivation of the method is to reliably reconstruct \(\not{E}_{\rm T}\) for analyses that are sensitive to low \(p_{\rm T}\) deposits coming mostly from neutral and charged pions, from soft jets, from the underlying event and from pile-up. This is important, for example, in reconstructing the invariant mass of the Standard Model Higgs boson, \(m_{H}\), in the \(H\to\tau^{+}\tau^{-}\) final state for masses in the range \(115<m_{H}<140\) GeV [4].

The object-based method comprises two main steps:

* Establish a classification between two main types of objects: high \(p_{\rm T}\) (e/\(\gamma,\mu,\tau\), jets) and low \(p_{\rm T}\) objects (\(\pi^{0},\pi^{\pm}\), unclustered deposits) coming from underlying event, pile-up of multiple \(pp\) collisions, initial and final state radiation, and other soft QCD processes.
* Apply the object-based calibration optimized for \(\not{E}_{\rm T}\) calculation.

The \(x\) and \(y\) components of \(\not{E}_{\rm T}\) and \(\sum E_{\rm T}\) are calculated by adding the contributions from each type of components:

\[\not{E}_{x,y} = -E_{x,y}^{\rm{High}}-E_{x,y}^{\rm{Low}} \tag{8}\] \[\sum E_{\rm T} = \sum E_{\rm T}^{\rm{High}}+\sum E_{\rm T}^{\rm{Low}}, \tag{9}\]

where the indices 'High' and 'Low' correspond to the \(\not{E}_{\rm T}\) and \(\sum E_{\rm T}\) calculated from high \(p_{\rm T}\) and low \(p_{\rm T}\) objects, defined below.

The object-based algorithm uses mostly the calorimeter to reconstruct \(\not{E}_{\rm T}\). Some objects such as electrons and taus also use the inner detector tracking, while the muons use both, inner detector and muon spectrometer information. Tracking is also used for the low \(p_{\rm T}\) deposits of soft objects.

Figure 1: Distribution of the difference between true and reconstructed \(\not{E}_{\rm T}\) for \(Z\to\tau\tau\) events (left) including and (right) excluding cells in Topoclusters not associated with reconstructed high-\(p_{\rm T}\) objects.

The object-based method uses the TopoClusters \(4/2/0\) (Section 2.1) and first calculates all contributions of high \(p_{\mathrm{T}}\) objects. Each TopoCluster is allowed to be included only once by the first object that is associated with it. The classification starts with the identification of electrons, photons, muons and \(\tau\)'s. Once the clusters belonging to these objects are removed from the event record, hadronic jets above a certain threshold are identified. TopoCells not part of any of the above high \(p_{\mathrm{T}}\) objects are classified as low \(p_{\mathrm{T}}\) deposit. The next subsections discuss the calibration of these objects.

#### 2.3.1 Calorimeter objects: electrons, hadronic \(\tau\)-jets, jets

Electrons:The electron objects are taken from the standard electron reconstruction and a matched track is always required. The default calibration of an electron is based on the'sliding window' EM clusters [5]. To be consistent with the combined \(4/2/0\) TopoClustering used for the object-based reconstruction, electrons are reconstructed from TopoClusters and they are calibrated by weighting the energy deposits in the longitudinal calorimeter layers. The electron \(p_{\mathrm{T}}\) is required to be at least 8.

Tau Leptons:The object-based method uses the calo-based reconstructed \(\tau\)-jets [6] and it calibrates them as jets. A cut of 20  on the \(\tau\)-jet \(p_{\mathrm{T}}\) is applied and a \(\tau\) likelihood \(>\) 4 is required.

Jets:A cone (\(\Delta R\) = 0.7) jet algorithm running on the TopoClusters is used for calculating the \(\not{E}_{\mathrm{T}}\) contribution from jets. Jets not overlapping with the electron and tau jets are chosen. The jet energy calibration is based on the 'H1-like' hadronic calibration [3], which corrects for the difference in response for \(\mathrm{e}/\gamma\) and hadrons, followed by a scale correction due to the non-uniformity of the reconstruction in \(\eta\). It is based on the \(\not{E}_{\mathrm{T}}\) projection method (used by CDF and D0)[7] using a dijet sample where forward jets are corrected with respect to well measured central jets (\(|\eta|<0.8\)). The jet \(p_{\mathrm{T}}\) is required to be at least 20.

#### 2.3.2 Muons

In general, the combined muons, reconstructed from the inner detector and the muon spectrometer, are used. In the region where the inner detector has no coverage (\(2.5<|\eta|<2.7\)) muons reconstructed from the spectrometer only are used. To reduce the number of fake muons originating from punch through of high \(p_{\mathrm{T}}\) jets, strong quality requirements are imposed on the combined track from the inner detector and the muon spectrometer. Additionally, if a muon passes inside a jet and the ratio of measured momenta in the inner detector and in the muon spectrometer is below 0.2, the muon is rejected. If the muon is found inside a jet or the total \(p_{\mathrm{T}}\) at the EM scale of the TopoClusters within a cone of 0.2 around the muon is \(>10\), either the measured muon energy loss in the calorimeter is subtracted from the combined \(p_{\mathrm{T}}\) or the muon spectrometer \(p_{\mathrm{T}}\) is used. The combined muon \(p_{\mathrm{T}}\) is required to be at least 6.

Inner detector tracks may be used to improve the \(\not{E}_{\mathrm{T}}\) reconstruction. They contain the muons not covered by the combination of inner detector and muon spectrometer, especially in the crack regions of the muon system. Only those tracks are retained which are isolated from others by a cone of size 0.3. Those tracks overlapping with electrons, muons or jets that are already used for \(\not{E}_{\mathrm{T}}\) are discarded. The tracks should have \(p_{\mathrm{T}}>6\) and should satisfy a muon likelihood criterion based on \(E/p\) and the energy in the calorimeter sampling layers. In addition, isolated tracks (mostly pions) with little energy deposits in the calorimeter can be used to improve \(\not{E}_{\mathrm{T}}\). These tracks are used only if \(p_{\mathrm{T}}\) less than 10, to avoid tracks with spurious high \(p_{\mathrm{T}}\),which deteriorates the \(\not{E}_{\mathrm{T}}\) performance.

#### 2.3.3 Low \(p_{\rm T}\) depositions: classification and calibration

Only those TopoClusters that have not been assigned to high \(p_{\rm T}\) objects are considered for classification as low \(p_{\rm T}\) objects of either electromagnetic or hadronic nature. For this purpose, clusters are further subdivided into so-called mini-jets. Mini-jets are reconstructed from TopoClusters using a cone algorithm of a relatively small radius of \(\Delta R=0.2\) and a seed cluster of \(p_{\rm T}>0.5\)\(\,\mathrm{GeV}\). A mini-jet is required to have \(p_{\rm T}>0.5\)\(\,\mathrm{GeV}\). The mini-jets are next classified as charged and neutral pions.

The separation between charged and neutral pions is done only in \(|\eta|<3.2\). A mini-jet is defined to be a \(\pi^{0}\) if the fractional energy in the hadronic compartments is less than \(2\,\%\) and \(p_{\rm T}>10\)\(\,\mathrm{GeV}\). The low \(p_{\rm T}\) deposits are calibrated under single charged and neutral pion hypotheses in the full \(\eta\) range. A sampling method similar to that used to extract longitudinal weights as implemented for the electron and photon calibration is used. The calorimeter sampling weights are determined separately for neutral and charged pions in different energy and \(\eta\) regions. A good linearity is achieved for both neutral and charged pion hypotheses. Figure 2 shows the linearity for charged and neutral pions in the central region, which roughly fluctuates within \(5\%\).

Mini-jets will not saturate all the low \(p_{\rm T}\) calorimeter deposits. There will remain a non-trivial amount of energy left in the calorimeter and clustered in TopoClusters from very low momentum pions, which will not form a mini-jet. These deposits are referred to as unassociated deposits. The energy calibration of these unassociated deposits has been estimated in three \(\eta\) regions, depending on the calorimeter region (barrel, end-cap, forward), and has been added to the \(\not\!\!E_{\rm T}\) calculation.

## 3 Performance of the reconstructed \(\not\!\!E_{\rm T}\)

In this section the performance of the \(\not\!\!E_{\rm T}\) reconstruction is discussed, focusing on the linearity and resolution of the reconstructed \(\not\!\!E_{\rm T}\) as a function of the true missing transverse energy, \(\not\!\!E_{\rm T}^{\rm True}\). The measurement of the \(\not\!\!E_{\rm T}\) direction and the dependence on topology are also discussed. Note that the performance of the two \(\not\!\!E_{\rm T}\) reconstruction methods is very similar, so it is not specified which method has been used to produce each performance plot.

\(\not\!\!E_{\rm T}^{\rm True}\) is defined from the sum of all stable and non-interacting particles in the final state (neutrinos and the lightest supersymmetric particles). Comparisons between \(\not\!\!E_{\rm T}\) and \(\not\!\!E_{\rm T}^{\rm True}\) are made for a number of physics processes with different topologies and final states.

The \(\not\!\!E_{\rm T}\) performance in case of events with large \(\not\!\!E_{\rm T}^{\rm Fake}\), which contribute predominantly to the tails of the \(\not\!\!E_{\rm T}\) distribution, is described in the next section.

Figure 2: Linearity for single charged \(\pi\) (left) and single \(\pi^{0}\) (right) as a function of \(\eta\) for the energy bin \(1<E<10\)\(\,\mathrm{GeV}\)).

### Linearity and resolution

The \(\not{E}_{\rm T}\) linearity is defined by the following expression:

\[Linearity=(\not{E}_{\rm T}^{\rm True}-\not{E}_{\rm T})/\not{E}_{\rm T}^{\rm True}, \tag{10}\]

where \(\not{E}_{\rm T}\) and \(\not{E}_{\rm T}^{\rm True}\) are reconstructed and true \(\not{E}_{\rm T}\), respectively. This definition of linearity assumes an \(\not{E}_{\rm T}^{\rm True}\) value above a threshold and an \(\not{E}_{\rm T}^{\rm Fake}\) value that is small such that the \(\not{E}_{\rm T}\) angle is well measured.

Figure 3 shows the reconstructed linearity as a function of \(\not{E}_{\rm T}^{\rm True}\) for a number of physics processes. The following statements summarize the behavior of the linearity distributions:

* The uncalibrated \(\not{E}_{\rm T}\) corresponds to the use of cell energies at the electromagnetic scale and shows a large systematic bias of 30%. In \(W\to e\nu\) and \(W\to\mu\nu\) decays, the bias is smaller since the hadronic activity on average is smaller.
* The reconstructed \(\not{E}_{\rm T}\) based on globally calibrated cell energies and reconstructed muons gives a linearity to within 5%.
* The reconstructed \(\not{E}_{\rm T}\) including the cryostat correction shows a linearity to within 1% for all processes except for \(W\to e\nu\).
* The refined \(\not{E}_{\rm T}\) calibration, which optimizes the calibration with reconstructed object identity, recovers the linearity for \(W\to e\nu\) events to within 1%. The refined calibration also gives the best resolution when compared with the above steps of calibration (see also Section 6).

The linearity for \(A\to\tau\tau\) with \(m_{A}=800\) GeV is shown in Fig. 3 (right) as a function of \(\not{E}_{\rm T}^{\rm True}\). The bias of linearity at low \(\not{E}_{\rm T}^{\rm True}\) is due to the finite resolution of the \(\not{E}_{\rm T}\) measurement. The reconstructed \(\not{E}_{\rm T}\) is positive by definition, so the linearity is negative when the true \(\not{E}_{\rm T}\) is near to zero. Excluding the events with \(\not{E}_{\rm T}^{\rm True}<40\) GeV, which have a small statistics the observed linearity is found to be within 2%.

Figure 3: (left) Linearity of response for reconstructed \(\not{E}_{\rm T}\) as a function of the average true \(\not{E}_{\rm T}\) for different physics processes covering a wide range of true \(\not{E}_{\rm T}\) and for the different steps of \(\not{E}_{\rm T}\) reconstruction (see text). The points at average true \(\not{E}_{\rm T}\) of 20 GeV are from \(Z\to\tau\tau\) events, those at 35 GeV are from \(W\to e\nu\) and \(W\to\mu\nu\) events, those at 68 GeV are from semi-leptonic \(t\bar{t}\) events, those at 124 GeV are from \(A\to\tau\tau\) events with \(m_{A}=800\) GeV, and those at 280 GeV are from events containing supersymmetric particles at a mass scale of 1 TeV. (right) Linearity of response for reconstructed \(\not{E}_{\rm T}\) as a function of the true \(\not{E}_{\rm T}\) for \(A\to\tau\tau\) events with \(m_{A}=800\) GeV.

The resolution is estimated from the width of the \(\not{E}_{\rm T}\) components with refined calibration as a function of the total transverse energy, \(\Sigma E_{\rm T}\) for low to medium values (left) and for higher values (right). The curves correspond to the best fits of \(\sigma=0.53\sqrt{\Sigma E_{\rm T}}\) through the points from \(Z\to\tau\tau\) events (left) and \(\sigma=0.57\sqrt{\Sigma E_{\rm T}}\) through the points from \(A\to\tau\tau\) events (right). The points from \(A\to\tau\tau\) events are for masses \(m_{A}\) ranging from 150 to 800 GeV and the points from QCD jets correspond to dijet events with \(560<p_{\rm T}<1120\) GeV.

The resolution is estimated from the width of the \(\not{E}_{\rm T,\,y}-\not{E}_{\rm x,\,y}^{\rm True}\) distribution in bins of the total transverse energy deposited in the calorimeters (\(\Sigma\not{E}_{\rm T}\)). The core of each distribution is fitted with a Gaussian shape to estimate the width. Figure 4 shows the \(\sigma\) of the fit plotted as a function of \(\Sigma\not{E}_{\rm T}\) when refined calibration is applied. The \(\not{E}_{\rm T}\) resolution approximately follows a stochastic behaviour as a function of \(\Sigma\not{E}_{\rm T}\). Deviations from this simple behaviour are expected, and observed for low values of \(\Sigma\not{E}_{\rm T}\) where the contribution of noise is important and for very high values of \(\Sigma\not{E}_{\rm T}\) where the constant term in the resolution of the calorimetric energy measurement dominates.

The \(\not{E}_{\rm T}\) resolution is fitted with a function \(\sigma=a\cdot\sqrt{\Sigma\not{E}_{\rm T}}\) for values of \(\Sigma\not{E}_{\rm T}\) between 20 and 2000 GeV. The parameter \(a\), which quantifies the \(\not{E}_{\rm T}\) resolution, varies between 0.53 and 0.57 (see Fig. 4 left and right, respectively). Refined \(\not{E}_{\rm T}\) calibration yields the best results when compared to earlier stages of the calibration as described above. For \(W\to e\nu\) decays the \(a\) parameter is reduced by 88% and for \(Z\to ee\) events it is reduced by 78% with respect to the global calibration with the cryostat correction applied. Figure 5 shows the resolution in the high \(\Sigma\not{E}_{\rm T}\) region for QCD jet samples. The jet samples used are generated in parton \(p_{\rm T}\) bins: J1 corresponds to \(17<p_{\rm T}<35\) GeV, J2 to \(35<p_{\rm T}<70\) GeV, J3 to \(70<p_{\rm T}<140\) GeV, J4 to \(140<p_{\rm T}<280\) GeV, J5 to\(280<p_{\rm T}<560\) GeV, J6 to \(560<p_{\rm T}<1120\) GeV,

Figure 4: Resolution of the two \(\not{E}_{\rm T}\) components with refined calibration as a function of the total transverse energy, \(\Sigma E_{\rm T}\) for low to medium values (left) and for higher values (right). The curves correspond to the best fits of \(\sigma=0.53\sqrt{\Sigma E_{\rm T}}\) through the points from \(Z\to\tau\tau\) events (left) and \(\sigma=0.57\sqrt{\Sigma E_{\rm T}}\) through the points from \(A\to\tau\tau\) events (right). The points from \(A\to\tau\tau\) events are for masses \(m_{A}\) ranging from 150 to 800 GeV and the points from QCD jets correspond to dijet events with \(560<p_{\rm T}<1120\) GeV.

Figure 5: Resolution of the two \(\not{E}_{\rm T}\) components with refined calibration as a function of \(\Sigma\not{E}_{\rm T}\) for QCD dijet samples (\(17<p_{\rm T}<2240\) GeV). See text for the definition of samples J1-J7. The curve corresponds to \(\sigma=0.55\sqrt{\Sigma\not{E}_{\rm T}}\) (combined fit in the low and medium \(\Sigma\not{E}_{\rm T}\) regions).

J7 to \(1120<p_{\rm T}<2240\) GeV. There is a clear degradation in the performance for the high \(p_{\rm T}\) jet samples (J6 and J7), where the linear term dominates.

The effect of angular calorimeter coverage on the \(\not{E}_{\rm T}\) measurement is evaluated by comparing the resolution with and without including the forward calorimeters (FCAL). In \(Z\to\tau\tau\)  events the \(\not{E}_{\rm T}\) resolution is 7.8 and 10.1 GeV, respectively, showing that the ATLAS coverage minimises by design the effect of particles escaping at very large \(\eta\) and that the forward calorimeter is very important to guarantee that.

Projections of \(\not{E}_{\rm T}\) along suitable axes can be used to check calibration problems and understand topology dependences. The quantity \(\not{E}_{\rm L}\) (longitudinal \(\not{E}_{\rm T}\) projection) is the \(\not{E}_{\rm T}\) projection onto the axis pointing in the direction of the genuine \(\not{E}_{\rm T}\) of the event. In events without genuine \(\not{E}_{\rm T}\), such as \(Z\to\ell\ell\)  events this axis is reconstructed from the direction of flight of the \(Z\) and in dijet events the projection is done along the dijet thrust axis. The quantity \(\not{E}_{\rm P}\) (perpendicular \(\not{E}_{\rm T}\) projection) is defined as a projection on the \(\not{E}_{\rm L}\) direction.

A bias of \(\not{E}_{\rm L}\) usually indicates mis-calibration of the object's energy scale (in most cases the hadronic scale). For events with significant values of \(\not{E}_{\rm T}^{\rm True}\), \(\not{E}_{\rm P}\) is a measure of the \(\not{E}_{\rm T}\) angular resolution. For dijet events and other back-to-back topologies with similarly defined \(\not{E}_{\rm P}\) usually there is no bias in \(\not{E}_{\rm P}\), but the resolution of \(\not{E}_{\rm P}\) is sensitive to soft radiation in the event. One possible source of bias in \(\not{E}_{\rm P}\) comes from a bias in the angular measurement of the objects in the event, which will cause a shift in the same direction on both sides of \(\not{E}_{\rm L}\).

Figure 6 shows the \(\not{E}_{\rm L}\) and \(\not{E}_{\rm P}\) linearity as a function of the true \(\not{E}_{\rm T}\) for different physics channels. The \(\not{E}_{\rm L}\) linearity is within 2% above 100 GeV and deviates by 5-10% at lower \(\not{E}_{\rm T}^{\rm True}\). The \(\not{E}_{\rm P}\) bias is consistent with zero throughout. Figure 7 shows the \(\not{E}_{\rm L}\) and \(\not{E}_{\rm P}\) resolution as a function of the true \(\Sigma\not{E}_{\rm T}\) for the QCD jet samples. As the \(\not{E}_{\rm L}\) for jet events is defined as the \(\not{E}_{\rm T}\) projection onto the thrust axis of the two leading jets which are back-to-back, a much larger resolution in absolute terms is expected with respect to \(\not{E}_{\rm P}\). The discontinuity in J4 (\(140<p_{\rm T}<280\) GeV) and J5 (\(280<p_{\rm T}<560\) GeV) \(\not{E}_{\rm P}\) resolution is a result of dividing the dijet events into samples based on the parton \(p_{\rm T}\). Events with the same \(\Sigma\not{E}_{\rm T}\) in J4 and J5 can have different energies in the perpendicular direction due to differences in underlying event, initial or final state radiation. This changes the \(\not{E}_{\rm P}\) resolution in the two samples.

A good performance in terms of linearity and resolution may enhance the ability to reconstruct the mass of final states which involve neutrinos. Despite the presence of several neutrinos in the final state, the invariant mass of the \(\tau\) pair can also be reconstructed in \(Z\to\tau\tau\)  and supersymmetric Higgs boson decays like \(A\to\tau\tau\)  under simplifying assumptions [8, 9, 10]. Figure 8 shows reconstructed mass peaks of \(Z\to\tau\tau\)  and supersymmetric Higgs boson decays \(A\to\tau\tau\)  with \(m_{A}=450\) GeV. The reconstructed masses are correct to \(\sim 2\%\) and the mass resolution is approximately 11%. Nevertheless, significant tailsremain in the distributions because of the highly non-Gaussian effects induced by mis-measurements of \(\not{E}_{\rm T}\) and by the approximations used.

### Measurement of the \(\not{E}_{\rm T}\) direction

Large energy fluctuations in the calorimeter or muon mis-measurements can produce large \(\not{E}_{\rm T}^{\rm Fake}\). In general, for events with genuine missing transverse energy, the \(\not{E}_{\rm T}\) angular resolution will depend on the relative fraction of \(\not{E}_{\rm T}^{\rm Fake}\) and on the event topology. Figure 9 shows the \(\not{E}_{\rm T}\) azimuthal angular resolution as a function of the \(\not{E}_{\rm T}^{\rm True}\) for three different physics processes. The measurement of the \(\not{E}_{\rm T}\) azimuth is clearly more accurate for \(W\to e\nu\) events, which in general contain one high-\(p_{\rm T}\) electron and moderate hadronic activity in addition, compared to \(t\bar{t}\) events. For values of \(\not{E}_{\rm T}^{\rm True}\) below 40 GeV, the accuracy of the measurement of the direction degrades rapidly. In contrast, for high values of \(\not{E}_{\rm T}^{\rm True}\), azimuthal accuracies below 100 mrad are achieved.

Detector inefficiencies may perturb the radial symmetry of the physics events. Thus, observations of \(\phi\) asymmetries in reconstructed variables may be a hint of instrumental problems. Due to the increased material (of \(\sim 5\%\) to 10%) in the upper half of the detector that was added artificially into the simulation, a \(\phi\) asymmetry is observed in \(\not{E}_{\rm T}\) as seen in Fig. 9 (right). This \(\phi\) asymmetry can also be observed in the \(\not{E}_{\rm T}\) computed at the event filter trigger level.

Figure 8: Distributions of the reconstructed invariant mass of \(\tau\)-lepton pairs with one \(\tau\)-lepton decaying to a lepton and the other one decaying to hadrons. The results are shown for \(Z\to\tau\tau\) decays (left) and for \(A\to\tau\tau\) decays with \(m_{A}=450\) GeV (right).

Figure 7: Resolution of \(\not{E}_{\rm L}\)(left) and \(\not{E}_{\rm P}\)(right) as a function of \(\Sigma\not{E}_{\rm T}\) for QCD jet samples. See text for the definition of samples J1-J7.

Similarly, problematic \(\eta\) regions may be spotted by looking at \(\not{E}_{\rm T}\) correlations with jet pseudorapidity, in particular in QCD events. In fact, in this kind of events, \(\not{E}_{\rm T}\) is mainly due to jet mis-measurements which will affect more the \(\not{E}_{\rm T}\) component parallel to the dijet axis than that perpendicular to it. Detector failures or incorrect calibration sets may be revealed as unexpected peaks in such plots.

## 4 Fake \(\not{E}_{\rm T}\)

The reconstructed \(\not{E}_{\rm T}\) has two constituents - one that is produced by particles that interact weakly with the detector (\(\not{E}_{\rm T}^{\rm True}\)) and the other one due to detector inefficiencies and resolution (\(\not{E}_{\rm T}^{\rm Fake}\)). Figure 10 shows the rate of \(\not{E}_{\rm T}^{\rm Fake}\) and \(\not{E}_{\rm T}^{\rm True}\) for the QCD sample generated with \(560<\mbox{$p_{\rm T}$}<1120\mbox{$\;\rm GeV$}\), where \(\not{E}_{\rm T}^{\rm Fake}\) dominates at lower values and also has a larger tail. The same figure also shows these distributions after excluding events with high \(p_{\rm T}\) jets within \(17^{o}\) of the reconstructed \(\not{E}_{\rm T}\) in the transverse plane. This considerably lowers the \(\not{E}_{\rm T}^{\rm Fake}\) rate compared to \(\not{E}_{\rm T}^{\rm True}\). For an accurate measurement of \(\not{E}_{\rm T}\) it is important to have a good understanding of the sources of \(\not{E}_{\rm T}^{\rm Fake}\) in data. Since the goal here is to study the performance and not the relative contributions of signal and background, comparisons between different physics samples are made for a common number of events rather than for a common luminosity.

The first two subsections discuss the \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) from muons and from the calorimeter under the assumption that all detector readout channels are functional. The impact of dead-regions in the detector is examined in the subsequent subsections.

### Fake \(\not{E}_{\mathrm{T}}\) from muons

\(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) from muons can be caused either by inefficiencies in reconstructing a high \(p_{\mathrm{T}}\) muon or by reconstructing a fake high \(p_{\mathrm{T}}\) muon. The latter could be present due to a combination of a lower \(p_{\mathrm{T}}\) muon and/or random hits from high \(p_{\mathrm{T}}\) jet punch-throughs from the calorimeter to the muon chambers. It can be argued that for reasonable muon identification efficiencies, \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) from missed muons will only be a small fraction of the \(\not{E}_{\mathrm{T}}^{\mathrm{True}}\) from neutrinos. For example in QCD samples the neutrino to muon ratio is roughly two. It gets higher in other physics samples depending on the fraction of \(\tau\) candidates in the event. On the other hand fake muons that are reconstructed from random hits in the muon chambers can be arbitrarily hard and strongly contribute to \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\). However, the study here shows that \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) from muons is dominated by missed muons rather than fake muons.

The total \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) in the MC sample can be defined as the vectorial difference of reconstructed \(\not{E}_{\mathrm{T}}\) and \(\not{E}_{\mathrm{T}}^{\mathrm{True}}\), as follows:

\[\not{E}_{\mathrm{T}}^{\mathrm{Fake}}=\sqrt{\not{E}_{x}^{\mathrm{Fake}}{}^{2}+ \not{E}_{y}^{\mathrm{Fake}}{}^{2}}\qquad\mathrm{where}\qquad\not{E}_{x,y}^{ \mathrm{Fake}}=\not{E}_{x,y}-\not{E}_{x,y}^{\mathrm{True}}. \tag{11}\]

\(\not{E}_{x,y}\) and \(\not{E}_{x,y}^{\mathrm{True}}\) are the \(x\) and \(y\) components of the final reconstructed \(\not{E}_{\mathrm{T}}\) and of the \(\not{E}_{\mathrm{T}}^{\mathrm{True}}\) defined in Section 3.

The contribution to the total \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) from muon mis-measurements can be defined by

\[\not{E}_{x,y}^{\mathrm{FakeMuon}}=\not{E}_{x,y}^{\mathrm{Muon}}-\not{E}_{x,y}^ {\mathrm{TrueMuon}}, \tag{12}\]

where \(\not{E}_{x,y}^{\mathrm{Muon}}\) and \(\not{E}_{x,y}^{\mathrm{TrueMuon}}\) are calculated by summing the reconstructed and true \(x\) and \(y\) components from muons in the event.

Figure 11 (left) shows the scatter plot of the two quantities defined in Equations (11) and (12) for the QCD sample with \(560<p_{\mathrm{T}}<1120\GeV\). In order to separate the \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) from muons with respect to the calorimeter related \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) the following cuts can be used: (a) \(\not{E}_{\mathrm{T}}^{\mathrm{FakeMuon}}>\not{E}_{\mathrm{T}}^{\mathrm{Fake}}/2\) which selects events with fake \(\not{E}_{\mathrm{T}}\) coming predominantly from muon mis-measurements, and (b) \(\not{E}_{\mathrm{T}}^{\mathrm{FakeMuon}}<\not{E}_{\mathrm{T}}^{\mathrm{Fake}}/2\)

Figure 11: (left) Total \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) as a function of \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) from muon mis-measurements. (middle and right) Cuts defined in (b) and (a) (see text) are used to separate calorimeter/jet and muon \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) components.

which selects events with fake \(\not{E}_{\rm T}\) coming predominantly from other sources like jet mis-measurements in the calorimeter. Figure 11 also shows how these cuts separate events with \(\not{E}_{\rm T}^{\rm Fake}\) from muons and from calorimeter induced effects.

Table 1 shows the number of events above various \(\not{E}_{\rm T}^{\rm Fake}\) thresholds for physics samples (QCD jets in the range \(560<\mbox{$p_{\rm T}$}<1120\) GeV, SU3, \(t\bar{t}\) and \(Z\rightarrow\mu\mu\) ) that are predominantly from muons (top rows) or from the calorimeter (bottom rows). It can be seen that the relative rate of \(\not{E}_{\rm T}^{\rm Fake}\) across samples depends on the muon and calorimeter activities.

In Table 2 different categories of muon mis-measurements and their relative contribution to \(\not{E}_{\rm T}^{\rm Fake}\) are shown2

Footnote 2: Due to technical reasons a small fraction of muon events were not classified in any category.

The first two rows are from missed muons and the last two rows are from fake muons reconstructed from random hits in the muon chambers and with a possible match to soft muon tracks in the inner detector. Table 2 shows a smaller contribution to \(\not{E}_{\rm T}^{\rm Fake}\) from fake muons compared to missed muons. Therefore the dominant contribution to \(\not{E}_{\rm T}^{\rm Fake}\) from muons is due to inefficiencies in the muon identification.

Figure 12 (left) shows the \(\eta\) distribution of the true muons that were missed at the reconstruction level in the \(Z\rightarrow\mu\mu\) sample with \(\mbox{$p_{\rm T}$}>100\) GeV. There are missed muons around \(\eta=0\), \(|\eta|\)=1.2 and at high \(\eta\) (\(|\eta|\)\(>\)2.7) where there is no muon coverage. Muon tracks cannot be reconstructed by the muon system around \(\eta=0\) (\(-0.05<\eta<0.05\)), because of service holes required for cables and cryogenics passage to the inner detectors and calorimeters. In the region around \(|\eta|\)=1 there is a loss of efficiency in muon reconstruction, due to the middle muon station missing for initial data taking. In these studies muons missed due to limitations of muon detector coverage or poor muon reconstruction have not been recovered. In the next software releases algorithms to recover some of these missed muons using energy

\begin{table}
\begin{tabular}{l r r r r} \hline \hline \multicolumn{5}{c}{\(\not{E}_{\rm T}^{\rm Fake}>60\) GeV} & \multicolumn{1}{c}{\(>90\) GeV} & \multicolumn{1}{c}{\(>120\) GeV} & \multicolumn{1}{c}{\(>150\) GeV} \\ \hline \(\not{E}_{\rm T}^{\rm Fake}\) from Muon & & & & \\ J6 & 61 & 33 & 20 & 13 \\ SU3 & 195 & 109 & 57 & 42 \\ \(t\bar{t}\) & 147 & 64 & 33 & 20 \\ \(Z\rightarrow\mu\mu\) & 436 & 94 & 37 & 20 \\ \hline \(\not{E}_{\rm T}^{\rm Fake}\) from Calorimeter & & & & \\ J6 & 4273 & 1249 & 351 & 110 \\ SU3 & 1005 & 176 & 56 & 53 \\ \(t\bar{t}\) & 104 & 15 & 4 & 2 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Number of events with \(\not{E}_{\rm T}^{\rm Fake}\) above various thresholds from muon (top) and calorimeter (bottom) mis-measurements. The J6 (QCD jets in \(560<\mbox{$p_{\rm T}$}<1120\) GeV range), SU3, \(t\bar{t}\), and \(Z\rightarrow\mu\mu\) samples are normalized to the same number of events (25k).

\begin{table}
\begin{tabular}{l r r r r} \hline \hline Sources & SU3 & J6 & \(t\bar{t}\) & \(Z\rightarrow\mu\mu\) \\ \hline MC muon not reconstructed & 121 & 17 & 42 & 332 \\ Reconstructed muon failed quality cut & 30 & 18 & 40 & 18 \\ Muon reconstructed with badly measured \(\mbox{$p_{\rm T}$}\) & 29 & 3 & 28 & 28 \\ Reco muon not close to MC muon (“fake muon”) & 11 & 23 & 0 & 25 \\ \hline \hline \end{tabular}
\end{table}
Table 2: The sources of mis-measured muons that contribute to \(\not{E}_{\rm T}^{\rm Fake}>60\) GeV. The columns are normalized to the same number of events (25k).

deposits in the calorimeter and tracks in the inner detector will be used.

Figure 12 (right) shows the \(\not{E}_{\rm T}^{\rm Fake}\) distributions for events in which the leptonically decaying \(W\) results in an electron and those resulting in a muon, respectively. The latter distribution clearly contains larger non-Gaussian tails. As discussed above, the sources of these large tails are either missed or fake muons.

### Fake \(\not{E}_{\rm T}\) from the calorimeter

In this section it is assumed that all calorimeter readout channels are functional. \(\not{E}_{\rm T}^{\rm Fake}\) in the calorimeter is then produced by mis-measurements of hadronic jets, taus, electrons or photons.

The calorimeter has cracks and gaps in the transition regions, which are also used for service outlets. These regions have poorer resolution and are expected to have larger contributions to \(\not{E}_{\rm T}^{\rm Fake}\) compared to the rest of the calorimeter. There are two gap regions defined in the following \(\eta\) ranges: (\(1.3<|\eta|<1.6\)) and (\(3.1<|\eta|<3.3\)). Figure 13 shows the \(\eta\) distribution of the worst and the second worst measured jet (defined w.r.t. the closest true jet and their energy difference) in the calorimeter for the QCD sample generated with \(560<\mbox{$p_{\rm T}$}<1120\) GeV. It shows that a large number of the worst measured

Figure 12: (left) The \(\eta\) distribution of true muons that were missed during reconstruction in a \(Z\rightarrow\mu\mu\) high \(\mbox{$p_{\rm T}$}>100\) GeV sample. (right) \(\not{E}_{\rm T}^{\rm Fake}\) in \(t\bar{t}\) events in the electron (hatched) and muon channel.

Figure 13: The \(\eta\) distribution of the worst (left) and second-worst measured jet (right) in the calorimeter in QCD events generated with \(560<\mbox{$p_{\rm T}$}<1120\) GeV.

jets have \(\eta\) pointing to \(|\eta|\) in 1.3-1.6. The \(\eta\) distribution of the second worst measured jet is more flat and peaks around \(|\eta|\) in 0.6-0.9, the transition region of the barrel tile calorimeter to the extended barrel tile calorimeter.

The above correlation of worst measured jets and their \(\eta\) suggests a large correlation between the jet \(\eta\) and \(\not\!\!E_{\rm T}^{\rm Fake}\). However, the \(\not\!\!E_{\rm T}^{\rm Fake}\) distribution from full simulation samples suggests otherwise. Figure 14 shows the \(\not\!\!E_{\rm T}^{\rm Fake}\) distribution in the QCD samples generated with \(560<\mbox{$p_{\rm T}$}<1120\) GeV and \(140<\mbox{$p_{\rm T}$}<280\) GeV, when a jet points to the crack/gap region or not. The slope of the distributions suggests no significant correlation between jets pointing to cracks and \(\not\!\!E_{\rm T}^{\rm Fake}\).

This apparent contradiction between Fig. 13 and Fig. 14 can be understood as follows: even though the worst measured jet contributes strongly to the \(\not\!\!E_{\rm T}^{\rm Fake}\), it is not the only source of \(\not\!\!E_{\rm T}^{\rm Fake}\) in the event. The worst measured jet contributes on average about 60% and the second worst measured jet contributes about 20% to \(\not\!\!E_{\rm T}^{\rm Fake}\). But not all worst measured jets are along the crack region and each event has many jets. In lower \(\not\!\!E_{\rm T}^{\rm Fake}\) regions there is a stronger correlation between \(\not\!\!E_{\rm T}^{\rm Fake}\) and jets pointing to cracks. For higher \(\not\!\!E_{\rm T}^{\rm Fake}\) ( \(>50\) GeV considered here ) there is more than one source contributing to \(\not\!\!E_{\rm T}^{\rm Fake}\) and the correlation of jets pointing to cracks is smeared out as can be seen in Fig. 14.

### Fake \(\not\!\!E_{\rm T}\) from calorimeter leakage

Jet leakage from the calorimeters or fluctuations in large jet energy deposits in non-instrumented regions such as the cryostat between the liquid argon and tile calorimeters can also be a source of \(\not\!\!E_{\rm T}^{\rm Fake}\). The method used to detect events with potential jet leakage is to look for large energy deposits in the following regions: the outermost layers of the TileCal and the HEC, the outermost LAr barrel layer and the innermost TileCal barrel layer, and in the TileCal gap and crack scintillators.

The following shows an example of selection cuts applied on different variables of the three leading \(p_{\rm T}\) jets with \(p_{\rm T}\)\(>100\) GeV: \(\rm E_{Tile2}/E_{Total}\)\(>0.05\), \(\rm E_{Tile10}/E_{Total}\)\(>0.7\), \(\rm E_{Cryo}/E_{Total}\)\(>0.2\), \(\rm E_{Gap}/E_{Total}\)\(>0.2\) and \(\rm E_{HEC3}/E_{Total}\)\(>0.5\), where \(\rm E_{Total}\) is the total jet energy, \(\rm E_{Tile2}\) is the jet energy in the outermost tile layer, \(\rm E_{Tile10}\) is the jet energy in the first two innermost tile layer, \(\rm E_{Cryo}\) is the energy lost by the jet in the cryostat, \(\rm E_{Gap}\) is the jet energy in the gap scintillators and \(\rm E_{HEC3}\) is the jet energy in the outermost layer of the HEC calorimeters. If any of these cuts is satisfied the event is rejected.

Furthermore, as the tracks found in the inner detector are not affected by the reconstruction, complementary information on events with fake \(\not\!\!E_{\rm T}\) can be obtained using \(\not\!\!E_{\rm T}_{\rm trk}\) from tracks which is the \(\not\!\!E_{\rm T}\) computed only from tracks. A cut on \((\not\!\!E_{\rm T}_{trk}-\not\!\!E_{\rm T}\)\(>50\) GeV\()\) was chosen for the optimization of the signal significance.

Figure 14: The \(\not\!\!E_{\rm T}^{\rm Fake}\) rate for QCD sample in \(560<\mbox{$p_{\rm T}$}<1120\) GeV range (left) and QCD sample in \(140<\mbox{$p_{\rm T}$}<280\) GeV (right) due to calorimeter mis-measurements.

Figure 15 shows the percentage of events remaining after the cuts described above are applied on QCD sample generated with \(560<p_{\mathrm{T}}<1120\GeV\). The right plot shows suppression of large fake \(\not{E}_{\mathrm{T}}\) generated due to high \(p_{\mathrm{T}}\) jet leakage. Larger fake \(\not{E}_{\mathrm{T}}\) are suppressed more strongly. It can also be noticed from the left plot that these cuts, although removing a large fraction of the events dominated by fake \(\not{E}_{\mathrm{T}}\), are not sensitive to the overall \(\not{E}_{\mathrm{T}}\) in the event and the fraction of remaining events is fairly constant over \(\not{E}_{\mathrm{T}}\). The method is of course analysis dependent and the values of the cuts should be chosen taking into account the signal efficiency.

### Fake \(\not{E}_{\mathrm{T}}\) from instrumental effects

In real data there will be sources of \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) which are not fully modeled in Monte Carlo simulations including, for example, mis-modeling of material distributions and instrumental failures. As the details of these \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) sources will be understood with time, increasingly refined analyses will be developed to minimize their associated backgrounds while maintaining high selection efficiencies for signals with genuine missing energy. While it is difficult to predict in advance the exact sources of mis-modeled \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\), it is nevertheless possible to insert problems into the Monte Carlo that match potential hardware failures. These include trips in high-voltage channels or readout power supplies of the calorimeter or noise in calorimeter channels or regions. The initial studies presented here are based on samples with simulated dead regions of the calorimeter, so called 'cell-killed' samples: one dead front-end readout crate in the LAr electromagnetic barrel calorimeter and one dead front-end readout crate affecting LAr electromagnetic and endcap calorimeters. Based on the location of these hardware failures the calorimeter is divided into three regions of \(\phi(\not{E}_{\mathrm{T}})\): 'Region 1' with EM endcap and hadronic endcap problems, 'Region 2' with EM barrel problems, and 'Region 3' with no problems.

These samples were used as references for the development of cuts that reduce the \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) background while maintaining high efficiencies for potential signal events. Since we will not know the precise location and nature of hardware problems in advance, the cuts are not tuned assuming that knowledge. In real data it will be possible to significantly improve the analysis performance by cutting harder when energy deposits are expected near regions with detector hardware problems, but that is not exploited in the studies so far. Future work will also include using these samples to develop data-driven techniques for predicting the \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) tails.

The high-\(p_{\mathrm{T}}\) (\(560<p_{\mathrm{T}}<1120\GeV\)) \(\gamma+\)jet MC sample was processed with the cell-killed configuration described above. Events with at least one back-to-back photon-jet pair were selected. Figure 16 shows the \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) generated in the three regions. Large \(\not{E}_{\mathrm{T}}\) tails are seen in Regions 1 and 2 where the holes in calorimeter coverage have been introduced. The effect of dead regions can also be seen in Table 3. The columns show the number of events above various \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\) thresholds. The first two rows show the

Figure 15: Fraction of events remaining after the cuts discussed in the text as a function of \(\not{E}_{\mathrm{T}}\)(left) and \(\not{E}_{\mathrm{T}}^{\mathrm{Fake}}\)(right) for the QCD sample generated with \(560<p_{\mathrm{T}}<1120\GeV\).

number of events with no dead-regions and with the above dead-regions simulated. A very large increase in high \(\not\!\!E_{\mathrm{T}}^{\mathrm{Fake}}\) is seen.

Several methods have been developed to suppress events with large fake \(\not\!\!E_{\mathrm{T}}\):

* **EM Fraction Method:** The EM fraction method starts by finding the closest calorimeter jet to the \(\not\!\!E_{\mathrm{T}}\) direction vector using \(\Delta\phi\) between the calorimeter jet and \(\not\!\!E_{\mathrm{T}}\). Figure 16 (right) shows the EM fraction distributions. Small EM fractions are due to a dead LAr EM calorimeter crates, whereas large EM fractions are due to a dead hadron calorimeter crates. The fake \(\not\!\!E_{\mathrm{T}}\) generated this way can be suppressed by requiring the EM fraction to be in a window from 0.40 to 0.96. The effect of this cut can be seen in the third row of Table 3 when compared to the increase in \(\not\!\!E_{\mathrm{T}}^{\mathrm{Fake}}\) due to dead-regions in row 2. A rejection of 1.5 to 4 is seen from low to high \(\not\!\!E_{\mathrm{T}}^{\mathrm{Fake}}\) bins. The selection efficiency can be defined as the ratio of the number of events after and before the cuts when events fall in Region 3 (Region 3 has small \(\not\!\!E_{\mathrm{T}}^{\mathrm{Fake}}\)). For the EM fraction method the selection efficiency is \(\sim 90\%\).
* **Track-Jet Methods:** jets were reconstructed from inner detector tracks using the cone algorithm with \(\Delta R=0.4\). A fiducial volume cut of \(|\eta|<2.5\) is applied due to the tracking coverage. Since track-jets use the inner tracking detectors, they provide a complementary identification of events with fake \(\not\!\!E_{\mathrm{T}}\). A number of different methods of exploiting the track-jets were studied. An effective method which only uses information present in the Analysis Object Data (AOD) is to sum the \(E_{\mathrm{T}}\) of calorimeter topological clusters within the track-jet \(\eta\)-\(\phi\) cone. The distributions of the \(E_{\mathrm{T}}\) ratio of the track-jet to the clusters has tails due to the dead calorimeter regions. A cut is applied requiring \(E_{\mathrm{T}}\) ratios larger than 1.0; the value was chosen to maintain a significant efficiency for signal samples, and could be substantially tightened for different physics analyses. The fourth row of Table 3 shows the effectiveness of this cut. Rejections from \(\eta=1.4\) to \(\eta=4\) are achieved from the low to high \(\not\!\!E_{\mathrm{T}}^{\mathrm{Fake}}\) regions, with efficiencies of \(\sim 93\%\).

Since the EM fraction method and track-jet methods are largely uncorrelated, they can be combined for better suppression of large \(\not\!\!E_{\mathrm{T}}^{\mathrm{Fake}}\). The last row in Table 3 shows the performance of the combined track-jet method. The selection efficiency for this combined method is \(\sim 84\%\). It must be emphasized that the results presented in this table represent the worst case since the cuts do not use the detailed information about detector problems that will be known from the detector control and data quality systems. In a final analysis, much harder cuts can be applied in regions with known detector problems. Of course, this will reduce the acceptance of the detector.

Figure 16: Cell-killed QCD sample in \(560<p_{\mathrm{T}}<1120\) range: the \(\not\!\!E_{\mathrm{T}}\) distribution (left) and the EM fraction (right). The histograms are normalized by area.

## 5 The \(\not{E}_{\rm T}\) Trigger algorithm performance

This section briefly describes the \(\not{E}_{\rm T}\) algorithms applied at the first level trigger (L1) and the higher-level trigger (HLT). The HLT is a combination of second level trigger (L2), and a third level trigger (or event filter, EF). The L1 algorithm is based on hardware, while the HLT algorithms are software based.

### The \(\not{E}_{\rm T}\) at L1

The \(\not{E}_{\rm T}\) L1 calorimeter triggers cover the region \(|\eta|<4.9\), which is the limit of the forward calorimeters [11]. The basic units of L1 \(\not{E}_{\rm T}\) and \(\Sigma\not{E}_{\rm T}\) trigger algorithms are 'jet elements', formed by summing over trigger towers within windows of \(0.2\times 0.2\) in the \((\eta,\phi)\) plane.3 They are processed by the Jet/Energy modules, which compute \(E_{x}\), \(E_{y}\) and \(\Sigma\not{E}_{\rm T}\) of each jet element. Four thresholds are available on \(\Sigma\not{E}_{\rm T}\) with values up to 2044 counts in steps of 4 (usually, 1 count = 1 GeV). Eight \(\not{E}_{\rm T}\) thresholds are available, up to a maximum threshold value of 504 counts. If an overflow occurs at any point in the \(\not{E}_{\rm T}\) or \(\Sigma\not{E}_{\rm T}\) algorithm, all of the corresponding thresholds are set as passed.

Footnote 3: For \(2.4<|\eta|<3.2\) the granularity is either \(\Delta\eta=0.2\) or \(\Delta\eta=0.3\), while FCAL jet elements extend from \(|\eta|=3.2\) to \(|\eta|=4.9\). The \(\phi\) granularity of the FCAL jet elements is \(\Delta\phi=0.4\).

For each event, the L1 \(E_{x}\), \(E_{y}\) and \(\Sigma\not{E}_{\rm T}\) are saved into one object of the RecEnergyRoI class, including overflow flags. If any threshold is passed, the JetEnergy RoI is also produced containing the bit pattern of the thresholds passed.

### \(\not{E}_{\rm T}\) at HLT

The offline algorithm described in Section 2.2 is too resource intensive (both in terms of memory access and calculations to be done) to be applied in the HLT. The following algorithms are ready for the first data taking4:

Footnote 4: At present, work is in progress to detect fake sources due to detector effects like uninstrumented regions or hardware failure, or physics environment, e.g. beam-halo or cosmic ray tracks.

* The L2 algorithm uses the calorimeter information in RecEnergyRoI provided by the L1 trigger and applies a correction for L2 muon objects.
* The default EF algorithm sums all calorimeter cells and applies a 0-th order hadronic calibration by multiplying \(\not{E}_{\rm T}\) and \(\Sigma\not{E}_{\rm T}\) by a constant related to the hadronic/electromagnetic calorimeter energy fraction in a jet. Finally, the EF takes the muon contribution into account.

Both at L2 and EF, the muon correction may be switched off independently for each trigger chain.

The decision taken both at L2 and EF is carried out by the same software package. This hypothesis testing code can be configured to accept events based on \(\not{E}_{\rm T}\), on \(\Sigma\not{E}_{\rm T}\) or on both.

\begin{table}
\begin{tabular}{l r r r r r} \hline \hline \(\not{E}_{\rm T}\)\({}^{\rm Fake}\) (GeV) & \(>100\) & \(>200\) & \(>300\) & \(>400\) & \(>500\) \\ \hline \hline No dead regions & 555 & 18 & 3 & 1 & 0 \\ \hline w/ dead regions & 2482 & 1308 & 864 & 501 & 199 \\ w/ EM fraction method & 1651 & 572 & 287 & 122 & 50 \\ w/ track-jet cluster method & 1786 & 664 & 313 & 129 & 49 \\ \hline w/ comb. track-jet cluster method & 1402 & 392 & 150 & 46 & 14 \\ \hline \hline \end{tabular}
\end{table}
Table 3: The number of events from \(\gamma\)+jet samples above various \(\not{E}_{\rm T}\)\({}^{\rm Fake}\) thresholds with no dead-regions, with simulated dead-regions and after applying various suppression techniques (see text). All numbers are normalized to 25k events sample size.

### The \(\not{E}_{\rm T}\) and \(\Sigma\not{E}_{\rm T}\) resolution at trigger level

Figure 17 shows the \(\not{E}_{\rm T}\) and \(\Sigma\not{E}_{\rm T}\) resolution for the L1, EF and offline algorithms as a function of the true \(\Sigma\not{E}_{\rm T}\) for \(t\bar{t}\) events. Since the L2 algorithm takes the L1 result and applies relatively small corrections, the present L2 resolution is practically the same as for L1 and therefore not shown. At true \(\Sigma\not{E}_{\rm T}\) values of 500 GeV, the L1 resolution on the \(\not{E}_{\rm T}\) measurement is about 25 GeV which is a factor of two larger than what is achieved offline. The EF resolution, for both \(\not{E}_{\rm T}\) and \(\Sigma\not{E}_{\rm T}\) lies in between the values for L1 and offline resolution.

## 6 \(\not{E}_{\rm T}\) in early data

Validation of the \(\not{E}_{\rm T}\) reconstruction described in the previous sections will be performed with the first LHC data accumulated by ATLAS. For the very first data, the two main issues are controlling instrumental failures and calibration of energy deposits in the calorimeter. At this stage, the overwhelming number of minimum bias events will be used to monitor and diagnose \(\not{E}_{\rm T}\) reconstruction problems.

The development of algorithms for data quality checks is being actively pursued to minimize the impact of such failures and will be optimized when the first data is collected. The'standard' \(\not{E}_{\rm T}\) calculation, using the calorimeter cells at the electromagnetic scale above a threshold will be always provided as a reference. The \(\not{E}_{\rm T}\) calibration strategy follows the steps described in Section 3. First, a simple global calibration for all the TopoCells will be used. As shown in Section 3 this already gives a good linearity behavior. As the event reconstruction becomes more robust, the event objects (e.g. electrons, jets, taus) will be used to obtain the best \(\not{E}_{\rm T}\) resolution.

Figure 3 already shows how the \(\not{E}_{\rm T}\) linearity improves from a simple to a more refined \(\not{E}_{\rm T}\) calculation. Figure 18 shows how the \(\not{E}_{\rm T}\) resolution improves arriving in steps to the final refined calibration.

Once data of the order of 100 pb\({}^{-1}\) are collected, the \(\not{E}_{\rm T}\) validation focuses on physics channels with relatively large \(\not{E}_{\rm T}\) and/or \(\Sigma\not{E}_{\rm T}\). This section briefly describes a few studies that will be performed with the first data.

The \(Z\to\tau\tau\) process, using the \(Z\) mass constraint, can be used to determine the \(\not{E}_{\rm T}\) scale in-situ to about 8% accuracy. The \(Z\to\ell\ell\) process with decays to electrons and muons does not have any significant \(\not{E}_{\rm T}^{\rm True}\) from neutrinos. The small background to these events will help to test possible \(\not{E}_{\rm T}\) biases, expected to be zero, and the resolution in a straightforward manner. The copiously produced \(W\to e\nu\) and \(W\to\mu\nu\) events can be used to test the reconstructed \(\not{E}_{\rm T}\) in the \((20-150)\) GeV range. Two methods to use these events are discussed. Semileptonic \(t\bar{t}\) events also have genuine \(\not{E}_{\rm T}\) and allow atest of the \(\not{E}_{\rm T}\) reconstruction in an environment relevant for many physics analyses and searches, notably SUSY.

### Minimum bias events

Minimum bias interactions at the LHC are dominated by soft collisions of the two interacting protons. These events are useful for \(\not{E}_{\rm T}\) commissioning, especially in the early stages of the experiment, due to their large statistics and their comparatively simple event selection. The main background in minimum bias events will originate from empty, beam gas and beam halo events, especially at the beginning of the experiment. Minimum bias events will be used to verify the \(\not{E}_{\rm T}\) reconstruction procedure and estimate the \(\not{E}_{\rm T}\) resolution for low \(\Sigma\not{E}_{\rm T}\)  events.

In the early stages of the experiment, minimum bias events will be selected by three types of triggers: randomly selected bunch crossings (MB1), randomly selected bunch crossings together with a SemiConductor Tracker space point trigger (MB2), and minimum bias trigger scintillator (MBTS2). The details of the triggers are described in Ref. [12].

For the study of \(\not{E}_{\rm T}\) in minimum bias events, high signal efficiency and background rejection are required. The relative fraction of non-diffractive, single diffractive and double diffractive events in the sample is not a concern. The selection criteria require at least 20 semiconductor tracker space points to reject empty events and at least one good reconstructed track to reject beam gas and halo events.

A Monte Carlo study predicts an overall trigger efficiency of 96.8%. The offline track selection efficiency (with respect to events passing the trigger) is 80.6% for a total selection efficiency of 78.0%.

The \(\not{E}_{\rm T}\) in minimum bias events is fairly low with a mean of 4.3. Fake \(\not{E}_{\rm T}\) is caused mainly by calorimeter energy resolution (82%) and acceptance (18%). The true \(\not{E}_{\rm T}\) is 0.06  on average, originating from \(K/\pi\) decays-in-flight and from the decay of charm and bottom particles. The true \(\Sigma\not{E}_{\rm T}\) in non-diffractive minimum bias events is typically 64, while the reconstructed \(\Sigma\not{E}_{\rm T}\) is on average 49 due to the loss of low energy particles which do not reach the calorimeters. Since minimum bias events are dominated by soft (low-\(p_{\rm T}\)) interactions, jets are reconstructed with a rate depending on \(\Sigma\not{E}_{\rm T}\). When minimum bias events with \(\Sigma\not{E}_{\rm T}\) of 50 are compared to events with \(\Sigma\not{E}_{\rm T}\) of 250, the average number of reconstructed jets with \(p_{\rm T}>7\) increases from below one to about nine with an average jet energy of 10 and 13 GeV, respectively.

The \(\not{E}_{\rm T}\) resolution in minimum bias events is expected to scale as \(\sqrt{\Sigma E_{T}}\) because the stochastic term of the calorimeter resolution is dominant in \(\Sigma\not{E}_{\rm T}\) regions as shown in the left plot of Fig. 19. These distributions are well fitted by Gaussian functions with offsets of zero (in the case of no \(\phi\) asymmetry) and resolutions which scale with \(\Sigma\not{E}_{\rm T}\).

The right plot of Fig. 19 shows the comparison of the \(\not{E}_{\rm T}\) resolution evaluated in this study with the higher \(\Sigma\not{E}_{\rm T}\) region (\(\Sigma\not{E}_{\rm T}>300\) GeV). The \(\not{E}_{\rm T}\) resolution in QCD dijet events matches well the resolution obtained from minimum bias events.

### Determining the \(\not{E}_{\rm T}\) scale using \(Z\to\tau\tau\) events

At the beginning of ATLAS operation, about 70k events of type \(Z\to\tau\tau\) with one leptonic and one hadronic \(\tau\)-decay will be produced in 100 pb\({}^{-1}\) of data. Such events can be selected with a lepton trigger. The \(Z\to\tau\tau\to\ell h\) are produced with genuine \(\not{E}_{\rm T}\) of typically 20 GeV and \(\Sigma\not{E}_{\rm T}\) of the order of 200 GeV. In these events the peak position of the \(\tau\tau\) invariant mass distribution is sensitive to \(\not{E}_{\rm T}\) and can be very useful in determining the \(\not{E}_{\rm T}\) scale [10].

The main backgrounds come from \(W\to\ell\nu\)+jets events, where one jet fakes a \(\tau\) decay, and from QCD events (mainly \(b\bar{b}\)). The \(t\bar{t}\) background has a much lower cross-section; the \(Z\to ee\) and \(Z\to\mu\mu\) backgrounds are also small and the \(WW\) background is negligible. Events with the final state lepton and \(\tau\)-jet of the same-sign are not expected to come from \(Z\to\tau\tau\) events which have opposite-sign. The backgrounds (apart from the \(t\bar{t}\) background, which is anyway low) contribute in the same way to the opposite-sign and the same-sign samples. Hence, the effect of backgrounds will be minimized using same-sign events, subtracted from the opposite-sign events.

For each reconstructed event, the leading and isolated lepton (electron or muon) with \(p_{\rm T}^{\ell}>15\) GeV and \(|\eta^{\ell}|<2.5\) is chosen and a set of basic cuts is applied: \(\not{E}_{\rm T}>20\) GeV (rejects QCD events), the transverse mass calculated from \(\not{E}_{\rm T}\) and the lepton \(<50\) GeV (suppresses events from semileptonic \(W\) decays), and \(\Sigma\not{E}_{\rm T}<400\) GeV (suppresses QCD). In addition it is required to have no tagged \(b\) jets (suppresses \(t\bar{t}\) and \(b\bar{b}\) events). Then at least one identified \(\tau\)-jet with \(p_{\rm T}^{\tau-{\rm jet}}>15\) GeV, \(|\eta^{\tau-{\rm jet}}|<2.5\)

Figure 19: (left) The \(\not{E}_{x,y}\) resolution for different \(\Sigma\not{E}_{\rm T}\) regions in minimum bias events. (right) The \(\not{E}_{\rm T}\) resolution in QCD dijet events (J0-J3: see Section 3.1 for definition) is shown together with the \(\not{E}_{\rm T}\) resolution from minimum bias events (black filled circles) as a function of \(\Sigma\not{E}_{\rm T}\). An integrated luminosity of the order of \(10^{-5}\) pb\({}^{-1}\) is used.

and a track multiplicity of one or three is required. The \(\Delta\phi\) between the isolated lepton and the \(\tau\)-jet is required to be in the range between \(1-2.8\), which reduces badly reconstructed events and further rejects backgrounds.

With 100 pb\({}^{-1}\) of data, 210 signal events (opposite-sign) are expected in the invariant mass range \(66\GeV<m_{\tau\tau}<116\GeV\). A total background of 16 events is expected. Figure 20 (left) shows the reconstructed mass peak for \(Z\rightarrow\tau\tau\) events as well as the small total backgrounds after analysis cuts for opposite-sign and same-sign events.

Figure 20 (right) shows a very good sensitivity of the measured \(Z\) mass reconstructed from \(\tau\)-pairs to the absolute \(\not{E}_{\rm T}\) scale. With an integrated luminosity of 100 pb\({}^{-1}\), the \(Z\) mass can be reconstructed with an uncertainty of \(\pm 0.8\GeV\). Taking into account the statistical uncertainty only, the \(\not{E}_{\rm T}\) scale could be determined with a precision of \(\sim 3\%\). But systematic effects, such as the subtraction of same-sign events and the stability of the fit will affect the measurement of the reconstructed mass peak. Therefore, assuming a resolution of \(\pm 3\sigma\) on the reconstructed \(Z\) mass, the \(\not{E}_{\rm T}\) scale can be determined to about \(\pm 8\%\).

### \(Z\rightarrow\ell\ell\) events

This analysis uses inclusive \(Z\to ee\) and \(Z\rightarrow\mu\mu\) samples to investigate the scale and resolution of the \(\not{E}_{\rm T}\) reconstruction in the first data. In these samples the transverse momentum of the two leptons from the \(Z\) boson decay are balanced by the hadronic recoil and \(\Sigma\not{E}_{\rm T}\) reaches values up to a few hundred GeV.

Events are selected by requiring two well reconstructed, identified and isolated leptons with \(p_{\rm T}>25\GeV\). They have to have equal or opposite charge and a reconstructed mass, \(m_{\ell\ell}\), in the interval \(70-100\GeV\). In a sample of \(250\,{\rm pb}^{-1}\) of data, about 400k events are expected.

Backgrounds from \(Z\rightarrow\tau\tau\) and \(W\rightarrow\ell\nu\) events are negligible. The background from QCD events in which two leptons are falsely identified is expected to be small but has to be carefully evaluated when data are available. In the present study, these backgrounds are not considered as they are expected to have negligible impact.

In Section 3, projections of \(\not{E}_{\rm T}\), called \(\not{E}_{\rm L}\) and \(\not{E}_{\rm P}\), were introduced. This analysis aims at optimizing the principle of using projections by resolving the missing transverse momentum along the so called 'longitudinal axis' which is defined by the combined direction of flight of the two leptons. The perpendicular axis is also defined in the transverse plane which is orthogonal to the longitudinal axis. The axes

Figure 20: (left) Reconstructed invariant mass of the pair of \(\tau\) leptons for \(Z\rightarrow\tau\tau\) decays and all backgrounds: opposite-sign background (dashed) and same-sign background (dotted). (right) Reconstructed invariant mass of the pair of \(\tau\) leptons for \(Z\rightarrow\tau\tau\) decays as a function of the \(\not{E}_{\rm T}\) scale. The horizontal lines correspond to \(\pm 1\sigma\) and to \(\pm 3\sigma\) w.r.t. the \(Z\) peak position. The analysis is based on an integrated luminosity of 100 pb\({}^{-1}\) of data.

as reconstructed from the measured angles of the leptons and their measured energies are thus not used at this point, which would fully exploit the good angular resolution of the ATLAS detector. In general, the longitudinal axis points in the direction of flight of the \(Z\) boson and away from the hadronic recoil.

Figure 21 (left) shows, for \(Z\to ee\) events, the average \(\not{E}_{\rm T}\) resolved along both axes as a function of the transverse momentum of the lepton system resolved along the longitudinal axis.

The results for the longitudinal axis exhibit a negative offset of up to \(\sim 4\) GeV at high values of \(p_{\rm T}\) of the lepton system, while the results for the perpendicular axis are consistent with zero. For \(Z\to\mu\mu\) events similar results are obtained. It has been verified that this offset is not caused by real neutrinos in the event. If the event topology is considered, it is clear that this is suggesting that the magnitude of the hadronic recoil \(p_{\rm T}\) is underestimated. The resolution of the \(\not{E}_{\rm T}\) projection on both axes as a function of the total scalar sum of the activity in the hadronic calorimeter, \(\sum E_{\rm T,\,cluster}\), is shown in Figure 21(right) for \(Z\to ee\) events. The fitted curve is of the form \(\sigma(\not{E}_{\rm T})=P_{0}\sqrt{\sum E_{T,\,cluster}}+P_{1}\) and illustrates the stochastic behavior of the calorimetric energy measurement.

These results on \(Z\to ee\) and \(Z\to\mu\mu\) events demonstrate that potential problems of the \(\not{E}_{\rm T}\) reconstruction can be located with high accuracy using the first data.

### \(W\to\ell\nu\) events

Events with \(W\to e\nu\) and \(W\to\mu\nu\) will be copiously produced at the LHC. Tens of thousands of events with an excellent signal-to-background ratio can be collected per pb\({}^{-1}\). With these events, a good understanding of the \(\not{E}_{\rm T}\) reconstruction can be achieved up to \(\not{E}_{\rm T}\) values of few hundred. The average \(\Sigma\not{E}_{\rm T}\) is of the order of 150 GeV.

In order to isolate \(W\to\ell\nu\) events, two basic selection cuts are required: existence of one high \(p_{\rm T}\) charged lepton with \(|\eta|<2.5\) and \(\not{E}_{\rm T}>20\). Possible backgrounds are from \(t\bar{t}\) production, \(W\to\tau\nu\), \(Z\to\ell\ell\), and QCD events.

Two methods have been investigated to check the \(\not{E}_{\rm T}\) reconstruction using these events. The first is based on the fact that the average \(p_{\rm T}\) of the charged lepton and the neutrino are the same, so the ratio \(R=p_{\rm T,\,\nu}/p_{\rm T,\,\ell}\) has been studied. This variable should be \(\sim 1\), but its distribution is distorted by the kinematic and acceptance requirements on the charged leptons. The method and related systematics have been checked with the fast ATLAS simulation. It is expected to be sensitive to values of \(\not{E}_{\rm T}\) up to 60  even with 1pb\({}^{-1}\) of data. Full simulation studies are in progress.

The second method, based on the shape of the reconstructed transverse mass of the \(W\) boson, is

Figure 21: For \(Z\to ee\) events: (left) \(\not{E}_{\rm T}\) projected onto the longitudinal and perpendicular axes as explained in the text as function of the \(p_{\rm T}\) of the lepton system resolved along the longitudinal axis. (right) The width \(\sigma(\not{E}_{\rm T})\) as a function of \(\sum E_{\rm T,\,cluster}\). Both plots use a sample corresponding to 250 pb\({}^{-1}\) of data.

sensitive to both the \(\not{E}_{\rm T}\) resolution and the scale. The transverse mass, \(m_{\rm T}^{W}\), is reconstructed under the hypothesis that \(\not{E}_{\rm T}\) is completely due to \(p_{\rm T}^{\rm v}\). An example of an \(m_{\rm T}^{W}\) distribution is shown in the next section for \(t\bar{t}\) events, which have high values of \(\Sigma\not{E}_{\rm T}\) of typically \(500\GeV\). The focus in this section however is on a dedicated analysis of the corresponding distribution for Drell-Yan events at lower \(\Sigma\not{E}_{\rm T}\) as statistically required.

The \(m_{\rm T}^{W}\) distribution (for Drell-Yan events) is fitted in a binned log-likelihood fit that uses template histograms. To minimize the dependence on the kinematics of the \(W\) boson, e.g. on its transverse momentum, the fit is restricted to values of \(m_{\rm T}^{W}\) in the range of 65 to 90. The template histograms of the \(m_{\rm T}^{W}\) distributions are generated by convolving the true transverse mass distribution with the \(\not{E}_{\rm T}\) response: \(\not{E}_{x,y}=\alpha p_{\rm T}^{\rm v}(x,y)\oplus\Gauss(0,\sigma)\) where parameters \(\alpha\) and \(\sigma\) are the \(\not{E}_{\rm T}\) scale and resolution (in GeV), respectively. Since the \(\not{E}_{\rm T}\) resolution strongly depends on the activity in the calorimeter, the analysis is performed in several \(\Sigma\not{E}_{\rm T}\) intervals.

Figure 22 (left) shows the resolution for \(W\to\mu\nu\) events. The results of the fit agree well with the expectations using truth information labeled as 'pseudo-data'. In Fig. 22 (right) the result for the \(\not{E}_{\rm T}\) scale is shown. The scale is measured at the 1% level over a large range of \(\Sigma\not{E}_{\rm T}\), confirming the excellent performance of this technique. The template fitting performs well in the low \(\Sigma\not{E}_{\rm T}\) region, while a small discrepancy is observed in the high \(\Sigma\not{E}_{\rm T}\) region.

This method described so far is applicable to W\(\to\mu\nu\) events, whereas in \(W\to e\nu\) events it has to be modified because the electron is included in the \(\Sigma\not{E}_{\rm T}\) calculation, while the muon is not. This leads to a significant correlation between \(\Sigma\not{E}_{\rm T}\) and the shape of the transverse \(W\) mass distribution when the template is made including the \(\Sigma\not{E}_{\rm T}\) dependence. Similar results for the \(\not{E}_{\rm T}\) scale and resolution are obtained, but systematic uncertainties have not yet been estimated.

Also if the backgrounds, including the QCD background, cannot be efficiently suppressed by the selection cuts, their influence could be non-negligible. Work is in progress on that.

### Semileptonic \(t\bar{t}\) events

Semileptonic \(t\bar{t}\) events have an interesting multi-jet topology. With genuine \(\not{E}_{\rm T}\) in the range from 20 to 100 and a total transverse energy of typically 50, they are representative of other physics

Figure 22: For W\(\to\mu\nu\) events: \(\not{E}_{\rm T}\) resolution (left) and scale (right) as a function of \(\Sigma\not{E}_{\rm T}\), using the second method described in the text. The circular dots represent the value calculated from pseudo-data and the triangular markers represent the estimation.

channels such as SUSY. This section shows that the reconstructed transverse \(W\) mass as well as a kinematic fit that exploits all mass constraints in \(t\bar{t}\) events without requiring \(b\) jet tagging, will be useful to investigate possible problems of the \(\not{E}_{\rm T}\) measurement in early data. Both methods are sensitive to the scale of \(\not{E}_{\rm T}\) to the level of a few percent (statistically) when a sample with an integrated luminosity of 200 pb\({}^{-1}\) is used. These methods are affected differently by jet energy scales and background and can provide complementary information.

About 7k events survive the selection requirements, which are: at least 3 jets with \(p_{\rm T}\geq 40\) GeV, at least one more jet with \(p_{\rm T}\geq 20\) GeV, \(\not{E}_{\rm T}\geq 20\) GeV, and one isolated lepton (\(e\) or \(\mu\)), with \(p_{\rm T}\geq 20\) GeV. The requirements strongly suppress the background from QCD events, which is expected to have no effect and is ignored. The QCD background is expected to be \(<10\%\) in \(t\bar{t}\) events, so, after the requirements for the kinematic fit, this assumption should be safe. The background from \(W\)+jets events is at the level of 20% and is included in this study.

In \(t\bar{t}\) analyses the usual assumption is that the \(\not{E}_{\rm T}\) in an event can be assigned to the neutrino from the leptonically decaying \(W\). With this assumption, the transverse mass \(m_{\rm T}^{W}\) can be reconstructed from the \(\not{E}_{\rm T}\) vector and the transverse momentum of the charged lepton. Figure 23 (left) shows that the shape of the \(m_{\rm T}^{W}\) distribution is distinctly different for various ranges of fake \(\not{E}_{\rm T}\)5), illustrating the power of these events to locate problems. To demonstrate that the transverse \(W\) mass distribution can be used to check the \(\not{E}_{\rm T}\) scale in early data, two additional event samples with the true \(\not{E}_{\rm T}\) scaled by 0.8 and 1.2, respectively have been produced and reconstructed. The samples are analysed by fitting a Gaussian shape to the core of the peak in the transverse mass distributions. The peak position shifts by -7 and +7 GeV for the sample with scale of 0.8 and 1.2 respectively, both with an statistical uncertainty of 0.5 GeV, indicating a sensitivity to the \(\not{E}_{\rm T}\) scale at the level of 2%.

Footnote 5: Here fake \(\not{E}_{\rm T}\) is defined as the scalar difference of reconstructed \(\not{E}_{\rm T}\) and true \(\not{E}_{\rm T}\).

Note that backgrounds other than \(W\)+jets events are not considered in this study. Background from SUSY events can have a severe impact on the distribution by shifting the peak and thus mimicking a \(\not{E}_{\rm T}\) scale calibration offset. The existing knowledge of \(t\bar{t}\) events can be combined in a kinematic fit to improve the measured quantities and to investigate the scale of the \(\not{E}_{\rm T}\) measurement. The following mass constraints are available: \(m_{W}^{\rm had}=m_{W}^{\rm lep}=80.4\) GeV, where \(m_{W}^{\rm had}\) is the reconstructed mass of two light jets of the hadronically decaying \(W\) and \(m_{W}^{\rm lep}\) is the reconstructed mass of the lepton and the neutrino of the leptonically decaying \(W\). The reconstructed mass of the leptonically decaying top quark and that of the hadronically decaying top quark are assumed to be \(m_{top}^{\rm had}=m_{top}^{\rm lep}=175\) GeV. The neutrino's transverse

Figure 23: In semileptonic \(t\bar{t}\) events, (left) the reconstructed transverse \(W\) mass in various ranges of fake \(\not{E}_{\rm T}\), (right) the distribution of the measured momentum difference of the two top quarks, \(\Delta p_{\rm T}\) for (true) \(\not{E}_{\rm T}\) scales of 0.8, 1.0 and 1.2 as indicated. The analysis is based on an integrated luminosity of 200 pb\({}^{-1}\) of data.

momentum is set equal to \(\not\!\!E_{\rm T}\) and its longitudinal momentum is analytically calculated from the \(m_{W}^{\rm lep}\) constraint.

The \(\chi^{2}\) function of the fit is built using the energy of the four leading jets, with fit parameters to scale the corrected jet energies, a constraint on the product of the fit parameters to the a-priori known or assumed overall jet energy scale and with the implementation of the four mass constraints. All twelve possible permutations of assigning jets to the two top quarks and \(W\) bosons respectively are considered. Finally, only the permutation with the lowest \(\chi^{2}\) is selected in each event.

It is found that the \(\not\!\!E_{\rm T}\), re-calculated after the fit, is not significantly improved. However, using a cut on \(\chi^{2}\) improves the resolution on \(\not\!\!E_{\rm T}\), so it is possible to use the \(\chi^{2}\) of a kinematic fit to classify \(t\bar{t}\) events with a relatively good \(\not\!\!E_{\rm T}\) measurement without using \(b\) tagging. In the first data this classification helps to locate possible detector problems.

The kinematic fitting procedure can be utilized to check the \(\not\!\!E_{\rm T}\) scale in early data. Background events are expected to be incompatible with the constraints used in the fit and thus be reduced by a cut on \(\chi^{2}\). Therefore, in contrast to the study using the transverse \(W\) mass as described above, this method suffers significantly less from backgrounds.

After applying the fit to the events and requiring \(\chi^{2}<10\) and in additional \(\not\!\!E_{\rm T}>40\) the background from \(W\)+jets event is reduced to the 1% level. A robust estimator of the \(\not\!\!E_{\rm T}\) scale is the measured transverse momentum difference of the (anti-) top quark mother of the leptonically and hadronically decaying \(W\) respectively: \(\Delta p_{\rm T}=p_{\rm T}^{\rm lep}-p_{\rm T}^{\rm had}\) where \(p_{\rm T}^{\rm lep}\) is the combined transverse momentum of the measured charged lepton, \(\not\!\!E_{\rm T}\) and one \(b\) jet, while \(p_{\rm T}^{\rm had}\) is the momentum of the jets of the hadronically decaying \(W\) and the other \(b\) jet. Of course, the assignment of the jets to the correct top quark is not guaranteed. Nevertheless, this quantity is remarkably sensitive to the \(\not\!\!E_{\rm T}\) scale, as can be seen in Fig. 23(right). The mean values of the distributions are \(-16.4\pm 0.9\) GeV, \(-4.5\pm 0.8\) GeV, and \(4.5\pm 0.9\) GeV for scales of 0.8, 1.0, and 1.2, respectively. This implies a sensitivity on the \(\not\!\!E_{\rm T}\) scale at the level of 2%. The systematic variation due to a shift of the top quark mass of 2.5 GeV is about 2%.

## 7 Summary

The \(\not\!\!E_{\rm T}\) in ATLAS is calculated from the energy in the calorimeter and from the reconstructed muons. The energy in the calorimeter is classified and calibrated according to the reconstructed objects to which it belongs. Two algorithms for reconstruction and calibration are presently implemented in the ATLAS software, one Cell-based, where the \(\not\!\!E_{\rm T}\) reconstruction and calibration is done starting from the energy deposited in calorimeter cells, and the other one Object-based, where the \(\not\!\!E_{\rm T}\) reconstruction is done from the reconstructed, classified and calibrated objects and from the energy outside of them. The performance of the two is similar.

The \(\not\!\!E_{\rm T}\) performance has been checked on a large variety of events with physical \(\not\!\!E_{\rm T}\) such as \(Z\to\tau\tau\), \(A/H\to\tau\tau\), SUSY, and \(t\bar{t}\), as well as events with no physical \(\not\!\!E_{\rm T}\) like minimum bias events, events with QCD jets, and \(Z\)+jets processes. The resulting linearity of the response is within 5%, even for low true \(\not\!\!E_{\rm T}\) values of the order of 40 GeV. The \(\not\!\!E_{\rm T}\) resolution, \(\sigma\), follows an approximate stochastic behaviour over a wide range of values of the total transverse energy deposited in the calorimeters. A simple fit to a function \(\sigma=a\cdot\sqrt{\Sigma E_{\rm T}}\) yields values between 0.53 and 0.57 for the parameter \(a\), for \(\Sigma E_{\rm T}\) values between 20 and 2000 GeV. Deviations from this simple behaviour are expected and observed for low values of \(\Sigma E_{\rm T}\) where noise is an important contribution, and for very high values of \(\Sigma E_{\rm T}\) where the constant term in the jet energy resolution dominates. For values of the true \(\not\!\!E_{\rm T}\) below 40 GeV, the accuracy of the measurement of the direction of the \(\not\!\!E_{\rm T}\) vector for small values of \(\not\!\!E_{\rm T}\) degrades rapidly. In contrast, for high values of the true \(\not\!\!E_{\rm T}\), azimuthal accuracies better than 100 mrad can be achieved. This accuracy of the measurement of the \(\not\!\!E_{\rm T}\) direction allows an isolation cut on \(\not\!\!E_{\rm T}\), which can efficiently suppress events with a badly measured jet and the resulting \(\not\!\!E_{\rm T}\) pointing in the jet direction.

A dedicated study of fake \(\not\!\!E_{\rm T}\) shows that instrumental effects like hot/dead/noisy cells (regions) in calorimeters, as well as beam-gas scattering or other machine backgrounds, or displaced vertices, are very important, and that their understanding will be crucial in the first days of data taking. Different methods can be used to clean events and to correct/recover the \(\not\!\!E_{\rm T}\) measurement. Mis-measurements in the detector itself, due to high-\(p_{\rm T}\) muons escaping from the fiducial acceptance or from large losses of deposited energy in cracks or inactive materials, might also effectively limit the performance of the \(\not\!\!E_{\rm T}\) reconstruction and have therefore been studied in detail.

With the first 100pb\({}^{-1}\) the algorithms for \(\not\!\!E_{\rm T}\) reconstruction and calibration can be checked studying the \(\not\!\!E_{\rm T}\) linearity and resolution in minimum bias events and in Standard Model processes like \(Z\) and \(W\) decays and in \(t\bar{t}\) processes. Complementary methods for the determination of the \(\not\!\!E_{\rm T}\) scale in-situ have been studied and it has been shown that it will be possible to determine the \(\not\!\!E_{\rm T}\) scale with a precision of at least 8%.

## References

* [1] Cojocaru, C. et al., Hadronic calibration of the ATLAS liquid argon end-cap calorimeter in the pseudorapidity region 1.6-1.8 in beam tests, NIM, A531 (2004), 481-514.
* [2] ATLAS Collaboration, Performance of Calorimeter Clustering Algorithms, note in preparation.
* [3] ATLAS Collaboration, Detector Level Jet Corrections, this volume.
* [4] Asai, S. et al, Prospects for the Search of a Standard Model Higgs Boson in ATLAS using Vector Boson Fusion, SN-ATLAS-2003-024 (2003).
* [5] ATLAS Collaboration, Calibration and Performance of the Electromagnetic Calorimeter, this volume.
* [6] ATLAS Collaboration, Reconstruction and Identification of Hadronic \(\tau\) Decays, this volume.
* 2900 (1992).
* [8] R. K. Ellis et al., Higgs decay to \(\tau^{+}\tau^{-}\): A possible signature of Intermediate Higgs Bosons at the SSC, Nucl. Phys. B297 (1988) 221.
* [9] L. DiLella, Proceedings of the Large Collider Workshop, edited by G. Jarlskog and D. Rein (Aachen, 4-9 October 1990), CERN 90-10/ECFA 90-133, Vol. II, p. 530..
* [10] ATLAS Collaboration, ATLAS Performance and Physics Technical Design Report, ATLAS TDR 15, CERN/LHCC/99-15 (25 May 1999).
* [11] The ATLAS L1Calo Group (E. Eisenhandler), ATLAS Level-1 Calorimeter Trigger Algorithms, 9 Sep 2004, ATL-DAQ-2004-011.
* [12] ATLAS Collaboration, A Study of Minimum Bias Events, this volume.