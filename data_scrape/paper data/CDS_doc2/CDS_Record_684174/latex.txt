ATLAS Muon Note: February 21, 2001

**Muon Spectrometer Alignment in ATLAS:**

**A Generalized Approach to Simulation**

**Ch. Amelung**

_EP Division_

_European Laboratory for Particle Physics (CERN)_

A program has been developed to simulate the performance of the alignment system for the ATLAS muon spectrometer. The concept of the program is simple and general, which makes its application to a specific alignment problem easy. The alignment of the different detector elements involved is reconstructed from the measurements provided by alignment sensors as the result of a \(\chi^{2}\) minimization performed by MINUIT. An example application implementing one octant of the muon spectrometer endcap is used to demonstrate the usefulness and reliability of the program.

Introduction

The ATLAS Muon Collaboration is currently setting up one octant of the muon spectrometer endcap, as a system test of the detector, in the H8 test beam area at CERN [1]. The first aspect that will be tested is the alignment system. A program has been developed to simulate the performance of this system; eventually, this will evolve from a simulation to a reconstruction program. The concept of the program is simple and general, which makes its application to a specific alignment problem easy. The alignment of the different detector elements involved is reconstructed from the measurements provided by alignment sensors as the result of a \(\chi^{2}\) minimization performed by MINUIT [2].

## 2 Concept of alignment

### Basics

Determining the alignment of objects in space means to determine the spatial relationship of a number of local coordinate systems (LCS) to one global coordinate system (GCS), i.e. to determine for each LCS its position, represented by the coordinates \(X,Y,Z\) of its origin in the GCS, as well as its orientation, represented by the angles of three subsequent rotations around the \(X,Y,Z\) axes, \(\alpha,\beta,\gamma\) (Fig. 1). Points on objects, e.g. the positions of active detector elements, may be defined in any of the LCSs. It may be useful to build a hierarchical structure of LCSs defined relative to others.

Information about the spatial relationship between pairs (or groups) of coordinate systems is obtained from alignment sensors. They relate points in different coordinate systems by providing a measurement related to their relative positions and/or orientations. If the cumulative information from all sensors is sufficient to unambiguously constrain all degrees of freedom of the problem, the alignment can be determined; if the problem is over-constrained, this can be exploited to improve the overall precision of the alignment.

### Three-dimensional objects

Three-dimensional deformable objects are represented by a number of LCSs to describe their position and shape. Usually, not all six parameters of each LCS are left free, in order to avoid ambiguities in cases where the same object shape could be described by different sets of LCS parameters.1

Footnote 1: It may also be interesting to fix additional parameters, e.g. those describing the object shape, in order to test the effect of the assumption that it were a perfectly rigid body, or those describing the object position, in order to neglect the uncertainty in the determination of its position.

Despite the apparent primitivity of this concept, any three-dimensional physical object and its deformations can be accomodated, without the need for an object-specific implementation for each new object. In other words, the object properties are taken care of in the user-defined geometry specification rather than inside the alignment program, thus permitting a very compact implementation of the alignment.

### Alignment sensors

Alignment sensors are treated as point-like objects. They have at least a sensor position associated with them, defined in an LCS, as well as a the position of a source they look at, defined in a different LCS. They may or may not in addition look at one or many auxiliary positions defined in additional LCSs (Fig. 2).2Each sensor has a sensor coordinate system, the origin of which coincides with the sensor position. The \(Z\) direction of the sensor coordinate system is defined as the looking direction of the sensor (i.e. along the line connecting the true positions of sensor and source); \(X\) and \(Y\) are the directions transverse to the looking direction, oriented such that the three axes form a right-handed Cartesian system.

The simulated readout of a sensor is computed (in a way characterizing the sensor type) from the positions of the sensor, the source, and the (if existing) auxiliary devices. It is randomly smeared reflecting the mounting accuracies, \(\sigma^{\mathrm{mount}}_{X,Y,Z}\), and intrinsic resolutions, \(\sigma^{\mathrm{resol}}_{X,Y,Z}\), of the sensor. The value of \(\sigma^{\mathrm{mount}}\) generally reflects all systematic effects on the sensor response, including for example the precision of the sensor calibration. In turn, \(\sigma^{\mathrm{resol}}\) reflects all statistical contributions to the sensor response.

Although in reality an alignment sensor may be composed of a number of elements (e.g. for an optical sensor: CCD, lenses, filters, mirrors, light sources, masks), it is actually sufficient to represent it by only a coordinate system and a list of points. This simplifies the implementation considerably, compared to (again in the example of an optical sensor) a complete ray-tracing technique that tracks the light from the source to a point on the CCD surface in order to obtain the simulated sensor readout.

## 3 Simulation program

The alignment simulation program implements the above concept, i.e. takes care of the various coordinate systems and the transformations between them, of the simulation of the alignment sensors, and eventually performs the determination of the alignment from the available information. It employs a Monte Carlo algorithm, i.e. all measurements are randomly smeared to reflect their resolutions.

### Simulation run

A single run of the alignment simulation program corresponds to the following steps:

* Set up the nominal geometry by positioning all LCSs in space. Randomly displace them within \(\pm 10\,\mathrm{mm}\) (\(\pm 1\,\mathrm{mrad}\)) of their nominal positions (orientations) to obtain the true geometry (this reflects the limited initial positioning accuracy of the elements, for those elements that are not by construction positioned very accurately relative to each other).
* Set up all sensor coordinate systems, by positioning each of them in its sensor position. Their orientations are chosen such that the \(Z\) axes point to the respective source positions; the directions of \(X\) and \(Y\) are chosen arbitrarily to form right-handed Cartesian systems.
* Randomly displace the sensor coordinate systems according to the mounting accuracy \(\sigma^{\mathrm{mount}}\) of the sensors. Simulate the sensor readout. Randomly smear the readout according to the intrinsic resolution \(\sigma^{\mathrm{resol}}\).
* Discard the true geometry, i.e. all the positions and orientations of the LCSs (after storing them for the purpose of comparison between true and reconstructed positions). Keep the sensor readout values.
* Reconstruct the positions and orientations from the sensor readout. This is done by minimizing a \(\chi^{2}\) function reflecting the deviation of the actual sensor readout from the expected one, weighted with the \(1\sigma\) error as derived from the individual sensor precision (mounting accuracy \(\oplus\) intrinsic resolution). The actual sensor readout is obtained by assuming a set of LCS positions and orientations and simulating the sensor readout for this configuration (without random displacement and smearing applied). The expected sensor readout is the one obtained before for the true configuration (with random displacement and smearing applied). At the minimum \(\chi^{2}\), the assumed set of LCSs reflects the alignment result. The standard minimization and fitting package MINUIT [2] is used. Two options have been implemented: * Overall minimization. This fits the positions of all LCSs in the problem at the same time, thus yielding the best possible precision by fully exploiting the available redundancy. It is, however, very time-consuming. * Step-by-step minimization. This fits the positions of user-defined groups of LCSs separately, thus reducing significantly the time consumption. The quality of the result depends, however, on the ability of the user to factorize the problem, and of the factorizability of the problem itself.
* Calculate a user-defined figure of merit (or generate a distribution) from the reconstructed LCS positions and orientations, possibly by comparing them to the true positions and orientations.

Usually, many runs of the alignment program are performed in order to average over the individually determined figures of merit and thus become independent of the starting conditions, i.e. the random number generator seed, and of statistical fluctuations owing to the Monte Carlo method.

### Implemented alignment sensors

Below, a list of the alignment sensors currently implemented in the simulation program is given. The variables \(X_{i},Y_{i},Z_{i}\) denote the coordinates of sensor (\(i=1\)), auxiliary (\(i=2\)), and source (\(i=3\)) positions in the sensor coordinate system (thus implying \(X_{1}=Y_{1}=Z_{1}=0\)); the variables \(X_{[\mathrm{sensor}]},Y_{[\mathrm{sensor}]},Z_{[\mathrm{sensor}]}\) denote the sensor readout. Some useful variables are \(d_{1}\), the nominal distance between sensor and auxiliary position, \(d_{2}\), the nominal distance between source and auxiliary position, and \(d\), the nominal distance between sensor and source. If the three positions are approximately collinear, \(d=d_{1}+d_{2}\); this approximation is made throughout the program. The resolutions given in the list are not precisely known and had to be estimated.

#### 3.2.1 Bcam

A BCAM is the simplest alignment device. It consists of a CCD and a lens, mounted together in a black box, as well as an LED light source. For simulation, the position of the black box is taken as the sensor position, while the position of the LED is represented by the source position. There are no auxiliary positions defined. The quantity measured by a BCAM is the distance between the sensor and the source, transverse to its looking direction (i.e. \(X,Y\) in the sensor coordinate system); the BCAM is insensitive to the distance along its looking direction (i.e. \(Z\) in the sensor coordinate system). Thus the measured values are

* \(X_{\mathrm{BCAM}}=X_{3}-X_{1}\),
* \(Y_{\mathrm{BCAM}}=Y_{3}-Y_{1}\),

with resolutions

* \(\sigma_{X,Y}^{\mathrm{resol}}=5\,\upmu\mathrm{rad}\cdot d\),
* \(\sigma_{X,Y}^{\mathrm{mount}}=10\,\upmu\mathrm{m}\oplus 50\,\upmu\mathrm{rad}\cdot d\).

#### 3.2.2 Rasnik

A RASNIK system consists of three separate components, a CCD, a lens, and an illuminated mask with a chessboard-like pattern. For simulation, the position of the CCD is taken as the sensor position, the position of the mask is represented by the source position, and the lens is placed at the auxiliary position. Transverse to its looking direction, a RASNIK measures the displacement of the mask relative to the line connecting CCD and lens; along its looking direction it is sensitive to the ratio of the distances CCD-lens and lens-mask. The measured values are

* \(X_{\rm RASNIK}=(1+d_{2}/d_{1})(X_{2}-X_{1})-(X_{3}-X_{1})\),
* \(Y_{\rm RASNIK}=(1+d_{2}/d_{1})(Y_{2}-Y_{1})-(Y_{3}-Y_{1})\),
* \(Z_{\rm RASNIK}=(1+d_{2}/d_{1})(Z_{2}-Z_{1})-(Z_{3}-Z_{1})\),

with resolutions

* \(\sigma_{X,Y}^{\rm resol}=1\,\upmu\)m, \(\sigma_{Z}^{\rm resol}=5\cdot 10^{-5}\cdot d\),
* \(\sigma_{X,Y,Z}^{\rm mount}=10\,\upmu\)m.

#### 3.2.3 BCAM proximity sensor

BCAM proximity sensors are a special case of BCAMs: they look at an illuminated RASNIK mask rather than at an LED. This adds sensitivity to the \(Z\) coordinate to the BCAM specifications from section 3.2.1:

* \(X_{\rm Prox}=X_{3}-X_{1}\),
* \(Y_{\rm Prox}=Y_{3}-Y_{1}\),
* \(Z_{\rm Prox}=Z_{3}-Z_{1}\),

with resolutions

* \(\sigma_{X,Y}^{\rm resol}=1\,\upmu\)m, \(\sigma_{Z}^{\rm resol}=5\cdot 10^{-5}\cdot d\),
* \(\sigma_{X,Y}^{\rm mount}=10\,\upmu\)m\(\oplus\)50\(\upmu\)rad\(\cdot d\), \(\sigma_{Z}^{\rm mount}=10\,\upmu\)m.

#### 3.2.4 BCAM looking at two sources

A BCAM looking at two sources is used to measure both the relative position of the sources (with high precision) as well as their absolute ones (with less high precision). Consequently, it is represented in the simulation by three alignment sensors: two normal BCAMs, each looking at one of the sources, as in section 3.2.1, plus an additional RASNIK-like device as in section 3.2.2. For the latter, the measured values are

* \(X_{\rm 2src}=(1+d_{2}/d_{1})(X_{2}-X_{1})-(X_{3}-X_{1})\),
* \(Y_{\rm 2src}=(1+d_{2}/d_{1})(Y_{2}-Y_{1})-(Y_{3}-Y_{1})\),

with resolutions

* \(\sigma_{X,Y}^{\rm resol}=5\,\upmu\)rad\(\cdot d\),
* \(\sigma_{X,Y}^{\rm mount}=10\,\upmu\)m.

In contrast to a RASNIK, a BCAM looking at two sources has no sensitivity to the \(Z\) coordinate.

#### 3.2.5 Temperature sensor

Temperature sensors are used to indirectly measure the length expansion of a massive object, derived from a change in temperature, \(\Delta T\), and the known thermal expansion coefficient of the material, \(\alpha\). They can thus be modelled as sensors which are only sensitive along their looking direction:

* \(Z_{\mathrm{temp}}=Z_{3}-Z_{1}\),

with resolutions

* \(\sigma_{Z}^{\mathrm{rssol}}=2\cdot 10^{-6}\cdot d\),
* \(\sigma_{Z}^{\mathrm{mount}}=0\).

This is an example of a sensor which, though not being an optical sensor, can be implemented in the same framework without problems.

## 4 Example application: Muon Endcap Alignment

The alignment of MDT endcap chambers is performed by aligning the chambers relative to auxiliary objects, so-called alignment bars, which are aligned in turn relative to each other, thus forming the global coordinate system for one muon endcap.

The alignment of alignment bars relative to each other is based on BCAMs3 looking from one bar to a source on another bar (polar and azimuthal BCAMs); some of them look at two sources on different bars. The alignment of MDT chambers with respect to alignment bars is based on pairs of parallel proximity sensors3 looking respectively from large chambers to bars, from small chambers to bars, and from large chambers to small chambers. The shapes of bars and chambers are monitored by RASNIKs, temperature sensors, and BCAMs looking along bars (radial BCAMs). The design alignment accuracy is defined by the requirement that the alignment contribution to false sagitta measurements be less than 30 \(\upmu\)m (r.m.s. value).

Footnote 3: In these details the current design deviates from the one presented in the Technical Design Report [3].

An alignment bar is an aluminium tube of up to about 10 m length and 8 cm (7.2 cm) outer (inner) diameter. For the purpose of simulation, its deformations are approximated by four straight sections connecting five points on the bar. This is implemented as five LCSs, one of which takes the role of the GCS of the bar (Fig. 3). In total, the bar position is described by 6 parameters, and its shape is described by 10 parameters.

An MDT endcap chamber has a trapezoidal shape. For the purpose of simulation, its deformations are approximated by seven straight sections connecting six points on the chamber. This is implemented as six LCSs (plus two that are needed later, when putting sensors on the chamber), one of which takes the role of the GCS of the chamber (Fig. 4). In total, the chamber position is described by 6 parameters, and its shape is described by 11 parameters.

Bars and chambers in this application are equipped with in-bar respectively in-chamber sensors as shown in Figs. 5 and 6. The full geometry of one endcap octant that has been implemented is shown in Fig. 7. This is to be understood as a toy geometry; the dimensions of bars and chambers and the positions of sensors are realistic to only about 10-20%. Also, for simplification only one pair of small and large chamber per station has been implemented.

The optional factorization in the minimization procedure has been implemented as follows: first, individual bar and chamber shapes are fitted separately (leaving free the parameters describing the bar respectively chamber shapes, and using those sensors that connect LCSs on one bar respectively chamber: RASNIKs, temperature sensors, and radial BCAMs), followed by thefit of bar positions in the GCS (leaving free the positions of all bars except for one which is chosen to coincide with the GCS, and using the azimuthal and polar BCAMs), after which finally the positions of chambers relative to bars are fitted (leaving free the positions of chambers, using the proximity sensors and fitting the positions of one large and one small chamber in the same station simultaneously).

As the figure of merit, the apparent sagitta of a straight track coming from the (imaginary) interaction point is defined. This number is calculated from the intersection points of the track with MDT chambers in the EI/EM/EO stations for true and reconstructed chamber positions (Fig. 8). For each run of the alignment program, about 500 tracks are generated. To obtain a smooth distribution with a stable r.m.s. value, at least about 50 runs are necessary.

The program is quite compact: it currently consists of about 700 lines (in C) for simulation, plus about 500 lines for the geometry and sensor position definitions. It works reliably owing to the use of a standard minimization tool; MINUIT turns out to be especially helpful while debugging the geometry setup, e.g. by issuing warnings about convergence problems related to the fact that the defined sensors do not unambiguously constrain all LCS positions. However, the performance of MINUIT also dominantly controls the computing speed, since it has been conceived as a rather general minimization tool.

As an example of computation speed, on a Pentium III-600 MHz PC under Linux, one run with the overall minimization option takes about 200 s; using the step-by-step-minimization option reduces this to 30 s. For the latter number, it is approximately valid to scale it linearly, e.g. to a full ATLAS endcap. The former grows exponentially with the number of sensors.

## 5 Summary

The alignment simulation program presented here is based on a simple and general concept. It can accomodate in a uniform way all kinds of optical sensors as well as quantities derived from other measurements, e.g. from temperatures. Owing to its concept, it is open to many applications besides the muon endcap alignment, e.g. any other detector that is constantly monitored by alignment sensors. Especially, since the program itself "knows" nothing about bars and chambers, it is easy to set up a new geometry (e.g. a full endcap or barrel), and thus to scale it up to a full ATLAS detector. The program, with the example application described here, has already proven its usefulness and reliability in uncovering a problem in the design of the endcap alignment system [4].

## 6 Outlook

The simulation program is supposed to evolve to a reconstruction code in the near future. Its first application foreseen is the test of a muon endcap octant in the H8 test beam area at CERN in 2001.

As an illustration of the necessary modifications for the transition to a reconstruction program, the sequence of program steps from section 3.1 is repeated here; additions for the reconstruction program are highlighted in **boldface**, obsolete fragments of the simulation part are typeset in small letters.

* Set up the nominal geometry by positioning all LCSs in space. Randomly displace them within \(\pm 10\) mm (\(\pm 1\) mrad) of their nominal positions (orientations) to obtain the true geometry (this reflects the limited initial positioning accuracy of the elements, for those elements that are not by construction positioned very accurately relative to each other). **Their positions are the result of a survey (for points on bars and chambers) respectively are only approximately known (for positions of bars and chambers), and are read from a database.*** Set up all sensor coordinate systems, by positioning each of them in its sensor position. Their orientations are chosen such that the \(Z\) axes point to the respective source positions; the directions of \(X\) and \(Y\) are chosen arbitrarily to form right-handed Cartesian systems. **Their orientations are the result of a calibration procedure, and are read from a database.**
* Randomly displace the sensor coordinate systems according to the mounting accuracy \(\sigma^{\rm mount}\) of the sensors. Simulate the sensor readout. Randomly smear the readout according to the intrinsic resolution \(\sigma^{\rm resol}\). **Read out the physical sensors and transform the obtained raw data to spatial information.**
* Discard the true geometry, i.e. all the positions and orientations of the LCSs (after storing them for the purpose of comparison between true and reconstructed positions). Keep the sensor readout values.
* Reconstruct the positions and orientations from the sensor readout. This is done by minimizing a \(\chi^{2}\) function reflecting the deviation of the actual sensor readout from the expected one, weighted with the \(1\sigma\) error as derived from the individual sensor precision (mounting accuracy \(\oplus\) intrinsic resolution). The actual sensor readout is obtained by assuming a set of LCS positions and orientations and simulating the sensor readout for this configuration (without random displacement and smearing applied). The expected sensor readout is the one obtained before for the true configuration (with random displacement and smearing applied). **The expected sensor readout is the one obtained above from the physical sensors.*
* At the minimum \(\chi^{2}\), the assumed set of LCSs reflects the alignment result. The standard minimization and fitting package MINUIT [2] is used. Two options have been implemented:
* Overall minimization. This fits the positions of all LCSs in the problem at the same time, thus yielding the best possible precision by fully exploiting the available redundancy. It is, however, very time-consuming.
* Step-by-step minimization. This fits the positions of user-defined groups of LCSs separately, thus reducing significantly the time consumption. The quality of the result depends, however, on the ability of the user to factorize the problem, and of the factorizability of the problem itself. **At this point, realistic models for the shapes of three-dimensional objects (bars and chambers) have to be employed (i.e. more realistic than straight-line interpolation between a small number of LCSs). It is desirable to give up as little as possible of the underlying concept; the current direction of thinking is to introduce a user-defined routine that performs the interpolation between the LCSs describing the shape of an object, and uses the deviation of this interpolation from the simple straight-line interpolation to accordingly shift and rotate additional LCSs that are physically fixed to the object, e.g. alignment sensors.**
* Calculate a user-defined figure of merit (or generate a distribution) from the reconstructed LCS positions and orientations, possibly by comparing them to the true positions and orientations.

## Acknowledgments

Informative discussions with J. R. Bensinger, C. Guyot, A. Ostapchuk, F. Cerutti, S. Palestini, Ch. Fabjan and A. Schricker are gratefully acknowledged. F. Bauer showed ASAP to me, the concepts of which were interesting to compare to. I am grateful to Ch. Fabjan and F. Cerutti for proof-reading of the manuscript and helpful comments.

## References

* [1] J. R. Bensinger et al., Muon Spectrometer Test Programme in H8, to be published.
* [2] F. James and M. Roos, Comp. Phys. Comm. **10** (1975) 343; [http://consult.cern.ch/writeup/minuit](http://consult.cern.ch/writeup/minuit).
* [3] ATLAS Muon Collaboration, ATLAS Muon Spectrometer Technical Design Report, CERN/LHCC/97-22.
* [4] Ch. Amelung, Muon Spectrometer Alignment in ATLAS: Reaching the Design Performance in the Endcap, ATL-COM-MUON-2001-007.