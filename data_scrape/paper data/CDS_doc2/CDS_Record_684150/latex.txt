# PC-based Event Filter Supervisor:

Design and Implementation

Z. Qian, C. Bee, E. Fede, C. Meessen, F. Touchard

CPPM Marseille

###### Abstract

This document presents a PC-Based Event Filter Supervisor design and implementation, based on Java and Java Mobile Agent technology. The supervisor has been in use for two years and has been tested in various configurations and on different platforms. Full integration with the ATLAS DAQ/EF prototype has been performed and is described in detail

Keywords : ATLAS, Event filter,Supervisor, Monitoring, Mobile Agent, Java Document version : 1.3 Reference : [http://atddoc.cern.ch/Atlas/EventFilter/documents/spv/spv.html](http://atddoc.cern.ch/Atlas/EventFilter/documents/spv/spv.html)

[MISSING_PAGE_EMPTY:2]

## 1 Introduction

The Event Filter (EF) is the last element in the DAQ chain before events are sent to permanent storage. The design of this element is described in a paper presented at RT99 conference [1]. The hardware configuration and the implementation of event data flow are shown in Figure 1 and Figure 2.

This document describes the design and implementation of the supervision of a PC-based EF. The Supervisor must fulfil the following requirements :

* Operation of the dataflow and the supervision must be totally independent, i.e. a crash of the supervisor should not affect the dataflow, and conversely.
* Platform, operating system independence, to cope with Event Filter's heterogeneity
* Event data flow independence for new technology and future development
* Scalability, which means that the Supervisor must be capable of handling different sized configurations, from one PC to several hundred PCs

Figure 1: Hardware configuration

Figure 2: Event data flow implementation* High degree of flexibility, to adapt to different architectures and implementation.
* Easy maintenance
* Robustness
* Remote control and monitoring
* Provide archiving means via access to a database.

The main functionality of EF Supervision is described in [2].

## 2 Technology Choices

The Java Mobile Agent technology has been chosen to implement the above requirements. The Supervisor is built on top of the ObjectSpace Voyager Core Technology, a Java Object Request Broker. All control functions and monitoring functions are performed by different types of Java Agents.

We summarise here some interesting features of Java Mobile Agents and of Voyager. A complete evaluation report can be found in [3].

### What a Java Mobile Agent system looks like

The Java Virtual Machine and Java's class loading model, coupled with several of the Java features, among which serialisation, remote method invocation, multithreading, and reflection are the most pertinent, have made building mobile agent systems a fairly simple task.

Java Mobile Agent systems have a number of key characteristics :

* All Java Mobile Agent systems provide an agent server, which is a contact point on a given machine (see Figure 3). Those server objects act as warehouses, or workplaces into which agents move, and in which agents act. A server provides a means of hosting and managing its own agent in an environment that is secure from malicious agents.
* Agents can migrate from server to server, carrying their state with them. After moving into a server, an agent becomes a local user, and it can do everything that a local user can do, e.g. get system resource information (process, disk, memory, CPU, network...), create/ delete processes, make local communication with process...
* Agents can load their code from a variety of sources. In general, since all the agent systems use a specialised version of the Java classloader, they can load Java class files from the local file system, the Web, and ftp servers.
* They are 100% pure Java. This means that they should run on any computer with a compatible Java runtime

Figure 3: Mobile agent principle

### What is Voyager and why Voyager was chosen

"ObjectSpace Voyager Core Technology" [4] is an advanced, 100% Java Object Request Broker (ORB), based on the Java language object model. Voyager 3.0 contains the following features : remote-enabling a class; remote create instance of any class and obtain his proxy; dynamic class loading;, remote message (one-way, sync, future); multicast; remote exception handling; distributed garbage collection; dynamic aggregation; support for IDL, IIOP and RMI; mobility - move any serializable object at runtime from one virtual machine to another; support autonomous mobile agents; activation of objects persisted in any kind of database; applets and servlets; universal naming service; publish-subscribe; thread pooling; enhanced security manager; possible for installing custom socket such as SSL; J2EE JMS compliance.

We decided to evaluate this framework for the following reasons:

* Three things in one, Voyager supports three types of communication : point-to-point, client/server, agent-based
* Easy of use
* Good performance
* Very good scalability
* Small (Voyager core classes are only 763k)
* Many facilities correspond to the requirement of the supervisor : space scalable group communication, publish/subscribe, event & listener, object persistence, integration with CORBA.
* possible use as internal message server

## 3 Supervisor design

### Design scheme

The design scheme is shown in Figure 4. There are 3 levels of monitoring : PC tool for system level supervision, Mobile Agent for event data flow control and monitoring, offline analyse tools for monitoring data archived in a database

Figure 4: Design scheme

### User Interface

#### 3.2.1 Online Graphical User Interface

A Graphical User Interface (GUI) was implemented in such a way that it can run in application mode (with a direct access to the agent server) or applet mode (via the Web); the same GUI can be used for monitoring and control and can run either in standalone mode or over the Web. Several copies of the interface can run at the same time, but only one is allowed to perform the control task. The agent server notifies all running interfaces when the EF status changes. Figure 5 illustrates how commands and status requests can be sent from the Control Interface to remote nodes by mobile agents and how status data is collected and returned to any monitoring interface.

The GUI has multiple functionality, including : online histogramming and plotting; different viewers to display the entire EF hardware configuration and event data flow structure; control of usage of archiving database; possibility to switch on/off the database and change the rate of monitoring data collection; possibility of add/delete process at runtime; modification of some dataflow parameters; display an agent's travelling status via an agent itinerary window.

A working GUI is shown in Figure 6 which contains 3 basic windows : the Main Window (Supervisor), the Activity Viewer, and the Config Tree. The detailed functionality of each window is described below.

#### 3.2.2 Online Graphical User Interface

A Graphical User Interface (GUI) was implemented in such a way that it can run in application mode (with a direct access to the agent server) or applet mode (via the Web); the same GUI can be used for monitoring and control and can run either in standalone mode or over the Web. Several copies of the interface can run at the same time, but only one is allowed to perform the control task. The agent server notifies all running interfaces when the EF status changes. Figure 5 illustrates how commands and status requests can be sent from the Control Interface to remote nodes by mobile agents and how status data is collected and returned to any monitoring interface.

The GUI has multiple functionality, including : online histogramming and plotting; different viewers to display the entire EF hardware configuration and event data flow structure; control of usage of archiving database; possibility to switch on/off the database and change the rate of monitoring data collection; possibility of add/delete process at runtime; modification of some dataflow parameters; display an agent's travelling status via an agent itinerary window.

A working GUI is shown in Figure 6 which contains 3 basic windows : the Main Window (Supervisor), the Activity Viewer, and the Config Tree. The detailed functionality of each window is described below.

#### 3.2.3 Online Graphical User Interface

A Graphical User Interface (GUI) was implemented in such a way that it can run in application mode (with a direct access to the agent server) or applet mode (via the Web); the same GUI can be used for monitoring and control and can run either in standalone mode or over the Web. Several copies of the interface can run at the same time, but only one is allowed to perform the control task. The agent server notifies all running interfaces when the EF status changes. Figure 5 illustrates how commands and status requests can be sent from the Control Interface to remote nodes by mobile agents and how status data is collected and returned to any monitoring interface.

The GUI has multiple functionality, including : online histogramming and plotting; different viewers to display the entire EF hardware configuration and event data flow structure; control of usage of archiving database; possibility to switch on/off the database and change the rate of monitoring data collection; possibility of add/delete process at runtime; modification of some dataflow parameters; display an agent's travelling status via an agent itinerary window.

A working GUI is shown in Figure 6 which contains 3 basic windows : the Main Window (Supervisor), the Activity Viewer, and the Config Tree. The detailed functionality of each window is described below.

#### 3.2.4 Online Graphical User Interface

A Graphical User Interface (GUI) was implemented in such a way that it can run in application mode (with a direct access to the agent server) or applet mode (via the Web); the same GUI can be used for monitoring and control and can run either in standalone mode or over the Web. Several copies of the interface can run at the same time, but only one is allowed to perform the control task. The agent server notifies all running interfaces when the EF status changes. Figure 5 illustrates how commands and status requests can be sent from the Control Interface to remote nodes by mobile agents and how status data is collected and returned to any monitoring interface.

The GUI has multiple functionality, including : online histogramming and plotting; different viewers to display the entire EF hardware configuration and event data flow structure; control of usage of archiving database; possibility to switch on/off the database and change the rate of monitoring data collection; possibility of add/delete process at runtime; modification of some dataflow parameters; display an agent's travelling status via an agent itinerary window.

A working GUI is shown in Figure 6 which contains 3 basic windows : the Main Window (Supervisor), the Activity Viewer, and the Config Tree. The detailed functionality of each window is described below.

#### 3.2.5 Online Graphical User Interface

A Graphical User Interface (GUI) was implemented in such a way that it can run in application mode (with a direct access to the agent server) or applet mode (via the Web); the same GUI can be used for monitoring and control and can run either in standalone mode or over the Web. Several copies of the interface can run at the same time, but only one is allowed to perform the control task. The agent server notifies all running interfaces when the EF status changes. Figure 5 illustrates how commands and status requests can be sent from the Control Interface to remote nodes by mobile agents and how status data is collected and returned to any monitoring interface.

The GUI has multiple functionality, including : online histogramming and plotting; different viewers to display the entire EF hardware configuration and event data flow structure; control of usage of archiving database; possibility to switch on/off the database and change the rate of monitoring data collection; possibility of add/delete process at runtime; modification of some dataflow parameters; display an agent's travelling status via an agent itinerary window.

A working GUI is shown in Figure 6 which contains 3 basic windows : the Main Window (Supervisor), the Activity Viewer, and the Config Tree. The detailed functionality of each window is described below.

#### 3.2.6 Online Graphical User Interface

A Graphical User Interface (GUI) was implemented in such a way that it can run in application mode (with a direct access to the agent server) or applet mode (via the Web); the same GUI can be used for monitoring and control and can run either in standalone mode or over the Web. Several copies of the interface can run at the same time, but only one is allowed to perform the control task. The agent server notifies all running interfaces when the EF status changes. Figure 5 illustrates how commands and status requests can be sent from the Control Interface to remote nodes by mobile agents and how status data is collected and returned to any monitoring interface.

The GUI has multiple functionality, including : online histogramming and plotting; different viewers to display the entire EF hardware configuration and event data flow structure; control of usage of archiving database; possibility to switch on/off the database and change the rate of monitoring data collection; possibility of add/delete process at runtime; modification of some dataflow parameters; display an agent's travelling status via an agent itinerary window.

#### 3.2.1.1 Main Window

The **Main Window** ( Figure 7) consists of three parts:

\(\bullet\)**Control panel** (top right): this panel allows to send commands to the Farm (partition) in standalone mode

\(\bullet\)**Run status panel** (top left): the status of execution of a command is displayed in this window. As an example, when "Start Up Check" button is pressed, an agent goes into EF, checks all components and shows the result in this panel:

\(``\)\(<\)STANDALONE_CONFIG_CHECK\(>\)\(==\)\(>\) over (194/195)"

This means that there are 195 processes in the config file, and 194 are presently running

\(\bullet\)**Config status panel** (bottom left): this panel displays the summary of config status, including the number of hosts and tasks in the configuration, the number of running hosts and tasks, bad task name if any. In Figure 7 the panel shows one bad task named subf0_pt_034\(0\)2 at host eff034.

Menu bar of the window provides extra functionality, e.g.

\(\bullet\)**PanelMode** allows to select the mode of the main window : Standalone, Combine, Combine be, Combine df. The differences between those modes are described in section 6.4.2.

\(\bullet\)From **ControlTools**, the user can pop up secondary windows : Config file selector,

Dataflow param viewer, Partial reset panel... When the user activates "Cfg autotest", the Supervisor sends ping agents at an adjustable time intervals. A superclean command kills all

Figure 6: Supervisor GUIcomponents of EF dataflow.
* **SpecialTools** used for supervisor functionality control, includes : internal message dump, native command panel, activate/deactivate supervisor debugging, reload supervisor init parameter, reconnect master...
* **DataStorage** allows to connect/disconnect with persistent data storage
* **BeTools** allows to make test with Online Software, include : send status, send EF info, change partition, set shutdown option... see section 6.4.2 for detail.

#### 3.2.1.2 Activity Viewer

The Activity Viewer (Figure 8) displays monitoring data given by each dataflow component in

Figure 7: Main Window

the system. Typical monitoring data is the total number of events having passed through the component, input/output FIFO occupancy, etc.... Data is displayed in form of a swing table. The following facilities are available from the menu bar :

* Get all value (manual operation)
* Get all value (automatic operation with an adjustable time intervals)
* Get value for selected components (manual/automatic operation)
* Display histogram built from the current values.

#### 3.2.1.3 Config Tree

The Config Tree (Figure 9) gives a global view of the farm configuration based on the config file. Configuration description is described more precisely below.

This window displays the tree structure of configuration (sub-farm \(\rightarrow\) host \(\rightarrow\) process) and their status. When the supervisor detects a dead process, the appearance of the corresponding line (the line subf0_pt_034\(0\)2 in fig 9) is modified, several parts of the line are changed in value and in colour. To highlight the problem, the parent lines of the dead process (eff034, subf0, EFroot) is also modified. the column "SubTree" shows that eff034 machine has 4 processes in config and 3

Figure 8: Activity viewer

are still running, subf0 has 25 hosts in config and 24 have normal status, EF has 2 sub-farms in config and only one is working perfectly.

To each line is associated a pop-up menu which allows the user to start/stop any part of farm during run time.

#### 3.2.2 GUI for configuration description

The configuration of the Farm is described in a XML file following the DTD (Document Type Definition) file displayed in Appendix 1

This XML file describes all the details of the farm, giving for every sub-farm its name, the hosts for the SFI and SFO components, the executable to be run by these components and the list of nodes involved for processing. For every node, the paths to the directories containing the binary files and the required information for the EF naming service are given. Finally, every component running on the node is described. The parameters of the different components are given in the "command line" given by the "Exec" attribute.

An user interface written in Tcl/Tk conveniently allows the generation of the XML file. It has been separated in two different processes. The first one (Figure 10 :)allows to modify all the basic parameters of the farm. It is intended to be an "expert" interface. The second one (Figure 11: ), more dedicated to the end users, allows to modify only parameters relevant of the application, such as the full path of the processing tasks to be executed for the filtering operation.

Figure 9: Configuration tree

#### 3.2.3 Offline Analyse Tool

An histogram package and a plot facility have been developed in parallel for online plotting and

Figure 11: User interface for farm applications

Figure 10: User interface for basic farm parametersoffline analysis. The histogram package contains 1D and 2D histogram creation and filling functions. The plot facility gives the possibility to display histograms in several manners : histogram with/ without statistics, runtime plot, slide. The data source can be an XML file, a flat file, a histogram saving file or a database (see Figure 12).

## 4 Using supervisor as end-user

For end-users, it is important that on one hand the agent framework should be as transparent as possible, and on the other hand that it is still possible to act upon it if desired. We try to follow this principle in the current implementation.

### Start the whole system from scratch

Starting the system step by step :

* start **Voyager** for each host : done by script StartVoyager
* start **Supervisor Master** : done by script SPVmaster and SPVstart
* start **GUI** : done by script SPVshow

Typically, **GUI** and **Master** are running on different hosts.

### Configure the SPV.ini

The Supervisor has a property file. Several parameters are predefined in this file, some of them can be changed at run-time, e.g. :

* hostsPerAgent : defines the degree of parallelism of the supervisor. It will play a role in farm start phase, and in dataflow data collection phase.

* poolingTimer : gives the pooling timeout

Figure 12: Online analysis package

The most often used properties are described in Section 7.

### 4.3 Exercise the GUI

See above description about GUI.

## 5 Using the Supervisor as a developer

### 5.1 Package description

The system hierarchy is shown in Figure 13. The package is composed of 4 parts :

* bridge for Atlas online software (so-called _be_ sub-package) : implemented, see below for detail.
* xml parser (so-called _xml_ sub-package) : implemented, see below for description.
* core supervision (so-called _spv_ sub-package) : implemented, see below for detail.
* Constant definition (so-called _def_ sub-package)

Figure 14 shows the implementation view of the system.

Figure 13: Package hierarchy

#### 5.1.1 spv package

_spv_ contains many components, each of them doing a well defined, limited job.

The package is also composed of 3 sub-packages :

* _agent_ contains all agent classes
* _master_ contains all master service classes
* _ui_ contains all user interface classes

#### 5.1.1 master package

_master_ is the core component of the supervisor.

This package must provide the following functions : management of different kinds of agent; define the task and itinerary for each agent; retrieval of the results after having finished the job; management of abnormal behaviour of agent; management of different copies of GUI, each of them being able to perform separate monitoring or control; basic functionality of a control system (run control, process manager, message handling, monitoring...); provision for future, possibly unplanned, system extensions.

In the current implementation, _master_ is divided into 7 sub-packages :

* _hostel_ : receives commands from various GUIs, sends dedicated agents to the Farm; retrieves information from agents when they have finished the job; sends information back to GUIs.
* _config_ : for farm online configuration storage.
* _status_ : is a set of classes for keeping various status of system
* _rc_ : is the "run control" of farm. It receives the command from local control panel in case of

Figure 14: Implementation viewstandalone operation and from higher level control process in case of integrated operation; sends dedicated agents to the farm; reports command execution status to command sender.
* _dfstatus_ : performs acquisition of dataflow status
* _db_ : an add-in package, run as bridge between hostel and a persistent database for monitoring data storage. Data connection is taken in charge by the agent, The persistent data will be used for further "offline" analysis.
* _msg_ : receive message from various senders. The message can be then filtered and analysed by different tools.

#### 5.1.1.2 _ui_ package

All classes concerning graphic user interface are put into this package. The most often used classes are:

* SVpanel : main window
* CfgSelector : config file selection
* ActivityViewer : dataflow activity data display
* ConfigTree : farm configuration status
* Reset : start/stop any part of farm
* DataflowParam : dataflow component parameter display/update
* NativeCmd : use native command for different platform

#### 5.1.1.3 _agent_ package

This package contains all implemented agents classes in supervisor. Figure 15 shows the class hierarchy of the package.

Figure 15: Class hierarchy

There are two distinct agents : monitor-agent inherited from GenericMonAgent, and control-agent inherited from GenericRcAgent. The function of each agent is :

* CmdAgent : carry users' command to target machine, execute the command, carry back the result if necessary.
* UDPAgent : go to target machine, send a UDP request message to dataflow component, go back with query result.
* RCconfigureAgent : start process on a remote machine.
* RCinjectAgent : perform injectOn, injectOff command, which corresponds to SFI start/ stop.
* RCshutdownAgent : stop process on a remote machine.
* UDPRcAgent : go to target machine, send a UDP request to dataflow component, go back with query result.

In the Voyager toolkit, any object can become an agent at condition of

1. it implements java.io.Serializable interface;
2. it uses Agent.of(this) statement.

In our case, these two conditions are set by GenericMonAgent and GenericRcAgent. Only one method has to be written for the final classes : atProgram(). We take CmdAgent.java (see below) as an example to show how agents work.

The job of CmdAgent is to carry users' command to the remote location, perform the action (via exec()), get result of execution and finally go to next location. The atProgram() method defines what to do at each remote location when the agent moves into that node. The first thing the agent has to do is to determine what type of OS is actually running. The next() call at the end of the method lets agent go to the next location defined in the agent's itinerary list.

``` publicvoidatProgram(){ //getlocalinformation try{  Runtimeruntime=Runtime.getRuntime();  Stringosname=System.getProperty("os.name");  Processproc=null;  if((osname.equals("Solaris"))||(osname.equals("Linux")))  proc=runtime.exec(unixCmd);  if(osname.equals("WindowsNT"))  proc=runtime.exec(winCmd);  //waitingforresult InputStreaminput=proc.getInputStream();  BufferedReaderin=newBufferedReader(  newInputStreamReader(input));  Strings;  while((s=in.readLine())!=null){  //dosomething } catch(java.io.IOExceptione){System.err.println(e);  }  next(); }

#### 5.1.1.4 event package

Internal events are defined here. See Section 5.2 for event-driven description.

#### 5.1.1.5 util package

All util classes used in this level are put in the package.

#### 5.1.2 xml package

As we have described before, EF configuration file is in XML format. To read the file into the supervisor, we use **Voyager dxml** facility and **IBM xml4j parser**.

**dxml** is a toolkit used to create a set of Java classes based at a DTD file. The classes can then be used to get data from a XML file. This package actually contains the classes created from cfg.dtd.

#### 5.1.3 def package

This package contains definitions of constant used by the Supervisor

#### 5.1.4 be package

This package contains bridge-classes for Online Software / EF supervisor integration,. It is described in more details in section 6.

### 5.2 Supervisor component synchronisation : Event-Driven

Like other control and monitoring systems, we had to decide how to put components together. There are different methods to synchronise components in general : method call, messaging, event,... On can choose one or another, or combine, depending on the system complexity. In the _spv_, the relationship between components is complex. All relations need to be implemented correctly, and documented clearly for maintaining the current system and for future extension.

We decided to use "Java event" in most of case. **Event-driven** synchronisation gives the system an extra flexibility to arrange components' dependency, to ease unplanned extension which is a very important feature for a prototype with which one has little experience.

To make the components work together, we have defined several events. The components use the events to communicate with each other. Each component can be the sender of some events, the receiver of other events. We present the inter-component relationship by a matrix (Figure 16 and Figure 17) which determines the component dependency in the initial design. Because of the Java event-listener mechanism, adding new components and new events, re-arranging their dependencies becomes a simple game. The matrix gives the developer a global view of the system dependency, allowing to make more easily extensions.

Figure 16 describes Component-Event pairs for _master_ package and _be_ package, shows how components communicate with each other. As an example, component config**S**ends the **ConfigStat** event, which will be **R**eceived by components' status, rc and hostel.

The same mechanism is also implemented for _ui_ package (see fig 16). As an other example, when user changes UI from control mode to monitoring mode, the SPpanel component **S**ends a **PanelModeChange** event which will be **R**eceived by CfgSelector, DataflowParam and Reset. When SVpanel**R**eceives a new report from an agent, it **S**ends **NewReport** event to the other windows : DataflowParam, ActivityViewer and ConfigTree.

Figure 16: Component–Event matrix for _master_ and _be_

### Proxy generation

To build a distributed system, each class which will be contacted by a remote process has its representative in the remote system, called a _proxy_. Depending on the communication tools used by components (CORBA, rmi, Voyager...), the way to construct proxies is different. Voyager provides two methods to construct a proxy :

* static : through **pgen** tool
* dynamic : through dynamic proxy generation system to generate proxy classes at runtime.

By default, Voyager creates proxy classes based on the interfaces the class implements, i.e. a remote deployment class XXX. java must have its interface class called IXXX. java which will be used for dynamic proxy generation. The advantage of interface-based proxies is that when using dynamic proxy class generation, Voyager will not require the implementation class to be present. This can be desirable for security reasons, to reduce remote classloading, or to be able to deploy a smaller.jar file on the client.

### Implementation environment

Platforms : Sun Solaris 2.7, Windows NT 4.0, Linux RedHat 6.2, TruUnix64 4.0F (Alpha)

Figure 17: Component–Event matrix for GUIPackages :

Java : jdk 1.3

Mobile agent system : Voyager 3.3

## 6 Online software / EF Integration

The proposal of the integration has been published in [5].

### Overview of organisation

A "2 component bridge" was inserted between Online Software (OS) and Event Filter Supervisor (EFS). Figure 18 shows the overall organisation in the case of a single farm.

The first component is _EFctrl_, which uses the Controller skeleton of the Run Control. It provides the essential functionality of the Online Software: the standard RC Finite State Machine, Database access, the publish/subscribe mechanism of IS and MRS which are needed by the EF Supervisor to synchronise with the Online Software. It communicates with the _Root Controller_ via the so-called _empty Controller_ in charge of building the EF state.

Figure 18: Integration overall scheme

The second component is a communication server which provides a bidirectional transfer mechanism for data exchange between OS and EFS via a publish/subscribe message model. It can be a CORBA server or a Message Oriented Middleware (MOM). The EF Supervisor uses this component to receive Online Software data (commands, IS information,

data (status, messages,...). EF monitoring data, even in a complex form such as histograms, can also be sent to the the Online Software Integrated Graphical User Interface (IGUI) by this means, provided the latter is able to handle such data. For the phase I integration, we have chosen to use the Information Service package [6] in order to implement this server.

### 6.2 Items for exchange

Presently, the following items are exchanged between OS and EFS. Other items can be added at a later stage :

RunCtrl.EF_Ctrl1_command ---> contains DAQ rctrl command

RunCtrl.EF_Ctrl1_efstate ---> contains rctrl cmd execution result

RunCtrl.EF_Ctrl1_dbname ---> contains EF configuration file name

RunCtrl.EF_Ctrl1_info ---> contains EF general status

### 6.3 Implementation

As described in Figure 13, all integration classes are grouped into the _be_ package. This piece of code listens to events sent by the other component and sends events to the related component.

Currently the following 5 events are used :

RunCmdAckEvent

ConfigStatEvent

CtrlModeEvent

InfoEvent

RunCmdEvent

The event relationship is described in Figure 16, except for InfoEvent which is sent by Online Software class.

Figure 19 shows the interaction sequence related to any of the events :

1. _be_ package subscribes to RunCtrl.EF_Ctrl1_command and waits for an event
2. **Bridge** sends InfoEvent
3. _be_ package gets InfoEvent then sends RunCmdEvent with parameter
4. _rc_ package receives RunCmdEvent, performs the corresponding action then sends RunCmdAckEvent.
5. _be_ package gets RunCmdAckEvent_and_ publishes it to **Bridge**

### Run EF with DAQ

#### 6.4.1 Start EF from script

The EF processes can be started from outside of its context. The following steps show how to do it :

1) Install in each EF machine 3 packages : _dataflow_, _monitoring_ and _script._ These files can be obtained from the tar file on [http://atddoc.cern.ch/Atlas/EventFilter/activity.html](http://atddoc.cern.ch/Atlas/EventFilter/activity.html)

To avoid unnecessary path and classpath problems, it is better to install them in the user home directory. On the lnxatd24 machine, currently used for EF tests at CERN, the files are installed in the directory /home/effuser. The password of the account effuser can be obtained on request to Z. Qian (gian@cppm.in2p3.fx)

2) Choose a host, later referred as the "EF Entry Point (EEP)" which is running _afs_ and is reachable from the outside. Do the following two preparation steps in the _script_ directory of this machine

- prepare the EF configuration file using the dedicated user interface

EFDB.tcl ("expert" to prepare the configuration database)

EFConfig.tcl (to finalise the configuration file)

- make EF setup files using the command :

makelist config-file-name

This tools creates a set of files which will be used by the different scripts :

ef_nshost : EF Naming server running machine

Figure 19: Interaction sequenceef_nsport:portnumberusedbyNamingserver  ef_master:EFMasterrunningmachine  ef_gui:EFsupervisorguirunningmachine  ef_slave:EFataflowmachinelist  Note:makelistwillexecutedonlyiftheEFisstopped(stateoff,seebelow).
3)Fromanyoutsidemachine,startandstoptheEFprocessesusingfollowingrshcommands: -rshEEPscript/play_ef_startpartitiongui_display_address -rshEEPscript/play_ef_stop  Figure20 showsEFstart-upsequencechart.Figure21 showsanexampleofplay_ef_start logscreen.

EF hasonlytwostates:onandoff,thisinformationiscreatedbyplay_ef_startandplay_ef_stop,andstoredintheef_statfile.

#### 6.4.2Dedicated tools for integration test

Some tools have been made available to ease the integration task. They can be used from the Main window menu (see Figure7).

**PanelMode** allows to select the mode of the main window : "Standalone", "Combine", "Combine be" and "Combine df". The differences between these modes are the following :

* **Combine** : dismissalllocalruncontrolcommand,dismisslocalSfi/Sfo
* **Combine be** : dismissalllocalruncontrolcommand,enablelocalSfi/Sfo,usedforBack-endintegrationtest.
* **Combine df** : enablelocalruncontrolcommand,dismissSfi/Sfostart,usedforataflow integrationtest.

**BeTools** menu allowsto:

* sendindividualEFstatustoBackend
* sendEFinformationtoBackend(tobedefined)
* changepartitionwithoutcompletestopofEF,canbeusedwhenBackendrestartorusingdifferentpartitionfortest...
* switchtheshutdowncommandonoroff.Whenitisswitchedoff,EFignores"unconfig-ure"commandssentbyBackendandnoprocesswillbekilled.

Figure 20: Sequence chart of play_ef_start script

Figure 21: Sequence chart of play_ef_start script

[marsol3]play_ef_startmy_partitionmarsol3  do EFstart  NServer:noprocesskilled  [1]8215  marntr2  voyager:noprocesskilled  java:noprocesskilled  [1]28262  marntr1  voyager:noprocesskilled  java:noprocesskilled  [1]1506  voyager:noprocesskilled  java:noprocesskilled  [1]8231  [2]8272  [2]-DoneSPVstartmy_partition>&../script/log_start_master_SPVstart  EF DISPLAY:marsol3:0.0  [1]8325

 start Voyager slave checking...

 check address : marntr2:9100  check address : marntr1:9100  at top://marntr2:9100 Linux  at top://marntr1:9100 Linux  ---------------------------------------  Running slave number : 2/2

_Figure 21 :play_ef_start screen log_

#### 6.4.3 Critical points

The following points should be carefully considered :

1) DAQ cosnaming reference IPC_REF_FILE must be correct, this reference is defined in ~monitoring/envm of the EFS master.

2) The full path to the EF configuration file must be stored into the DAQ configuration database.

## 7 System properties

Supervisor uses a set of system properties to control itself, including control panel presentation, agent behaviour, integration parameter, etc... All properties are stored in the SPV.ini file in the ~monitoring directory. The table below shows the list of properties used to set the configuration.

\begin{tabular}{|l|c|l|} \hline \multicolumn{1}{|c|}{_Property_} & _Possible value_ & \multicolumn{1}{c|}{_Description_} \\ \hline SPV.master & – & SPV master address \\ \hline SPV.defaultControlMode & STANDALONE & See section 6.4.2 for mode \\  & COMBINE & description \\  & COMBINE\_BE & \\  & COMBINE\_DF & \\ \hline SPV.defaultShutdown & true & See section 6.4.2 for switch \\  & false & description \\ \hline SPV.hostsPerAgent & Any positive number & This parameter defines the degree of parallelism of the supervisor. \\  & & \(=1:\) fully parallel operation \\  & & \(=99999:\) fully sequencial op. \\  & & The value will play a role in farm start phase, and in \\  & & dataflow data collection phase. \\ \hline SPV.poolingTimer & Any positive number (in second) & When launch parallel agents \\  & second) & for pooling dataflow info, \\  & & supervisor set this timeout for \\  & & waiting latest agent return \\ \hline SPV.configureTimeout & Any positive number (in second) & Timeout for run control \\  & second) & ”configure” cmd execution. \\  & & Supervisor wait the timeout \\  & & before launch check–agent. \\ \hline SPV.unconfigureTimeout & Any positive number (in second) & Timeout for run control \\  & & second) & ”unconfigure” cmd execution. \\ \hline SPV.stopTimeout & Any positive number (in second) & Timeout for run control ”stop” cmd execution. \\ \hline SPV.dfJavaImp & true & Define which version of \\  & false & dataflow is to be started (Java \\  & & or C++) \\ \hline SPV.javaVM & – & Java VM path in dataflow \\  & & machine. Only used when \\  & & SPV.dfJavaImp\(=\)true. \\ \hline SPV.classpath & – & Java classpath in dataflow \\  & & machine. Only used when \\  & & SPV.dfJavaImp\(=\)true. \\ \hline BE.partition & – & Default value, can be changed \\  & & in the run time \\ \hline BE.server & – & Fixed value, can not be \\  & & changed \\ \hline \end{tabular}

## 8 Reference

[1] The ATLAS Event Filter, C.P. Bee _et al._, Real Time 99, Santa Fe, USA, Conference proceedings [http://atddoc.cern.ch/Atlas/EventFilter/documents/rt99-157-paper.pdf](http://atddoc.cern.ch/Atlas/EventFilter/documents/rt99-157-paper.pdf)

[2] Event Handler Supervisor High Level Design, ATLAS DAQ-1 Note 92, [http://atddoc.cern.ch/Atlas/Notes/092/Note092-1.html](http://atddoc.cern.ch/Atlas/Notes/092/Note092-1.html)

[3] Java Mobile Agent for monitoring task, ATLAS DAQ-1 Note 78, [http://atddoc.cern.ch/Atlas/Notes/078/Note078-1.html](http://atddoc.cern.ch/Atlas/Notes/078/Note078-1.html)

[4] Voyager - [http://www.objectspace.com/voyager](http://www.objectspace.com/voyager)

[5] Event Filter / Online software Integration, ATLAS COM-DAQ Note 2000

[6] Online Software Summary Document, ATLAS DAQ Note 2000-

## Appendix 1 : Configuration file

### DTD file

<!ELEMENT Cfg (GeneralInfo?,Subfarm+)> <!ELEMENT GeneralInfo (NsAddress,MasterHost,GuiHost)> <!ELEMENT NaAddress (#PCDATA)> <!ELEMENT MasterHost (#PCDATA)> <!ELEMENT GuiHost (#PCDATA)> <!ELEMENT Subfarm (Sname,SfiHost?,SfoHost?,SfiCmd?,SfoCmd?,Node+)> <!ELEMENT Sname (#PCDATA)> <!ELEMENT SfHost (#PCDATA)> <!ELEMENT SfoHost (#PCDATA)> <!ELEMENT SfiCmd (#PCDATA)> <!ELEMENT SfoCmd (#PCDATA)> <!ELEMENT Node (Name,BinDir,IorDir,Task+)> <!ELEMENT Name (#PCDATA)> <!ELEMENT BinDir (#PCDATA)> <!ELEMENT TorDir (#PCDATA)> <!ELEMENT Task EMPTY> <!ATTLIST Task  Id CDATA #REQUIRED  Type CDATA #REQUIRED  Sequence CDATA #REQUIRED  Exec CDATA #REQUIRED>

### XML configuration file (an example)

The XML file generated by the configuration GUI, which contains 2 sub-farms of 1 node each running 1 processing task.

<?xml version="1.0" encoding="ASCII"?> <!DOCTYPE Cfg SYSTEM "[http://atddoc.cern.ch/Atlas?EventFilter/xml/dtd/cfg.dtd](http://atddoc.cern.ch/Atlas?EventFilter/xml/dtd/cfg.dtd)"> <Cfg>  <GeneralInfo>  <NsAddress>marntr4:7200</NsAddress>  <MasterHost>marntr4</MasterHost>  <GuiHost>marntr4</GuiHost>  </GeneralInfo>  <Subfarm>  <Sname>subl</Sname>  <SfiHost>marntr1</SfiHost>  <SfoHost>marntr1</SfoHost> <SfiCmd>/home/efuser/dataflow/bin/sfi subl_d1 marntr4:7200 /home/efuser/dataflow/geo/GeomRun.cz</SfiCmd>  <SfoCmd>/home/efuser/dataflow/bin/sfo subl_c1 marntr4:7200</SfoCmd>  <Node>  <Name>marntr1</Name>  <BinDir>/home/efuser/dataflow/bin/</BinDir>  <TorDir>/home/efuser/dataflow/ior/</TorDir>  <Task Id="subl_d1" Type="fifo:did2" Sequence="1" Exec="dld2 -id_d1 subl_d1 -id_d2 subl_d2 -nbr_d2 1 -type fifo -ns marntr4:7200 -path /home/efuser/dataflow"/>  <Task Id="subl_d2_0" Type="fifo:did2" Sequence="1" Exec="ps"/>  <Task Id="subl_c1" Type="fifo:c1" Sequence="2" Exec="fifo -id subl_c1 -depth 1 -type fifo -ns marntr4:7200 -path /home/efuser/dataflow"/>  <Task Id="subl_pt1" Type="pt:01" Sequence="3" Exec="pt -id subl_pt1 -type pt -eventtype 01 -ns marntr4:7200 -path /home/efuser/dataflow-geo GeomRun.cz -PTH10 -reject 50 -src subl_d2_0 -dst subl_c1"/>  </Node>  </Subfarm>  <Subfarm>  <Sname>sub2</Sname>  <SfiHost>marntr2</SfiHost>  <SfoHost>marntr2</SfoHost> <SfiCmd>/home/efuser/dataflow/bin/sfi sub2_d1 marntr4:7200  /home/efuser/dataflow/geo/GeomRun.cz</SfiCmd>  <SfoCmd>/home/efuser/dataflow/bin/sfo sub2_c1 marntr4:7200</SfoCmd>  <Node>  <Name>marntr2</Name>  <BinDir>/home/efuser/dataflow/bin/</BinDir>  <TorDir>/home/efuser/dataflow/ior/</TorDir> <Task Id="sub2_d1" Type="fifo:did2" Sequence="1" Exec="dld2 -id_d1 sub2_d2 -nbr_d2 1 -type fifo -ns marntr4:7200 -path  /home/efuser/dataflow"/>  <Task Id="sub2_d2_0" Type="fifo:did2" Sequence="1" Exec="ps"/><Task Id="sub2_cl"Type="fifo:cl"Sequence="2"Exec="fifo -id sub2_cl -depth 1 -type fifo -ns marmtr4:7200 -path /home/efuser/dataflow"/> <Task Id="sub2_ptl"Type="pt:01"Sequence="3"Exec="pt -id sub2_pt1 -type pt -eventype 01 -ns marmtr4:7200 -path /home/efuser/dataflow-geo GeomRun.cz -PTH 10 -reject 50 -src sub2_d2_0 -dst sub2_cl"/>  </Node>  </Subfarm> </Cfg>