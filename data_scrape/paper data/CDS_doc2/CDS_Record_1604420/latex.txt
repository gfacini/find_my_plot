Performance assumptions based on full simulation of an upgraded ATLAS detector at a High-Luminosity LHC

The ATLAS Collaboration

###### Abstract

This note documents the performance assumptions used for ATLAS physics projections presented at the 2013 ECFA HL-LHC workshop. Parametrisations are derived for the object selection efficiencies and resolutions for an upgraded detector at a High Luminosity LHC. These are based on full simulations of the Phase II upgraded detector with realistic levels of in-time and out-of-time pile-up. The upgraded tracker maintains the performance of the Run 1 detector even in the presence of high pileup, with improved muon momentum resolution and b-tagging performance.

_errata corrige 20-09-2016: fix Figure 2-a vertical axis label ([%] removed)_

(c) Copyright 2016 CERN for the benefit of the ATLAS Collaboration.

Reproduction of this article or parts of it is allowed as specified in the CC-BY-3.0 license.

Introduction

Studies have been made of the future physics potential of the ATLAS experiment at the Large Hadron Collider, LHC. This note documents the performance assumptions for future upgrades of the ATLAS detector. Proton-proton collision data were collected at centre-of-mass energies of 7 and 8 TeV during Run 1. After the first long shutdown, the approved program will continue in 2015 at close to the design energy of 14 TeV. A substantial so-called Phase-I upgrade of the detector will be made in 2018, during the second long shutdown, with the aim of delivering a total integrated luminosity of about 300 fb\({}^{-1}\) at 14 TeV collision energy by the end of the approved program. It is proposed to make a futher Phase-II upgrade in the third long shutdown to achieve luminosities well in excess of design with the High Luminosity Large Hadron Collider (HL-LHC) yielding a total integrated luminosity of 3000 fb\({}^{-1}\) after ten additional years running. The nominal luminosity for HL-LHC is \(5\times 10^{34}\) cm\({}^{-2}\) s\({}^{-1}\), corresponding to an average number of proton-proton interactions in the same bunch crossing (pile-up) of \(\langle\mu\rangle=140\). An upper limit on the possible instantaneous luminosity of \(7\times 10^{34}\) cm\({}^{-2}\) s\({}^{-1}\), corresponding to \(\langle\mu\rangle=200\) is also considered here.

Initial results were input to the Update of the European Strategy for Particle Physics [1, 2]. In the absence of a full simulation of the upgraded Phase-II detector, those studies relied on a fast simulation, based on parametrisations of the trigger and detector response to generator level objects such as leptons, jets, \(b\)-jets, and missing transverse energy, \(E_{\mathrm{T}}^{\mathrm{miss}}\)[3]. Functions to describe the detector resolution, reconstruction efficiency and trigger efficiency were defined by extrapolations from the existing data sample, and Monte Carlo simulations including an average of up to 69 proton-proton interactions in the same bunch crossing (in-time pile-up), and in preceeding bunch crossings (out-of-time pile-up). In defining these parametrisations, it was also considered that the Phase-II detector would be designed to retain the performance of the present detector for many aspects.

The Letter of Intent for the Phase-II detector upgrade includes performance studies with a full simulation of the new all-silicon inner tracker, ITK, and with up to 200 pile-up events [4]. These were stand-alone studies of the ITK. Additional fully simulated event samples are now available with all the same details of the baseline new tracker, but with the tracker embedded in the Run 1 calorimeter and muon spectrometer, allowing detailed studies taking into account in-time and out-of-time pile-up. These simulated event samples have been used to revise many of the parametrisations of the Phase-II detector performance to explore further the HL-LHC physics case for the October 2013 ECFA workshop. The improved tracker has a significant impact on the \(b\)-tagging performance and muon resolution, and it has been possible to evaluate the \(E_{\mathrm{T}}^{\mathrm{miss}}\) performance directly with high pile-up. Improved parametrisations of the photon performance have also been developed. Jet reconstruction with high pile-up has been studied in full simulation, and the previous parametrisations [3] were found to be reasonable. The previous parametrisations for the electron response and tau-lepton assumptions are also retained. The updated photon, muon, \(E_{\mathrm{T}}^{\mathrm{miss}}\) and \(b\)-tagging parametrisations are described in the following sections.

## 2 Photons

### Parametrisation of the identification performance

The parametrisation of the photon identification performance was obtained by fitting the efficiency of tight identification and isolation selection requirements as a function of the true \(p_{\mathrm{T}}\) of the photon. The tight identification used corresponds to the latest 2012 optimisation for 8 TeV data, with an isolation variable calculated from calorimeter energy deposits [5]. The identification and isolation variables, including contributions from pile-up events, are expected to be well modelled by the fully simulated samples used to evaluate the performance. The Monte Carlo (MC) samples used to parametrise the efficiency are fully simulated \(H\to\gamma\gamma\) events produced from gluon-gluon fusion with pile-up corresponding to an average value of \(\langle\mu\rangle\)=80. It is then assumed that the efficiency of this selection for samples with \(\langle\mu\rangle\)=80 is representative of the performance of an identification algorithm developed and optimised for \(\langle\mu\rangle=140\). The improved algorithm should be able to recover any further efficiency loss.

The photon selection efficiency as a function of the \(p_{\rm T}\) of the true photon is parametrised with the function

\[\epsilon(p_{\rm T})=0.76-1.98\times e^{-\frac{p_{\rm T}}{16.1\rm GeV}}. \tag{1}\]

This parametrisation is derived for photons with true \(p_{\rm T}\) greater than 15 GeV, to cover the range used in physics studies. The efficiency values and derived parametrisation are shown in Figure 1. The previous parametrisation was based on a sample with \(\langle\mu\rangle=46\), with a higher plateau efficiency of 83%, so the new function is more conservative in its predictions for signal efficiency at HL-LHC.

### Fake photons

The rate of jets passing the photon identification and isolation requirements is also derived. Photons from neutral meson decays (eg. \(\pi^{0}\) decays) are not considered to be true photons, but contribute to the jet fake rate. The fake photon is required to be within \(|\eta|<2.35\) and outside the transition regions \(1.37<|\eta|<\)1.52.

Samples of fully simulated di-jet events at a centre-of-mass energy \(\sqrt{s}\) of 14 TeV and \(\langle\mu\rangle=80\) are used to evaluate the rate of fake photons. Following the same strategy as for signal photons, this is then assumed to represent the future photon identification fake rate with \(\langle\mu\rangle=140\). The fake rate is parametrised as a function of the true jet \(p_{\rm T}\) above 30 GeV with an exponential function,

\[\epsilon(p_{\rm T})=9.3\cdot 10^{-3}\times e^{-\frac{p_{\rm T}}{17.3\rm GeV}}. \tag{2}\]

Figure 2(a) shows the fake rate as a function of true jet \(p_{\rm T}\).

Figure 1: The efficiency of the photon identification and isolation requirements as a function of the true photon \(p_{\rm T}\). The fitted parametrisation is superimposed.

In addition, the ratio of the reconstructed and true \(p_{\mathrm{T}}\) of the fake photon was studied. The fake photon energy response is parametrised with a Gaussian function, as shown in Figure 2(b). For fakes with \(p_{\mathrm{T}}>25\) GeV and passing the photon selection, this ratio was found to be around 75% on average, whether using simulated samples with \(\langle\mu\rangle=40\), 60 or 80.

## 3 Muons

In previous studies, a uniform 97% efficiency was assumed for muon identification. A more realistic evaluation is now available. Two different muon selections have been considered: tight muons, corresponding to combined muons found in the inner detector (ID) and in the muon spectrometer (MS), with hits in at least two MS stations; and loose muons, that include the combined and segment-tagged muons, calorimeter-tagged muons for \(|\eta|<0.1\) and MS-only tracks for \(2.5<|\eta|<2.7\), as descibed in Ref. [6]. The tight muon selection is expected to be used for analyses requiring high muon purity and small resolution tails, while the loose muon selection is intended to maximise the acceptance. The corresponding reconstruction efficiencies are reported in Table 1 and are taken from measurements in 2012 data.

The trigger efficiency, estimated with respect to the tight muon selection, is assumed to be the same as that for single-muon triggers in 2012 and is reported in Table 1. The \(p_{\mathrm{T}}\) thresholds will depend on the particular trigger chain to be used. They are expected to be close to or above the 2012 single-muon threshold of \(p_{\mathrm{T}}=24\) GeV for single muon triggers and \(p_{\mathrm{T}}=15\) GeV for multi-object triggers.

Separate momentum resolution functions are derived for the ID and MS. These are then merged into

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline \(|\eta|\) & \(0:0.1\) & \(0.1:1.05\) & \(1.05:2.4\) & \(2.4:2.5\) & \(2.5:2.7\) \\ \hline Reco. Loose & \multicolumn{4}{c|}{0.99} \\ \hline Reco. Tight & 0.54 & \multicolumn{4}{c|}{0.97} & 0.00 \\ \hline Trigger & \multicolumn{2}{c|}{0.70} & 0.86 & 0.00 \\ \hline \end{tabular}
\end{table}
Table 1: Muon reconstruction and trigger efficiencies for several \(\eta\) ranges.

Figure 2: The fake rate after applying photon identification and isolation requirements as a function of true jet \(p_{\mathrm{T}}\) (a), and the ratio of reconstructed photon \(p_{\mathrm{T}}\) to the true jet \(p_{\mathrm{T}}\) (b). In each case, the fitted parametrisations are also displayed.

a "Combined" resolution function according to the following:

\[\sigma_{\rm ID} = p_{\rm T}\times\sqrt{a1^{2}+(a2\times p_{\rm T})^{2}},\] \[\sigma_{\rm MS} = p_{\rm T}\times\sqrt{\left(\frac{b0}{p_{\rm T}}\right)^{2}+b1^{2}+ (b2\times p_{\rm T})^{2}},\] \[\sigma_{\rm CB} = \frac{\sigma_{\rm ID}\times\sigma_{\rm MS}}{\sqrt{\sigma_{\rm ID}^ {2}+\sigma_{\rm MS}^{2}}}\]

where \(p_{\rm T}\) is the truth muon transverse momentum (in GeV). The MS factors b0, b1, b2 are determined using the Run 1 MS setup and are assumed to be appropriate also for simulations of future operation. For the ID two different sets of parameters a1, a2 are provided: those based on the current setup (assumed to be still valid for Phase-I) and those corresponding to the improved performance expected after Phase-II upgrade (ITK), taken from a parametrisation of the results published in the Letter of Intent for the ATLAS Phase-II upgrade [4]. The different factors in these formulas are listed in Tables 2 and 3. Figure 3 shows the muon resolution as a function of \(p_{\rm T}\) for the MS, ID and ITK for two values of \(\eta\). The ID and MS parameters for the Run 1 detector are at the moment given in two large \(\eta\) bins (barrel and endcap) and should be updated with a finer binning for a more detailed comparison with the ITK.

Figure 4 illustrates the improved performance of the Phase-II upgrade (MS+ITK) compared to that of the current setup (MS+ID). A Higgs-like resonance with a pole mass of 400 GeV and decaying to two muons was simulated using MadGraph 5.1. The mass resolution of the resonance improves to 16.3 GeV with the ITK configuration from 17.6 GeV with the current configuration.

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|} \hline  & a1 & a2 & b0 & b1 & b2 \\ \hline \(|\eta|<1.05\) & 0.01607 & 0.000307 & 0.24 & 0.02676 & 0.00012 \\ \hline \(|\eta|>1.05\) & 0.03000 & 0.000387 & 0.00 & 0.03880 & 0.00016 \\ \hline \end{tabular}
\end{table}
Table 2: Parameters used in the muon momentum smearing functions for the Run 1 detector.

\begin{table}
\begin{tabular}{|l c|c|c|} \hline \(|\eta|\) range & a1 & a2 \\ \hline
0.00 & 0.18 & 0.01061 & 0.000157 \\
0.18 & 0.36 & 0.01084 & 0.000153 \\
0.36 & 0.54 & 0.01124 & 0.000150 \\
0.54 & 0.72 & 0.01173 & 0.000149 \\
0.72 & 0.90 & 0.01269 & 0.000148 \\
0.90 & 1.08 & 0.01406 & 0.000161 \\
1.08 & 1.26 & 0.01623 & 0.000192 \\
1.26 & 1.44 & 0.01755 & 0.000199 \\
1.44 & 1.62 & 0.01997 & 0.000232 \\
1.62 & 1.8 0 & 0.02453 & 0.000261 \\
1.80 & 1.98 & 0.03121 & 0.000297 \\
1.98 & 2.16 & 0.03858 & 0.000375 \\
2.16 & 2.34 & 0.05273 & 0.000465 \\
2.34 & 2.52 & 0.05329 & 0.000642 \\
2.52 & 2.70 & 0.05683 & 0.000746 \\ \hline \end{tabular}
\end{table}
Table 3: Parameters used in the ID muon momentum smearing functions for the Phase-II setup.

Figure 4: Distribution of the difference between the reconstructed and true mass for a 400 GeV Higgs-like resonance for the current ID configuration (MS+ID) and for the Phase-II configuration (MS+ITK).

Figure 3: Muon resolution as a function of \(p_{\rm T}\) for the MS, the Run 1 ID and for the Phase-II inner tracker (ITK), where the left plot corresponds to central rapidity (\(|\eta|=0.1\)) and the right plot corresponds to \(|\eta|=1.7\).

## 4 Missing transverse energy

The true \(E_{\rm T}^{\rm miss}\), calculated from the sum of true stable interacting particles in the detector acceptance, is smeared in \(x\) and \(y\) using a parametrised fuction:

\[E_{x,y}^{\rm miss}=E_{x,y}^{\rm miss,true}+\mbox{Gaussian}(0,\sigma(\mu)), \tag{3}\]

where \(\sigma(\mu)\) is the resolution which depends on the average number of pile-up events. The parametrisation has been derived from \(Z^{\prime}\to t\bar{t}\) (\(m_{Z^{\prime}}=2\) TeV), minimum bias (_min-bias_) and di-jet samples at \(\sqrt{s}=14\) TeV and 25 ns bunch spacing for three different pile-up conditions: \(\langle\mu\rangle\)=60, 80, 140. The noise threshold is optimized for the corresponding \(\langle\mu\rangle\) value. Three ranges of jet \(p_{T}\) have been considered in the di-jet events: 0-20 GeV, 80-200 GeV and 200-500 GeV, referring to them hereafter as J0, J2 and J3 samples, respectively.

Figure 5: \(\Sigma E_{\rm T}^{\rm PU}\) distributions for \(\langle\mu\rangle\) values of 60, 80 and 140, for \(Z^{\prime}\to t\bar{t}\) events and min-bias events. In the \(E_{\rm T}^{\rm miss}\) parametrisation, the nominal parametrisation of \(\Sigma E_{\rm T}^{\rm PU}\) is obtained from \(Z^{\prime}\) events, and the min-bias sample provides a systematic variation to account for differences in the distribution due to the physics process studied.

### \(\Sigma E_{\rm T}\) parametrisation

The \(E_{\rm T}^{\rm miss}\) resolution depends on the total \(\Sigma E_{\rm T}\), which is formed from the true \(\Sigma E_{\rm T}\) of the event of interest, and the additional \(\Sigma E_{\rm T}\) due to the pile-up. \(\Sigma E_{\rm T}^{\rm PU}\) can thus be defined as

\[\Sigma E_{\rm T}^{\rm PU}=\Sigma E_{\rm T}-\Sigma E_{\rm T}^{\rm True}. \tag{4}\]

Figure 5 shows the \(\Sigma E_{\rm T}^{\rm PU}\) distributions in \(Z^{\prime}\) and min-bias samples. There is a small positive bias in \(\Sigma E_{\rm T}^{\rm PU}\) for events where the hard scatter of interest has low intrinsic \(\Sigma E_{\rm T}^{\rm True}\). To estimate the total \(\Sigma E_{\rm T}\), a random value is drawn from the \(\Sigma E_{\rm T}^{\rm PU}\) distribution and added to the true \(\Sigma E_{\rm T}\). The default parametrisation is taken from \(Z^{\prime}\to t\bar{t}\) samples.

Two types of systematic variations were considered, as indicated in Table 4. The first is due to the change in response for different physics processes, and the second from varying the noise threshold applied to suppress pile-up when forming energy clusters in the calorimeter.

The uncertainy due to differences in the nature of physics processes is evaluated by changing from the default distribution, obtained with \(Z^{\prime}\) events, to the distribution from a min-bias sample, as illustrated in Figure 5. This is listed as the process uncertainty in Table 4.

The second source of uncertainty is introduced by the pile-up noise thresholds. The formation of energy clusters in the calorimeter depends on thresholds which are optimized for the expected level of pile-up, denoted \(\sigma^{\rm pile-up}_{\rm noise}(\mu)\). The aim of these thresholds is to suppress pile-up fluctuations in the calorimeter deposits. The systematic variation in the pile-up noise threshold illustrates the present uncertainty on what the exact value chosen for data-taking will be, and the fact that it could differ from the one considered optimal for the pile-up level expected in data.

Since the selection of the cell noise thresholds plays a relevant role in determining the \(\Sigma E_{\rm T}^{\rm PU}\) shape, as can be seen in Figure 6, dedicated variations of the histograms for the change of the threshold have been provided. These variations were derived using \(Z^{\prime}\) samples with fixed \(\langle\mu\rangle\) and different \(\sigma^{\rm pile-up}_{\rm noise}(\mu)\). Where \(Z^{\prime}\) samples were not available, the equivalent di-jet sample (\(200<p_{\rm T}<500\) GeV, called _J3_ in Table 4 and Figure 6) was used instead. The pile-up noise threshold of the different samples was varied by changing the \(\langle\mu\rangle\) for which the threshold is optimized. The \(\langle\mu\rangle\) range of this variation is smaller for lower values of \(\langle\mu\rangle\) (\(\pm 20\) for \(\langle\mu\rangle\)=60,80) and larger for \(\langle\mu\rangle\)=140 (\(\pm 60\)). We refer to this uncertainty as the _threshold_ uncertainty in Tables 4 and 5 and Figure 6.

### \(E_{\rm T}^{\rm miss}\) resolution

The \(E_{\rm T}^{\rm miss}\) resolution is then calculated as a function of the \(\Sigma E_{\rm T}\) estimated as described in Section 4.1. The \(E_{x}^{\rm miss}\), \(E_{y}^{\rm miss}\) resolution is studied as a function of the total \(\Sigma E_{\rm T}\) either by using a functional parametrisation derived from simulation or taking directly the value from the fit to the simulated data. Specifically:

\begin{table}
\begin{tabular}{|l|l|l|l|l|} \hline \multicolumn{5}{|c|}{\(\Sigma E_{\rm T}^{\rm PU}\)} \\ \hline \multirow{3}{*}{\(\langle\mu\rangle\)} & \multirow{3}{*}{Nominal} & \multicolumn{3}{c|}{Systematic uncertainties} \\ \cline{3-5}  & & Process & Threshold Up & Threshold Down \\ \hline
60 & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=60) & min-bias, \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=60) & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=80) & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=80) \\
80 & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=80) & min-bias, \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=80) & J3, \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=100) & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=60) \\
140 & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=140) & min-bias, \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=140) & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=200) & \(Z^{\prime}\), \(\sigma^{\rm pile-up}_{\rm noise}(\mu\)=100) \\ \hline \end{tabular}
\end{table}
Table 4: Origin of the full-simulation distributions used to generate random values of \(\Sigma E_{\rm T}^{\rm PU}\), and the variations due to systematic uncertainties. A di-jet sample (_J3_) is used when an appropriate \(Z^{\prime}\) sample is not available.

* In the low \(\Sigma E_{\rm T}\) region the resolution is obtained from the min-bias sample (J0).
* In the high \(\Sigma E_{\rm T}\) region the fit obtained from the \(Z^{\prime}\to t\bar{t}\) events is used.
* In a small \(\Sigma E_{\rm T}\) region between the two regimes, where both samples have enough statistics, a linear interpolation is used.

Two sources of uncertainties have been considered which are assumed to be uncorrelated:

* Variations due to different samples: an optimistic scenario, in which the degradation of the resolution at low \(\Sigma E_{\rm T}\) is removed by extending the \(Z^{\prime}\to t\bar{t}\) parametrisation, and it is assumed on top of this that the resolution is 5% better than the resulting estimate. Since at low \(\Sigma E_{\rm T}\) the min-bias full simulation shows a worse resolution than the extrapolation of the fit in the \(Z^{\prime}\to t\bar{t}\) sample, a second pessimistic variation is provided, equidistant from the nominal scenario, but in the opposite direction.
* Possible variation in the pile-up noise thresholds, included as a fixed 5 GeV uncertainty.

Figure 6: \(\Sigma E_{\rm T}^{\rm PU}\) distributions for \(\langle\mu\rangle\) values of 60, 80 and 140, with pile-up noise threshold variations. For each value of \(\langle\mu\rangle\), the pile-up noise threshold of the different samples was varied by changing the \(\langle\mu\rangle\) for which the threshold is optimized. The \(\langle\mu\rangle\) range of this variation is \(\pm\)20 for \(\langle\mu\rangle\)=60, 80 and \(\pm\)60 for \(\langle\mu\rangle\)=140.

An outline of the method is given in Table 5, which shows also the \(\Sigma E_{\mathrm{T}}\) ranges for the different working points and the fit values.

Figure 7 shows the resolution of the two components of the \(E_{\mathrm{T}}^{\mathrm{miss}}\) vector as a function of \(\Sigma E_{\mathrm{T}}\) for the different physics processes. The parametrisation together with the associated systematic uncertainties are superimposed.

### Validation plots

In Figure 8 the reconstructed \(E_{\mathrm{T}}^{\mathrm{miss}}\) distribution is compared to the parametrisations previously used for inputs to the European Strategy group, and the one described above, including the dominant systematic variations. The current parametrisation is able to describe the scale and the resolution of the reconstructed \(E_{\mathrm{T}}^{\mathrm{miss}}\) distribution more accurately than the previous parametrisation when the pile-up noise threshold is optimized for the \(\langle\mu\rangle\) of interest. The difference is especially relevant at \(\langle\mu\rangle\)=140. In general, the previous European Strategy parametrisation predicts higher tails for \(\langle\mu\rangle\)=140.

### Angular description

The parametrisation described above does not take into account possible intrinsic correlations in the resolution of \(E_{\mathrm{T}}^{\mathrm{miss,reco}}\) and \(E_{\mathrm{T}}^{\mathrm{miss,true}}\) which go beyond the uncorrelated smearing of \(E_{x,y}^{\mathrm{miss}}\). The distribution of \(\Delta\phi(E_{\mathrm{T}}^{\mathrm{miss,reco}},E_{\mathrm{T}}^{\mathrm{miss,true}})\) for the fully simulated \(E_{\mathrm{T}}^{\mathrm{miss}}\) and the result of the different smearing procedures has been studied and is shown in Figure 9. In events with no real \(E_{\mathrm{T}}^{\mathrm{miss}}\), such as min-bias and di-jet, both smearing methods give reasonable agreement with the reconstructed azimuthal angle \(\phi^{\mathrm{miss}}\). In \(Z^{\prime}\) events, especially for \(\langle\mu\rangle\)=140, the parametrisation is in better agreement with the reconstructed case than the previous smearing used in the European Strategy studies.

## 5 b-tagging

The \(b\)-tagging performance for two tagging algorithms - the combined 3D track impact parameter / secondary vertex tagger IP3D+SV1 and the multivariate tagger MV1 [7] has been parametrized as a function of \(\eta\) and \(p_{\mathrm{T}}\) for each jet flavour. The parametrisation has been computed using a simulated sample of \(t\bar{t}\) events having at least one of the two W bosons decaying leptonically. The working point chosen for the taggers corresponds to an average \(b\)-jet efficiency of 70%. Other operating points will be investigated in the future.

\begin{table}
\begin{tabular}{|l|l l|l|} \hline \multicolumn{4}{|c|}{\(E_{\mathrm{T}}^{\mathrm{miss}}\) resolution} \\ \hline \multirow{2}{*}{\(\mu\)} & \multicolumn{2}{c|}{Nominal} & \multirow{2}{*}{Systematic} \\ \cline{2-2} \cline{4-4}  & \(\Sigma E_{\mathrm{T}}\) range & \(\mathrm{Res}(E_{\mathrm{T}}^{\mathrm{miss}})\) & \\ \hline \multirow{3}{*}{140} & \(\Sigma E_{\mathrm{T}}\)\(<\) 1300 GeV & min-bias interp. & \multirow{3}{*}{} \\  & \(1300<\Sigma E_{T}<\) 1700 GeV & Linear interp. min-bias\(\to Z^{\prime}\) & \\  & \(\Sigma E_{\mathrm{T}}\)\(>\) 1700 GeV & \(Z^{\prime}\) fit: \(32.1+0.720\times\sqrt{\Sigma E_{T}}\) & \\ \hline \multirow{3}{*}{80} & \(\Sigma E_{\mathrm{T}}\)\(<\) 900 GeV & min-bias interp. & \multirow{3}{*}{} \\  & \(900<\Sigma E_{T}<\) 1100 GeV & Linear interp. min-bias\(\to Z^{\prime}\) & \\ \cline{1-1}  & \(\Sigma E_{\mathrm{T}}\)\(>\) 1100 GeV & \(Z^{\prime}\) fit: \(24.0+0.679\times\sqrt{\Sigma E_{T}}\) & \\ \hline \multirow{3}{*}{60} & \(\Sigma E_{\mathrm{T}}\)\(<\) 700 GeV & min-bias interp. & \multirow{3}{*}{} \\ \cline{1-1}  & \(700<\Sigma E_{T}<\) 1100 GeV & Linear interp. min-bias\(\to Z^{\prime}\) & \\ \cline{1-1}  & \(\Sigma E_{\mathrm{T}}\)\(>\) 1100 GeV & \(Z^{\prime}\) fit: \(18.7+0.650\times\sqrt{\Sigma E_{T}}\) & \\ \hline \end{tabular}
\end{table}
Table 5: Overview of the simulated samples used to define the parametrisation of the \(E_{\mathrm{T}}^{\mathrm{miss}}\) resolution.

Figure 7: The \(E_{\rm T}^{\rm miss}\) resolution as a function of \(\Sigma E_{\rm T}\) obtained from different physics samples, and compared with the parametrisation. They are all consistent with the nominal value obtained from the parametrisation within the systematic uncertainties (grey band), calculated as specified in Table 5. The three last points of the J3 sample suffer from statistical limitations, which inject instabilities in the fitting procedure.

Figure 8: \(E_{\rm T}^{\rm miss}\) distribution obtained from the parametrisation (blue) and compared to the reconstructed value obtained from full simulation (red) and to the parametrisation used for the European Strategy (green). The closure of the parametrisation is tested in different physics processes: from left to right, minimum bias, di-jet and \(Z^{\prime}\) events. Systematic variations are also included (open markers) and shown to cover the differences between the parametrisation and the reconstructed \(E_{\rm T}^{\rm miss}\).

Figure 9: Distributions of the difference, \(\Delta\phi\), between the true and reconstructed \(\phi\) direction of the \(E_{\mathrm{T}}^{\mathrm{miss}}\) obtained from the parametrisation (blue) and compared to the reconstructed value obtained from full simulation (red) and to the parametrisation used for the European Strategy (green). The closure of the parametrisation is tested in different physics processes: from left to right, minimum bias, di-jet and \(Z^{\prime}\) events.

The \(b\)-tagging performance is expected to degrade in the presence of pile-up due to primary vertex misidentification, contamination from tracks from pile-up events and an increase of fake tracks due to the dense environment. Therefore, the parametrisations were derived for three different \(t\bar{t}\) samples generated with 80, 140, and 200 interactions (\(\mu\)) per bunch crossing, respectively. Figure 10 shows the behavior of the \(b\)-jet, \(c\)-jet and light-flavour jet efficiencies of the MV1 tagger at \(\mu=140\) in the \(p_{\mathrm{T}}\)-\(\eta\) plane.

The performance of the MV1 algorithm is compared to the parametrisation previously used, which was based on the Run 1 ATLAS detector with pile-up of up to 40, in Figure 11. The dotted lines indicate the uncertainty in the interpolation to higher pile-up. As expected, the new tracker has a more uniform performance as a function of \(\eta\). As a result, the selected tagging point with average \(b\)-tag efficiency of 70% has by construction slightly lower efficiency in the central region. However, it has a much lower mistag rate.

The tagging algorithms used to derive the parametrisations were not re-optimized for the new geometry, so one might expect further performance improvement after algorithm tuning. In addition, the possibility of reducing the pile-up performance degradation by adjusting the track selection is currently under study.

Figure 10: \(b\)-jet, \(c\)-jet and light jet \(b\)-tagging efficiencies as function of \(p_{\mathrm{T}}\) and \(|\eta|\) in a sample of \(t\bar{t}\) events.

Figure 11: The parametrasions of \(b\)-jet (left) and light jet (right) tagging efficiencies, as function of \(p_{\rm T}\) for fixed values of \(|\eta|\). The new parametrisations with the Phase-II tracker, ITK, are shown with \(\langle\mu\rangle=80\), 140 and 200. The old European Strategy, ES, parametrisations are shown as a dotted line for comparison.

## 6 Conclusion

Updated parametrisations of the performance for photons, muons, \(E_{\mathrm{T}}^{\mathrm{miss}}\) and \(b\)-tagging have been derived to give the trigger and detector response to generator level objects, based on full simulations of the Phase II ATLAS tracker embedded in the calorimeter and muon spectrometer with high pile-up. These parametrisations in general show an improved performance compared to the results interpolated from lower pile-up with the Run 1 ATLAS detector configuration, which were used in studies presented for the update of the European Strategy for particle physics [3]. They should also be more reliable in predicting the performance. The parametrisations give a good description of the simulated response for a range of processes. As anticipated, the upgraded tracker recovers the performance in the presence of high pile-up, with improved muon momentum resolution and \(b\)-tagging performance. A more complete study of the in-time and out-of-time effects of pile-up on the \(E_{\mathrm{T}}^{\mathrm{miss}}\) reconstruction also shows that the European Strategy assumptions were conservative.

These updated parametrisations have been used for physics studies presented at the ECFA HL-LHC meeting in October 2013.

## References

* [1] ATLAS Collaboration, _Physics at a High-Luminosity LHC with ATLAS_, Tech. Rep. ATL-PHYS-PUB-2012-001, CERN, Geneva, Aug, 2012.
* [2] ATLAS Collaboration, _Physics at a High-Luminosity LHC with ATLAS (Update)_, Tech. Rep. ATL-PHYS-PUB-2012-004, CERN, Geneva, Oct, 2012.
* [3] ATLAS Collaboration, _Performance assumptions for an upgraded ATLAS detector at a High-Luminosity LHC_, Tech. Rep. ATL-PHYS-PUB-2013-004, CERN, Geneva, Mar, 2013.
* [4] ATLAS Collaboration, _Letter of Intent for the Phase-II Upgrade of the ATLAS Experiment_, Tech. Rep. CERN-LHCC-2012-022, CERN, Geneva, Dec, 2012.
* [5] ATLAS Collaboration, _Measurements of Higgs boson production and couplings in diboson final states with the ATLAS detector at the LHC_, Phys. Lett. **B726** (2013), arXiv:1307.1427 [hep-ex].
* [6] ATLAS Collaboration, _Preliminary results on the muon reconstruction efficiency, momentum resolution, and momentum scale in ATLAS 2012 pp collision data_, Tech. Rep. ATLAS-CONF-2013-088, CERN, Geneva, Aug, 2013.
* [7] ATLAS Collaboration, _\(b\)-jet tagging calibration on c-jets containing \(D^{*+}\) mesons_, Tech. Rep. ATLAS-CONF-2012-039, CERN, Geneva, Mar, 2012.