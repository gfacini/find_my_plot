[MISSING_PAGE_EMPTY:1]

## 1 Introduction

Electrons1 are important final state particles in the physics programme of the ATLAS experiment [1] at the Large Hadron Collider (LHC) [2]. Their clean signature in the detector makes them perfect candidates for measurements and searches for new physics Beyond the Standard Model (BSM). However, for this purpose mostly prompt electrons originated from \(W\) and \(Z\) boson, \(\tau\) leptons, or BSM particles are relevant. Other sources of electrons like heavy-flavour quark decays or the conversion of photons are considered as background. Furthermore, light-flavour jets can also mimic the signature of prompt electrons consisting of a track and a cluster of energy deposits in the calorimeter system mostly located in the electromagnetic part. Hence, the ability to further reduce background contributions by identifying the prompt electrons with a high efficiency while distinguishing them from other objects is important for the ATLAS physics programme.

Footnote 1: “Electrons” refers to both electrons and positrons unless otherwise stated.

In this note, an electron identification algorithm using a deep neural network (DNN) is described. Its primary goal is to distinguish prompt electrons from objects mimicking the signature thereof. This includes electrons from photon conversions, electrons from heavy-flavour quark decays, electrons and photons from light-flavour hadron decays, and light-flavour hadrons. The DNN is compared to the current electron identification algorithm used in ATLAS, which is based on a likelihood approach (LH), in terms of performance. Furthermore, the DNN performs multinomial classification which alongside a standard discriminant allows forming different discriminants which can be used to focus more on specific backgrounds without the need of retraining the network.

This note is structured as follows. Section 2 introduces the ATLAS detector, Section 3 describes the datasets used to train and evaluate the algorithms as well as the input classes and input variables, while Section 4 describes the reconstruction and current identification of electrons in the ATLAS experiment. Section 5 introduces the algorithm based on a DNN architecture, whose performance will be compared to that of the LH based algorithm in Section 6. Finally, Section 7 summarizes the results.

## 2 ATLAS detector

The ATLAS experiment at the LHC is a multipurpose particle detector with a forward-backward symmetric cylindrical geometry and a near \(4\pi\) coverage in solid angle.2 It consists of an inner tracking detector surrounded by a thin superconducting solenoid providing a 2 T axial magnetic field, electromagnetic and hadron calorimeters, and a muon spectrometer.

Footnote 2: ATLAS uses a right-handed coordinate system with its origin at the nominal interaction point (IP) in the centre of the detector and the \(z\)-axis along the beam pipe. The \(x\)-axis points from the IP to the centre of the LHC ring, and the \(y\)-axis points upwards. Cylindrical coordinates \((r,\phi)\) are used in the transverse plane, \(\phi\) being the azimuthal angle around the \(z\)-axis. The pseudorapidity is defined in terms of the polar angle \(\theta\) as \(\eta=-\ln\tan(\theta/2)\). Angular distance is measured in units of \(\Delta R\equiv\sqrt{(\Delta\eta)^{2}+(\Delta\phi)^{2}}\).

The inner tracking detector covers the pseudorapidity range \(|\eta|<2.5\). It consists of silicon pixel, silicon microstrip (SCT), and transition radiation tracking (TRT) detectors. The TRT is built of straw drift tubes which are filled with a xenon-based gas mixture. This gas mixture causes highly relativistic charged particles to produce transition radiation which can be used for electron identification. Due to gas leaks, some TRT modules contain an argon-based gas mixture instead. The different gas-mixtures are takeninto account in the simulation. The TRT has a more limited pseudorapidity coverage (\(|\eta|\lesssim 2\)) than the remainder of the inner detector.

Lead/liquid-argon (LAr) sampling calorimeters provide electromagnetic (EM) energy measurements with high granularity. They consist of three layers with varying depth and a presampler. The first layer consists of strips which are finely segmented in \(\eta\), providing discrimination between single photon showers and overlapping photon showers from the decays of neutral hadrons. The second layer has the largest depth with about 17 radiation lengths. The majority of the energy of electrons and photons is deposited in this layer. The third layer serves as an estimate of the leakage beyond the EM calorimeter for highly energetic electrons and photons. A steel/scintillator-tile hadron calorimeter covers the central pseudorapidity range (\(|\eta|<1.7\)). The endcap and forward regions are instrumented with LAr calorimeters for both the EM and hadronic energy measurements up to \(|\eta|=4.9\).

The muon spectrometer surrounds the calorimeters and is based on three large superconducting air-core toroidal magnets with eight coils each. The field integral of the toroids ranges between 2.0 and 6.0 T m across most of the detector.

A two-level trigger system is used to select events. The first-level trigger is implemented in hardware and uses a subset of the detector information to accept events at a rate below 100 kHz. This is followed by a software-based trigger that reduces the accepted event rate to 1 kHz on average depending on the data-taking conditions. An extensive software suite [3] is used in the reconstruction and analysis of real and simulated data, in detector operations, and in the trigger and data acquisition systems of the experiment.

Due to the coverage of the inner detector, only electrons with \(|\eta|<2.47\) are considered in this note. Furthermore, the transition region of the EM calorimeter between barrel and endcap, \(1.37<|\eta|<1.52\), is generally not considered for use in physics analyses due to a reduced performance of the identification and a worse energy resolution in this area. However, both algorithms are still applicable in this region with dedicated tunes and therefore a comparison is performed.

## 3 Samples

### Simulated samples

Signal electrons will be considered from simulated \(Z\to ee\) and \(J/\psi\to ee\) samples, while background will be considered from simulated samples containing two-to-two processes, \(t\bar{t}\) decays, or \(Z\gamma\) decays.

The Powheg Box v1 MC generator [4, 5, 6, 7] was used for the simulation at NLO accuracy of the hard-scattering processes of \(Z\) boson production and decay in the electron channel. It was interfaced to Pythia 8.186 [8] for the modelling of the parton shower, hadronisation, and underlying event, with parameters set according to the AZNLO tune [9]. The CT10NLO PDF set [10] was used for the hard-scattering processes, whereas the CTEQ6L1 PDF set [11] was used for the parton shower. The effect of QED final-state radiation was simulated with Photos++ 3.52 [12, 13]. The EvtGen 1.2.0 program [14] was used to decay bottom and charm hadrons. \(J/\psi\to ee\) samples were generated using Pythia 8.186. The A14 [15] set of tuned parameters was used with the CTEQ6L1 PDF set. The \(J/\psi\) in this sample are produced promptly.

Two-to-two processes were simulated using Pythia 8.186 with the A14 set of tuned parameters and the NNPDF2.3LO [16] PDF set to obtain backgrounds mimicking the signature of prompt electrons. The simulated processes include multijet production, \(qg\to q\gamma\), \(q\bar{q}\to g\gamma\), \(W\) and \(Z\) boson production, and top quark production. No restrictions are placed on the decays of the bosons. To enrich the sample in electron backgrounds, only events where the sum of transverse energy of particles of the hard scatter (excluding muons and neutrinos) in a \(\Delta\eta\times\Delta\phi\) window of \(0.1\times 0.1\) exceeds 17 GeV are selected. This high localised energy deposit mimics the signature of prompt electrons. For the remainder of this note, this sample will be referred to as JF17.

The production of \(t\bar{t}\) events was modelled using the Powheg Box v2[6] generator at NLO with the NNPDF3.0NLO [17] PDF set and the \(h_{\text{damp}}\) parameter3 set to 1.5 \(m_{\text{top}}\)[18]. The events were interfaced to Pythia 8.230 [19] to model the parton shower, hadronisation, and underlying event, with parameters set according to the A14 tune and using the NNPDF2.3LO set of PDFs. The decays of bottom and charm hadrons were performed by EvtGen 1.6.0. During the simulation, at least one of the \(W\) bosons originating from a top quark is required to decay leptonically. The production of the \(Z\gamma\) final state with the \(Z\) boson decaying into two electrons was simulated with the Sherpa 2.2.4 [20] generator. Matrix elements at LO accuracy in QCD for up to three additional parton emissions were matched and merged with the Sherpa parton shower based on Catani-Seymour dipole factorisation [21; 22] using the MEPS@LO prescription [23; 24; 25; 26]. Samples were generated using the NNPDF3.0NNLO PDF set, along with the dedicated set of tuned parton-shower parameters developed by the Sherpa authors.

Footnote 3: The \(h_{\text{damp}}\) parameter is a resummation damping factor and one of the parameters that controls the matching of Powheg matrix elements to the parton shower and thus effectively regulates the high-\(p_{\text{T}}\) radiation against which the \(t\bar{t}\) system recoils.

The effect of multiple interactions in the same and neighbouring bunch crossings (pile-up) was modelled by overlaying the simulated hard-scattering event with inelastic proton-proton (\(pp\)) events generated with Pythia 8.186 using the NNPDF2.3LO set of parton distribution functions (PDF) and the A3 set of tuned parameters [27]. The distribution of average interactions per bunch crossing follows the distribution of data recorded in 2018 at the ATLAS detector.

All particles are processed with the ATLAS detector simulation [28] based on Geant4[29].

### Classes

Different types of particles with different origins at MC truth level can mimic the signature of prompt electrons and therefore be reconstructed as one. The rejection power of any identification algorithm will vary greatly between these. Table 1 lists all classes used throughout this note, their definitions, and the samples used to obtain candidates belonging to the different classes. Prompt electrons and charge flip electrons are only taken from the \(Z\to ee\) and \(J/\psi\to ee\) sample. The other four classes are all obtained from the JF17 sample. Due to low statistics of some of these classes in the JF17 sample, additional electrons from heavy-flavour quark decays are obtained from the \(t\bar{t}\) sample, whereas additional electrons from photon conversions are obtained from the \(t\bar{t}\) and the \(Z\gamma\) sample. The selection of the candidates is based purely on simulation information.

Throughout the note, "Signal" only refers to the prompt electron class. Charge flip electrons are prompt electrons, but the reconstructed charge does not correspond to the true charge. Depending on the physics analysis, these can either be considered as signal or background. Especially, physics analyses with a final state consisting of two leptons with the same charge should reject charge flip electrons to reduce the contribution of events containing a Drell-Yan process leading to two leptons with opposite charges. Reconstructing one of these charges wrong can lead to a contribution to the background due to the higher cross-section of the Drell-Yan process. Rejecting charge flip electrons can reduce this type of background.

For physics analyses with just one lepton in the final state that are independent of the charge of the lepton, accepting charge flip electrons will increase the amount of selected signal events. The other four classes, electrons from photon conversions, electrons from heavy-flavour quark decays, electrons or photons from light-flavour hadron decays, and light-flavour hadrons, are all considered background. Due to the differences in rejection power, the rejection against the single background classes will be shown as well as the rejection against the combined background consisting of the four aforementioned classes.

## 4 Electron reconstruction and identification

A detailed description of the reconstruction and identification of electrons can be found in Refs. [30] and [31], respectively.

\begin{table}
\begin{tabular}{|c|l|c|c|} \hline Class & Description & Label & Sample \\ \hline \multirow{6}{*}{Prompt Electrons} & Prompt isolated electrons, e.g. electrons from & & \\  & \(Z\to ee\), \(W\to ev\), \(J/\psi\to ee\) decays with the & & \\  & \(J/\psi\) being produced in the hard scatter. Electrons & & \\  & from a final state radiation photon or & & \\  & bremsstrahlung are also considered here if the & & \\  & origin is a prompt electron. Furthermore, the & & \\  & reconstructed charge is the same as the true charge. & & \\ \hline \multirow{6}{*}{Charge Flip} & Same as prompt electrons, but the reconstructed & & \\  & charge is the opposite of the true charge. In case & & \\ \cline{1-1}  & of an electron originating from bremsstrahlung, & & \\ \cline{1-1}  & the charge of the original prompt electron is & & \\ \cline{1-1}  & considered the true charge. & & \\ \hline \multirow{6}{*}{Photon Conversion} & Electrons from prompt photons which convert & & \\ \cline{1-1}  & into an \(e^{+}e^{-}\) pair. Prompt photons which are & & \\ \cline{1-1}  & reconstructed as an electron are also considered & & \\ \cline{1-1}  & for this class. & & \\ \hline \multirow{6}{*}{Heavy-Flavour} & Electrons coming from a decay of a \(b-\) or \(c-\) & & \\ \cline{1-1}  & hadron. Prompt quarkonium decays such as & & \\ \cline{1-1}  & \(J/\psi\to ee\) where the \(J/\psi\) is produced in the hard & & \\ \cline{1-1}  & scatter event are not included here but rather as & & \\ \cline{1-1}  & prompt electrons. & & \\ \hline \multirow{6}{*}{Light-Flavour \(e/\gamma\)} & Electrons and photons from a decay of a \(u-\), \(d-\), & & \\ \cline{1-1}  & or \(s-\) hadron. This also includes for instance & & \\ \cline{1-1}  & electrons from intermediate photon conversions: & & \\ \cline{1-1}  & \(\pi^{0}\rightarrow\gamma\gamma\) with \(\gamma\to ee\). & & \\ \hline Light-Flavour Hadrons & Undecayed hadrons & LFH & & \\ \hline \end{tabular}
\end{table}
Table 1: Different classes used for electron candidates throughout the note based on truth information of the simulation. A short description, the label used in figures or equations, and the samples used to obtain the respective class are given as well.

### Reconstruction

Electrons are reconstructed from a cluster of energy deposits in the calorimeter system and a track. The clusters are built using the topo-cluster reconstruction algorithm [32, 33]. To reduce the amount of topo-clusters reconstructed from pile-up, only clusters with at least half of their energy deposited in the electromagnetic calorimeter are considered for the electron reconstruction. These topo-clusters are matched to tracks in the inner detector. The tracks are re-fitted to account for bremsstrahlung [34]. To also capture possible energy deposits from bremsstrahlung, super-clusters are formed which can contain multiple topo-clusters.

### Variables used by the DNN

Table 2 shows all variables included in the DNN. They contain information of the tracking system, the calorimeters, and the matching of the track to the cluster of energy deposits in the calorimeters and are chosen to separate electrons from the various background components. The chosen variables differ slightly from the ones used for the LH [31]. For instance, the transverse energy \(E_{\mathrm{T}}\) and \(|\eta|\) are used as an input to the network to parametrise the DNN whereas these quantities cannot be used in the LH directly. However, these are used indirectly by deriving different LH algorithms in bins of \(E_{\mathrm{T}}\) and \(|\eta|\). Another change in the variables is that the DNN can use correlated inputs whereas for the LH all inputs should ideally be uncorrelated as the LH is built as a product of one-dimensional probability density functions (PDF). Therefore, \(R_{\mathrm{had}}\) and \(R_{\mathrm{had1}}\) which are heavily correlated can be used as an input to the network over the whole \(|\eta|\) range whereas the LH only uses one of them depending on the \(|\eta|\) value of the candidate. This choice of the LH also depends on the geometry of the detector. In regions where there is no first layer of the hadronic calorimeter \(R_{\mathrm{had}}\) is used, whereas in the remainder of the detector \(R_{\mathrm{had1}}\) is used since it has less noise. The final decision whether an electron candidate passes a working point is not only based on the output of the DNN. Additional requirements are placed on the number of hits in different parts of the tracking detector as well as the ambiguity type. These additional requirements are the same as the ones used for the LH. The variables used for these requirements are also listed in Table 2 and marked with a "C" in the "Usage" column.

#### 4.2.1 Correction factors

Since some variables used as input for electron identification and therefore the DNN are not well described by the simulations, corrections are applied to these variables in simulated data. A detailed description of these corrections can be found in Ref. [31]. They are affine transformations applied to each simulated quantity separately. Electron candidates selected with a \(Z\to ee\) tag-and-probe selection in simulation and data are used to obtain the parameters of the affine transformation. The \(\chi^{2}\) between simulation and data is minimised to acquire the best set of parameters. Different transformations are applied depending on \(E_{\mathrm{T}}\) and \(|\eta|\). They are applied such that the training dataset obtained from simulation resembles data as closely as possible.

\begin{table}
\begin{tabular}{|l|l|c|c|} \hline Type & Description & Name & Usage \\ \hline Hadronic & Ratio of \(E_{\rm T}\) in the first layer of the hadronic calorimeter & \(R_{\rm had1}\) & DNN \\ leakage & to \(E_{\rm T}\) of the EM cluster & & \\ \cline{2-3}  & Ratio of \(E_{\rm T}\) in the hadronic calorimeter to \(E_{\rm T}\) of the EM cluster & \(R_{\rm had}\) & DNN \\ \hline Third layer of & Ratio of the energy in the third layer to the total energy in the & \\ EM calorimeter & EM calorimeter. Due to known mismodelling at high \(|\eta|\), this & \(f_{3}\) & DNN \\  & variable is set to a default value for candidates with \(|\eta|>2.01\) & \\ \hline Second layer of & Lateral shower width, \(\sqrt{(\Sigma E_{i}\eta_{i}^{2})/(\Sigma E_{i})-((\Sigma E_{i}\eta_{i})/( \Sigma E_{i}))^{2}}\), & \\ EM calorimeter & where \(E_{i}\) is the energy and \(\eta_{i}\) is the pseudorapidity & \(w_{\eta 2}\) & DNN \\  & of cell \(i\) and the sum is calculated within a window of 3\(\times\)5 cells & \\ \cline{2-3}  & Ratio of the energy in 3\(\times\)3 cells over the energy in 3\(\times\)7 cells & \(R_{\phi}\) & DNN \\  & centred at the electron cluster position & \\  & Ratio of the energy in 3\(\times\)7 cells over the energy in 7\(\times\)7 cells & \(R_{\eta}\) & DNN \\  & centred at the electron cluster position & \\ \hline First layer of & Shower width, \(\sqrt{(\Sigma E_{i}(i-i_{\rm max})^{2})/(\Sigma E_{i})}\), where \(i\) runs over & \\ EM calorimeter & all strips in a window of \(\Delta\eta\times\Delta\phi\approx 0.0625\times 0.2\), & \(w_{\rm 3tot}\) & DNN \\  & corresponding typically to 20 strips in \(\eta\), and \(i_{\rm max}\) is the & \\  & index of the highest-energy strip & \\ \cline{2-3}  & Ratio of the energy difference between the maximum & \\  & energy deposit and the energy deposit in a secondary & \(E_{\rm ratio}\) & DNN \\  & maximum in the cluster to the sum of these energies & \\  & Ratio of the energy in the first layer to the total energy & \(f_{1}\) & DNN \\  & in the EM calorimeter & \\ \hline Track & Number of hits in the innermost pixel layer & \(n_{\rm Bayer}\) & C \\ \cline{2-3} conditions & Number of hits in the pixel detector & \(n_{\rm pixel}\) & DNN/C \\ \cline{2-3}  & Total number of hits in the pixel and SCT detectors & \(n_{\rm Si}\) & DNN/C \\ \cline{2-3}  & Transverse impact parameter relative to the beam-line & \(d_{0}\) & DNN \\  & Significance of transverse impact parameter & \(|d_{0}/\sigma(d_{0})|\) & DNN \\  & defined as the ratio of \(d_{0}\) to its uncertainty & \\  & Momentum lost by the track between the perigee and the last & \(\Delta p/p\) & DNN \\  & measurement point divided by the momentum at perigee & \\ \hline TRT & Likelihood probability based on transition radiation in the TRT. & \\  & This variable is set to a default value for candidates with \(|\eta|>2.01\) & eProbabilityHT & DNN \\  & due to the limited coverage of the TRT. & \\ \hline Track–cluster & \(\Delta\eta\) between the cluster position in the first layer & \(\Delta\eta_{1}\) & DNN \\ matching & and the extrapolated track & \\ \cline{2-3}  & \(\Delta\phi\) between the cluster position in the second layer & \\  & of the EM calorimeter and the momentum-rescaled & \(\Delta\phi_{\rm res}\) & DNN \\  & track, extrapolated from the perigee, times the charge \(q\) & \\  & Ratio of the cluster energy to the track momentum & \(E/p\) & DNN \\ \hline Kinematics & Transverse energy of the electron measured by the calorimeter system. & \\  & This variable is not used for discrimination purposes but to give the & \\  & DNN additional information. & \\  & Absolute value of the pseudorapidity of the electron as & \\  & measured by the calorimeter system. This variable is not used for & \\  & discrimination purposes but to give the DNN additional information. & \\ \hline Reconstruction & Output of an ambiguity resolution algorithm to distinguish & Ambiguity type & C \\  & objects that are reconstructed as both electrons and photons [30]. & \\ \hline \end{tabular}
\end{table}
Table 2: Type and description of the quantities used in the electron identification based on the DNN. In the column labelled “Usage,” a “DNN” indicates that the quantity is used as an input to the DNN and a “C” indicates that this quantity is used as an additional selection criterion. If the quantity is used as an input to the DNN and as an additional selection criterion, it is denoted by “DNN/C”. In the description of the quantities formed using the second layer of the calorimeter, 3\(\times\)3, 3\(\times\)5, 3\(\times\)7, and 7\(\times\)7 refer to areas of \(\Delta\eta\times\Delta\phi\) space in units of \(0.025\times 0.025\). Adapted from Ref. [31].

### Likelihood identification

The current identification algorithm for electrons uses a likelihood approach. One-dimensional probability PDFs are formed for all input variables without taking correlations into account, separately for signal and background. The PDFs of the single variables are multiplied to get a likelihood of being signal or background, \(L_{\mathrm{S}}\) or \(L_{\mathrm{B}}\).

\[L_{\mathrm{S(B)}}(\mathbf{x})=\prod_{i}P_{\mathrm{S(B)},i}(x_{i})\]

where \(P_{\mathrm{S(B)},i}(x_{i})\) is the PDF of the \(i\)-th input variable. From these likelihoods, a discriminant \(d_{L}\) is formed which is used to select electrons by applying a cut on the discriminant.

\[d_{\mathrm{L}}=\frac{L_{\mathrm{S}}}{L_{\mathrm{S}}+L_{\mathrm{B}}}\]

To account for differences in the variables with respect to the kinematics of the candidate, different PDFs are formed in bins of \(E_{\mathrm{T}}\) and \(|\eta|\). The selection on the discriminant also varies with \(E_{\mathrm{T}}\) and \(|\eta|\) to achieve the desired signal efficiency over the whole phase space. To avoid large changes in signal efficiency across \(E_{\mathrm{T}}\) due to these different selections, the cut value on the discriminant is interpolated along \(E_{\mathrm{T}}\). The final selection is not only based on the discriminant, but additional requirements need to be passed. These are the same as for the DNN. To fulfil the needs of many different analyses, different working points, with different requirements on the discriminant and the additional variables, are used. In this note, the Loose, Medium, and Tight working point will be compared to the neural network introduced in the next section. The Loose working point has the highest signal efficiency and lowest background rejection, whereas the Tight working point has the lowest signal efficiency but highest background rejection. To more accurately describe the collected data, the latest version of the LH uses data enriched in prompt electrons or background electrons to obtain the PDFs. For the signal PDFs, electron candidates are collected using a \(Z\to ee\) or \(J/\psi\to ee\) tag-and-probe selection, whereas the background candidates are selected based on prescaled single electron triggers. Vetoes targeting \(W\to e\nu\) and \(Z\to ee\) decays are applied. The resulting sample will be dominated by dijet events. Additional corrections are applied to the final discriminant of the LH to maintain a constant background rejection with respect to pile-up.

## 5 Deep neural network

The LH approach described in Section 4.3 by design is only optimal for input data without correlations by using one dimensional PDFs, while the DNN can also account for correlations between inputs. This could lead to a more performant algorithm even when training on the exact same information. This section will describe the training procedure of this DNN.

The training data is taken from the datasets described in Section 3. All described samples are used for the training of the neural network. For the evaluation, only the \(Z\to ee\), \(J/\psi\to ee\), and JF17 samples are used. The selection for all datasets is based purely on simulation by selecting specific classes for the single samples as shown in Table 1. The variables of all candidates are transformed using the corrections described in Section 4.2.1.

### Downsampling and reweighting

In Figure 1(a), the distribution of \(E_{\mathrm{T}}\) of the different classes after the simulation-based selection can be seen. At around 45 GeV, there is a clear peak for prompt electrons arising from electrons from a \(Z\to ee\) decay. If this data was to be used to train the network while using \(E_{\mathrm{T}}\) as an input variable, the score of the network would be heavily biased with regard to \(E_{\mathrm{T}}\). Since the network should not base the score directly on \(E_{\mathrm{T}}\) or \(|\eta|\) but only use it as information how the other variables change, the input distribution of \(E_{\mathrm{T}}\) and \(|\eta|\) should be the same for all classes during the training. Therefore, a mixture of downsampling of the prompt electrons and reweighting of all candidates in the training dataset is applied.

First, only part of the prompt electrons are kept based on how many background candidates there are with respect to prompt electrons in bins of \(E_{\mathrm{T}}\). The choice of which electrons are removed is based on random numbers. This removes prompt electrons around 45 GeV as can be seen in Figure 1(b). This is done to reduce the range of weights needed to match the distributions of the different classes as it was seen that too large ranges of weights have a negative impact on the performance and convergence of the DNN. No downsampling is applied to the charge flip electrons. The peak is not as pronounced as for the prompt electrons and the overall statistics is lower such that downsampling would affect the performance more. After the downsampling, the distributions are separately reweighted in \(E_{\mathrm{T}}\) and \(|\eta|\), multiplying the two weights together for a final weight. During this step, the sum of weights is unchanged for the separate classes. The result of the reweighting in \(E_{\mathrm{T}}\) can be seen in Figure 1(c), whereas for \(\eta\) it is shown in Figure 1(d). The target shape in \(|\eta|\) is flat whereas for \(E_{\mathrm{T}}\) a flat distribution until 15 GeV and a distribution following the shape of the light-flavour jet class in the \(t\bar{t}\) dataset is chosen. This shape reduces the bias of the score with respect to \(E_{\mathrm{T}}\) and \(|\eta|\) considerably without reducing the performance of the DNN. Since two separate weights are retrieved for \(E_{\mathrm{T}}\) and \(|\eta|\) which are then multiplied, slight differences in the reweighted distributions can appear due to correlations between \(E_{\mathrm{T}}\) and \(|\eta|\). A two-dimensional reweighting approach to mitigate these differences would suffer from the low statistics of some classes.

An additional weight is applied before the training procedure to reduce any bias from the different amount of candidates of the different classes. Each class is assigned one weight which is multiplied with the weight obtained from the reweighting such that all classes have overall the same sum of weights. This additional weight is not applied in Figures 1(c) and 1(d) so that the distribution of all classes is visible.

### Transformation

Before passing the variables to the network, they are further transformed using a modified version of the QuantileTransformer implemented in Scikit-learn[35]. The modification is needed to accomodate the weights derived in the previous section. This transformation is based on the quantiles of the original distributions and maps these between zero and one such that the summed output distribution of the six classes follows a flat distribution. It is obtained using the combined distribution of all six classes. Instead of using the original distribution to obtain the quantiles, the weighted distributions described in Section 5.1 are used. As an example, Figure 2 shows the distribution of \(R_{\mathrm{had}}\) before and after this transformation. The full distribution as well as only the prompt electrons and the light-flavour hadrons are shown. As can be seen, the transformed distribution of the full dataset is a rectangular distribution between zero and one while maintaining the overall relation between the classes due to the monotonic nature of the transformation.

### Architecture and training

The DNN is trained using TensorFlow[36]. An overview of the architecture can be seen in Figure 3. It consists of five hidden layers with 256 nodes each, and one output layer with six outputs, one for each of the classes. After each of the hidden layers a leakyrelu activation function followed by a batch normalisation layer [37] is placed. The six outputs of the final layer are passed through a softmax activation function such that the sum of the outputs is equal to one. The training was performed using the Adam optimiser [38] with a cyclical learning rate following a triangular pattern [39]. While testing different architectures, this one led to the best performance on a statistically independent validation dataset. The training procedure of each model is stopped once the validation loss does not improve after one cycle of the learning rate, and the model with the lowest validation loss is chosen as the final model. The lwtnn package [40] is used to interface it within the ATLAS analysis framework [3].

Figure 1: \(E_{\mathrm{T}}\) distribution of the different classes in the training dataset after (a) selection, (b) downsampling, and (c) the kinematic reweighting and (d) \(\eta\) distribution after the kinematic reweighting. The weights making all classes equiprobable are not applied.

### Multinomial classification

Some input variables vary significantly between the classes described in Table 1. For instance, the impact parameter \(d_{0}\) has a wider distribution for electrons from heavy-flavour quark decays than for instance light-flavour hadrons, due to the long lifetime of hadrons containing \(b-\) or \(c-\) quarks. Therefore, the DNN performs a multinomial classification, meaning it not only predicts the probability of the candidate being a prompt electron but of the six classes. This allows the network to better exploit differences between the

Figure 3: Schematic overview of the architecture of the DNN. The amount of layers and number of nodes shown correspond to the final optimised architecture

Figure 2: Distribution of \(R_{\text{had}}\) in the training dataset for all candidates, only prompt electrons, and only light-flavour hadrons (a) before and (b) after the transformation of the QuantileTransformer. The distributions are shown with the previously described downsampling and reweighting applied. Only two of the six classes are shown to reduce the number of histograms shown in the figure.

classes and can lead to a better performance than a binary classifier.

However, in the end a binary decision of being identified as a prompt electron or not is required since physics analyses are only interested if an object was a true electron or some background that should be removed. According to the Neyman-Pearson lemma [41], the most powerful binary test statistic is obtained by a likelihood ratio. Therefore, the discriminant \(\mathcal{D}_{\mathrm{el}}\) combining the model outputs is formed by

\[\mathcal{D}_{\mathrm{el}}=\ln\left(\frac{f_{\mathrm{El}}p_{\mathrm{El}}+(1-f_{ \mathrm{El}})p_{\mathrm{CF}}}{f_{\mathrm{PC}}p_{\mathrm{PC}}+f_{\mathrm{HF}}p_ {\mathrm{HF}}+f_{\mathrm{LFEg}}p_{\mathrm{LFEg}}+(1-f_{\mathrm{PC}}-f_{ \mathrm{HF}}-f_{\mathrm{LFEg}})p_{\mathrm{LFH}}}\right) \tag{1}\]

where the \(f_{\mathrm{X}}\) are free parameters and the \(p_{\mathrm{X}}\) are the outputs of the network. During the training, the classes have the same sum of weights removing biases towards specific classes due to different statistics seen during the training. Therefore, the \(f_{\mathrm{X}}\) can be interpreted as importance of the specific background class. Both, the prompt electron and charge flip electron output are placed in the numerator as they are considered signal for the most generic electron identification.

The choice of the values of the \(f_{\mathrm{X}}\) has a significant influence on the behaviour of the discriminant. For the background classes, increasing the value will lead to a higher emphasis on this output, leading to a higher rejection of the corresponding class, while sacrificing rejection power of the other classes. A short demonstration of this added versatility can be seen in Section 6.3. In the numerator as well as the denominator, the sum of all \(f_{\mathrm{X}}\) are required to sum to one to reduce the number of degrees of freedom while optimising the values. This also allows the numerator and the denominator to be interpreted as probability of being signal and background, respectively. One disadvantage of using such a multinomial model is the inability to use only data for the training since it is not possible to construct pure enough selections for all classes.

## 6 Results

### Performance

A statistically independent dataset of simulated electron candidates that was not used at any point in the training process is used to evaluate the DNN performance. To evaluate the performance, the additional background candidates from the \(t\bar{t}\) sample and the \(Z\gamma\) sample are not used. Therefore, all background candidates are from the JF17 sample. This sample does not perfectly represent the expected performance in data since it is not a fully physical sample. Especially for \(E_{\mathrm{T}}<17\)\(\mathrm{GeV}\) differences can appear due to the filter requirement of the sample. However, for higher values of \(E_{\mathrm{T}}\), the composition should be similar to the expected composition of background in data and represents a fair comparison between the two methods across the whole \(E_{\mathrm{T}}\) range. The LH is optimised on data whereas the DNN is optimised on simulated samples. Therefore, the improvement in performance when evaluating on collision data can be expected to differ from what is observed with simulated data. This dataset has the corrections to simulated data described in Section 4.2.1 applied to best represent the expected performance in data. No downsampling or reweighting as described in Section 5.1 is applied. The composition of the background in the dataset, is shown in Table 3. Both, the inclusive composition and the one for candidates with \(15\mathrm{\,GeV}<E_{\mathrm{T}}\leq 20\mathrm{\,GeV}\) and \(0.0<|\eta|\leq 0.8\) are shown.

The \(f_{\mathrm{X}}\) used to form the discriminant in Eq. 1 are optimised to give the best inclusive background rejection for signal efficiencies between 70% and 95% by maximising the area under the Receiver OperatingCharacteristic (ROC) curve in the given signal efficiency range. This range of signal efficiencies covers most of the working points used for the LH. Since the composition of the candidates changes with respect to the pseudorapidity, the \(f_{\mathrm{X}}\) are optimised in bins of \(|\eta|\). Even though the composition can also change with \(E_{\mathrm{T}}\), the \(f_{\mathrm{X}}\) are kept the same along \(E_{\mathrm{T}}\) to have a smooth distribution of the final discriminant along \(E_{\mathrm{T}}\). To achieve the same signal efficiencies as the LH working points over the whole phase space, different requirements are placed on the discriminant in bins of \(E_{\mathrm{T}}\) and \(|\eta|\). The bins used for the working point definitions and the optimisation of the \(f_{\mathrm{X}}\) can be seen in Tables 4 and 5. The binning for the optimisation is chosen coarser to have sufficient statistics of all background classes.

In Figure 4, the final discriminant \(\mathcal{D}_{\mathrm{el}}\) defined by Eq. 1 can be seen for the different classes in one (\(E_{\mathrm{T}},|\eta|\)) bin. Clear separation of the prompt electrons from the remaining classes can be seen. Both the distribution of charge flip electrons and electrons from heavy-flavour quark decays have a non-negligible overlap with the distribution of prompt electrons. Since these are genuine electrons in the detector a similar output of the DNN can be expected. Especially for electrons from heavy-flavour quark decays with a short decay time of the heavy-flavour hadron, the signature will be very similar to that of actual prompt electrons. Electrons from photon conversions appear in a separate peak to the signal. The clearest separation from the signal can be found for electrons or photons from light-flavour hadrons and hadronic background with the latter having lower scores on average. Candidates of these two classes are the most different from prompt electrons due to their increased hadronic activity. Figure 4(c) shows the discriminant for the prompt electrons and the background, combining electrons from photon conversions, electrons from heavy-flavour quark decays, \(e/\gamma\) objects from light-flavour hadrons, and light-flavour hadrons. No weights are applied, so the composition is as shown in Table 3.

To evaluate the performance of the DNN in comparison to the LH, ROC curves are used. Scanning

\begin{table}
\begin{tabular}{l|c c c c c c c c c c} \hline \hline  & \multicolumn{8}{c}{Bin boundaries in \(|\eta|\)} & \\ \hline Discriminant cuts & 0.0 & 0.1 & 0.6 & 0.8 & 1.15 & 1.37 & 1.52 & 1.81 & 2.01 & 2.37 & 2.47 \\ \(f_{\mathrm{X}}\) optimisation & 0.0 & & 0.8 & 1.37 & 1.52 & & 2.01 & & 2.47 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Binning in \(|\eta|\) chosen for different cut values on the discriminant and the optimisation of the \(f_{\mathrm{X}}\) comprising the discriminant.

\begin{table}
\begin{tabular}{l|c c} \hline \hline  & Inclusive & \(15<E_{\mathrm{T}}\) [GeV] \(\leq\) 20 \\  & & \(0.0<|\eta|\leq 0.8\) \\ \hline Fraction of Photon Conversions [\%] & \(0.142\pm 0.001\) & \(0.30\pm 0.01\) \\ Fraction of Heavy-Flavour [\%] & \(0.528\pm 0.002\) & \(1.24\pm 0.02\) \\ Fraction of Light-Flavour \(e/\gamma\) [\%] & \(24.12\pm 0.01\) & \(18.59\pm 0.08\) \\ Fraction of Light-Flavour Hadrons [\%] & \(75.21\pm 0.01\) & \(79.87\pm 0.08\) \\ \hline \hline \end{tabular}
\end{table}
Table 3: Composition of the background in the dataset used to evaluate the performance.

\begin{table}
\begin{tabular}{l c c c c c c c c c} \hline \hline  & \multicolumn{8}{c}{Bin boundaries in \(E_{\mathrm{T}}\) [GeV]} \\ \hline
4 & 7 & 10 & 15 & 20 & 25 & 30 & 35 & 40 & 45 & \(\infty\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Binning in \(E_{\mathrm{T}}\) chosen for different cut values on the discriminant the discriminant at different values \(\tau\), the signal efficiency and the background rejection are calculated. The signal efficiency is defined as the number of signal electrons with \(\mathcal{D}_{el}>\tau\) divided by the number of total signal electrons while the background rejection is defined as the number of total background electrons divided by the number of background electrons with \(\mathcal{D}_{el}>\tau\) where background electrons contain electrons from photon conversions, electrons from heavy-flavour quark decays, \(e/\gamma\) objects from light-flavour hadrons, and light-flavour hadrons.

Figure 5 shows the ROC curve in one (\(E_{\mathrm{T}},|\eta|\)) bin for the combined background and for the single background classes separately. For the LH, only the working points, opposed to a continuous discriminant, are shown as markers at the corresponding signal efficiency and background rejection. Since the LH working points are not only based on the discriminant obtained from the PDFs but also includes rectangular

Figure 4: Final discriminant \(\mathcal{D}_{\mathrm{el}}\) of the DNN for (a) prompt electrons, charge flip electrons, electrons from photon conversions, and electrons from heavy-flavour quark decays, (b) prompt electrons, \(e/\gamma\) objects from light-flavour decays, and light-flavour hadrons, (c) prompt electrons and the combined background consisting of all classes except prompt electrons and charge flip electrons. Only electron candidates satisfying \(15<E_{\mathrm{T}}\) [GeV] \(\leq 20\) and \(|\eta|\leq 0.8\) are shown.

cuts, the same cuts are applied for the DNN as a prerequirement. These requirements are different for the three different working points, Loose, Medium, and Tight. Therefore, the plot showing the performance on the combined background shows three ROC curves each applying one of the different requirements. The ROC curve and the matching LH working point are drawn in the same colour. Since the statistics of the single backgrounds become low at the signal efficiencies of interest and therefore the statistical uncertainties on the background rejection are large for some classes, only the curve matching the Tight working point requirements is drawn.

To have a good visualisation of the performance with respect to charge flip electrons, they are not included in the signal for Figure 5. Instead, a ROC curve with the charge flip electrons defined as background is shown in Figure 5(b). Some of the curves follow a step like pattern caused by low remaining background statistics.

The DNN has a higher background rejection for the combined background as can be seen in Figure 5(a). The background rejection is increased by a factor of two at the signal efficiency of the Tight LH working point compared to the LH. For higher signal efficiencies, the improvement is larger. In Figure 5(b), the charge flip rejection is shown. Since charge flip electrons are still prompt electrons but reconstructed with the wrong charge, they are considered as signal and should therefore not be rejected. The DNN has compared to the LH a higher rejection of charge flip electrons and thus accepts less of these. However, due to the much higher amount of prompt electrons expected in data, the signal efficiency when considering both as signal would not be effected. Figures 5(c)-5(f), show the rejection of the single background classes. For all classes the DNN has a higher rejection than the LH, but the increase in background rejection varies considerably. While the increase for electrons from photon conversions and electrons or photons objects in light-flavour hadrons is relatively small, the rejection of light-flavour hadrons is increased by a factor larger than four. For the combined background, the different requirements on tracking variables and ambiguity type for the three working points result in a negligible difference if rejection as can be seen from the ROC curves. However, for single background classes larger differences can appear.

Figure 5: ROC curves for (a) the combined background, (b) only charge flip electrons, (c) only electrons from photon conversions, (d) only electrons from heavy-flavour quark decays, (e) only electrons and photons from light-flavour hadrons, and (f) only light-flavour hadrons. Only candidates with \(15<E_{\rm T}\) [GeV] \(\leq 20\) and \(|\eta|\leq 0.8\) are shown. Statistical uncertainties of the background rejection are shown as bands.

[MISSING_PAGE_EMPTY:17]

the LH, though an improvement can still be seen across the whole phase space. The largest improvement in \(|\eta|\) can be seen in the transition region of the calorimeter from barrel to endcap, \(1.37<|\eta|<1.52\), which is generally not considered in physics analyses. Disregarding this region, an improvement between a factor of 1.7 and 2.5 can be seen. The signal efficiency of both algorithms drops with increasing pile-up, but a larger drop can be observed for the DNN. However, the rejection of the DNN also rises with increasing pile-up, whereas the one of the LH stays constant. This behaviour of the LH is enforced by modifying the LH discriminant based on the number of reconstructed primary vertices in the event [31], whereas the DNN does not have any information about pile-up during training or the application of a cut.

Figure 7: Performance plots matching the DNN signal efficiency to that of the Tight LH working point. Plots (a), (b), and (c) show the background rejection with respect to \(E_{\mathrm{T}}\), \(|\eta|\), and average interactions per bunch-crossing \(\langle\mu\rangle\). Plot (d) shows the signal efficiency with respect to \(\langle\mu\rangle\). The ratio is shown with respect to the LH working point. The signal efficiencies with respect to \(E_{\mathrm{T}}\) and \(|\eta|\) are not shown since they are the same by design.

### Comparison of selected electrons

Due to their clean signature, electrons are often used as a trigger requirement. To reduce the rate of selected events with reconstructed electron candidates, an identification algorithm is applied at trigger level as well. This algorithm was based on the same LH approach used for the identification after the full reconstruction during data taking from 2015 to 2018. This ensures the online and offline identification select the same candidates and inefficiencies are kept to a minimum.

In Figures 8 and 9, a comparison of the selected electrons between the offline LH and the DNN are shown for the Loose and Tight working points. Figure 8 shows prompt electrons while Figure 9 shows the inclusive background. Most of the prompt electrons are accepted or rejected in the same way by both algorithms, LH and DNN. However, there is a considerable amount of prompt electrons selected by only one of the algorithms and not the other. For the Loose working point these are \((5.72\pm 0.02)\%\) of prompt electrons, while for the Tight working point these are \((9.67\pm 0.03)\%\) of prompt electrons. For the background, the improved rejection of the DNN can be seen again. Most of the background candidates selected by the DNN also get selected by the LH. For the Loose working point, the DNN selects \((0.069\pm 0.005)\%\) of background candidates not selected by the LH, whereas the LH selects \((0.60\pm 0.02)\%\) not selected by the DNN. For the Tight working point, these numbers are \((0.042\pm 0.004)\%\) and \((0.19\pm 0.01)\%\), respectively.

### Added flexibility of multinomial classification

One of the advantages of the multinomial classification is the flexibility of defining different discriminants by changing the values of the \(f_{\mathrm{X}}\) or even which output is placed in the numerator and the denominator. Following the Neyman-Pearson lemma, one alternative to the definition of the discriminant in Eq. 1 is to

Figure 8: Comparison of the selection of prompt electrons based on the DNN and the LH. (a) shows a Loose working point, while (b) shows a Tight working point. Only candidates fulfilling \(15<E_{\mathrm{T}}\) [GeV] \(\leq 20\) and \(|\eta|\leq 0.8\) are shownplace the charge flip output in the denominator.

\[\mathcal{D}^{\prime}_{\text{el}}=\ln\left(\frac{p_{\text{EI}}}{\sum_{\text{X}\in \{\text{CF},\text{PC},\text{HF},\text{LFEg}\}}f^{\prime}_{\text{X}}p_{\text{X}}+ \left(1-f^{\prime}_{\text{CF}}-f^{\prime}_{\text{PC}}-f^{\prime}_{\text{HF}}-f^ {\prime}_{\text{LFEg}}\right)p_{\text{LFH}}}\right)\]

This would instead of accepting charge flip electrons reject them. In Figure 10, the ROC curves for the standard discriminant, the charge flip rejecting discriminant, and the standard discriminant with different \(f_{\text{X}}\) to target electrons from heavy-flavour quark decays. This is done by increasing \(f_{\text{HF}}\) of the discriminant optimised using the JF17 sample by a factor of 20 and dividing all other \(f_{\text{X}}\) by 1.22 can be seen.

For the combined background in Figure 10(a), the charge flip rejecting and the standard discriminant lead to a similar background rejection, while the heavy-flavour rejecting one has a slightly lower rejection. The rejection of charge flip electrons can be increased significantly when using the charge flip rejecting discriminant as can be seen in Figure 10(b). Increasing the importance of the heavy-flavour output on the other hand reduces the charge flip electron rejection. When increasing the importance of the heavy-flavour output, the importance of the remaining outputs is reduced. Since electrons from photon conversions can be similar to charge flip electrons a reduction of this output can lead to a lower rejection of charge flip electrons. The rejection of electrons from heavy-flavour quark decays can be improved by around 25% at 65% signal efficiency using the discriminant with increased \(f_{\text{HF}}\) as can be seen in Figure 10(c). A slight drop in rejection can be seen for the light-flavour hadrons background for the charge flip rejecting discriminant in Figure 10(d), whereas the rejection of the heavy-flavour rejecting one drops significantly.

Overall, by placing the charge flip output in the denominator, the rejection against all backgrounds is kept similar, while the rejection of charge flip electrons is significantly increased. Increasing the importance of the heavy-flavour output greatly increases the rejection of the heavy-flavour background while sacrificing rejection of the other backgrounds. However, for a sample with a higher fraction of electrons from heavy-flavour quark decays, for instance final states involving a \(t\bar{t}\) pair, this discriminant could lead to a better combined rejection.

Figure 9: Comparison of the selection of the inclusive background based on the DNN and the LH. (a) shows a Loose working point, while (b) shows a Tight working point. Only candidates fulfilling \(15<E_{\text{T}}\)\([\text{GeV}]\leq 20\) and \(|\eta|\leq 0.8\) are shown

But, changing the discriminant can lead to a different selected sample of prompt electrons which can lead to inefficiencies with respect to the trigger as discussed in the Section 6.2.

## 7 Conclusion

An identification algorithm for prompt electrons based on a deep neural network is introduced. It is shown to be able to improve the background rejection of the current algorithm based on a likelihood. The improvement on the inclusive background of the JF17 sample ranges from a factor of 1.7 to 5.5 depending on the region of phase space and the chosen signal efficiency. The largest improvement in the rejection for single background classes can be seen for light-flavour hadrons. Since the LH is optimised on data whereas

Figure 10: ROC curves for (a) the combined background, (b) only charge flip electrons, (c) only electrons from heavy-flavour quark decays, and (d) only light-flavour hadrons comparing different versions of the discriminant \(\mathcal{D}_{el}\). Only candidates with \(15<E_{\mathrm{T}}\) [GeV] \(\leq 20\) and \(|\eta|\leq 0.8\) are shown. Statistical uncertainties of the background rejection are shown as bands.

the DNN is optimised on simulated samples, the improvement in performance when evaluating on collision data can be expected to differ from what is observed with simulated data. The majority of signal electrons are accepted the same way for the DNN as for the LH, but a sizeable component is different. This will cause inefficiencies with respect to the trigger which uses an algorithm similar to the LH. Therefore, a DNN based identification at trigger level for the coming data taking period could be beneficial. Furthermore, due to using a multinomial classification, the algorithm is not only limited to the standard working points with one discriminant. Using a different discriminant can again introduce inefficiencies with respect to the trigger identification. But the discriminant can be tuned to also reject charge flip electrons or improve performance for a different background composition allowing for more versatility with one algorithm.

## References

* [1] ATLAS Collaboration, _The ATLAS Experiment at the CERN Large Hadron Collider_, JINST **3** (2008) S08003.
* [2] L. Evans and P. Bryant, _LHC Machine_, JINST **3** (2008) S08001.
* [3] ATLAS Collaboration, _The ATLAS Collaboration Software and Firmware_, ATL-SOFT-PUB-2021-001, 2021, url: [https://cds.cern.ch/record/2767187](https://cds.cern.ch/record/2767187).
* [4] P. Nason, _A new method for combining NLO QCD with shower Monte Carlo algorithms_, JHEP **11** (2004) 040, arXiv: hep-ph/0409146.
* [5] S. Frixione, P. Nason and C. Oleari, _Matching NLO QCD computations with parton shower simulations: the POWHEG method_, JHEP **11** (2007) 070, arXiv: 0709.2092 [hep-ph].
* [6] S. Alioli, P. Nason, C. Oleari and E. Re, _A general framework for implementing NLO calculations in shower Monte Carlo programs: the POWHEG BOX_, JHEP **06** (2010) 043, arXiv: 1002.2581 [hep-ph].
* [7] S. Alioli, P. Nason, C. Oleari and E. Re, _NLO vector-boson production matched with shower in POWHEG_, JHEP **07** (2008) 060, arXiv: 0805.4802 [hep-ph].
* [8] T. Sjostrand, S. Mrenna and P. Skands, _A brief introduction to PYTHIA 8.1_, Comput. Phys. Commun. **178** (2008) 852, arXiv: 0710.3820 [hep-ph].
* [9] ATLAS Collaboration, _Measurement of the \(Z/\gamma^{*}\) boson transverse momentum distribution in \(pp\) collisions at \(\sqrt{s}=7\) TeV with the ATLAS detector_, JHEP **09** (2014) 145, arXiv: 1406.3660 [hep-ex].
* [10] H.-L. Lai et al., _New parton distributions for collider physics_, Phys. Rev. D **82** (2010) 074024, arXiv: 1007.2241 [hep-ph].
* [11] J. Pumplin et al., _New Generation of Parton Distributions with Uncertainties from Global QCD Analysis_, JHEP **07** (2002) 012, arXiv: hep-ph/0201195.
* [12] P. Golonka and Z. Was, _PHOTOS Monte Carlo: a precision tool for QED corrections in \(Z\) and \(W\) decays_, Eur. Phys. J. C **45** (2006) 97, arXiv: hep-ph/0506026.