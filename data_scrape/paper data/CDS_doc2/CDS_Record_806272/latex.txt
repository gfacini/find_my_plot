# Measurement of the Gluino Mass via Cascade Decays for SPS la

B. K. Gjelsten

Department of Physics, University of Oslo, N-0316 Oslo, Norway

E-mail: B.K.Gjelsten@fys.uio.no

D. J. Miller

Department of Physics and Astronomy, University of Glasgow, Glasgow G12 8QQ, UK.

E-mail: D.Miller@physics.gla.ac.uk

P. Osland

Department of Physics, University of Bergen, N-5007 Bergen, Norway

and TH Division, Physics Department, CERN, CH 1211 Geneva, Switzerland

E-mail: Per.Osland@ift.uib.no

###### Abstract:

IFR-parity conserving supersymmetry is realised with masses below the TeV scale, sparticles will be produced and decay in cascades at the LHC. In the case of a neutral LSP, which will not be detected, decay chains cannot be fully reconstructed, complicating the mass determination of the new particles. In this paper we extend the method of obtaining masses from kinematical endpoints to include a gluino at the head of a -particle decay chain. This represents a non-trivial extension of the corresponding method for the squark decay chain. We calculate the endpoints of the new distributions and assess their applicability by examining the theoretical distributions for a variety of mass scenarios. The precision with which the gluino mass can be determined by this method is investigated for them SUGRA point SPS la. Finally we estimate the in proven method for adding a Linear Collider measurement of the LSP mass.

SUSY,BSM,MSM. +

###### Contents

* 1 Introduction
* 2 G hino endpoints
	* 2.1 Endpoint calculation
	* 2.2 Quark ambiguity
	* 2.3 Theory distributions
* 3 Measuring gluino endpoints for SPS 1a
	* 3.1 Signal and backgrounds
	* 3.2 Non-b-tagged distributions
	* 3.3 b-tagged distributions
	* 3.4 Propagation of energy scale errors
* 4 Masses from endpoints
	* 4.1 \(10\,\rho 00\) ATLAS experiments
	* 4.2 Mass estimation
	* 4.3 Edge sensitivities
* 5 Increasing the errors
	* 5.1 Disentangling statistical from energy scale errors
	* 5.2 Doubling the statistical errors
	* 5.3 Doubling the energy scale errors
* 6 LHC + Linear Collider (LC )
* 7 Conclusion
* A Calculation of \(m_{\rm qq1L}^{\rm\,max}\)
* A.1 Method 1: By means of angles
* A.2 Method 2: On a line
* B Calculation of \(m_{\rm qq1L(low)}^{\rm\,max}\)
* B.1 Preparations: review \(m_{\rm qq1L(low)}^{\rm\,max}\)
* B.2 \(m_{\rm qq1L(low)}^{\rm\,max}\)
* B.3 \(m_{\rm qq1L(low)}^{\rm\,max}=m_{\rm qq1L}^{\rm\,max}\)
* B.4 \(m_{\rm qq1L(low)}^{\rm\,max}=m_{\rm qq1L}^{\rm\,max}\)
* B.5 \(m_{\rm qq1L(low)}^{\rm\,max}=m_{\rm qq1L(low)}^{\rm\,max}\)
* B.6 General solution

\(\{\,1\,\{\}\)

[MISSING_PAGE_FAIL:3]

[MISSING_PAGE_EMPTY:4]

[MISSING_PAGE_EMPTY:5]

[MISSING_PAGE_FAIL:6]

[MISSING_PAGE_EMPTY:7]

Furthermore, for the four \(m_{q1}\) distributions one can collect four new distributions based on the order of the four values per event. Only the endpoint of the \(m_{q1(high)}\) distribution is readily available, while the other three endpoints become very difficult to calculate. A programme to calculate the new endpoints where quarks are not distinguished, has so far not been started.

The above discussion shows that as a second jet is added, the complexity of the situation increases significantly. In return many more endpoints become available, allowing for thorough consistency checks. In Sect. 3 we will return to these issues in the context of a simulation at the standard SPS 1a point.

### Theory distributions

In order for the endpoint method to be useful, not only must the analytic expressions for the endpoints be available, it must also be possible to determine these endpoints from the experimental mass distributions. A first criterion for this is that the edges of the distributions 'point' unambiously towards the exact endpoints. If the shape of a distribution is sufficiently concave at high values, the endpoint will most likely be underestimated and large systematic uncertainties must be added. In general the shapes of the mass distributions vary if the sparticle masses are varied. To investigate the range of possible shapes for each distribution, the full cascade was generated for approximately 500 unique mass scenarios, and the resulting theoretical mass distributions studied visually.

A representative selection of mass scenarios, showing some of the shape variety of the gluino distributions, is given in Fig. 1. In generating these decays, quarks and leptons are assumed to be massless, which in the worst case (b-quark) leads to a perfectly acceptable error of \(O(M\,\mathrm{eV})\). Furthermore, only decay phase space has been used, without the associated matrix elements. In principle, this ignores possible spin correlations between leptons and/or quarks. However, since the distributions used here are summed over lepton charge, no spin effects are expected [16]. A similar investigation for the squark distributions was performed in [12], See also [17].

Since \(m_{q1}\) is constructed from two nearest neighbours in the decay chain, the shape is triangular for any masses, similar to \(m_{1}\). Its endpoint can thus in principle be determined quite accurately. The shape of the \(m_{q1(high)}\) distribution depends on the masses, but in practically all scenarios the edge is well described by a linear descent towards the theoretical endpoint. This should guarantee its determination experimentally if the background is sufficiently low. Form most scenarios this is also true for \(m_{q1(low)}\), although the distribution can take on other shapes.

The three high' distributions, \(m_{q1(high)},m_{q1(high)}\) and \(m_{q_{1}(high)}\), show a large variety of forms. The available shapes of the \(m_{q1(high)}\) distribution are very similar to those of the \(m_{q_{1}(high)}\) distribution and are not reproduced here (see [12]). A common feature of these distributions is the danger of not noticing the 'foot', seen, for example, in \(m_{q1(high)}\), scenario (iv), where the true maximum value may be obscured by backgrounds.

The last of the three-particle distributions, \(m_{q1,1}\), also has an extensive variety of shapes. The behaviour of the edge is usually reasonable, but with a certain danger of foot-like structures, as in scenario (i). Finally, the two distributions are often unreliable in that the edges are concave. It may therefore be difficult to get good estimat

Figure 1: Theory distributions for SPS 1a and four other mass scenarios, showing some of the shape variety. Only ghino distributions are shown. Kinematic endpoints are marked with a triangle and given in units of \(m_{qq\parallel}^{\max}\), the largest of the endpoints. (All panels start at zero invariant mass.) The scenarios (i)((iv)) are defined by the following sets of mass ratios \(r\) (\(m_{q}\)=m_{q}\), \(m_{q}\)=m_{q}\), \(m_{q}\)=m_{q}\), \(m_{q}\)=m_{q}\), \(m_{q}\)=m_{q}\). \(r_{(i)}\) = (1.03;1:30;1:07;601), \(r_{(ii)}\)= (1.179;30;1:15;1:59), \(r_{(iii)}\)= (1.45;1:05;1:27;508) and \(r_{(iv)}\)= (1.03;1:29;2:02;3:60).

In summary, from the 500 mass scenarios of which the distributions in Fig. 1 comprise a fairly representative selection, the following can be stated regarding their overall behaviour: The distributions \(m_{\rm qq}\) and \(m_{\rm qq1}\) point reliably towards the endpoint for any mass scenario. Somewhat less reliable are the endpoint estimates found from the three-particle distributions. Lastly, even less reliable endpoint estimates can be obtained from the two \(m_{\rm q1}\) distributions. In the next section we will see how these statements change for a'realistic' experimental setup.

## 3 Measuring gluino endpoints for SPS 1a

Here we investigate the measurement of the endpoints associated with gluino decays for SPS 1a at ATLAS. Unless otherwise stated, the details of the analysis are identical to those for the squark chain, as described in Ref. [12], and will not be reproduced here.

### Signal and backgrounds

The SPS 1a point is defined by the SUGRA GUT-scale parameter values

\[m_{1=2}=250\GeV\;;m_{0}=\Lambda_{0}=100\GeV\;;\tan\;=10;\;>0 \tag{3.1}\]

evolved down to the electroweak scale by version 7.58 of ISAJET [18]. The masses of particles at the electroweak scale can be found in [12]. Fig. 2 show the signal chain with branching ratios: to the left the production rate of gluinos is shown, followed by the branching ratios of a gluino into left-handed squarks and both bottom states. Since the mass difference between \(B_{1}\) and the other squarks is comparable to the mass difference between the gluino and the squarks, phase space effects become significant, resulting in a noticeably enhanced decay rate into \(B_{1}\).

Signal and background are generated for 300 fb\({}^{-1}\), which corresponds to three years at design luminosity of \(10^{34}\) cm\({}^{-2}\)s\({}^{-1}\). The low-energy parameters are passed, via the standard interface, to PYTHIA 6.2 [19] which calculates the decay widths and the LHC cross-sections by use of CTEQ 5L [20]PDF's, and generates the events. Finally ATLAS 2.60 [21] performs a parametrised fast simulation of the ATLAS detector. The simulation setup is identical to that used for the squark-endpoint analysis, except that four jets are now required with \(P_{\rm T}^{\rm jet}>150\);100;50;20 GeV, rather than only three. Also, the definition of \(M_{\rm e}\) is extended to include the fourth jet.

Figure 2: SPS 1a cascade decay with branching ratios and cross-sections.

The QCD background is cut away by the requirement of two leptons2 and of considerable missing \(\Pp\). For the processes involving \(\Z\) and \(\W\) the requirement of high hadronic activity together with the missing \(\Pp\) removes nearly all events. After these rather hard cuts, the Standard Model background consists of approximately 95% tt. Most likely the Standard Model background is significantly underestimated, as the parton shower approach of PYTHIA does not generate at a realistic rate the hard jets which are required in the selection cuts. However, because of the large SUSY cross-section for this scenario, the main background will come from other SUSY processes. The possible underestimation of the Standard Model background is therefore not a danger for the current analysis.

Footnote 2: For convenience of notation we will for the rest of the paper use “lepton’/“lepton’ for the two rest generations and “tau’/“tau’ for the third generation.

It is convenient to divide the background into three di-entent parts, "lepton-unconrelated", "lepton-correlated" and " combinatorial". The two rest consist of events which do not contain the signal chain. In the lepton-uncorrelated background two leptons are produced, but in di-ent parts of the decay and therefore independently. With the assumption of lepton universality and neglecting the mass difference between electrons and muons, which is very reasonable for the energies involved, this background can be removed by subtracting the distribution for di-ent-avour leptons, as was done in Ref. [12].

For the lepton-correlated background, the leptons are always same-avour, so no di-ent-avour sample is available to show its distribution. These events typically come from the decay of \(\Z\), in which case they can to some degree be controlled, or from sleptonic decay of neutralinos. In the latter case no particular signature, e.g. in the \(\Pp\Pp\) distribution, is available to discriminate this background from the signal. In particular much of this background will come from \(\Pp\Pp\)'s decaying sleptonically, but which are not part of our signal chain. For the analysis of the squark chain, as done in [12], one in portant criterion is that the \(\Pp\Pp\) produced from squarks make up a good fraction of the total \(\Pp\Pp\) production. Events with \(\Pp\Pp\)'s not originating from the relevant squarks usually still contain jets and constitute a large part of the background. As the signal chain grows longer, this background increases relative to the signal. In the case of the whole gluino chain what is in portant is that the \(\Pp\Pp\)'s with a gluino grandparent are not severely outnumbered by the total \(\Pp\Pp\) production, for the events selected. This is a stricter criterion, and we will not that the flavour of the intermediate squark, whether it is \(\mathbf{q}\) or \(\mathbf{B}\), will be crucial for the isolation of the signal.

The third background type, combinatorial background, is a result of our inability to know which of the jets correspond to the quark sent out from the gluino (\(\mathbf{q}_{1}\)) and from the squark (\(\mathbf{q}_{2}\)). In most analyses one assumes that the quark from a squark decay can on average be distinguished from the quark from a gluino decay on the basis of hardness. In most SUSY scenarios this is viable, as \(\Pp\Pp\) is so much lighter than the squark. Since two squarks are expected in nearly all events, assuming \(\Pp\Pp\Pp\), one can attribute the two hardest jets to the decay of the two squarks. Remaining jets can then be attributed to gluino decays, other quarks in the event, e.g. from the decay of t or W, and/or the underlying event. The exact jet selection algorithms used in this study are based on these assumptions, and will be detailed in the subsections below.

In more general SUSY scenarios it need not be the case that \(q_{i}\) is harder than \(q_{i}\). In general, given an unknown SUSY scenario, the appropriate jet selection procedure must be the result of careful study. For this also the mass hierarchy of the gluino and the squarks must be established. A systematic study of how such information can be obtained is lacking but would be very valuable.

### Non-b-tagged distributions

In Fig. 3 two of the non-b-tagged distributions, \(m_{\rm qq}\) and \(m_{\rm qqL}\), are shown. In black with error bars the diemert-avour-subtracted distribution (SF-DF') is shown. Solid green shows the SUSY background (SUSY '). Its shape is given by the lepton-correlated part, but the lepton-uncorrelated part is also significant and increases the random fluctuations. The Standard Model background is negligible and is not shown separately. The blue curve shows the parton-level distribution of the selected events (TH '), while the red points with error bars show the part of the diemert-avour-subtracted sample which contains the correct signal chain (SC '), also referred to as the'signal-chain distribution'. Any discrepancy between these two distributions is mostly due to combinatorial background, i.e. from picking the wrong jets.

For these distributions \(q_{i}\) was assumed to be one of the two hardest jets while \(q_{i}\) was selected among number three or four in \(p_{i}\)-hardness. This is in line with the mass assumptions usually valid in SUGRA scenarios, as described above. The jet selection used for the distributions plotted was, on an event-by-event basis, the one out of four possible combinations which gave the smallest \(m_{\rm qqL}\) value. In addition we required that neither of the involved jets was b-tagged. (The b-tagging simulation is described in [12] and is rather crude, although with a reasonable overall behaviour.)

It is clear that the positions of the endpoints, which are seen in the parton-level distributions (TH '), are not easily detectable from the diemert-avour-subtracted sample. This is mainly due to the size of the lepton-correlated part of the SUSY background (SUSY '),

Figure 3: Invariant mass distributions for non-b-tagged events. Endpoints not detectable. See the text for details.

which makes up 80% of the total sample. Structures in the signal part of the sample are therefore not easily identified. This result can be anticipated from Table 3 of Ref. [12], which shows that only 82-328 = 25% of 9% originate from a glino. The ratio of glino-induced \({}^{0}_{2}\)'s becomes therefore quite small.

Another di-cutly is the combinatorial background. The signal-chain distributions (SC ') do not at all point to the nominal endpoints at 242 GeV and 490 GeV (for \(\mu_{\rm L}\)). This is because the jet pair selected is often not the correct one.

Other jet selection algorithms of this simple type have been tried, but none allows any edge structure caused by the kinematics of the decay chain to be recognised. This is also true for the other - we glino distributions (not shown). One must therefore conclude that the endpoints of the non-b-tagged glino distributions are not experimentally obtainable by looking at one distribution at a time. If instead correlations between mass distributions were investigated in might be possible to identify endpoint-related edge structures.

### b-tagged distributions

The distributions of the b-tagged samples are shown in Figs. 4(5. The curves follow the colour code of Fig. 3, except the Standard Model background (SM ') is also shown (green points with error bars). For the b-tagged distributions the di-cutor distribution is 40% of the same-avour distribution, which is somewhat larger than for the non-b-tagged distribution where the ratio is 25%. In both cases the di-cutor distribution favours lower mass values and does not interfere very much with the edge structure.

Contrary to the previous case, the b-tagged distributions have clear edge structures which provide values for the endpoints. The main reason for this is that the di-cutor-subtracted SUSY background (solid green) now makes up a manageable 35%, to be compared with 80% for the non-b-tagged sample. This reduction is due to the fact that the majority of b's are produced indirectly from glino decay [because of the low-content of the proton] in combination with a jet selection requirement of exactly two b-tagged jets. Although the total production of \({}^{0}_{2}\) is 6(7 times larger (see Fig. 2) than the production width starts out from 9! fb, two b-jets are also needed, which reduces considerably the number of selected background events. (For background events the b's are usually produced in the other chain, typically from the same 9! fb which then does not continue sleptonically, or from 9! fb in either of the chains, which also produces multiple b's.) Since the rate of b-jets is considerably smaller than the rate of light jets, also in SUSY events, we are likely not to have additional b-jets in a signal event. The combinatorial background is therefore small, as is clear from the good correspondence between the parton-level distribution ('TH ') and the signal-chain distribution (SC ').

The specific jet-selection used here is in line with the previous assumption that \(b_{\rm f}\) is harder than \(b_{\rm h}\). The first is searched for among the two \(p_{\rm T}\)-hardest, the second among number three and four. Only events which have one b-jet among the two hardest and one among the two next were selected. (In a more realistic study where emphasis is put on issues like fitting techniques, impact on the distributions from the precuts etc., it would be natural to investigate the effect of also including events which have their two b-tagged jets as number 1 and 2 or as number 3 and 4.)

[MISSING_PAGE_EMPTY:14]

[MISSING_PAGE_EMPTY:15]

[MISSING_PAGE_FAIL:16]

scaling the jet momenta of each event by 1.01 and taking the ratio of the new and the old invariant mass. We then find the following average and root-mean-square values (in parentheses) of the relevant energy scale errors,

\[\frac{(m_{\rm bbl})}{m_{\rm bbl}} = 0.56(0.10)\%\ ;\qquad\frac{(m_{\rm bbl}({\rm Low}\ ))}{m_{\rm bbl}({\rm Low}\ )}=0.80(0.11)\%\] \[\frac{(m_{\rm bbl}({\rm high}))}{m_{\rm bbl}({\rm high})} = 0.71(0.10)\%\ ;\qquad\frac{(m_{\rm bbl}\ 1)}{m_{\rm bbl}\ 1}=0.42(0.02)\% \tag{3.6}\]

Inclusion of the lepton energy scale will give a small correction to these numbers. For \(m_{\rm bbl}\), which we will not be using, the energy scale is nearly constant. For the three other distributions, the errors lie between approximately 0.5% and 1%, and fairly uniformly distributed, as is reflected in the root-mean-square values. For the fitting, only the energy scale error for masses which lie in the edge region is relevant. However, it turns out that at SPS 1a and for these distributions, the error is almost the same for low as for high invariant mass values. Although the error of each distribution is found to lie in a fairly broad interval rather than being constant for all events, we have here used the average values, Eq. (3.6), as a basis for the energy scale errors in Table 1.

An alternative approach could be to scale the jet momenta up/down as done above, then radio the entire fitting process on the new distributions and from this extract the effect of the energy scale error. For this to work one would have to disentangle the effect of the scaling from the yet uncontrolled systematics of the fitting procedure. At the present stage of fitting competence the gain from using a more correct procedure is probably lost in the increased complexity.

## 4 Masses from endpoints

### 10,000 ATLAS experiments

The sparticle masses can be obtained from a numerical \(\!\!\)t based on the glino endpoints found in the previous section together with the squark endpoints of [12]. Due to the

\begin{table}
\begin{tabular}{|c c c c c|} \hline  & Nominal & Fit & Energy Scale & Statistical \\ Edge & Value & Value & Error ( scale) & Error (  stat) \\  & [GeV ] & [GeV ] & [GeV ] & [GeV ] \\ \hline \(m_{\rm bbl}^{\rm max}\) & 312.7 & 335(339 & 3.4 & 6(10 \\ \(m_{\rm bbl}^{\rm max}\) & 496.3 & 494(500 & 3.3 & 5(7 \\ \(m_{\rm bbl}({\rm Low}\ ) & 413.2 & 407(417 & 3.3 & 8(12 \\ \(m_{\rm bbl}^{\rm max}\) & 461.9 & 454(462 & 3.3 & 5(7 \\ \end{tabular}
\end{table}
Table 1: Endpoint values found from fitting the edges in Fig. 4, for 300 fb\({}^{-1}\). The nominal values correspond to the mass of \(\rm B_{\rm\rm\rm\rm\,t}\) which is produced at significantly higher rates than the heavier \(\rm E_{\rm\rm\,t}\). The energy scale errors are based on the discussion in Sect. 3.4. No values are given for the three distributions in Fig. 5.

[MISSING_PAGE_EMPTY:18]

When more glino endpoints are added, the glino sector becomes over-determined, and the positions of the minima a will change, i.e. the other masses will be a cected. Since the glino endpoints have somewhat larger errors than the squark endpoints, large e.g. \(\mathrm{e}\)ets are not expected, except perhaps for \(\mathrm{B}_{\mathrm{L}}\). Below, results are given for the case when all three selected glino endpoints are used.

For the current precision of the endpoint measurements, the numerical therapy always returns two minima, one in mass region (1,1),3 which is the region of the nominal masses at SPS la, and one in mass region (1,2). If the minima are close in -value, both must be considered. Table 2 shows the probability of having more than one solution in an experiment. The cut on, the distance to the global minimum, gives the quality of the second minimum. In most cases the (1,1) minimum is the selected one. These numbers are very similar to the numbers obtained without the glino endpoints, Table 5 of [12], where a more detailed description can also be found.

Footnote 3: The definition of the regions is given in Sect. 4.3 of [12]. For a mass region (i,j) the rest index refers to the expression used for \(m_{q,1}^{\,\mathrm{ax}}\), the second index shows which combination is used for \((m_{q,1}^{\,\mathrm{ax}})\), \(m_{q,10,3}^{\,\mathrm{ax}}\)), see Eqs. (4.4)(4.5) of [12].

The masses are given in Table 3 for minima a which satisfy 1. The numbers are very close to the ones obtained without the glino endpoints, see Table 6 of [12]. Only \(\mathrm{B}_{\mathrm{L}}\) is a cected, as was expected.

The glino mass is quite well determined. The ensemble mean is at the nominal value, and the root-mean-square deviation from the mean is 7.2 GeV, only a GeV more than for \(m_{\mathrm{L}}\). For the other masses, especially the lighter ones, mass differences are much more accurately determined than the masses themselves. This is also the case for the glino,

[MISSING_PAGE_EMPTY:20]

[MISSING_PAGE_FAIL:21]

[MISSING_PAGE_EMPTY:22]

[MISSING_PAGE_FAIL:23]

[MISSING_PAGE_FAIL:24]

accessible, in particular \(\sim_{1}^{0}\). Such a measurement will be the scale xer whith is lacking in the LHC data, and will in combination with the LHC measurements allow one to also x the masses of the heavier sparticles not accessible at the Linear Collider.

To estimate the effect of a Linear Collider measurement of \(m_{{}_{\perp}^{0}}\), we add to our least-square function, at term [fm \(m_{{}_{\perp}^{0}}\) m\({}_{{}_{\perp}^{0}}^{\rm LC}\) = \(\rm{{}^{LC}_{\perp}}\) \(\rm{{}^{F}_{\perp}}\), where the quantity with superscript LC' is the Linear Collider measurement, and generate an ensemble of LHC and LC experiments. Since \(\rm{{}^{LC}_{\perp}}\) = 0.05 GeV [24], the LC measurement practically xes m\({}_{{}_{\perp}^{0}}\) at the nominal value. (For the LHC measurements we use in this section the default endpoint errors.)

For the (1,2) solutions, which normally return \(\sim_{1}^{0}\) masses same 10 GeV below the nominal value, the LC measurement has the dramatic effect of reducing their occurrences to 1% (for 3). These minima can therefore for most purposes be neglected. As a consequence, the probability of having two minima is strongly reduced, to the permille level. For SPS 1a the Linear Collider measurement thus closes the issue of multiple minima altogether. (This behaviour was already reported in [12], the inclusion of the gluino endpoints thus makes no difference in this respect.)

The combined LHC + LC results are shown in Table 9. Comparison with the numbers of Table 3 shows that the precision of the mass determination improves considerably when the LC measurement is included. The root

\begin{table}
\begin{tabular}{|c|r|r r|r r|} \hline  & & \multicolumn{3}{c|}{(1,1)} & \multicolumn{3}{c|}{(1,2)} \\  & N cm & Mean & RMS & Mean & RMS \\ \hline m\({}_{{}_{\perp}^{0}}\) & 96.1 & 96.3 & 3.7 & 85.5 & 3.4 \\ m\({}_{{}_{\parallel}^{0}}\) & 143.0 & 143.2 & 3.7 & 130.6 & 3.8 \\ m\({}_{{}_{\perp}^{0}}\) & 176.8 & 177.0 & 3.6 & 165.7 & 3.5 \\ m\({}_{{}_{\parallel}^{0}}\) & 537.2 & 537.3 & 7.3 & 523.8 & 6.4 \\ m\({}_{{}_{\parallel}^{0}}\) & 491.9 & 492.1 & 13.0 & 472.1 & 13.1 \\ m\({}_{{}_{\parallel}^{0}}\) & 595.2 & 595.3 & 9.3 & 582.9 & 8.9 \\ \hline m\({}_{{}_{\parallel}^{0}}\) & m\({}_{{}_{\perp}^{0}}\) & 46.92 & 46.93 & 0.29 & 45.11 & 0.72 \\ m\({}_{{}_{\perp}^{0}}\) & m\({}_{{}_{\perp}^{0}}\) & 80.77 & 80.77 & 0.22 & 80.19 & 0.32 \\ m\({}_{{}_{\parallel}^{0}}\) & m\({}_{{}_{\perp}^{0}}\) & 441.2 & 441.1 & 5.1 & 438.3 & 4.9 \\ m\({}_{{}_{\parallel}^{0}}\) & m\({}_{{}_{\perp}^{0}}\) & 395.9 & 395.8 & 11.8 & 386.6 & 11.8 \\ m\({}_{{}_{\parallel}^{0}}\) & m\({}_{{}_{\perp}^{0}}\) & 499.1 & 499.0 & 8.1 & 497.4 & 8.1 \\ m\({}_{{}_{\parallel}^{0}}\) & m\({}_{{}_{\parallel}^{0}}\) & 103.3 & 103.2 & 9.3 & 110.9 & 9.8 \\ \hline \end{tabular}
\end{table}
Table 8: Same as Table 3, except for doubled energy scale errors: Mean and root-mean-square deviations from the mean (RMS) [GeV].

\begin{table}
\begin{tabular}{|c|r|r r|} \hline  & & \multicolumn{2}{c|}{(1,1)} \\  & N cm & Mean & RMS \\ \hline m\({}_{{}_{\perp}^{0}}\) & 96.05 & 96.05 & 0.05 \\ m\({}_{{}_{\parallel}^{0}}\) & 142.97 & 142.97 & 0.29 \\ m\({}_{{}_{\perp}^{0}}\) & 176.82 & 176.82 & 0.17 \\ m\({}_{{}_{\parallel}^{0}}\) & 537.2 & 537.2 & 2.5 \\

[MISSING_PAGE_EMPTY:26]

Finally the impact of a joint LHC (LC analysis was estimated. The endpoint of measurements from the LHC were combined with a Linear Collider measurement for the LSP mass. This essentially fixes the SUSY mass scale. Consequently, in the combined analysis the masses themselves are determined with roughly the same precision as that of mass differences determined at the LHC alone. According to a dedicated study [25], the anticipated accuracy will also be to determine the high-scale mass parameters with a precision ranging from 0.1% for \(m_{1=2}\) to 14% for \(A_{0}\).

### A. Calculation of \(m_{\rm qyll}^{\rm\, max}\)

Below we use the calculation of the known squark endpoint \(m_{\rm qyll}^{\rm\, max}\) as an aid to obtain \(m_{\rm qyll}^{\rm\, max}\). We first follow what may seem to be them ost obvious route, then note that while this works one for \(m_{\rm qyll}^{\rm\, max}\), the increased complexity of having one more particle to consider strongly limits the applicability to \(m_{\rm qyll}^{\rm\, max}\). An alternative method is then developed by which \(m_{\rm qyll}^{\rm\, max}\) can be found in a straightforward manner.

### A.1 Method 1: By means of angles

In the first method we keep the calculation close to the physical progression of the decay, picking up all decay angles and eventually maximising with respect to these. Fig. 7 shows in a stepwise manner the \(\varphi\), decay chain from which \(m_{\rm qyll}^{\rm\, max}\) is calculated. Start in the rest frame of \(\varphi\), and align the coordinate system to its decay products. Next, boost to the rest frame of \(\varphi_{2}^{0}\), which decays such that \(\varphi_{1}\) is emitted at an angle relative to the direction of \(\varphi\). Finally, boost to the rest frame of \(\varphi\), which in turn decays; for a given angle, \(m_{\rm qyll}\) is maximised by choosing \(P_{\rm k}\) opposite to \(P_{\rm qk}+P_{\rm k}\), in the rest frame of \(\varphi\) (giving a planar decay on \(\varphi\)).

The resulting \(m_{\rm qyll}\) is expressed in terms of the angle and the four sparticle masses involved. In order to maximise with respect to, the critical points of this constrained \(m_{\rm qyll}\) distribution must be sought (and tested if they are maxima or minima). In the part of mass space where no critical point is found, the endpoints of the domain, \(2\)[0;], must be analysed. In this case, three different expressions are found for three distinct regions in mass space. In total, mass space is thus divided into four regions, each with its special \(c\) expression for \(m_{\rm qyll}^{\rm\, max}\), see Eq. (4.4) of [12]. (See [11] for a different derivation.)

The above calculation becomes fairly involved, and is preferably performed with the assistance of a computer program. If we now want to calculate \(m_{\rm qyll}^{\rm\, max}\), a gluino is added at the head of the chain. In general two more angles are needed to describe the gluino decay. However, since the maximum of the endpoint values are obtained with planar decay on \(\varphi\), one of the angles can be dropped. The remaining additional angle is nevertheless a client to complicate significantly the search for extrema of \(m_{\rm qyll}\).

### A.2 Method 2: On a line

In the alternative approach to \(m_{\rm qyll}^{\rm\, max}\) (and \(m_{\rm qyll}^{\rm\, max}\)) the physical progression of the decay is not tracked. Instead an expression for the endpoint is found in terms of the one missing four-vector, that of \(\varphi_{1}^{0}\). Arguments which invoke the notion of dominant decays are then applied to point out a number of limiting decay configurations (of great geometrical simplicity) which must be considered.

Investigating first \(m_{\alpha\,\pm\,1}^{\,\max}\), the four-vector of the sum of the end products; the two leptons, the quark and the LSP, equals the four-vector of the squark. We therefore have

\[m_{\alpha}^{\,2}=\,(p_{q_{L}\,\pm\,1}+\,P_{-1})^{2}=m_{\alpha\,\pm\,1}^{\,2}+m_ {\alpha\,\cdot\,1}^{\,2}+2p_{q_{L}\,\pm\,1}\quad P_{1}^{\,0}\] (A.1)

where \(p_{q_{L}\,\pm\,1}\) is the sum of the four-vectors of the two leptons and the (far) quark. In the rest frame of \(\alpha\), we have

\[P_{q_{L}\,\pm\,1}=\quad P_{-1}^{\,0};\quad E_{q_{L}\,\pm\,1}=m_{\alpha\,\pm\,1} \quad E_{-1}^{\,0}\] (A.2)

which gives

\[m_{q_{L}\,\pm\,1}^{\,2}=m_{\alpha\,\pm\,1}^{\,2}\quad m_{-1}^{\,2}\quad 2m_{ \alpha\,\pm\,1}\quad m_{-1}^{\,2}+p_{-1}^{\,0}\quad m_{-1}^{\,2}\] (A.3)

The smaller the momentum of the LSP is in the rest frame of the initial squark, the larger \(m_{q_{L}\,\pm\,1}\) is, which agrees with one's intuition. At the extreme, if the LSP is brought to rest in the squark rest frame, \(m_{q_{L}\,\pm\,1}\) will attain its largest value, \(m_{\alpha\,\pm\,1}\), \(m_{-1}^{\,0}\), which corresponds to the critical-point solution of method 1.

In some regions of mass space it is however not possible to have \(\sim_{1}^{\,0}\) at rest in the rest frame of \(\alpha\). In these regions, one of the intermediate sparticles is sent to with so high momentum that not even optimal choices of directions for the other two decays can bring \(\sim_{1}^{\,0}\) to rest (in the rest frame of \(\alpha\). ). For the decay which gives the maximum value of \(m_{q_{L}\,\pm\,1}\), the LSP will have a non-zero momentum in the same direction as the sparticle sent out from the 'fandest' decay. There are three separate dominance regions in mass space where this happens, one for each sparticle decay in the cascade.

Consider the case where the second decay, that of \(\sim_{2}^{\,0}\), is dominant. If \(\sim_{1}^{\,0}\) cannot be brought to rest in the rest frame of \(\alpha\), the maximum value is obtained for the optimised case where \(\alpha_{\ell}\) and \(\lambda_{\ell}\) y \(\circ\) in one direction and \(\lambda_{\ell}\) in the opposite, see Fig. 8. In the last step of the figure all momenta are boosted back to the rest frame of \(\alpha\). If we are inside the dominance region, \(\sim_{1}^{\,0}\) ends up with a momentum pointing upwards' in the rest frame

Figure 7: Traditional way of calculating \(m_{q_{L}\,\pm\,1}^{\,\max}\).

[MISSING_PAGE_EMPTY:29]

con quations available for the gining decay chain. In order to demonstrate the peculiarities of 'low 'endpoints in a pure form, we first review the calculation of \(m_{q\perp({\rm Low})}^{\rm\ max}\), the simplest of the 'low 'endpoints. For the calculation of \(m_{q\perp({\rm Low})}^{\rm\ max}\), which follow thereafter may of the considerations are similar, only significantly more difficult to carry through.

B.1 Preparations: review \(m_{q\perp({\rm Low})}^{\rm\ max}\)

Let us first recall that since there are two leptons, two invariant masses \(m_{q\perp}\) can be constructed, one of which will be higher than the other. These will be denoted the high' and 'low 'distributions, each of which will have a maximum, denoted'max'. Thus, the diuly lies in identifying whether high' and 'low'correspond to the 'near' (\(l_{n}\)) and 'far' (\(l_{k}\)) leptons, or vice versa. The \(m_{q\perp({\rm High})}\) and \(m_{q\perp({\rm Low})}\) distributions are constructed from the highest/lowest of \(m_{q\perp}\) and \(m_{q\perp}\) on an event by event basis. (We here assume that the correct jet has been selected.) Since the \(m_{q\perp}\) value which gives the absolute maximum must necessarily be the higher of \(m_{q\perp}\) and \(m_{q\perp}\) for the given on equation, we simply have \(m_{q\perp({\rm High})}^{\rm\ max}=\rm\max(m_{q\perp}^{\rm\ max}m_{q\perp k}^{ \rm\ max})\). Form \(m_{q\perp({\rm Low})}^{\rm\ max}\) the situation is more complicated; we need to look for the maximum value of the lower of \(m_{q\perp}\) and \(m_{q\perp}\). This conditional maximum is required that both \(m_{q\perp}\) values are compared for the given on equation. Under no circumstance can the endpoint be higher than the lower of the two maxima, \(m_{q\perp({\rm Low})}^{\rm\ max}\), \(m_{q\perp({\rm Low})}^{\rm\ max}\), \(m_{q\perp k}^{\rm\ max}\).

Let us first assume a mass scenario where \(m_{q\perp k}^{\rm\ max}<m_{q\perp k}^{\rm\ max}\), which directly corresponds to the condition

\[m_{k}^{\rm\ 2}>m_{\mbox{\tiny$\sim$}_{1}^{\rm\ \

[MISSING_PAGE_EMPTY:31]

[MISSING_PAGE_EMPTY:32]

[MISSING_PAGE_EMPTY:33]

[MISSING_PAGE_EMPTY:34]

[MISSING_PAGE_EMPTY:35]

[MISSING_PAGE_EMPTY:36]

[MISSING_PAGE_EMPTY:37]

B.6 General solution

Putting all this together, the fully general solution for \(m\,\underset{\text{qq1}(\text{Lew})}{\max}\) is given by

\[m\,\underset{\text{qq1}(\text{Lew})}{\max}\] (B.40)

where

\[h\text{cutli}=\] (B.41) \[W\] (B.42) \[W\] (B.43) \[W\] (B.44) \[W\] (B.45) \[W\] (B.46) \[W\] (B.47) \[W\] (B.48) \[W\] (B.49) \[W\] (B.40)

is constructed from (B.40), (B.41) and (B.42) together with the appropriate region conditions. Expressions for \(m\,\underset{\text{qq1}}{\max}\) and \(m\,\underset{\text{qq1}}{\max}\) are given in Eqs. (2.14) and (2.15) respectively, and \(m\,\underset{\text{qq1}(\text{eq1})}{\max}\) is given by

\[m\,\underset{\text{qq1}(\text{eq1})}{\max}=m\,\underset{\text{qq1}(\text{eq1} )}{\max}\,m\,\underset{\text{qq1}(\text{eq1})}{\max}\,m\,\underset{\text{qq1}( \text{eq1})}{\max}\,m\,\underset{\text{qq1}(\text{eq1})}{\max}\,m\,\underset{ \text{qq1}(\text{eq1})}{\max}\,m\,\underset{\text{qq1}(\text{eq1})}{\max}\] (B.42)

which uses (B.41) and (B.42)(B.43).

### Achrow ledgments

This work has been performed partly within the ATLAS Collaboration, and we thank collaboration members for helpful discussions. We have made use of the physics analysis framework and tools which are the results of collaboration-wide e orts. We are in particular grateful to Giacom O. Poleello for numerous discussions. BKG would like to thank Steinar Stapnes for useful discussions. This research has been supported in part by the Research Council of Norway.

## References

* [1] P. Fayet and S. Ferrara, Phys. Rept. 32 (1977) 249.
* [2] S. Dimopoulos and H. Georgi, Nucl. Phys. B 193 (1981) 150.