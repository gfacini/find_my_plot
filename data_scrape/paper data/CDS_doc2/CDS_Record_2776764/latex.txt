# Sensitivity to exclusive \(WW\) production in photon scattering at the High Luminosity LHC

The ATLAS Collaboration

The prospects of measuring the process \(\gamma\gamma\to WW\) with the ATLAS detector during the high luminosity phase of the Large Hadron Collider (HL-LHC) with a centre-of-mass energy of 14 and an integrated luminosity of 3000 fb\({}^{-1}\) are studied. The opposite-flavour, opposite-sign fully leptonic final state is considered. The precision of the inclusive cross-section measurement in the fiducial volume is expected to be slightly improved relative to the one obtained in Run 2 measurement if the track transverse-momentum (\(p_{\mathrm{T}}\)) threshold can be maintained at 500 and assuming a similar systematic uncertainty on the background yield of \(\pm\) 12%. This study compares baseline HL-LHC track reconstruction to low-\(p_{\mathrm{T}}\) tracking and finds that low-\(p_{\mathrm{T}}\) tracking is an essential research and development area for exclusive analyses at the HL-LHC. It also demonstrates that reducing background modelling uncertainties will be important in order to benefit from improvements in statistical precision. A differential analysis in dilepton mass shows that the sensitivity will be improved in the high-mass region with respect to the Run 2 analysis, opening up avenues for improved limits on anomalous gauge couplings and effective field theory fits in this region.1

Footnote 1: Figure 5(c) is updated after approval.

## 1 Introduction and Motivation

The first observation of the rare electroweak process \(\gamma\gamma\to WW\to e^{\pm}\nu_{e}\mu^{\mp}\nu_{\mu}\) in proton-proton (\(pp\)) collisions at the Large Hadron Collider (LHC) was made by the ATLAS collaboration in 2020, in which the background-only hypothesis was rejected with a significance of 8.4 standard deviations using \(139\,\mathrm{fb}^{-1}\) of data collected in Run 2 [1]. The cross-section was measured in the fiducial region to be \(3.13\pm 0.31\) (stat.) \(\pm\) 0.28 (syst.) fb. Evidence of the process had previously been seen by both ATLAS [2] and CMS [3, 4] using data collected in Run 1. The fully-leptonic final state was chosen due to its experimentally clean signature that is easier to distinguish from backgrounds, despite having a smaller branching fraction than the semi- and fully-hadronic decay modes. The measured cross-section contains not only the elastic case, where both protons remain intact and form part of the final state, but also the single- and double-dissociative cases, where one or both protons break-up as a result of incoherent photon exchange. The proton remnants after dissociation are typically produced in the forward direction, often outside of the detector acceptance. Due to otherwise overwhelming backgrounds, photon-induced \(WW\) production is measured in an exclusive phase-space where the exclusivity criterion requires that there are no tracks other than those of the \(W\) decay products.

The \(\gamma\gamma\to WW\) process is unique as it can only occur via electroweak gauge boson couplings at leading-order, making it an ideal probe for searching for new physics via anomalous gauge boson couplings. These anomalous couplings can be parametrised by an Effective Field Theory (EFT) which contains additional higher-order terms to the Standard Model (SM). When anomalous couplings are sufficiently large, they lead to differences between the experimentally measured cross-section and the cross-section predicted by the SM. The high centre-of-mass, \(\sqrt{s}\), energies at the LHC provide a unique laboratory to put additional constraints on anomalous gauge couplings with the \(\gamma\gamma\to WW\) process, with the most sensitivity expected for dimension-8 operators [5]. Some of the operators not only change the inclusive \(\gamma\gamma\to WW\) cross-section but can also cause enhancements in certain kinematic regions, such as higher diboson mass, \(m_{WW}\). Therefore, differential measurements in dilepton mass, \(m_{\ell\ell}\), which is strongly correlated with diboson mass, allow the high-mass region to be selected to search for any discrepancies with the SM.

The High Luminosity LHC (HL-LHC) is a major upgrade planned for the LHC over the first half of this decade in order to increase its instantaneous luminosity by a factor of five and the integrated luminosity by a factor of ten beyond the original LHC design values [6]. The increased luminosity at the HL-LHC will allow a large improvement in statistical precision for any given measurement, which is especially important for rare processes with small cross-section like \(\gamma\gamma\to WW\). However, this analysis is very sensitive to the presence of multiple simultaneous interactions per bunch crossing. One metric used to quantify this is the average number of interactions per bunch crossing, \(\mu\), also referred to as pileup. The pileup at the HL-LHC is predicted to be between \(140<\mu<200\)[7, 8], compared to an average of 33-35 in Run 2 [9]. The increase in pileup will be detrimental to the \(\gamma\gamma\to WW\) analysis due to the way in which the exclusivity requirements are defined.

This note studies the expected sensitivity to the \(\gamma\gamma\to WW\) process at the HL-LHC when using a similar analysis approach as in the Run 2, 13 TeV analysis [1]. The aim is to understand how the HL-LHC environment and planned detector upgrade will impact the measurement and to identify which areas could benefit from more research and development for these types of analyses to be fruitful. For this purpose, the relative statistical and total uncertainties on the signal yield will be used as figure of merit. In order to counteract the increase in pileup at the HL-LHC, the impact of key operational parameters is studied.

These include changing the definition of the exclusivity selection, investigating the effect of the minimum transverse momentum (\(p_{\mathrm{T}}\)) used for reconstructing charged particles, and the effect of the extended tracking acceptance of the upgraded tracker compared to the present inner detector. Not considered in this study are changes in lepton reconstruction, triggering and acceptance between Run 2 and the HL-LHC. Changes in both signal and background cross-section between \(\sqrt{s}=13\) TeV and \(\sqrt{s}=14\) TeV are equally not considered in the detailed comparisons made below due to their small impact but an estimate of their size is given in the relevant sections.

## 2 The ATLAS Detector and Track Reconstruction

The ATLAS detector [10] at the LHC is a multipurpose detector with forward-backward symmetric cylindrical geometry and nearly \(4\pi\) coverage in solid angle.2

Footnote 2: ATLAS uses a right-handed coordinate system with its origin at the nominal interaction point (IP1) in the centre of the detector and the \(z\)-axis coinciding with the axis of the beam pipe. The \(x\)-axis points from the interaction point to the centre of the LHC ring, and the \(y\)-axis points upward. The pseudorapidity is defined in terms of the polar angle \(\theta\) as \(\eta=-\ln\tan(\theta/2)\), and \(\phi\) is the azimuthal angle around the beam pipe relative to the \(x\)-axis. The angular distance is defined as \(\Delta R=\sqrt{(\Delta\eta)^{2}+(\Delta\phi)^{2}}\).

The current detector consists of an inner detector (ID) surrounded by a thin superconducting solenoid providing a 2 T axial magnetic field, electromagnetic and hadronic calorimeters, and a muon spectrometer. The ID covers the pseudorapidity range \(|\eta|<2.5\) and consists of silicon pixel and microstrip detectors, as well as a transition radiation tracker that provides additional electron and pion identification. The ID will be replaced by the inner tracker (ITk) during Phase-II upgrades, in preparation for running at the HL-LHC. The ITk will comprise of a silicon pixel detector [11] complemented by a silicon strip detector [12], together allowing track reconstruction in the range \(|\eta|<4.0\). A minimum number of 9 measurements is assured throughout the angular acceptance range, with an average of about 13 pixel plus strip detectors measurements for most of the acceptance range.

A critical aspect for this study is the reconstruction of charged particles in the ITk. The design goal of the ITk is to maintain high efficiency for charged particles above \(p_{\mathrm{T}}>1\) GeV and to have a low number of wrong combinations of measurements (fake tracks). The minimum reconstructed \(p_{\mathrm{T}}\) and the minimum number of measurements required for track reconstruction in ITk is reported in Table 1 and is referred to as the HL-LHC baseline reconstruction, comparing with the Run 2 detector.

The new whole-silicon inner tracker allows a much stronger rejection of fake tracks compared to the present ID, resulting in a negligible fake rate for tracks with \(p_{\mathrm{T}}>1\) GeV. The longitudinal impact parameter (\(z_{0}\)) resolution is improved with the ITk relative to the Run 2 ID, going from about 100 \(\mathrm{\SIUnitSymbolMicro m}\) to about 50 \(\mathrm{\SIUnitSymbolMicro m}\) in the central region for a representative \(p_{\mathrm{T}}\) of 2 GeV. Figure 1 shows that the \(z_{0}\) resolution worsens in the

\begin{table}
\begin{tabular}{l|c|c c c}  & Run 2 ID & \multicolumn{3}{c}{ITk (HL-LHC baseline)} \\  & \(|\eta|<2.5\) & \(|\eta|<2.0\) & \(2.0<|\eta|<2.6\) & \(2.6<|\eta|<4.0\) \\ \hline Min. \(p_{\mathrm{T}}\) [MeV] & 500 & 900 & 400 & 400 \\ Min. number of Si hits & 7 & 9 & 8 & 7 \\ \hline \end{tabular}
\end{table}
Table 1: Minimum \(p_{\mathrm{T}}\) and minimum number of required silicon (pixel + strips) hits for track reconstruction in the current Run 2 ID and foreseen for ITk. The latter is further segmented in three \(|\eta|\) regions. It is this set of track reconstruction requirements that is referred to as the “HL-LHC baseline” configuration.

forward region of the ITk, due to increased material budget and longer extrapolation distance, to a bit more than 1 mm at the edge of the angular acceptance. Similarly, the \(p_{\mathrm{T}}\) resolution worsens in the forward region relative to central \(\eta\) values due to the fact that the solenoid field in this region is weaker and the transverse path length of the tracks is shorter; the degrading resolution requires to loosen the \(p_{\mathrm{T}}\) requirements on the reconstructed tracks in this region, in order to ensure full efficiency for charged particle reconstruction with transverse momenta above 1 GeV. For more details on the performance of track reconstruction in ITk, see Ref. [13].

Tracks with \(p_{\mathrm{T}}\) below the baseline thresholds given in Table 1 are reconstructed as a second pass on the leftover hits from the default reconstruction with a \(z\)-window restriction around the signal vertex, following the strategy described in Ref. [14]. This process is very time intensive and therefore for this study a parametrised approach is utilised to investigate how a lower reconstructed track \(p_{\mathrm{T}}\) affects this measurement. The parameterised track efficiency and \(z_{0}\) resolution values were estimated from a fully-simulated \(t\overline{t}\) sample with \(\mu=200\), described in Section 3, where a preliminary low-\(p_{\mathrm{T}}\) configuration has been developed to provide reasonable efficiency for tracks with \(p_{\mathrm{T}}>500\) MeV and \(|\eta|<2.5\). It is assumed such a reconstruction can be developed for nominal pileup conditions whilst maintaining sufficiently low fake rate. Charged particles below the minimum reconstructed threshold were weighted by the parametrised reconstruction efficiencies as a function of \(p_{\mathrm{T}}\) and \(\eta\). The production-vertex \(z\)-position of each charged particle was smeared by a Gaussian distribution with a width equal to the parametrised track resolution, as given in Figure 1, also as a function of \(p_{\mathrm{T}}\) and \(\eta\). The inefficiency of reconstructing any charged particle was then calculated as \(\prod_{i}(1-\varepsilon^{i}_{\mathrm{trk}})\), where \(\varepsilon^{i}_{\mathrm{trk}}\) is the probability of reconstructing the \(i^{\mathrm{th}}\) charged particle in the event. Therefore, the product over charged particles in the exclusive phase-space gives the probability of reconstructing the event to have zero additional tracks, i.e. the probability that the event passes the exclusivity criterion as defined in Section 1.

Further changes to the ATLAS detector include the installation of a High-Granularity Timing Detector, based on low gain avalanche detector technology during the ATLAS Phase-II upgrade [15]. The detector is designed to cover the pseudorapidity region between 2.4 and 4.0, with a timing resolution of 30 ps for minimum-ionizing particles. The detector is projected to significantly improve the suppression of pile-up

Figure 1: The longitudinal impact parameter (\(z_{0}\)) resolution as a function of \(\eta\) and \(p_{T}\) for \(t\overline{t}\) events at pileup \(\mu=200\). Details on this sample are provided in Section 3.

jets in vector-boson-scattering topologies [16] utilizing track-vertex association. This relies on the time of a vertex being known with high accuracy by averaging the track time-of-arrival in the HGTD of high-\(p_{\mathrm{T}}\) good-quality tracks attached to it and then rejecting those jets with tracks inconsistent with the timing of the primary vertex. As the signal process studied here has only very few tracks associated to the primary vertex, whose timing cannot be as well determined, possible gains are expected to be less than for other measurements and are not investigated in this note.

## 3 Simulated event samples

Dedicated HL-LHC Monte Carlo (MC) samples were produced with \(\sqrt{s}=14\) TeV and \(\mu=200\) for the signal \(\gamma\gamma\to WW\) process and the main background process, \(qq\to WW\). These samples were used to calculate signal and background selection efficiencies compared to Run 2 and these efficiencies were then used to extrapolate the expected Run 2 yields to the HL-LHC. The HL-LHC samples use the same generators as the Run 2 samples (listed in Ref. [1]) though in some cases use updated versions of the generators.

The elastic component of the \(\gamma\gamma\to WW\) signal process was modelled at leading order (LO) using using MG5_aMC@NLO 2.8.1 [17] interfaced to Pythia 8.244. The default photon flux in MG5_aMC@NLO and the CT14QED [18] parton distribution function (PDF) were used to model coherent and incoherent photon emissions, respectively. The elastic sample cross-section was corrected to account for the dissociative components of the signal which are not included in the simulation, using a signal modelling correction derived in the Run 2 analysis [1]. The signal modelling correction is a data-driven correction factor obtained from a \(\gamma\gamma\to\ell\ell\) (\(\ell=e,\mu\)) control sample, following a procedure similar to that applied in Refs. [2; 4]. It also corrects for effects from the rescattering of protons, which are related to possible additional gluon interactions between the protons (or proton remnants). It is assumed that this correction factor does not change significantly between Run 2 and the HL-LHC and the HL-LHC value was therefore taken to be equal to the value calculated in the Run 2 analysis [1], which is \(3.59\pm 0.15\).

The dominant \(qq\to WW\) background was modelled using Powheg-Box v2 with the CT10 [19] PDF for the matrix element calculation. It was interfaced to Herwig 7.2.1 using the H7UE tune [20] and the MMHT2014LO PDF set [21] for the parton shower.

The performance of the track reconstruction was studied using \(t\bar{t}\) events where the average number of pileup interactions was either set to zero or to \(\mu=200\). The production of these events was modelled using the Powheg Box v2 [22; 23; 24; 25] generator at NLO with the NNPDF3.0NLO [26] PDF set and the \(h_{\mathrm{damp}}\) parameter3 set to \(1.5\,m_{\mathrm{top}}\)[27]. The events were interfaced to Pythia 8.240p4 [28] to model the parton shower, hadronisation, and underlying event, with parameters set according to the A14 tune [29] and using the NNPDF2.3LO set of PDFs [30].

Footnote 3: The \(h_{\mathrm{damp}}\) parameter is a resummation damping factor and one of the parameters that controls the matching of Powheg matrix elements to the parton shower and thus effectively regulates the high-\(p_{\mathrm{T}}\) radiation against which the \(t\bar{t}\) system recoils.

The effect of multiple interactions in the same and neighbouring bunch crossings (pileup) was modelled by overlaying the simulated hard-scattering event with inelastic \(pp\) events generated with Pythia 8.244p3 [31] using the NNPDF2.3LO set of PDFs [30] and the A3 set of tuned parameters [32]. Charm and bottom decays were modelled using the EvtGen 1.7.0 programme.

The event samples were processed with a full detector simulation of ATLAS [33] using Geant4 [34], including the ITk layout as described in Ref. [13].

## 4 Event selection

The event selection follows the same logic as prescribed in the Run 2 \(\gamma\gamma\to WW\) analysis at 13 TeV [1], with a few important changes and additions described in this section. The signal region (SR) is defined by applying the event selection at the reconstruction level summarised in Table 2.

One of the most important selections applied in this analysis is the \(n_{\mathrm{trk}}=0\) requirement, which is how exclusivity is defined. Exclusive processes like \(\gamma\gamma\to WW\) are produced with very little or no activity in the central detector, other than from the decay of the \(W\)-bosons. Conversely, inclusive backgrounds like \(qq\to WW\) are accompanied by an underlying event (UE) where the proton remnants undergo additional soft interactions, resulting in additional tracks associated to the hard-scatter vertex. The \(n_{\mathrm{trk}}=0\) requirement exploits this difference between exclusive and inclusive processes by requiring no charged-particle tracks, other than the two from the leptons, to be reconstructed within a symmetric \(z\)-window around the dilepton vertex, referred to as the track-veto window. The larger the window, the more likely that a track not associated to the hard-scatter (i.e. a track originating from a pileup vertex) is to fall within it, causing the event to fail the \(n_{\mathrm{trk}}=0\) requirement. On the other hand, the smaller the window, the more likely that tracks associated to the UE of the \(qq\to WW\) background fall outside of it due to finite \(z_{0}\) resolution or because they are due to a hadronic interaction and subsequent secondary-particle production and slightly displaced with regards to the interaction vertex. Therefore, the optimal window size is a compromise between retaining as much signal as possible whilst also rejecting as much background as possible.

The track-veto window definition is depicted in Figure 2. The size of this window was optimised to be 1 mm in the Run 2 analysis [1] and window sizes ranging between 0.1-1 mm are investigated for the HL-LHC projection. The impact of the minimum reconstructed-track \(p_{\mathrm{T}}\) is considered for the \(n_{\mathrm{trk}}=0\) requirement, and investigations on the effect of lowering the baseline minimum \(p_{\mathrm{T}}\) (see Table 1) to 500 MeV are presented in the next sections. The effect of the extended tracking acceptance of the upgraded inner tracker (\(|\eta|<4.0\)) is also investigated compared to a baseline similar to Run 2 where only central (\(|\eta|<2.5\)

\begin{table}
\begin{tabular}{l l} \hline Reconstruction-level selection requirement & Reconstruction-level selection value \\ \hline Single-lepton transverse momentum & \(p_{\mathrm{T}}>27\) GeV (leading), \(p_{\mathrm{T}}>20\) GeV (subleading) \\ Electron pseudorapidity & \(|\eta|<2.47\), excluding \(1.37<|\eta|<1.52\) \\ Muon pseudorapidity & \(|\eta|<2.4\) \\ Dilepton selection & Exactly 2 leptons (\(e^{+}\mu^{-}\) or \(e^{-}\mu^{+}\)) \\ Dilepton vertex & \(z_{\mathrm{vtx}}^{\ell\ell}=(z_{\ell_{1}}\sin^{2}\theta_{\ell_{1}}+z_{\ell_{2} }\sin^{2}\theta_{\ell_{2}})/(\sin^{2}\theta_{\ell_{1}}+\sin^{2}\theta_{\ell_{ 2}})\) \\ Lepton-vertex association & \(|z_{\ell}-z_{\mathrm{vtx}}^{\ell\ell}|<0.5\) mm \\ Dilepton mass & \(m_{\ell\ell}>20\) GeV \\ Dilepton transverse momentum & \(p_{\mathrm{T}}^{\ell\ell}>30\) GeV \\ Exclusivity definition & \(n_{\mathrm{trk}}=0\) \\ \hline \end{tabular}
\end{table}
Table 2: The reconstruction level selections that define the signal region. The \(n_{\mathrm{trk}}=0\) requirement refers to primary charged tracks that have passed track selections discussed in the text and that fall within a symmetric \(z\)-window around the dilepton vertex. The dilepton vertex is reconstructed from the two leptons in the event, \(\ell_{1}\) and \(\ell_{2}\), as the weighted average \(z\)-position of the lepton tracks extrapolated to the beam line, where \(\sin^{2}\theta_{\ell}\) approximately parametrises the resolution of the \(z\)-positiontracks are considered. All reconstructed tracks are also required to have a transverse impact parameter \(|d_{0}|<1.0\) mm.

The luminous region, or beamspot, refers to the region around the interaction point where collisions take place within the ATLAS detector. The size of the beamspot determines the vertex and track density, variations of which impact the probability of both signal and background events passing the \(n_{\rm trk}=0\) requirement. It is sensitive to the machine optics and can vary with time. Specifically, the beamspot size can differ between data and MC simulation, which is produced before the data taking. It was simulated to have a Gaussian shape with longitudinal size of \(\sigma_{z}=42\) mm in Run 2 MC whereas the average beamspot size in data was around 35 mm. For this reason, a dedicated track \(z\)-rescaling was applied in the Run 2 analysis [1] to correct for these differences. The beamspot was simulated in the HL-LHC MC to have a longitudinal size of \(\sigma_{z}=45\) mm and no corrections were applied.

## 5 Projection Strategy

Three different HL-LHC configurations are investigated:

1. Nominal configuration - Baseline HL-LHC track reconstruction (see Table 1) with track-\(|\eta|<2.5\).
2. Forward-tracking configuration - Baseline HL-LHC track reconstruction with track-\(|\eta|<4.0\).
3. Low-\(p_{\rm T}\) configuration - Track-\(p_{\rm T}>500\) MeV, track-\(|\eta|<2.5\).

The expected signal yield at the HL-LHC, \(N_{\rm signal}^{\rm HL\text{-LHC}}\), can be calculated as a function of the expected Run 2 yields, \(N_{\rm signal}^{\rm Run\,2}\), considering the ratio of various efficiencies related to operating conditions and detector

Figure 2: A diagram of the symmetric track-veto window, centered in \(z\) around the lepton vertex. Scans of the beamspot width, \(\sigma_{z}\) are also performed, in increments of the window size, in order to count pileup tracks and evaluate the probability of measuring \(n_{\rm trk}=0\) in the presence of pileup. The window size is exaggerated here for clarity. Figure taken from auxiliary material of Ref. [1].

performance between the HL-LHC and Run 2:

\[N_{\text{signal}}^{\text{HL-LHC}}=N_{\text{signal}}^{\text{Run 2}}\times\frac{ \mathcal{L}_{\text{HL-LHC}}}{\mathcal{L}_{\text{Run 2}}}\times\frac{\varepsilon_{\text{ pileup}}^{\text{HL-LHC}}}{\varepsilon_{\text{ pileup}}^{\text{Run 2}}}\times\frac{\varepsilon_{\gamma\gamma WW}^{\text{HL-LHC}}}{\varepsilon_{ \gamma\gamma WW}^{\text{Run 2}}}, \tag{1}\]

where \(\mathcal{L}\) is the integrated luminosity, \(\varepsilon_{\gamma\gamma WW}\) is the efficiency of passing the event selections (Table 2) without taking into account pileup effects in the exclusivity requirement calculation, and \(\varepsilon_{\text{pileup}}\) is the efficiency of the signal passing the \(n_{\text{trk}}=0\) requirement when in the presence of pileup, i.e. when \(\mu>0\). The integrated luminosity at the HL-LHC is predicted to be \(3000\,\text{fb}^{-1}\)[8], around twenty times that of Run 2.

The signal selection efficiency of the lepton vertex, \(\varepsilon_{\gamma\gamma WW}\), is expected, to first order, to be very close to the Run 2 value; when varying the size of the \(z\)-window considered for the exclusivity requirement, an additional correction is considered measuring the probability for both leptons to fall within the \(z\)-window of interest. This requirement is more than 98% efficient for all window sizes investigated, with the exception of the smallest window size of 0.1 mm, where the efficiency drops to 94%. Therefore, \(\varepsilon_{\gamma\gamma WW}\) is a minor consideration, even at the smallest track-veto window size.

The efficiency for pileup effects, \(\varepsilon_{\text{pileup}}\), can be calculated using truth information in simulation or using the same data-driven procedure outlined in Ref. [1] which is demonstrated in Figure 2. The pileup efficiency depends on track-veto window size, as shown in Figure 3.

The smaller the track-veto window, the smaller the probability that a pileup track falls within it. Therefore, the probability of the exclusive signal passing the \(n_{\text{trk}}=0\) requirement increases as the window size decreases. The pileup efficiency is lower than the Run 2 value at a window size of 1 mm for all configurations investigated due to the much denser pileup environment at the HL-LHC. Increasing the tracking acceptance from \(|\eta|<2.5\) to \(|\eta|<4.0\) increases the probability of reconstructing pileup tracks and therefore decreases the pileup efficiency relative to the

Figure 3: The pileup efficiency, \(\varepsilon_{\text{pileup}}\), as a function of window size and for the three different HL-LHC configurations investigated. The efficiency in MC the Run 2 analysis [1] is marked by a red cross at the optimal Run 2 window size of 1 mm. Uncertainties on each point are statistical only and are generally too small to see.

baseline \(|\eta|<2.5\) configuration. Similarly, reconstructing tracks with lower \(p_{\rm T}\) also increases the number of pileup tracks that are reconstructed within the track-veto window, decreasing the pileup efficiency. If the pileup efficiency, as shown in Figure 3, was the only consideration, the optimal analysis would be the baseline HL-LHC reconstruction with track-\(|\eta|<2.5\) and with an infinitesimal window size.

The background extrapolation contains many of the same considerations as the signal, with \(\varepsilon_{qqWW}\) in place of \(\varepsilon_{\gamma\gamma WW}\):

\[N_{\rm bkgd.}^{\rm HL-LHC}=N_{\rm bkgd.}^{\rm Run\;2}\times\frac{\mathcal{L}_{ \rm HL-LHC}}{\mathcal{L}_{\rm Run\;2}}\times\frac{\varepsilon_{\rm pileup}^{ \rm HL-LHC}}{\varepsilon_{\rm pileup}^{\rm Run\;2}}\times\frac{\varepsilon_{qq WW}^{\rm HL-LHC}}{\varepsilon_{qqWW}^{\rm Run\;2}}. \tag{2}\]

The background efficiency, \(\varepsilon_{qqWW}\), is dominated by the probability of the inclusive background having no reconstructed tracks originating from the UE. The background process can pass the \(n_{\rm trk}=0\) requirement if additional tracks from the UE are either too soft or too forward to be reconstructed, i.e. if additional tracks are below the minimum-\(p_{\rm T}\) threshold reconstructed or outside of the detector acceptance. This background efficiency decreases as the track-veto \(z\)-window size increases, as shown in Figure 4.

As the background efficiency is a measure of the hard-scatter process and underlying event, it is independent of pileup and therefore it is expected that the efficiency should be similar between Run 2 and the HL-LHC if the detector acceptance and performance is similar between the two. This can be seen in Figure 4 by comparing the track-\(p_{\rm T}>500\) MeV, track-\(|\eta|<2.5\) configuration to the Run 2 result at a window size of 1 mm. This HL-LHC configuration was chosen to closely match the Run 2 configuration.

The background efficiency starts to increase rapidly at the smallest window sizes, due to tracks from the underlying event being reconstructed outside of the track-veto window when the size is comparable to the track \(z_{0}\) resolution. Increasing the tracking acceptance reduces the background efficiency due to being

Figure 4: The efficiency of the dominant \(qq\to WW\) background passing the \(n_{\rm trk}=0\) requirement, once all other event selections have been applied. The efficiency for the three different HL-LHC configurations is shown as a function of the track-veto window size and compared directly to the result in Run 2 which is marked by a red cross. Uncertainties on each point are statistical only. Analysis specific corrections, such as the charged particle multiplicity correction described in Ref. [1], are assumed to cancel between Run 2 and the HL-LHC.

able to reconstruct additional UE tracks that are produced in the forward region. However, the largest reduction in the background efficiency is seen when the minimum track-\(p_{\mathrm{T}}\) threshold can be reduced to 500 \(\mathrm{Me\kern-1.0ptV}\) from the baseline reconstruction given in Table 1. This is because UE tracks are produced from soft interactions, usually with very low-\(p_{\mathrm{T}}\)[35]. By lowering the track \(p_{\mathrm{T}}\) threshold, more of these UE tracks can be reconstructed and it is possible to better reject inclusive backgrounds like \(qq\to WW\). If the background efficiency was the only consideration in this analysis, the optimal setup would be to reconstruct tracks low in \(p_{\mathrm{T}}\) and have a window size that covered the entire beamspot. Unfortunately, this is in direct contradiction with the optimal setup when only considering the pileup efficiency in Figure 3. Hence, the analysis must be optimised to find a middle-ground between these two efficiencies.

When extrapolating the Run 2 yields using Eqs. (1) and (2), it is implicitly assumed that the total background yield scales in the same way as the \(qq\to WW\) yield which is only true for inclusive processes like \(qq\to Z/\gamma^{*}\to\ell\ell\). Exclusive backgrounds like \(\gamma\gamma\to\ell\ell\) are not affected by this efficiency due to a lack of underlying event. This assumption is motivated by the fact that \(qq\to WW\) is the dominant background, making up 75% 4 of the Run 2 background yield in the SR, with exclusive backgrounds contributing around 10%. The remaining backgrounds include Drell-Yan and other diboson processes that scale in a similar way to \(qq\to WW\).

Footnote 4: The yields for \(qq\to WW\) also contain a small contribution from gluon-induced \(WW\) and electroweak \(WWjj\) production.

When considering the differential analysis in \(m_{\ell\ell}\), a fixed window size is used. It is assumed that all efficiencies affecting the signal, as given in Eq. (1), are constant at any fixed window size and are independent of \(m_{\ell\ell}\). Therefore, the only \(m_{\ell\ell}\) dependence in Eq. (1) is due to \(N_{\mathrm{signal}}^{\mathrm{Run}\,2}\) which peaks between \(60<m_{\ell\ell}<80\)\(\mathrm{Ge\kern-1.0ptV}\). The background efficiency, \(\varepsilon_{qqWW}\), in Eq. (2) decreases with increasing \(m_{\ell\ell}\) due to larger proton deceleration producing a harder underlying event, resulting in more tracks being reconstructed and therefore reducing the probability that the background passes the \(n_{\mathrm{ttk}}=0\) requirement.

Systematic uncertainties were assumed to remain unchanged between the HL-LHC and Run 2, where the largest source of systematic uncertainty was due to background modelling of the underlying event, giving an uncertainty on the background yield of \(\pm 12\) %. This is a pessimistic approach as it is likely that modelling uncertainties will be reduced before the start of HL-LHC data-taking and analysis, with the increased LHC dataset to feed into theory predictions. Therefore reduced background systematic uncertainties of 6% and 3% were also considered and compared to the nominal projection.

As the signal and background yields are not calculated directly from the HL-LHC samples and are instead calculated by extrapolating the Run 2 yields using the ratios of various efficiencies, as given in Eqs. (1) and (2), the changes in cross-section going from \(\sqrt{s}=13\)\(\mathrm{Te\kern-1.0ptV}\) to \(\sqrt{s}=14\)\(\mathrm{Te\kern-1.0ptV}\) are not included in the expected HL-LHC yields. An estimate of this size of this effect is given for both an inclusive and differential cross-section measurement in Section 6.

## 6 Results

The results are presented in two parts. The first part reports results on the expected sensitivity for a fiducial cross-section analysis as a function of track-veto \(z\)-window size. In order to optimise to the denser tracking environment at the HL-LHC, the impact of various potential improvements from the Run 2 approach are also assessed. Several directions are investigated one at the time in Section 6.1: The impact of the minimum \(p_{\mathrm{T}}\) of reconstructed tracks is assessed using the procedure outlined in Section 2; the sensitivity found in a central-only analysis with track-\(|\eta|<2.5\) is then compared to an extended tracking range of \(|\eta|<4.0\);the impact of using a more sophisticated exclusivity definition based on multivariate techniques is also briefly discussed. The second part reports the result differentially in the dilepton mass for the optimal configuration found in the fiducial measurement, to investigate sensitivity in the high \(m_{\ell\ell}\) region.

Results are presented as both the absolute expected signal and background yield, as well as the relative uncertainties on the signal yield. All results are compared to those in the nominal Run 2 analysis [1], which had a track-veto window size of 1 mm and reconstructed tracks with \(p_{\mathrm{T}}>500\) MeV and \(|\eta|<2.5\).

### Inclusive fiducial measurement

The metric used to quantify the expected sensitivity at the HL-LHC is the relative uncertainty on the extracted signal yield after selections and background subtraction.

The statistical-only uncertainty is then defined as:

\[\sigma_{\mathrm{stat.}}/N_{\mathrm{sig.}}=\sqrt{N_{\mathrm{sig.}}+N_{\mathrm{ bkgd.}}}/N_{\mathrm{sig.}}, \tag{3}\]

while the total relative uncertainty on the extracted signal yield is defined as

\[\sigma_{\mathrm{tot.}}/N_{\mathrm{sig.}}=\sqrt{N_{\mathrm{sig.}}+N_{\mathrm{ bkgd.}}+(xN_{\mathrm{bkgd.}})^{2}}/N_{\mathrm{sig.}}, \tag{4}\]

where \(x\) represents the fractional systematic on the background yield, nominally taken to be 0.12 as in the Run 2 analysis [1].

The expected signal and background yields after selections are calculated separately for the three different HL-LHC configurations listed in Section 5. The results are shown in Table 3, together with the expected statistical-only and total relative uncertainty on the extracted signal, calculated using Eqs. (3) and (4) respectively. The Run 2 yields are also shown with uncertainties calculated in the same way. Both the efficiency in pileup and the \(qq\to WW\) background efficiency increase as the window size is decreased. While for Run 2, it was better to have a window width that was many times the tracking resolution in order to consider tracks from the background UE, the denser pileup environment at the HL-LHC results in the optimal window being narrower to reduce signal losses. When considering statistical uncertainties only,

\begin{table}
\begin{tabular}{l|r|r|r|r} Configuration & \(N_{\mathrm{sig.}}\) & \(N_{\mathrm{bkgd.}}\) & \(\sigma_{\mathrm{stat.}}/N_{\mathrm{sig.}}\) & \(\sigma_{\mathrm{tot.}}/N_{\mathrm{sig.}}\) \\ \hline Run 2 & 174 & 132 & 0.10 & 0.14 \\ \hline
1 mm window & & & & \\ \hline HL-LHC baseline, track-\(|\eta|<2.5\) & 929 & 2 840 & 0.07 & 0.37 \\ HL-LHC baseline, track-\(|\eta|<4.0\) & 209 & 281 & 0.11 & 0.19 \\ Track-\(p_{\mathrm{T}}>500\) MeV, track-\(|\eta|<2.5\) & 611 & 323 & 0.05 & 0.08 \\ \hline
0.2 mm window & & & & \\ \hline HL-LHC baseline, track-\(|\eta|<2.5\) & 2 930 & 15 300 & 0.05 & 0.63 \\ HL-LHC baseline, track-\(|\eta|<4.0\) & 934 & 3 560 & 0.07 & 0.46 \\ Track-\(p_{\mathrm{T}}>500\) MeV, track-\(|\eta|<2.5\) & 1 684 & 2 410 & 0.04 & 0.18 \\ \end{tabular}
\end{table}
Table 3: Expected number of signal and background events, the expected statistical-only and the total relative uncertainty on the extracted signal are shown for the configurations tests in this note. A luminosity of 3000 fb\({}^{-1}\) and a background systematic of 12% are assumed. The HL-LHC baseline track reconstruction is given in Table 1.

the optimal window size is 0.2 mm but becomes wider when introducing systematic uncertainties on the large background yields. The effect of a lower reconstructed track-\(p_{\mathrm{T}}\) threshold reduces the efficiency in pileup simply due to more pileup tracks being reconstructed, which in turn reduces both signal and background yields. However, a lower threshold also largely reduces the background efficiency due to the ability to reconstruct more tracks from the UE, which generally have very low-\(p_{\mathrm{T}}\). Therefore, lowering the track-\(p_{\mathrm{T}}\) threshold from the HL-LHC baseline to 500 MeV improves the signal to background ratio.

When considering the effect of systematics, Figures 5(a)-5(d) show the relative uncertainty on the signal yield for the baseline and the lower-\(p_{\mathrm{T}}\) configurations. The total uncertainty, as given in Eq. (4), is reduced relative to the Run 2 uncertainty for many window sizes, when considering a background systematic of \(\pm\) 12% and reconstructing tracks with \(p_{\mathrm{T}}>500\) MeV, shown in Figure 5(c). This is not the case if the baseline track reconstruction is used, shown in Figure 5(a). Figures 5(a)-5(c) also show the impact of a lower background modelling uncertainty. A lower background systematic uncertainty is seen as a key requirement to make the measurement competitive when such a large dataset will be available.

The analysis was repeated with an extended tracking acceptance from the ITk of \(|\eta|<4.0\) when using the baseline HL-LHC track reconstruction and results are shown in Figure 5(b). The signal yield in the central plus forward regions is reduced to 32% (55%) of the central-only yield for a 0.2 mm window and baseline (low) \(p_{\mathrm{T}}\) tracking, as shown in Table 3. The background yield is reduced to 23% of the central-only yield when reconstructing tracks with baseline \(p_{\mathrm{T}}\) requirements. This is partly due to the increased tracking acceptance making it more likely to reconstruct tracks from the \(qq\to WW\) hard-scatter but also due to the poor tracking \(z_{0}\) resolution in the forward-\(\eta\) region. The degrading resolution with increasing track-\(\eta\) causes an increase in the number of pileup tracks not associated to the hard-scatter that migrate into the track-veto window, providing additional background rejection but also causing large signal losses. The background yield is still increased by almost 50% for this configuration compared to the track-\(p_{\mathrm{T}}>500\) MeV, track-\(|\eta|<2.5\) configuration, despite the relative increase in tracking acceptance.

For the baseline track reconstruction, an analysis that uses the forward-tracking region would likely bring slight gains in \(\gamma\gamma\to WW\) signal significance compared to a central-only analysis, especially when considering a background systematic of 12%. However, the reduction in the background yield caused by the increased tracking acceptance is not enough to compensate the large background yields accumulated from the increase in minimum track-\(p_{\mathrm{T}}\) compared to Run 2. This results in a relative uncertainty on the signal that is still almost roughly 1.4 times the size of the relative uncertainty on the Run 2 result at the nominal 1 mm window. The only way to improve on Run 2 with baseline tracking is to reduce the background systematics by at least a factor of 2. Reducing the background yield by a factor of 2-4 would have a similar effect, although it is extremely difficult to do this without also losing signal, as has been demonstrated. The largest improvement is seen for the low-\(p_{\mathrm{T}}\) configuration, which reduces the total uncertainty on the signal to less than 60% of the Run 2 value for the nominal 1 mm window. Figure 5(d) compares the total uncertainty of the three different HL-LHC configurations when considering the nominal background systematic of 12% and shows that the configuration in which tracks can be reconstructed with \(p_{\mathrm{T}}>500\) MeV is optimal for all window sizes investigated.

For the forward tracking configuration, no changes in the signal modelling correction, as briefly discussed in Section 3, are considered. An increased tracking acceptance means that tracks from proton dissociation are more likely to be reconstructed, potentially causing the dissociative signal to fail the \(n_{\mathrm{trk}}=0\) requirement and resulting in further signal loss. A generator-level acceptance study predicted that the relative reduction in the signal modelling correction would be within 8% of the Run 2 value when extending the tracking acceptance 
Figure 5: A comparison of the relative uncertainty on the signal for (a) the baseline HL-LHC track reconstruction, when considering the central detector only (\(|\eta|<2.5\)), (b) the baseline HL-LHC track reconstruction with an extended tracking acceptance of \(|\eta|<4.0\), (c) low-\(p_{\rm T}\) tracking (\(p_{\rm T}>500\) MeV) and \(|\eta|<2.5\), (d) a comparison of all setups when considering a nominal systematic on the background of 12%. Each plot shows the relative uncertainty for different sizes of background systematics.

from \(|\eta|<2.5\) to \(|\eta|<4.0\). Therefore, it can be expected to lose up to an additional 8% of the signal yields quoted above for the forward tracking configuration. The background yields are unaffected by this correction.

The conclusion of this study is that it will be possible to perform a measurement of the fiducial \(\gamma\gamma\to WW\) cross-section at the HL-LHC with baseline track reconstruction but it will be challenging to improve on the Run 2 precision without improved background suppression or improved background modelling leading to reduced background systematics. It is not unreasonable to assume that modelling will improve before and during HL-LHC data-taking but modelling systematics of the UE will have to be reduced by over a factor of 2 before the relative uncertainty on the signal is halved compared to Run 2, in the best case scenario. It has been demonstrated in this study that dedicated low-\(p_{\mathrm{T}}\) tracking below the baseline ITk reconstruction will be crucial for the \(\gamma\gamma\to WW\) analysis at the HL-LHC and therefore this is an important area of research and development that should continue to be pursued. Not included in the results is the expected increase in cross-section going from \(\sqrt{s}=13\) TeV to \(\sqrt{s}=14\) TeV. This increase is expected to be roughly 10% for both the elastic \(\gamma\gamma\to WW\) and \(qq\to WW\) processes.

A multivariate approach based on a neutral network was also explored to enhance signal to background separation for the baseline configuration. The neural network was trained using the Keras [36] framework. All tracks within a 2 mm window of the dilepton vertex were selected and the 15 reconstructed tracks closest to the dilepton vertex were used as input to the network. If less than 15 tracks were present, a default (un-physical) value was assigned to the properties of the remaining tracks. The distance between reconstructed tracks and the dilepton vertex, safe track quality variables (such as number of hits), and event-level variables (such as the average pileup) were used as input variables. Properties such as track momentum were not used at this stage, given the expected poorer modelling of the simulation for this quantity, but could be explored in the future thanks to more refined and dedicated measurements. Such an approach results in a gain in sensitivity that strongly depends on the assumed systematic uncertainty. Counting experiments using events passing optimised selections on the neural-network output yield between 10% (stat. only) to a factor up to about 5 (nominal systematics) improvement on the expected cross-section uncertainty, when evaluated using Eqs. (3) and (4) and compared to the baseline approach with 1 mm window. It is also worth noting that such an approach is expected to become more powerful when lower momentum tracks are included, resulting in a larger probability to reconstruct more than one track per near-by pileup interactions and therefore giving a better handle to not consider those tracks when evaluating if to keep or reject the given event.

Other methods to suppress the background, such as through proton-tagging with the ATLAS Forward Proton (AFP) detector [37], are beyond the scope of this note.

### Differential measurement in \(m_{\ell\ell}\)

The increase in statistical precision at the HL-LHC opens up the potential to study the high-energy tails of distributions that were limited by statistical uncertainties in Run 2. The analysis was performed differentially in \(m_{\ell\ell}\) with the aim of probing the measurement sensitivity in the high-\(m_{\ell\ell}\) region for EFT fitting prospects, where the analysis is expected to be most sensitive to dimension-8 operators. The \(m_{\ell\ell}\) binning is chosen in order to maintain a similar number of signal events in each bin (with the exception of the overflow bin at the highest \(m_{\ell\ell}\) value). Although Figure 5 shows that the relative uncertainty on the signal is fairly flat with increasing window size when background systematics are considered, a window size of 0.2 mm is chosen for the differential analysis in \(m_{\ell\ell}\) to minimise the relative statistical uncertainty in each bin, which becomes particularly important at high-\(m_{\ell\ell}\) where yields are low. The differential analysis is performed with track-\(p_{\mathrm{T}}>500\) MeV and track-\(|\eta|<2.5\), as this setup was found to have the best signal precision in Section 6.1.

The expected signal and background yields decrease with increasing \(m_{\ell\ell}\), the background yield falls faster due to the decreasing background efficiency and therefore the signal to background ratio increases with increasing \(m_{\ell\ell}\). The predicted HL-LHC yields in the SR are shown, with their relative statistical and total uncertainty, in Figure 6(a) and a comparison of the statistical to total uncertainties with different levels of background systematics is given in Figure 6(b), as well as a comparison to the Run 2 values. The statistical uncertainty is reduced by a factor of 2.6 in the \(200<m_{\ell\ell}<380\) bin, when comparing to the Run 2 expected yields separated with the same binning in \(m_{\ell\ell}\). However, the relative systematic uncertainty is almost two times larger when considering the nominal 12% background systematic due to the much larger background yield. The relative total uncertainty on the signal is reduced by almost 50% in the \(200<m_{\ell\ell}<380\) bin compared to Run 2, even when considering the nominal 12% background systematic. An even larger relative improvement is found in the \(m_{\ell\ell}>380\) region due to the very large Run 2 statistical uncertainty in this bin.

Figure 6(b) demonstrates the effect of reducing the background systematics by a factor of 2 and 4. It is seen that reducing the background systematic has a large effect at low \(m_{\ell\ell}\) but is not so important at high \(m_{\ell\ell}\) where background yields are much smaller. Even with the large increase in integrated luminosity at the HL-LHC, the statistical uncertainty on the signal yield begins to dominate in the highest \(m_{\ell\ell}\) bins but is still largely reduced relative to Run 2. A roughly 64% reduction on Run 2 in expected relative statistical uncertainty and almost 50% reduction in relative total uncertainty is seen in the \(200<m_{\ell\ell}<380\) bin. Improving background modelling systematics of the underlying event before HL-LHC data analysis begins should remain a priority in order to keep up with improvements in statistical precision but it is not as crucial as for a fiducial measurement when studying tails of distributions where yields are low. The results in the differential analysis assume that dedicated low-\(p_{\mathrm{T}}\) tracking will be possible and therefore focus on optimising low-\(p_{\mathrm{T}}\) reconstruction methods at the HL-LHC is required. Not included in the results are changes in cross-section going from \(\sqrt{s}=13\) to \(\sqrt{s}=14\). These increases are expected to range from roughly 2% in the lowest \(m_{\ell\ell}\) bin to 16% in the highest \(m_{\ell\ell}\) bin, for the elastic \(\gamma\gamma\to WW\) process.

\begin{table}
\begin{tabular}{l r r r r r} \hline  & \multicolumn{5}{c}{Dilepton mass [GeV]} \\  & 20–80 & 80–120 & 120–200 & 200–380 & 380+ \\ \hline \multicolumn{1}{l}{**Signal**} & & & & \\ \hline Run 2 & 43 & 39 & 49 & 32 & 10 \\ HL-LHC & 419 & 377 & 477 & 310 & 97 \\ \hline \multicolumn{1}{l}{**Background**} & & & & \\ \hline Run 2 & 54 & 33 & 29 & 13 & 3 \\ HL-LHC & 997 & 603 & 529 & 236 & 50 \\ \hline \end{tabular}
\end{table}
Table 4: Comparison of expected signal and background yields between the Run 2 analysis [1] and the HL-LHC projection in bins of dilepton mass, \(m_{\ell\ell}\), for \(p_{\mathrm{T}}>500\) and \(|\eta|<2.5\) tracking and with a track-veto window-size of 0.2 mm. The Run 2 window size is 1 mm. All yields are rounded to the nearest integer. An integrated luminosity of 3000 and \(\mu=200\) are assumed at the HL-LHC.

## 7 Conclusion

The expected sensitivity to the process \(\gamma\gamma\to WW\to e^{\pm}\nu\mu^{\mp}\nu\) with the ATLAS detector at the HL-LHC, when assuming an integrated luminosity of \(3000\,\mathrm{fb}^{-1}\) and \(\mu=200\), was estimated by projecting the Run 2 analysis [1] and correcting for the main expected differences in performance after the ATLAS Phase-II upgrade. Full-simulation HL-LHC MC samples were used to derive the expected performance of the upgraded ATLAS Inner Tracker. Furthermore, several potential optimisations of the HL-LHC baseline analysis have been investigated, including narrowing the track-veto \(z\)-window size, reducing the minimum-reconstructed track-\(p_{\mathrm{T}}\) to the nominal Run 2 value of \(500\) MeV, increasing the tracking acceptance from \(|\eta|<2.5\) to \(|\eta|<4.0\), and investigating alternative means of signal and background separation using a multivariate classifier. The expected sensitivity to background modeling uncertainties was also investigated. The prospects for a differential analysis in \(m_{\ell\ell}\) were also investigated, with the aim of targeting the high-\(m_{\ell\ell}\) region for improved constraints on Effective-Field-Theory dimension-8 operators. The increased statistical precision at the HL-LHC results in improved prospects in this region, with a roughly \(64\%\) reduction in expected relative statistical uncertainty and almost \(50\%\) reduction in relative total uncertainty in the \(200<m_{\ell\ell}<380\) GeV bin, when using a minimum reconstructed track-\(p_{\mathrm{T}}\) of \(500\) MeV.

The results presented in this study have shown that the higher pileup environment expected at the HL-LHC will give rise to important challenges for accurately identifying exclusive final states. The theoretical modelling uncertainty on the main background becomes a dominant uncertainty with large expected

Figure 6: The expected signal and background yields at the HL-LHC are shown in (a), stacked and as a function of the dilepton mass. The relative statistical and total uncertainty on the signal are shown in the bottom panel of (a), assuming the same background systematic as in Run 2 of \(12\%\). A comparison of the total uncertainty when considering a reduction in the nominal background systematic by a factor of 2 and 4 is shown in (b) and compared to the Run 2 relative uncertainties. The bottom panel in (b) shows the ratio of the total relative uncertainty on the signal yield at the HL-LHC as a ratio to the Run 2 uncertainty. The average pileup in Run 2 was \(\langle\mu\rangle=33.7\).

increases in background yields and efforts to reduce it would ensure it will not limit the overall expected uncertainty on the extracted cross-section. The reconstructed track-\(p_{\mathrm{T}}\) threshold will be a key experimental consideration in the prospects for \(\gamma\gamma\to WW\) analyses at the HL-LHC and further research and development is required to optimise low-\(p_{\mathrm{T}}\) tracking methods for HL-LHC operating conditions.

## References

* [1] ATLAS Collaboration, _Observation of photon-induced \(W^{+}W^{-}\) production in \(pp\) collisions at \(\sqrt{s}=13\) TeV using the ATLAS detector_, Phys. Lett. B **816** (2021) 136190, arXiv: 2010.04019 [hep-ex] (cit. on pp. 2, 5-9, 11, 15, 16).
* [2] ATLAS Collaboration, _Measurement of exclusive \(\gamma\gamma\to W^{+}W^{-}\) production and search for exclusive Higgs boson production in \(pp\) collisions at \(\sqrt{s}=8\) TeV using the ATLAS detector_, Phys. Rev. D **94** (2016) 032011, arXiv: 1607.03745 [hep-ex] (cit. on pp. 2, 5).
* [3] CMS Collaboration, _Study of exclusive two-photon production of \(W^{+}W^{-}\) in \(pp\) collisions at \(\sqrt{s}=7\) TeV and constraints on anomalous quartic gauge couplings_, JHEP **07** (2013) 116, arXiv: 1305.5596 [hep-ex] (cit. on p. 2).
* [4] CMS Collaboration, _Evidence for exclusive \(\gamma\gamma\to W^{+}W^{-}\) production and constraints on anomalous quartic gauge couplings in \(pp\) collisions at \(\sqrt{s}=7\) and \(8\) TeV_, JHEP **08** (2016) 119, arXiv: 1604.04464 [hep-ex] (cit. on pp. 2, 5).
* [5] E. Chapon, C. Royon and O. Kepka, _Anomalous quartic \(WW\gamma\gamma\), \(ZZ\gamma\gamma\), and trilinear \(WW\gamma\) couplings in two-photon processes at high luminosity at the LHC_, Phys. Rev. D **81** (2010) 074003, arXiv: 0912.5161 [hep-ph] (cit. on p. 2).
* [6] I. Bejar Alonso et al., _High-Luminosity Large Hadron Collider (HL-LHC): Technical design report_, 2020, url: [http://cds.cern.ch/record/2749422](http://cds.cern.ch/record/2749422) (cit. on p. 2).
* [7] ATLAS Collaboration, _Expected pile-up values at the HL-LHC_, ATL-UPGRADE-PUB-2013-014, 2013, url: [https://cds.cern.ch/record/1604492](https://cds.cern.ch/record/1604492) (cit. on p. 2).
* [8] ATLAS Collaboration, _Expected performance of the ATLAS detector at the High-Luminosity LHC_, ATL-PHYS-PUB-2019-005, 2019, url: [https://cds.cern.ch/record/2655304](https://cds.cern.ch/record/2655304) (cit. on pp. 2, 8).
* [9] ATLAS Collaboration, _Characterization of Interaction-Point Beam Parameters Using the \(pp\) Event-Vertex Distribution Reconstructed in the ATLAS Detector at the LHC_, ATLAS-CONF-2010-027, 2010, url: [https://cds.cern.ch/record/1277659](https://cds.cern.ch/record/1277659) (cit. on p. 2).
* [10] ATLAS Collaboration, _The ATLAS Experiment at the CERN Large Hadron Collider_, JINST **3** (2008) S08003 (cit. on p. 3).
* [11] ATLAS Collaboration, _ATLAS Inner Tracker Pixel Detector: Technical Design Report_, ATLAS-TDR-030; CERN-LHCC-2017-021, 2017, url: [https://cds.cern.ch/record/2285585](https://cds.cern.ch/record/2285585) (cit. on p. 3).
* [12] ATLAS Collaboration, _ATLAS Inner Tracker Strip Detector: Technical Design Report_, ATLAS-TDR-025; CERN-LHCC-2017-005, 2017, url: [https://cds.cern.ch/record/2257755](https://cds.cern.ch/record/2257755) (cit. on p. 3).
* [13] ATLAS Collaboration, _Expected Tracking Performance of the ATLAS Inner Tracker at the HL-LHC_, ATL-PHYS-PUB-2019-014, 2019, url: [https://cds.cern.ch/record/2669540](https://cds.cern.ch/record/2669540) (cit. on pp. 4, 6).