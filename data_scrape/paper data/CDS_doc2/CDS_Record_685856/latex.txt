**ATLAS Internal Note**

**INDET-NO-021**

**19 January 1993**

On The Design Of The ATLAS Tracker

U. Stiegler

Abstract

Design criteria for a tracker at LHC are discussed and two different trackers, with and without TRD/T, are proposed.

Procedure

In Designing a detector it is important to separate the work in some steps which should be done one after the other. The following steps seem reasonable:

* basic design
* optimization
* choice of technology
* technical design

The first step aims at achieving a rough design based on the analysis requirements of the expected physics. Both the adding of additional layers to improve redundancy and choosing quantative design parameters belong to the second step. Of course these steps are highly correlated and an iterative approach must be taken. Fortunately, this iteration can be minimised by using the previous experience gained in designing the ATLAS detector.

This note puts most effort on the first two steps of the design of the barrel inner detector. The end cap is different from the barrel region but it is thought that the experience gained by designing the barrel will help in the design of the end cap region. So the end cap region is ignored hoping for a small correlation between barrel and end cap.

From previous work we also have a idea of available technologies. There are:

* layers with strips measuring \(\phi\) or \(z\) (solid state, MSGC)
* layers with space points (pads, pixel, stereo)
* a continuous tracker (straw of TRD/T)

The strip length is considered to be between 5 and 20cm so the only parameters are the radius and the required resolution and efficiency. The layers can be combined by having a double sided readout (but in the present note this is counted as two layers). Layers with space points might have low (pads) or high (pixel) resolution. In regions with low occupancy a pair of stereo layers can be considered as a layer with one space point. The occupancy in the barrel region is for most of these devices lower than 1% if the radial distance is larger than 30cm [1]. Therefore pile-up is only relevant at smaller radii or in the end cap region. Scintillating fibers with diameters between \(20\mu m\) and \(100\mu m\) can only be considered if they are packed with stereo angles. Therefore they provide something like a space point with a rate of fake hits of 3% per \(0.5cm\times 0.5cm\) at a radius of 1m [2]. At lower radius the occupancy is too high to use them.

The smallest possible radius which is allowed by radiation arguments is not a well defined number. This depends on the following questions:

* do we want different technology as a function of r * do we replace the layer every one or two year
* how large is the beam halo
* occupancy

In the barrel region at \(r\geq 30cm\) these questions are not relevant. Further points on the smallest possible radius are discussed below.

For a continuous tracker only the TRD is available which has in the barrel region straws with a length between 1m and 2m. Because of high occupancy at small radius the innermost straw should be at \(r>50cm\).

### The Requirements

The requirements on the tracker are efficient track reconstruction whilst minimising the number of fake hits and tracks, momentum resolution, some vertexing, particle identification and a level two trigger. The question which is asked now is which of these requirements are important for the first or for the second step. So the requirements will not be ordered by the physics importance but by their expected impact on the design.

**Pattern Recognition:** At \(r=30cm\) the occupancy for all the various discrete detectors is between 0.1% and 1% (0.1% per \(mm^{2}\)) [1]. If a TRD is used then its inner radius should be larger than 50cm. A detailed study of pattern recognition is done in [3, 4]. The fake track rate at high luminosity is lower than 0.3% for setup A and B of the LOI(p.41f) [1]. Also the \(K^{0}\) should be reconstructed by the tracker allowing the study on CP-violation.

**Momentum Resolution:** The requirement on the momentum resolution is given by the charge measurement: 30% at 500GeV [1]. Using the constraint given by the interaction point, is not so difficult to obtain 30% at 300GeV which corresponds to 50% at 500GeV. Using a least square fit the resolution was calculated for three different setups:

* **A** one layer at r=100cm and a resolution of \(\delta x=60\mu m\)
* **B** one layer at r=75cm and a resolution of \(\delta x=60\mu m\)
* **C** one layer at r=75cm and a resolution of \(\delta x=100\mu m\) and a second layer at r=50cm with \(\delta x=20\mu m\)

and an additional layer with a radius between 30cm and 50cm and a resolution \(\delta x\) of 10\(\mu m\), 20\(\mu m\) and 40\(\mu m\) for all the three setups. The layer at r=75cm can also represent the TRD/T. Fig. 1[5] shows the resolution at \(P_{t}=500GeV\) as a function of r and \(\delta x\) of this additional layer. A resolution of 50% at 500GeV can be easily obtained. A requirement of 30% at 500GeV needs either a layer at around r=100cm or several layers between r=30cm and r=50cm giving an overall resolution better than 10\(\mu m\) or a layer at around r=75cm with a better resolution. Fig. 2[5] shows the minimal requirement on the resolution of the outer most layer as a function of its radius for three different setups:* **D**\(20\mu m\) **at r=30cm plus outer layer**
* **E**\(30\mu m\) **at r=50cm plus outer layer**
* **F**\(20\mu m\) **at r=30cm plus**\(30\mu m\) **at r=50cm plus outer layer**

**The requirement on momentum resolution was 30% at 500GeV. The figure tells that in setup D and F a layer at r=80cm (r=90cm) with a resolution of \(40\mu m\) (60\(\mu m\)) is sufficient. It should be realised that according to Fig. 2 that the resolution is given by the outer and innermost layer and not by the layer at r=50cm. This is in agreement with Fig. 1 setup B which shows that the optimal radius is r=30cm.**

**Since it is not clear how many layers are needed because of other requirements, the requirement due to momentum resolution is ignored in the first step - it belongs to the second step, the optimization step. Furthermore, an important impact on the resolution is given by alignment problems which can only be studied if an overall design is available.**

**Vertexing: Vertexing for b and \(\tau\) physics needs some tracking near the interaction point. These requirements belong also to the optimization step because, if the overall design would not give us appropriate vertexing, additional layers near the beam are needed. They should be radiation hard (built to last) or cheap (built to be exchanged) As shown below there are strong requirements on the material thickness.**

**Particle Identification: The tracker has also to provide some particle identification complementary to the calorimeter [6, 4]. The major problems in particle identification are given by radiation, conversion and Dalitz decay:**

* \(\gamma/(e\to e\gamma)\) **separation**
* \(e/(\gamma\to ee)\) **separation**

**these, as well as pattern recognition are the most important aspects of the overall design. The \(\gamma/\pi^{0}\to ee\gamma\) separation is not investigated.**

**Trigger: If only discrete tracking devices are used, then several layers are needed to obtain reasonable momentum resolution and particle identification. Therefore a level two trigger should not require additional tracking layers, which means the trigger has no impact on the first step. A TRD already provides an electron trigger. Of course some redundancy coming from a stand alone trigger signal given by the discrete tracker is desirable. But it is important to realize that this is not a redundancy which is needed for measuring and understanding the trigger efficiency. The trigger efficiency can be well measured by the correlation of the trigger signals in \(Z\to ee\). Therefore this trigger should be called a back-up trigger which could be used if part of the TRD is not working. To conclude, in case of a continuous tracker, the discrete tracking may provide a back-up trigger signal, therefore the trigger has only impact on the second step.**

**To summarize, the most important ingredients for the basic design are the identification of radiated photons, conversions and Dalitz decays as well as pattern recognition.**

## 2 Tracker with TRD/T

To profit from a TRD a sufficient thickness of the TRD is needed. It is assumed there is a TRD, 2m long, starting at around r=50cm and ending at around r=100cm. The exact radii depends on the position of the discrete tracking layers. The TRD can be split somewhere giving radial space of around 5cm for discrete tracking. Splitting the TRD will decrease the \(\epsilon/\pi\) separation by around 50% at \(\eta=0\) and by a factor two at \(\eta=1\)[7]. So splitting should be acceptable if there are strong points making it desirable.

The set of discrete tracking layers between beam pipe and TRD is called inner tracker (ITR), the other layers are called outer tracker (OTR).

### First Step, The Basic Design

As shown above, the basic impact on the design is given by radiation, conversion and Dalitz decay. To avoid confusion, the electron from the background with the lowest energy is called the veto electron \(e_{veto}\).

#### 2.1.1 Methods for Background Rejection

**Dalitz Decay, \(e/(\pi^{0}\to e_{veto}e\gamma)\) Separation:**

Dalitz decay can be rejected by identifying the electron pairs using the TRD. A rejection factor of 30 for the veto electron was achieved which is sufficient. Never the less, it should be possible to improve the selection by applying a cut on the electron pair mass \(m_{ee}\). Furthermore the electrons must have the same polar angle. The cut on the mass and on the polar angle requires a measurement of the polar angle in front of the TRD. Therefore two layers with z-readout are needed. The mass resolution should be of the order of 100MeV resulting in an angular resolution of around 10mrad. Assuming that one electron has an energy between 10GeV and 100GeV and the other electron, the veto electron, has an energy of around 2GeV. This can be achieved by two layers at r=50cm and r=30cm with a z-resolution of around 1mm. The same resolution is needed in \(\phi\) and can be measured by using the TRD. The problem which is left is the matching between the TRD hits and the z-hits. Different solutions are available.

**1)** The two layers provide a space point with a resolution of 1mm in z and \(\phi\).

**2)** One of the layers provides a space point with a resolution of 1mm in z and \(\phi\). The second layer can have strips measuring the z-coordinate. Therefore, the procedure to search for a Dalitz decay is the following:

* start with an electromagnetic cluster with a well matched track, the 'potential' electron
* search for a additional track or even a electron in the TRD within an appropriate defined \(\phi\) interval
* match the TRD-track with the space point* search for a hit in the second layer in an appropriate z-interval.

**3)** Another solution could be to have several pairs of layers with strips along z and \(\phi\). From these layers a track segment can be reconstructed with a certain amount of fake tracks. The tracks have to match the TRD track. This matching can only be done in \(\phi\) because of the length of the straws. In the r-z projection it should be searched over a certain region for tracks pointing to the em. cluster. But since there is a highly energetic 'potential' electron the region is of the order of 5mm and not several cm given by the beam spread. For 5cm long strips the probability to obtain a hit (due to pile-up) in the z-interval is 25%. Since the hits in the two layers are generated by tracks they are strongly correlated, therefore the probability to obtain a track segment in the r-z projection is also of the order of 25% resulting in an electron inefficiency of 25%. If two strip layers, measuring z, are arranged in such a way that the end points of the strips (in \(r-\phi\)) are not on top of each other (so they are arranged almost like bricks of a house but corrected by the projective geometry) then the inefficiency is reduced by a factor of around two which is still not acceptable.

One of the problems by using strip detectors is the link between the \(r-\phi\) projection and the \(r-z\) projection. This can be done by a large number of layers (shuffled like bricks) or by having at least one space point with a resolution of several millimeters. One such space point is given by the calorimeter therefore, high energetic tracks can easily be reconstructed. Searching for low energetic tracks, not reaching the calorimeter, one layer with space points is needed. Of course, arguments like redundancy and hit efficiency are counting for two layers. This is considered to be part of the optimization procedure. The space point can be realised by pads, pixels or stereo layers.

**Conversion, \(e/(\gamma\to e_{veto}e)\) Separation:** If the conversion appears in the TRD/T then no track element in the ITR will be found. Further more the TRD/T can be used to find the electron pairs. If the conversion appears at the beam pipe the situation is similar to that of the Dalitz decay.

**Radiation, \(\gamma/(e\to e_{veto}\gamma)\) Separation:** A highly energetic photon has to be distinguished from an electron which radiates a photon. If the electron and photon cluster are merged together or not far from each other the identification is easily done by the TRD. So it is assumed that there is no electron cluster or that the electron cluster is far away. Therefore if the radiation appears at the outer radius of the TRD the identification can be done with the TRD because the clusters are not far from each other.

If the radiation appears at the inner radius of the TRD/T a similar technique to that be applied to the Dalitz decay can be used. The track segment of the TRD/T has to be linked (correcting for the kink which is given by the photon energy) with the track segment of ITR. If this segment points to the photon cluster a radiated electron is identified. The same holds if the radiation appears at the beam pipe.

#### 2.1.2 Requirements on Hit Efficiency

The procedure to separate electrons from Dalitz decay and conversion is described in [8, 9]. Typical electron identification criteria are the following:

* electromagnetic calorimeter cluster (\(P_{t}>15GeV\))
* track isolation (\(P_{t}>5GeV\))
* require a hit in the inner tracking layer
* energy isolation in the calorimeter

After applying these cuts the contributions from the conversions and Dalitz decays to the fake electron rate are comparable. The fake electron rate compared to \(W\rightarrow\epsilon\nu\) decay varies from \(10(P_{t}\approx 10GeV)\) to \(10^{-2}(P_{t}=100GeV)\), depending on the transverse energy of the high energetic electron. The fake electron rate is 1 at \(P_{t}\approx 10...20GeV\).1 Since the \(W\rightarrow\epsilon\nu\) is a non-reducible background for any search a fake electron rate which is a factor 10 lower than the \(W\to e\nu\) rate was asked for. This would allow us also to do some W-physics. Therefore the ITR and the TRD have to reduce the background due to conversions and Dalitz decays by a factor which is between 10 and 100. This can be done by identifying the veto electron with an efficiency between 90% and 99%. Using the setup as described above an efficiency of 90% is easily obtained. As shown in [6] a rejection factor for Dalitz decay of around 30 can be achieved with the TRD. To obtain an efficiency of 99% would mean an incredible amount of effort, if at all possible.

Footnote 1: Concerning the \(P_{t}\) at which the fake electron rate is 1 compared to the \(W\rightarrow\epsilon\nu\) rate a difference between [8] and [9] was realised. I could not figured out the reason for it.

The requirements for the \(\gamma/e\) separation are dominated by \(H\rightarrow\gamma\gamma\) with \(m_{h}=m_{Z}\). Electrons have to be rejected by a factor 500. Due to the large number of straws the track inefficiency for electrons is negligibly small if no radiation occurred. The worst case, which will be considered here is if the conversion happened before the TRD leaving an veto electron with an energy lower than 2GeV. In a medium with \(x/X_{0}=5\%\) radiation length the probability, \(p\), to obtain an electron with an energy lower than \(E_{out}=2GeV\) for an incidence energy, \(E_{in}\), of 20GeV (40GeV) is 0.5% (0.3%) (\(p=x/X_{0}\log E_{in}/(E_{in}-E_{out})\)). The probability to lose half of its energy is 3.4%. Therefore electrons with an energy of around 2GeV have to be reduced by only a factor 2.5. Electrons with an energy lower than 200MeV will curl up. The probability to obtain 200MeV (500MeV) out of 20GeV is 0.05% (0.1%). If it is assumed that it is not possible to identify electrons with an energy lower than 500MeV then the electron inefficiency for electrons above 500MeV has to be less than 0.1%. This seems to be possible because of the large number of straws. Lets take an example: electrons below 500MeV are not identified, electrons between 500MeV and 2GeV are reduced by a factor 5 and electrons with an energy above 2GeV are identified with a veto inefficiency of 0.02% then the overall factor 500 is obtained. Of course, for higher photon energies, lets say 100GeV, the probability to obtain 500MeV out of 100GeV is only 0.03% so the curling up can be neglected. If electrons between 500MeV and 2GeV are reduced by a factor 5 and if the veto inefficiency for electrons above 2GeV is better than 0.1% then the overall rejection factor is 500.

The \(\gamma\)-efficiency can be increased by adding the information of the r-z projection; the event is only rejected if the polar angle of the veto electron is aligned with the em. cluster direction (ignoring for a moment internal bremsstrahlung). This cut has to be only applied if the electron energy is less than around 10GeV because the presence of a high energetic electron will give a clean veto. The probability to get 10GeV out of 100GeV is 0.5%. Therefore an efficiency of around 90% for finding the r-z-vector is required, which is possible if the hit efficiency of the two layers are 95%. If the physics requirement turns out to ask for a reduction factor of 500 at a photon energy of 50GeV and if the r-z information is needed to obtain a high photon efficiency then the hit efficiency has to be 97.5% which correspond to an r-z-vector efficiency of 95%.

In case of internal bremsstrahlung (\(Z\to ee\gamma\)) the rejection power of the TRD is sufficient. It seems to be difficult to get any improvement from the tracking layers.

The next question is what are the requirements on the hit efficiency due to Dalitz decay. It is assumed that, for a reasonable electron efficiency, the r-z information is needed in the similar way as for the photon selection. The TRD give us a stand alone rejection factor of around 30 with an electron efficiency of \((94\pm 2)\%\) at \(P_{t}=20GeV\). If the efficiency for finding the r-z-vector is 95% (97%) then the overall rejection factor is found to be 12 (16). This corresponds to a single hit efficiency of 97.5% (98.5%). The increase of the final electron efficiency has to be studied by simulation but it will be certainly better than 94%.

To summarize; the backgrounds above have one high energetic cluster (neutral or charged) and a additional low energetic electron coming from the interaction point or somewhere along the line pointing to the cluster. The requirements on the rejection power can be achieved with the TRD and a ITR having two layers with space points (pads, pixel, stereo) or one layer with space points and one with strips measuring z. The resolution in z and \(\phi\) has to be around 1mm. The hit efficiency has to be at least 95%. But it should be pointed out that a hit efficiency of around 98% is a qualitative increase of confidence.

### Second Step, Optimization

Now there is the more difficult part in front of us, the optimization or to say it in other words, the questions of taste. It is shown above that there has to be two layers in the ITR one with space points and one with strips to measure z. The resolution has to be 1mm and the hit efficiency at least 95%. To increase the confidence and the electron and photon efficiency it was asked for around 98% hit efficiency (the safety factor here is a question of taste). It means for instance that one layer could be build up by two layers with an efficiency of 96%.

The momentum resolution requires at least one layer between r=80cm and r=90cm or a \(\phi\) resolution of the ITR of better than 10\(\mu m\). For the last case the TRD was approximated as one measurement at r=75cm with a resolution of \(\phi\) = 60\(\mu m\). Neglecting the correlation of alignment errors, this means that 4 layers with 20\(\mu m\) resolution or 2 layers with 20\(\mu m\) and 4 layers with 30\(\mu m\). Therefore it is concluded that one layer with \(60\mu m\) resolution at a radius less than one meter is needed or the requirement on charge measurement up to \(P_{t}=500GeV\) cannot be fulfilled. The question which is left is what kind of physics is lost if the charge can only be measured up to \(P_{t}=300GeV\).

There is an other consideration which should be taken into account. A z measurement just in front of the calorimeter increases the confidence in the analysis because from 50cm up 100cm there is no z coordinate available. It would also help to do the alignment between the tracker and the calorimeter and between the tracker and the muon system. A z resolution of 1mm can be obtained by having a pair of layers with \(60\mu m\) resolution and a stereo angle of 1.8deg. The resolution in \(\phi\) would not be changed by this small angle. I am personaly for a stereo layer at r=88cm with \(60\mu m\) resolution. It is difficult to exclude this \(10\mu m\) resolution of the ITR but it is also difficult to see the realization because of the correlation of alignment errors. If it turns out that scintillating fibers are much cheaper compared to the total(!) cost of a down or upgraded ATLAS detector (\(300...450\)MSFr), then the reliability, the number of fake hits, the number of bad measured points because of the overlapping pile-up-hits, the level 2 trigger etc. should be examined.

To reduce the background two inner layers (one with space point) with a hit efficiency of 98% are required. If the outer layer has an hit efficiency of 95% then a trigger efficiency of 91% for stiff tracks would be obtained. This is acceptable because it cannot be assumed that the full TRD trigger will fail but only some trigger segments.

**Proposed Design:** To place at around 88cm one pair of strip layers with a stereo angle of 1.8deg with \(60\mu m\) resolution. The hit efficiency is 95%. This splits the TRD.

Around 50cm a z and \(\phi\) measurement with 1mm resolution (because of background) is required. The efficiency should be 98%. If this efficiency is too high to be technically realised a pair of strip layers with a single layer efficiency of 96% is proposed. This pair of stereo layer would also largely increase the confidence. Pads and pixels are as good.

At around 30cm a layer with a space point measurement is required with an resolution of 1mm in z and \(20\mu m\) in \(\phi\) and an efficiency of 98%. Because of the low occupancy a pair of stereo layers with strips can be considered as a space point.

In case of stereo layers the efficiency has to be reconsidered. Assume a pair of stereo layers at r=50cm and at r=30cm and a single hit efficiency of 95%. A track element is reconstructed if at least 3 out of 4 hits are present resulting in an efficiency for the track element of 98.6%; a number which is better than the requirements. Therefore some space is left for redundancy. Pads or pixels with an efficiency of 98% are as good. But if the pad or pixel detectors have an efficiency of 96% two of them are needed. Then you have to decide if you want two pad or pixel layers or a pair of strip layers. In this case the reliability, costs, number of electronic channels, trigger etc. has to be considered.

**Improvements:** As described in the LOI p.92 [1] a jet is tagged as a b-jet if it contains one associated track with \(P_{t}>2GeV\) and an impact parameter greater than \(200\mu m\). Cutting at a higher impact parameter increases the purity. For the case of two layers r=30cm \(\delta x\) = \(20\mu m\) and r=50cm \(\delta x\) = \(30\mu m\) the resolution on the impact parameter is around \(70\mu m\) according to a least square calculation. This might be sufficient. If a third layer is added r=10cm \(\delta x\) = 20(10)\(\mu m\) then the impact parameter resolution is around \(25(15)\mu m\) plus the error of the beam spot. It is important to realize that this layer has to be seen in conjunction with conversion and radiation background and the selection efficiency for electrons and photons.

Adding this layer at r=10cm needs a detailed study of fake hits but additional faktors have to considered. At low luminosity, where a good impact parameter resolution might be needed the number of fake hits should be low. At low luminosity b-tagging leads to an improvement of the signal to background ratio (i.g. \(t\to bH^{+}\)) but it is not essential (cf. LOI p94 [1]). B-tagging without the layer at r=10cm should be studied.

The arguments for \(\tau\) physic: it is important to realize that for the search for \(t\to bH^{+}\)\(H^{+}\rightarrow\tau\nu\) only a luminosity of \(10^{33}cm^{-2}s^{-1}\) is needed (cf. LOI p93f [1]). This channel seems to be rather important because, due to the large top mass compared to the b mass. a \(\tan\beta>>1\) is motivated and this would enhance the channel.

To sumarise, the layer at r=50cm should also have a high resolution in \(\phi\). An additional layer at r=10cm may be needed but without the requirements on radiation hardness at high luminosity. A Monte Carlo study under this assumptions could help to come to a final conclusion concerning the tracking at \(r<30cm\), otherwise too much taste is involved.

Of course the purpose of LHC is to discover something new. Tagging of fermions with high mass has the advantage that in most cases the corrections due to unknown physics and cross sections are larger. But nevertheless it seems to be a question of taste if b and \(\tau\) tagging is considered as being important at high luminosity.

**The Improved Design** Taking into acount b tagging at low luminosity the following design is proposed: At around r=88cm, r=50cm and r=30cm are the layers as described above but the resolution which is required in \(\phi\) at r=50cm has to be around \(30\mu m\). In addition there is a layer at r=10cm with a resolution of \(10\mu m\) in \(\phi\) and a z resolution which has to be figured out. This layer has not to be radiation hard and no strong requirements on the efficiency are needed at low luminosity. The thickness of this layer is essential if this layer will be left in while running at high luminosity. Less than half of the beam pipe thickness would mean that it can basicly be ignored.

A more elaborate radiation hard vertex detector with rather stringent requirements on the thickness should be considered as an upgrade of ATLAS. To stress the thickness: The challenge due to thickness requirements is at least as hard as the radiation hardness. To be more precise: The effective thickness which depends on the true thickness, pattern recognition and the veto efficiency for low energetic electrons is the important number. During the low luminosity phase a LEP-type vertex detector can be considered but it is expected that it has to be taken out not only because of damage but also because of the thickness.

The decision on the vertex detector is similar to that on the TRD; something is lost (because of the thickness) which has to be brought back. Part of this question, ignoring energy resolution of the em. calorimeter and efficiency, can be expressed in terms of effective radiation length which is for the TRD 0.02% [6]. Of course this number can only be used for estimating the signal to background ratio given by bremsstrahlung and conversions whereas the selection efficiency and energy resolution for electrons and photons is given by the true thickness.

**Some Important Numbers:** This tracker for LHC, running at high luminosity, can be summarized by the following numbers which are the most important ones: the veto efficiency for a low energetic electron between 500MeV and 2GeV is better than 97% including the information in the r-z plane which will result in an efficiency for the accompanied high energetic electron or photon which is certainly better than 94%. The thickness between r=0 and r=50cm is 5% radiation length. If a larger thickness is considered a better veto efficiency has to be required. The veto inefficiency at higher energies is negligible. The electron-photon separation has an rejection factor of around 500. The fake track rate has to be studied by Monte Carlo. These numbers are the power of the tracker.

## 3 Tracker without TRD/T

This section is now short for two reasons: first, most of the arguments can be taken from above, second pile-up plays a more important role if there is no particle identification power assumed therefore, more Monte Carlo input is needed for the various possible setups.

To be honest one word has to be said: The information which is available due to a dE/dx measurement is ignored because of the lack of knowledge of the author. This affects the final electron and photon efficiency because it could be said that a low energetic track gives only a veto if a certain signal high is recorded (a truncated mean over several layer). This cut may help because the energy of the veto electron is around 2GeV. Since this information is ignored pile-up plays a more important rule.

Considering momentum resolution and background it is thought that the tracker which was design above is a good starting point leaving the TRD and the layer at r=10cm out.

Electrons, radiating a photon such that the remaining electron energy is between 500MeV and 2GeV has to be found which, because of the bending at 500\(M\epsilon V\), means one additional layer is needed. The radius should be larger than 30cm because if this layer fails almost all of the nice LHC physics is lost. It is assumed to have it at r=40cm. The required veto inefficiency for electrons with an energy larger than 500MeV has to be 0.1% as shown above. Two hits out of three with a single hit efficiency of 98% result in a veto efficiency of 99.9%. Of course these two or three hits must align with the electron or photon cluster in the r-z projection. The final electron and photon selection efficiency has to be estimated as well as the number of fake tracks.

Adding additional layers to increase the selection efficiency by keeping the veto efficiency constant seems to be very costly. Three hits out of four gives only 99.77% veto efficiency. Two out of four will decrease the selection efficiency. Three out of five is 99.99%. A detailed simulation is needed at that place but it seems that five layers at r=30cm, r=35cm, r=40cm, r=50cm and r=88cm should be sufficient. The hit efficiency should be 98%. The four inner layers must provide z and \(\phi\) information, two of them can have a resolution of only 1mm in \(\phi\). It should be realised that all the layers should stay at \(r>30cm\) because a degrading efficiency due to radiation damage is not acceptable.

This is the minimal tracker without a TRD. A efficient level two trigger should be possible. It seems to be difficult to do any further statement without some more Monte Carlo. Of course the arguments concerning b and \(\tau\) tagging are the same as above.

## 4 Conclusion

Two types of tracker with and without TRD are proposed. They have a high veto efficiency against Dalitz decay, conversion and bremsstrahlung. The selection efficiency for photons and electrons has to be estimated by Monte Carlo as well as b and \(\tau\) tagging. Stringent requirements are given on the thickness of a vertex detector running at high luminosity. The difference in radiation length between the two detector is basically the difference between the thickness of the TRD and the two layers at r=35cm and r=40cm. How this affects the energy resolution is not investigated. The effective difference of the thickness, which is an important number, should be studied by Monte Carlo. If no TRD is used the hit efficiency of the layers should not decrease during data taking.

Concerning the radius of the outer most layer the expected error on the resolution in \(\phi\) has to be pined down.

**Acknowledgements** It is a pleasure to thank M. Dodgson, D. Froidevaux and A. Poppleton for all the inspiring discussions and reading the text.

**Fig. 1 Expected momentum resolution at \(P_{t}=500GeV\) as a function of the radius of the innermost layer for three different setups:**

* **A** one layer at r=100cm and a resolution of \(\delta x=60\mu m\)
* **B** one layer at r=75cm and a resolution of \(\delta x=60\mu m\)
* **C** one layer at r=75cm and a resolution of \(\delta x=100\mu m\) and a second layer at r=50cm with \(\delta x=20\mu m\)

plus an additional layer with a radius between 30cm and 50cm and a resolution \(\delta x\) of \(10\mu m\), \(20\mu m\) and \(40\mu m\) for all the three setups [5].

**Fig. 2 Expected momentum resolution at \(P_{t}=500GeV\) as a function of the radius of the innermost layer for three different setups:**

* **A** one layer at r=100cm and a resolution of \(\delta x=60\mu m\)
* **B** one layer at r=75cm and a resolution of \(\delta x=60\mu m\)
* **C** one layer at r=75cm and a resolution of \(\delta x=100\mu m\) and a second layer at r=50cm with \(\delta x=20\mu m\)

plus an additional layer with a radius between 30cm and 50cm and a resolution \(\delta x\) of \(10\mu m\), \(20\mu m\) and \(40\mu m\) for all the three setups [5].

[MISSING_PAGE_EMPTY:14]

## References

* [1] ATLAS LOI.
* [2] U. Stiegler and R. Clifft, unpublished simulation.
* [3] I. Gavrilenko, ATLAS note INDET-016 (1992).
* [4] A. G. Clark et al., ASCOT/EAGLE note INDET 015.
* [5] Plots produced by A. Poppleton.
* [6] V.A. Polychronakos et al., CERN/DRDC/91-47, RD-6 (1991).
* [7] TRD/T barrel optimization I. Gavrilenko, (private communication).
* [8] K. Jakobs and U. Stiegler, ASCOT note 004 (1991); K. Jakobs, Addendum to ASCOT note 004 (1992).
* [9] D. Froidevaux and A. Poppleton, EAGLE note INDET-002 (1992).