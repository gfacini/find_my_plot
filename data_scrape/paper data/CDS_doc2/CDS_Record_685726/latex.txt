**ATLAS /DAQ - No - 11**

**EAST 94-08**

March 22, 1994

**WHAT CAN ARTIFICIAL NEURAL NETWORKS DO FOR**

**THE GLOBAL SECOND LEVEL TRIGger**

**R.K. Bock, J. Carter, I.C. Legrand**

**1. Introduction**

The aim of this paper is to present several results concerning the local/global algorithmic structure of the second level trigger. Simple models have been used to generate sets of input data since here we are more concerned with general statistical properties than physical details. The second level trigger, guided by the local first level trigger region of interest (RoI), is organized in hierarchical levels which concentrate the information in order to perform a global event decision. In this paper we would like to emphasise:

-The general statitistical results in this paper are implementation independent, i.e. they are not restricted to Artificial Neural Networks (ANNs).

-An efficient trigger should _not_ simply be an AND scheme between local decisions of different sub-detectors: to maximise the quality in identifying particles, the "features" from different sub-detectors must be combined coherently.

-A flexible and efficient way to analyse the particles from an event can be performed by using "probabilities" for each type of particle. These new probability features can be obtained by a proper training of an ANN having as input the features from different sub-detectors and an output node for each type of particle.

-We believe that familiar physical characteristics should be used in the selection of interesting events (e.g. invariant masses): the ANNs we have studied are unable to identify kinematical correlations of this type.

**2. Combining features from different sub-detectors**

Our trigger model assumes that upstream of the feature extraction architectures, a unit with access to the second level buffers collects data from the regions of interest (RoIs) pointed out by the first level trigger, and sends the raw RoI data for sub-detectors from the same geometrical region in proper format to the feature extractors. The objective of the feature extraction algorithms [1,2,3,4,5] is to find a few decision variables, suitable for describing the detected phenomena in each type of sub-detector, and provide a bandwidth reduction of more than an order of magnitude over the raw RoI data.

At the global trigger level [6,7] we need to combine the features coming from different sub-detectors in order to improve the quality of the particle classification and of the variables used for the kinematical reconstruction of the event. Since these sub-detectors are designed to measure complementary physics qualities, the features should be combined coherently. As we will show later, at this stage it is better not to perform an exclusive particle identification which may diminish the quality of the event decision, but to generate another set of features, "particle probabilities", based on the features coming from different sub-detectors. In the following we will consider only the statistical properties of features and how one can combine them in order to improve the quality of the decision.

We will discuss this problem based on a simple example: two sub-detectors each characterized by only one feature. Again for simplicity we consider only two types of particle, i.e. electrons and jets which pass the first level trigger. We assume that for each type of particle the features are normally distributed and that the overlap of the probability distribution functions in each sub-detector feature space is different from zero, as in figure 1. In this example we consider that for both sub-detectors the overlap is 10% (e.g. by using simple cuts each sub-detector identifies correctly 90% of each type of particle)

Consider first the simplest case when the two sub-detectors are not correlated. The least efficient way to make a decision is to classify with each sub-detector and after that to perform an AND between these classifications. In our example this type of decision will identify correctly only 81% (the product of the probabilities) of each type of particles.

The decision can be much improved if the two features are analysed together in a two dimensional space (figure 2). Cutting with a plane as shown, both types of particle are \(\sim\)96% correctly identified. Such cuts are performed also by a simple ANN [8] structure using the identity function as the transfer function for the neurons.

As the number of sub-detectors increases, the difference between these two ways of discriminating becomes more marked. In table 1 we present for comparison the results of identifying particles in our simple model, with different numbers of sub-detectors, for the sequential AND algorithm and for the simple ANN scheme presented in figure 3. As long as the features coming from different sub-detectors for the same particle are uncorrelated the ANN does not need hidden layers for classifying particles. This means that simple hyper-planes in the feature space are sufficient to find the best discrimination.

In reality the features are correlated, and it is most likely that these correlations will not simply be linear. In this case classical threshold conditions are difficult to define, and to perform

Figure 1: The distribution of the features for two sub-detectors (1 & 2) and two types of particles (electron & jets). The overlap of these gaussian distribution functions was chosen such that classical one dimensional cut will provide 90% correct identification in each sub-detector feature space.

such a classification many threshold comparisons have to be done, which are usually derived empirically.

\begin{table}
\begin{tabular}{|c|c|c|} \hline Number of & \multirow{2}{*}{Sequential AND classification} & Classification in multidimensional \\ detectors & & feature space \\ \hline \hline
1 & 90\% & 90\% \\ \hline
2 & 81\% & 96.5\% \\ \hline
3 & 73\% & 98.8\% \\ \hline
4 & 65\% & 99.4\% \\ \hline
5 & 59\% & 99.8\% \\ \hline \end{tabular}
\end{table}
Table 1: Comparison of efficiencies for a sequential AND classification and for an ANN classification, using uncorrelated features.

Figure 2: Classifying particles in a two dimensional feature space. The features coming from each sub-detector are not correlated.

As long as these correlations are not strongly non-linear a reasonably efficient way to classify is to use a simple ANN scheme.

To optimize ANNs for correlated data, hidden layers are necessary. In figure 4 we present three ANN schemes and their performances in classifying correlated data. Finding the simplest network which provides the best classification for correlated data is not in general an easy task. Strongly non-linear correlations require preprocessing of the input data to transform the feature space. Similar results have been obtained in studies of ANNs for feature extraction algorithms [4, 5].

The ANN algorithms in this example are simple and can be efficiently implemented without the need of special hardware. Such algorithms are also robust against small changes in the input stream and also if part of the input data is corrupted.

## 3 Combining the RoI-s

As discussed above, for particle identification at the first stage of the global trigger it is much better to use an ANN scheme which provides as output "probabilities" for each type of particle. This means that instead of making sharp cuts in the feature space each cell in the output layer will provide a value between 0 and 1, a likelihood for the particle to be in each predefined class. These values are proportional with the shortest distance between the point in the multidimensional feature space for each particle and the hyper-surfaces which are optimum sharp cuts. This means that the ANN scheme has as many output nodes as types of particle considered. Using these particle "probabilities" the event decision algorithm is more flexible and can better discriminate between different interesting physical channels.

As an artificial example to show the use of particle classification probabilities, take the case of a pair of electrons when several jets may also be present. The electron/jet separation obtained at the RoI level expressed as a binary classification is compared with an a model which provides "probabilities" for each types of particle. For simplicity we consider that each RoI is characterized by only one feature. In this case a simple function can be used to generate probabilities. In figure 5, the results of identifying a pair of electrons in a "background" of 4 jets are presented for the cases where the electron/jet separation in the feature space is 95% and 90%. The discrimination quality curve for the electron pair was obtained by taking different threshold conditions for the total electron likelihood probability. The "*" point in each diagram is the result obtained by considering a binary particle identification at the RoI level. The algorithm based on combining probabilities has several advantages compared with the binary classification:

-In general it provides a better quality in selecting combinations of particles.

-The thresholds on the probabilities can be adjusted for different luminosities.

-For pairs of interesting particles which are also correlated by an invariant mass condition, it is better to select the pair by thresholding the sum of the probability of the pair for large acceptance, even if the number of selected false pairs increases. The kinematical correlation itself will cut out most of the background events that pass the pair identification condition.

Identification of single particles is in general uncorrelated, and the assumptions made in this example are quite realistic. For more than one pair of interesting particles the difference between these two algorithmic models became more pronounced. The same holds when the number of particles increases.

Figure 4: Artificial Neural Network classification of correlated features

## 4 Event decision

In order to have an efficient trigger the event decision algorithm should consider all the physical constraints for interesting physics channels. As an example, the Higgs channels are often characterized by pairs of particles correlated through an invariant mass condition. By using at the trigger level such conditions to select events the quality of the decision is improved and maintained even at high luminosity [9].

These kinematical correlations are strongly non-linear. Figure 6 shows different two dimensional views of the six dimensional kinematical parameter space for two particles correlated by an invariant mass constraint. For such correlations an ANN structure cannot be used directly. In practice it is simpler to compute such quantities than to use an ANN structure with a preprocessing part, since the preprocessing part in this case will be as complex as the actual computation of such quantities. We have tried to use fairly large feed forward ANNs to identify such correlations, but the results are poor (60% of the correlated data was correctly classified and about 40% of the events without such correlations have been classified as correlated).

In addition the event decision algorithm has to cope with events having a variable number of RoIs (particles selected by the first level trigger), which again is not well suited for an ANN structure.

Based on these arguments we consider that an event decision algorithm using invariant mass conditions cannot be performed efficiently using the simple ANNs we have examined. Moreover, since we believe that familiar physical characteristics should be used in the global trigger algorithm for reasons of flexibility and user comprehension, the use of more complex ANNs may be inappropriate.

Combining probabilities for all the RoIs and using computed kinematical correlations

Figure 5: Decision quality diagrams for selecting a pair of electrons in a “background” of four jets when the electron/jet overlap in an one dimensional feature space is 5% (a) and 10% (b). The decision diagram was obtained by varying the threshold condition for the total pair electron probability. The “*” points represent the results obtained if binary particle classification is made at the RoI level.

Figure 6: Two particle invariant mass correlations. Each diagram shows a two dimensional view of what is in reality a six dimensional parameter space.

can provide a flexible, physics based decision structure which can be easily adjusted to run efficiently at different luminosities.

We intend to pursue this approach to global second level trigger algorithms, including realistic physical simulations (currently in progress) and a more comprehensive theoretical basis, in order to demonstrate in detail the feasibility of our model.

REFERENCES:

1. J. Badier et al, Evaluating Parallel Architectures for Two Real-Time Applications with 100kHz Repetition Rate, IEEE Transactions on Nuclear Science, vol 40, No. 1, (1993).
2. J.Badier, R.K. Bock, C. Charlot and I.C. Legrand, Benchmarking architectures with Spacal data, CERN/EAST Note 91-10, (1991)
3. P. Bialas, J. Chwastowski, P. Malecki and A. Sobala, Benchmarking with data from the transition radiation detector, CERN/EAST Note 91-11,(1991).
4. H.M.A Andree, W. Lourens, A. Taal, J. Vermeulen, Feedforward neural networks as an on-line pattern recognition tool. Third International Workshop on Software Engineering, Artificial Intelligence and Expert Systems for High Energy and Nuclear Physics, Oberammergau, Germany, October 1993
5. J.M. Seixas, L.P. Caloba, M.N. Souza, A.L. Braga, A.P. Rodrigues and H. Gottschalk, Neural Networks Applied to a Second Level trigger based on Calorimeters, Third International Workshop on Software Engineering, Artificial Intelligence and Expert Systems for High Energy and Nuclear Physics, Oberammergau, Germany, October 1993.
6. R.K. Bock, J. Carter, E. Denes, I.C. Legrand, M. Novak, J. Varela, Second-level trigger: global decision structure CERN/EAST Note 92-06 (1992).
7. R.K. Bock, J. Carter, I.C. Legrand, J. Varela, Test data for the global second level trigger CERN/EAST Note 93-01 (1993)
8. C. Peterson, T. Roognvaldsson, L.Lonnblad, JETNET 3. A versatile Artificial Neural Network Package.
9. R.K. Bock, J. Carter, I.C. Legrand, Modelling of global decision structure, CERN/EAST Note 93-03 (1993).