[MISSING_PAGE_EMPTY:1]

## 1 Introduction

Tau leptons, and particularly their hadronic decays, will play an important role at the LHC. They will provide an excellent probe in searches for new phenomena: the Standard Model Higgs boson at low masses, the MSSM Higgs boson or Supersymmetry (SUSY). Therefore, understanding their selection efficiencies and the cross-sections at which they will be produced is essential for discovering new physics.

Tau leptons are massive particles with a measurable lifetime undergoing electroweak interactions only. The production and the decay of \(\tau\) leptons are well separated in time and space (\(\Gamma_{\tau}/m_{\tau}\sim 10^{-11}\)), providing potential for unbiased measurements of the polarisation, spin correlations, and the parity of the resonances decaying into \(\tau\) leptons. The excellent knowledge of \(\tau\) decay modes from low energy experiments indeed makes this an ideal signature for the observations of new physics.

The interesting transverse momentum range of \(\tau\) leptons spans from below 10 GeV up to at least 500 GeV. Experiments at the LHC will thus have to identify them in a wide momentum range. The low energy range should be optimized for analyses related to W and Z boson observability with \(\tau\) decays and also to Higgs boson searches and SUSY cascade decays. The higher energy range is mostly of interest in searches for heavy Higgs bosons in MSSM models and for extra heavy W and Z gauge bosons. For illustration, Fig. 1 shows the transverse energy spectrum of the visible decay products of \(\tau\) leptons from different processes of interest normalized to the predicted cross-section with which they will be produced at the LHC and to an integrated luminosity of 10 fb\({}^{-1}\).

The reconstruction of \(\tau\) leptons is usually understood as a reconstruction of the hadronic decay modes, since it would be difficult to distinguish leptonic modes from primary electrons and muons. Despite a strong physics motivation for exploring data with \(\tau\) leptons in the final state, their reconstruction at hadron colliders remains a very difficult task in terms of distinguishing interesting events from background processes dominated by QCD multi-jet production. Another related challenge is providing efficient triggering for these events while keeping trigger rates at manageable levels.

The availability of various decay modes makes \(\tau\) leptons a rich but not totally unique signature. Hadronically decaying \(\tau\) leptons2 are distinguished from QCD jets on the basis of low track multiplicities contained in a narrow cone, characteristics of the track system and the shapes of the calorimetric showers. Isolation from the rest of the event is required both in the inner detector and the calorimeter.

Figure 1: The visible transverse energy of \(\tau\) leptons from different physics processes: top quark decays, W/Z production, Standard Model vector boson fusion Higgs boson production for \(m_{H}=120\) GeV with \(H\to\tau\tau\), for \(\tau\) leptons from low energy Supersymmetry with a light stau (SU1 sample), heavy \(Z^{\prime}\) bosons, and heavy Higgs bosons from \(bbH\) production in the MSSM with \(\tan\beta=20(45)\) for masses of 400 GeV (800 GeV).

From this information, a set of identification variables is built, to which either a traditional cut-based selection or multi-variate discrimination techniques are applied.

The inner detector provides information on the charged hadronic track or the collimated multi-track system reconstructed in isolation from the rest of the event. These tracks should neither match track segments in the muon spectrometer nor reveal features characteristic of an electron track (e.g. high threshold hits in the Transition Radiation Tracker). In the case of a multi-track system, they should be well collimated in \((\eta,\phi)\) space and the invariant mass of the system should be below the \(\tau\) lepton mass. The charge of the decaying \(\tau\) lepton can be directly determined from the charge(s) of its decay product(s).

Calorimetry provides information on the energy deposit from the visible decay products (i.e. all decay products excluding neutrinos). Hadronically decaying \(\tau\) leptons are well collimated (with an opening angle limited by the ratio \(m_{\tau}/E_{\tau}\) ) leading to a relatively narrow shower in the electromagnetic (EM) calorimeter with, for single-prong decays with one or few \(\pi^{0}\)'s, a significant pure electromagnetic component. On average in this case about 55% of the energy is carried by \(\pi^{0}\)s present among the decay products.

The calorimeter and tracking information should match, with narrow calorimeter cluster being found close to the track(s) impact point in the calorimeter. Furthermore, the invariant mass of the cluster should be small and the cluster should be isolated from the rest of the event.

The algorithms for the reconstruction of hadronically decaying \(\tau\) leptons are considered higher level reconstruction as they use components provided by algorithms specific to different subdetectors like track reconstruction in the inner detector or topological clustering of the energy deposits in the calorimeter. At present, two complementary algorithms have been implemented into the ATLAS offline reconstruction software.

* The calorimetry-based algorithm starts from clusters reconstructed in the hadronic and electromagnetic calorimeters and builds the identification variables based on information from the tracker and the calorimeter.
* The track-based algorithm starts from seeds built from few (low multiplicity) high quality tracks collimated around the leading one. The energy is calculated with an energy-flow algorithm based only on tracks and the energy in the electromagnetic calorimeter. All identification variables are built using information from the tracker and the calorimeter.

A short overview of the features of \(\tau\) lepton decays is included in Section 2. In Section 3 selected topics on the performance of the detector directly relevant to the reconstruction and identification of the hadronically decaying \(\tau\) leptons are discussed. Offline reconstruction algorithms and performance results are described in Section 4. In the remaining part of the note strategies for analyses using \(\tau\) leptons with the first 100 pb\({}^{-1}\) of data are presented.

## 2 Topology of \(\tau\) leptons in LHC collisions

The transverse momentum range of interest spans from below 10 GeV up to 500 GeV. \(\tau\) leptons decay hadronically in 64.8% of all cases, while in \(\sim\) 17.8% (17.4%) of the cases they decay to an electron (muon) [1]. From the detection point of view, hadronic modes are divided by the number of charged \(\pi\)s among the decay products into single-prong (one charged \(\pi\)) and three-prong (three charged \(\pi\)s) decays. The small fraction (0.1%) of five-prong decays is usually too hard to detect in a jet environment. The \(\tau\rightarrow\pi^{\pm}\nu\) mode contributes 22.4% to single-prong hadronic decays and the \(\tau\to n\pi^{0}\pi^{\pm}\nu\) modes 73.5%. For three-prong decays, the \(\tau\to 3\pi^{\pm}\nu\) decay contributes 61.6%, and the \(\tau\to n\pi^{0}3\pi^{\pm}\nu\) mode only 33.7%. In general, one- and three-prong modes are dominated by final states consisting of \(\pi^{\pm}\) and \(\pi^{0}\). There is a small percentage of decays containing \(K^{\pm}\) which nevertheless can be identified using the same technique as for states with \(\pi^{\pm}\) from the ATLAS detector point of view. A small percentage of states with \(K^{0}_{S}\) cannot be easily classified as belonging to either the single-prong or three-prongs categories as the number of registered prongs depends on the actual \(K^{0}_{S}\) interaction within the detector. Unless specific studies are done, other multi-prong hadronic modes can be safely neglected.

The lifetime of the \(\tau\) lepton (\(c\tau=87.11\mu m\)) in principle allows for the reconstruction of its decay vertex in the case of three-prong decays. The flight path in the detector increases with the Lorentz boost of the \(\tau\) lepton, but at the same time the angular separation of the decay products decreases. A resulting transverse impact parameter of the \(\tau\) decay products can be used to distinguish them from objects originating from the production vertex.

The incorporation of spin effects in \(\tau\) lepton decays is often of importance. This was done within the framework of the ATLAS Monte Carlo simulation and events were generated using PYTHIA[2] interfaced with TAUOLA[3]. The generation process has correctly included full spin correlations in production and decays of the \(\tau\) leptons. Tau leptons from the decay of gauge bosons, Higgs bosons or in SUSY cascade decays will carry information on the polarisation of the decaying resonance and in the case of pair production also some information on the spin correlations. Tau leptons from \(W\to\tau\nu\) and \(H^{\pm}\to\tau\nu\) will be 100% longitudinally polarised, with \(P_{\tau}=+1.0\) and \(P_{\tau}=\) -1.0 respectively, resulting in different distributions of the charged to total visible energy for single-prong decays in the center-of-mass system of the decaying resonance. At the LHC this effect can be used to suppress \(W\to\tau\nu\) background and to increase the \(H^{\pm}\to\tau\nu\) observability[4]. The \(\tau\) polarisation could also be used as a tool to discriminate between MSSM versus Extra Dimension scenarios[5]. The longitudinal polarisation of \(\tau\) leptons from neutral Higgs boson decays will be democratic with 50% probability, thus \(\tau\) leptons from Higgs boson decays are effectively not polarized. The polarisation of \(\tau\) leptons from Z boson decays will be a more complicated function of the center-of-mass energy of the system and the angle of the decay products[6]. In the cleaner environment of the ILC and also perhaps at the sLHC, building variables sensitive to the longitudinal and transverse spin correlations may lead to a CP measurement of the Higgs boson[7, 8].

## 3 Performance of the ATLAS detector for \(\tau\) identification

Hadronic \(\tau\) decays can be efficiently reconstructed and identified using information from the inner detector and from the calorimeter. Reconstruction is done only for the visible part of the decay products, however, for specific analyses like \(H\to\tau\tau\) the complete invariant mass of the \(\tau\tau\) system may be reconstructed using the collinear approximation[9] (neutrino momenta parallel to that of the visible decay products). A few selected topics related to the performance of the detector are discussed below before turning to the reconstruction algorithms.

### Tracking and vertexing

The reconstruction of tracks from charged pion decays is an important ingredient of the \(\tau_{had}\) reconstruction algorithms. The track-based algorithm is seeded by one or more good quality tracks which allow for the calculation of the \(\tau_{had}\) energy with the so called energy-flow scheme. Both the calo-based and the track-based algorithm determine the charge of the \(\tau_{had}\) candidate by summing up the charge(s) of the tracks reconstructed in the \(\tau_{had}\) core region3). The tracking information is further used to identify hadronically decaying \(\tau\) leptons and to discriminate them against the background from hadronic jets by considering the track multiplicity, the impact parameter and the transverse flight path in the case of multi-track candidates. The track selection should therefore ensure high efficiency and quality of the reconstructed tracks over a broad momentum range from 1 GeV to a few hundred GeV.

#### 3.1.1 Reconstruction efficiency and track quality

The efficiency for track reconstruction in \(\tau\) decays is defined as the probability for a given charged \(\pi\) from a \(\tau\) decay to be reconstructed as a track. With respect to the reference tracking performance of the detector established for single muons in the low \(p_{T}\) range a degradation due to hadronic interactions (a charged \(\pi\) interacting with the material of the inner detector) is expected. In the higher \(p_{T}\) range a degradation is caused by the strong collimation of the multi-track system for three-prong decays.

Good quality tracks reconstructed with \(p_{T}\) as low as 1 GeV are required by the track-based algorithm, while the calorimeter-based algorithm accepts any track with \(p_{T}>2\) GeV. A standard quality selection has been defined in Ref. [10]. However, for the reconstruction of \(\tau\) leptons a somewhat stricter selection has been applied. Good quality tracks are required to satisfy \(\chi^{2}/\mathrm{n.d.f}<1.7\), to have a number of pixel and SCT hits \(\geq 8\) and transverse impact parameters \(d_{0}<1\)mm. For the leading track in addition the number of low threshold TRT hits has to be larger than 10 in a pseudorapidity \(\eta\) range up to 1.9, while for the second or third track the presence of a B-Layer hit and ratio of the of high-to-low threshold hits of smaller than 0.2 are required. Both requirements were added to minimize the number of accepted tracks from conversions. A dedicated veto against electron tracks being used as leading tracks is not applied at the reconstruction level. This will be taken care of separately as part of the identification procedure.

Figure 2 shows the reconstruction efficiency for \(p_{T}=1-50\) GeV using the standard quality selection as defined in Ref. [10]. Adding the additional quality criteria as described above, the overall efficiency for reconstructing good quality tracks from \(\tau\) lepton hadronic decays is reduced to \(82-83\%\). The reconstruction efficiency is slightly higher for tracks from single prong decays compared to three-prong decays, where tracks could be very collimated particularly for boosted \(\tau\) leptons.

#### 3.1.2 Charge misidentification

The charge of the \(\tau\) lepton is calculated as the sum of the charges of the reconstructed tracks. For the leading track, which is required (e.g. by the track-based algorithm) to have a transverse momentum 4 larger than 9 GeV, charge mis-identification is limited to \(\sim 0.2\%\) using the quality cuts described above. The overall charge mis-identification probability for the hadronically decaying \(\tau\) lepton is however dominated by combinatorial effects: single-prong decays may migrate to the three-prong category due to photon conversions or the presence of additional tracks from the underlying event. A three-prong decay

Figure 2: Reconstruction efficiency for tracks from charged \(\pi\)s for one- and three-prong hadronic \(\tau\) decays from \(W\to\tau V\) and \(Z\to\tau\tau\) signal samples as a function of the transverse momentum of the track (left) and of the pseudorapidity for three different ranges of track \(p_{T}\) (right).

might be reconstructed as a single-prong decay due to inefficiencies of the track reconstruction and selection. This overall charge mis-identification is estimated to be below \(\sim 3.6\%\) without requiring additional quality cuts. In fact, the \(\tau\) charge misidentification is dominated by a combination of effects, but the contributions from the charge misidentification of the individual tracks should not be neglected.

Table 1 shows the percentage of contamination for one- and three-prong candidates using the aforementioned quality criteria for tracks in the core region. For the roughly 3.9% contamination of the single-track candidates from three-prong decays, about 85% are due to hadronic interactions. A 3.8% contamination of three-track candidates from one-prong decays is observed with 70% of them being due to conversions. The percentage of the overall charge misidentification is also shown. Requiring at least one B-Layer hit reduces the charge misidentification both in the case of electron tracks from conversions and in the case of hadronic interactions at low radii. However, this happens at the expense of an additional loss in efficiency in particular for three-prong decays.

#### 3.1.3 Tracks from conversions

Photons from \(\pi^{0}\) decays might convert in the material of the inner detector and then contribute additional tracks to the core or isolation region of the \(\tau_{had}\) candidate. This could result in one-prongs being reconstructed as three-prong candidates, in an inefficiency of the reconstruction and identification criteria and in a degradation of the energy resolution as calculated from the energy-flow algorithm.

A large fraction of reconstructed \(\tau_{had}\) candidates are accompanied by conversions. In 1.5% of the cases a conversion electron is reconstructed as the leading track of the one-prong candidate, while 5.7% of the three-prong candidates contain one reconstructed track coming from a conversion electron. In Table 1 the effects of charge misidentification and contamination from photon conversions are quantified.

#### 3.1.4 Impact parameter

The mean proper lifetime of the \(\tau\) lepton is about 0.29 ps. Although the lifetime of the \(\tau\) lepton is about five times shorter than that of the \(b\)-quark, the transverse impact parameters of its decay products are still useful for \(\tau\) identification. The impact parameters, \(d_{0}\) and \(z_{0}\sin(\theta)\), have been studied for one-prong candidates reconstructed by the track-based algorithm. The transverse impact parameter \(d_{0}\) is defined

\begin{table}
\begin{tabular}{|l|c|c|c|} \hline Seeds for track-based & Reconstructed as & Reconstructed as & Reconstructed as \\ \(\tau_{had}\)-candidates & single-prong & three-prong & two-prong \\ \hline \begin{tabular}{l} Electron contamination \\ (from conversion) \\ \end{tabular} & 1.5\% & 5.7\% & 2.9\% \\ \hline \hline \(\tau\rightarrow\pi^{\pm}n\pi^{0}\nu\) & 96.1\% & 3.8\% & 23.8\% \\ \hline \(\tau\rightarrow3\pi^{\pm}n\pi^{0}\nu\) & 3.9 \% & 96.2\% & 76.2\% \\ \hline \hline 
\begin{tabular}{l} Charge misid. \\ (no had. interact.) \\ \end{tabular} & 1.7\% & 3.6\% & \\ \hline \hline \end{tabular}
\end{table}
Table 1: Percentage of one- and three prong \(\tau\) lepton hadronic decays within reconstructed one-, two- and three-prong \(\tau_{had}\) candidates by the track-based algorithm, matched to true \(\tau\) decays. Tracks in a cone of \(\Delta R=0.2\) around the leading good quality track are considered. A transverse momentum of \(p_{T}>9\) GeV is required for the leading track. An estimate for electron contamination and charge misidentification is given in addition. Separately specified are results for a subsample where no hadronic secondary interaction of primary charged \(\pi\) was recorded inside the inner detector volume. Events from \(Z\rightarrow\tau\tau\) and \(W\rightarrow\tau\nu\) samples were used.

as the smallest distance in the transverse plane between the track and the reconstructed primary vertex. The impact parameter \(z_{0}\) is given by the distance in \(z\)-direction between the reconstructed primary vertex and the point of closest approach in the transverse plane of the track multiplied by \(\sin(\theta)\) to obtain the component transverse to the track direction. Tracks assigned to the \(\tau_{had}\) candidate are not used in the primary vertex fit.

In Fig. 3 the resolution of the transverse (left) and longitudinal (right) impact parameters are shown as a function of \(|\eta|\). The resolution for final state muons and pions from \(\tau\to\mu\nu\nu\) and \(\tau\to\pi(\pi^{0})\nu\) decays are similar: about 13 \(\mu\)m for \(|\eta|<1.0\) and about 50 \(\mu\)m for \(|\eta|>1.0\) for the transverse and longitudinal impact parameters, respectively. No degradation related to hadronic interactions for \(\tau\to\pi\nu\) decays is observed. This has been verified by studying events with elastic interaction in the Inner Detector (hadronic interaction), defined as events where the outgoing \(\pi^{\pm}\) carries more than 90 % of the transverse energy of the incoming \(\pi^{\pm}\). This observation is consistent with that presented in Ref. [11].

In Fig. 4 distributions of the significances of the impact parameters are presented. The significance is defined as the impact parameters divided by its estimated error. The distribution shows a moderate discrimination power between one-prong candidates reconstructed from hadronic \(\tau\) decays and fake one-prong candidates. Due to the limited resolution of the longitudinal impact parameter, the separation between the two classes is less significant in that case.

Figure 4: Significances of the impact parameters \(d_{0}\) (left) and \(z_{0}\sin(\theta)\) (right) for 1-prong \(\tau_{had}\) candidates reconstructed by the track-based algorithm. Distributions are shown for \(\tau_{had}\) candidates reconstructed from \(\tau\) decays and for fake candidates which do not originate from the decays of \(b\)- or \(c\)-hadrons.

Figure 3: Transverse (left) and longitudinal (right) impact parameter resolution as a function of \(|\eta|\) from a one-prong \(Z\to\tau\tau\) sample. The open (full) circles are from \(\tau\to\pi(\pi^{0})\nu\) (\(\tau\to\mu\nu\bar{\nu}\)) events.

#### 3.1.5 Secondary vertex reconstruction and transverse flight path

The significant lifetime of the \(\tau\) lepton (\(c\tau=87.11\mu\)m) allows the reconstruction of its decay vertex for three-prong decays. Currently, five vertex fitting algorithms [12, 13, 14] are implemented in the ATLAS reconstruction framework. Among these the adaptive vertex fitter [13], an iterative re-weighted fit which down-weights tracks according to their weighted distance to the vertex, was found to give the optimal performance.

To estimate its performance, secondary vertex fits were performed using tracks associated with \(\tau_{had}\) candidates from \(Z\rightarrow\tau\tau\) and \(W\rightarrow\tau\nu\) events. The quality criteria applied in the track-based reconstruction were required to be met by the tracks. The \(\tau_{had}\) candidates associated with a true hadronic \(\tau\) decay were divided into two classes. Candidates with three tracks successfully matched to true particles coming from the same true three-prong hadronic \(\tau\) decays were used as a reference. These candidates are denoted hereafter as fully-matched. The second class is composed of the remaining candidates with at least two tracks of which at least one is matched to a true particle coming from a hadronic \(\tau\) decay. These candidates are denoted hereafter as partially matched.

The resolution of the secondary vertex position varies strongly if measured in the perpendicular or parallel direction with respect the momentum of \(\tau_{had}\) candidate. The resolution on the position of the secondary vertex calculated in the plane perpendicular to the momentum of the \(\tau_{had}\) candidate is expected to be better than in the parallel direction due to the collimation of tracks. To estimate the resolution in the transverse plane, the residuals of the vertex position in the direction perpendicular to both momentum of a \(\tau_{had}\) candidate and the beam axis were calculated. The distributions were approximated by a double Gaussian fit. For fully matched three-prong \(\tau_{had}\) candidates there is no significant difference between the distributions obtained with different fitters. The distributions of residuals of the secondary vertex position obtained with the adaptive fitter, parallel and perpendicular to the direction of flight of the \(\tau_{had}\) candidate are presented in Fig. 5. Shown in Table 2 are the resolution5), the mean values of the fit and 68.3 % and 95.0 % coverages6) for the fully matched, partially matched and combined samples. As expected, the transverse resolution (\(\sigma\sim 10\ \mu m\)) is far more accurate than the parallel one (\(\sigma\sim 600\ \mu m\)). The non-Gaussian tails are significant in both cases, but far more important in the case of the parallel component. A precise reconstruction of the transverse flight path is therefore possible, which is important for further rejection of the QCD background. It may also be possible to obtain a competitive measurement of the \(\tau\) lifetime, which requires a measurement of the flight path and momentum of the \(\tau\) lepton.

Footnote 5: In the case of a double Gaussian fit, the width of the central Gaussian will be quoted as the resolution hereafter.

Footnote 6: The coverage is the half-width of a symmetric interval covering a given percentage of the distribution.

Shown in Fig. 6 is the resolution on the transverse flight path as a function of the transverse momentum and the pseudorapidity of the \(\tau_{had}\) candidates. The resolution was obtained from a Gaussian fit to a central interval covering 80% of distributions of residuals of a transverse flight path for the adaptive vertex fitter for fully matched three-prong candidates. In addition the 68.3% and 95% coverages of distributions of residuals are presented.

Distributions of the significance of the transverse flight path, for different classes of three-prong candidates are shown in Fig. 7. This distribution might be used to discriminate between true \(\tau_{had}\) candidates and fake candidates from light jets. The discrimination in the case of \(b\)- and \(c\)- jets seems however to be difficult.

An efficient rejection of tracks coming from photon conversions, decays of long-lived particles and hadronic interactions in the material reduce the number of one-prong candidates wrongly reconstructed as two- or three-prong candidates and improve the separation between correctly reconstructed three-prong candidates and candidates from light jets. It is a subject of further studies currently in progress.

\begin{table}
\begin{tabular}{|c||c||c||c||c||} \hline \hline  & Resolution & Mean & 68.3\% & 95\% \\ \hline \hline  & \multicolumn{4}{|c||}{Parallel} \\ \hline Fully matched 3-prong & \(0.593\pm 0.008\,\mathrm{mm}\) & \(0.006\pm 0.006\,\mathrm{mm}\) & \(1.27\,\mathrm{mm}\) & \(5.33\,\mathrm{mm}\) \\ Partially matched & \(0.703\pm 0.030\,\mathrm{mm}\) & \(-0.035\pm 0.020\,\mathrm{mm}\) & \(3.83\,\mathrm{mm}\) & \(>15\,\mathrm{mm}\) \\ Combined & \(0.613\pm 0.008\,\mathrm{mm}\) & \(0.004\pm 0.006\,\mathrm{mm}\) & \(1.89\,\mathrm{mm}\) & \(11.37\,\mathrm{mm}\) \\ \hline \hline  & \multicolumn{4}{|c||}{Transverse} \\ \hline Fully matched 3-prong & \(10.1\pm 0.2\,\mathrm{\mu m}\) & \(0.2\pm 0.1\,\mathrm{\mu m}\) & \(14.4\,\mathrm{\mu m}\) & \(36.9\,\mathrm{\mu m}\) \\ Partially matched & \(11.3\pm 0.5\,\mathrm{\mu m}\) & \(-0.1\pm 0.2\,\mathrm{\mu m}\) & \(20.9\,\mathrm{\mu m}\) & \(72.2\,\mathrm{\mu m}\) \\ Combined & \(10.5\pm 0.2\,\mathrm{\mu m}\) & \(0.1\pm 0.1\,\mathrm{\mu m}\) & \(16.4\,\mathrm{\mu m}\) & \(48.1\,\mathrm{\mu m}\) \\ \hline \end{tabular}
\end{table}
Table 2: Resolution and mean of the distribution of residuals of the secondary vertex position in the directions parallel and transverse to that of the reconstructed momentum vector of the \(\tau_{had}\) candidate as obtained from the adaptive vertex fitter. Candidates with up to three associated tracks reconstructed by the track-based algorithm were used. The resolution quoted is the \(\sigma\) of the core Gaussian of a double Gaussian fit in the range \([-4\,\mathrm{mm},4\,\mathrm{mm}]\) in the parallel direction and \([-50\,\mathrm{\mu m},50\,\mathrm{\mu m}]\) in the transverse direction. The 68.3% and 95% coverages are also quoted.

Figure 5: Residuals of the secondary vertex position parallel and perpendicular to the direction of flight of the \(\tau_{had}\) candidate using the adaptive vertex fitter. Fully (solid) and partially (open) matched three-prong \(\tau_{had}\) candidates reconstructed with the track-based algorithm from \(Z\rightarrow\tau\tau\) and \(W\rightarrow\tau\nu\) processes are used.

Figure 6: Resolution on the transverse flight path reconstructed with the adaptive vertex fitter for fully matched three-prong \(\tau_{had}\) candidates as a function of the transverse momentum (left) and the pseudorapidity (right). Standard deviations of Gaussians fitted to central intervals covering 80% of the residual distributions are shown (black points). In addition the 68.3% and 95% coverages of the distributions of residuals of the secondary vertex position are shown (dashed and dot-dashed lines).

Figure 7: Significance of the transverse flight path for fully matched and partially matched three-prong and for fake candidates with and without hadrons containing b or c quarks (the contribution from semileptonic decays of b/c jets into \(\tau\) leptons was not subtracted).

### Reconstruction of \(\pi^{0}\) subclusters

The high granularity of the electromagnetic calorimeter in ATLAS allows for the identification of isolated subclusters from \(\pi^{0}\)s inside the core region of the reconstructed \(\tau\) lepton hadronic decays.

Studies have been performed based on the topological clustering algorithm [15] with only the middle layer of the calorimeter used for finding primary maxima, and the strip layer used for finding the secondary maxima. The clustering was performed based on cells in a region \(\Delta R<0.4\) around the direction of the leading track satisfying \(p_{T}>9\) and only subclusters with center within \(\Delta R<0.2\) were taken. A subtraction procedure was applied first to reduce the impact from energy deposits of nearby \(\pi^{\pm}\)'s and of energy double-counting when adding the latter (track + \(\pi^{0}\) clusters) to reconstruct the visible \(\tau_{had}\) energy. Namely, before clustering procedure, cells being closest to the impact point of the track (\(\Delta R<0.0375\)) were removed. The subtraction was stopped when the subtracted energy exceeded 70% of the track momentum. In the case of coincidence of large energy deposits in the hadronic calorimeter (above 40% of the track momentum) and in the presampler+strip layer close to the track, indicating superposition of \(\pi^{0}\) and \(\pi^{\pm}\) showers, cells were subtracted only from the middle layer up to the point where the transverse energy of the remaining cells exceeded \(2.5\cdot E_{T}\) collected in the presampler+strip layer (always counted in \(\Delta R<0.0375\) from the track impact point).

Reconstructed subclusters were required to have \(E_{T}>1\) and be separated by \(\Delta R>0.0375\) from the impact point of the track in the middle layer. In addition, subclusters were accepted if their reconstructed energy in the strip+presampler layers exceeded 10% of their total energy. These requirements efficiently removed about 50% of satellite clusters from charged \(\pi\)s in the case of \(\tau\rightarrow\pi\nu\) decays. Table 3 summarizes the results in terms of the fraction of one-prong candidates reconstructed with a given multiplicity of \(\pi^{0}\) subclusters.

Reconstructing the track and \(\pi^{0}\) subclusters for single-prong decays allows for the definition of the energy and visible mass of the hadronic \(\tau\) decays from the vector sum of both components. The procedure was evaluated for one-prong decays from \(W\rightarrow\tau\nu\) events, i.e. for \(\tau\) leptons with visible transverse momenta below \(50\). Figure 8 shows the response and resolution obtained by this algorithm for reconstructing the visible energy in decays of type \(\tau\rightarrow\rho\nu\) from \(W\rightarrow\tau\nu\) events in case at least one \(\pi^{0}\) subcluster is reconstructed. A Gaussian fit to the core region of the distribution yields a resolution of 4.6% with an effective shift of \(-2.4\%\), dominated by the calibration of the electromagnetic calorimeter not being optimal for the \(\pi^{0}\) subcluster reconstruction.

As a final benchmark for the quality of the \(\pi^{0}\) cluster reconstruction discussed above, the invariant mass of \(\tau\rightarrow\rho\nu\rightarrow\pi^{0}\pi\nu\) decays is reconstructed from the track + \(\pi^{0}\) subcluster system which is more difficult than the reconstruction of the transverse energy only since the resolution is dominated by the precision of the reconstruction of the angle between the charged and the neutral pion. Figure 8 (right) shows the reconstructed visible mass for \(\tau\rightarrow\rho\nu\), \(\tau\to a_{1}(\to 2\pi^{0}\pi)\nu\), and \(\tau\rightarrow\pi\nu\) decays. The relative contributions are proportional to the branching fractions convoluted with the experimental efficiencies of the algorithm applied to inclusive hadronic decays of the \(\tau\) lepton. If more than one \(\pi^{0}\) subcluster is reconstructed the energy weighted barycenter of the cluster system is taken.

\begin{table}
\begin{tabular}{|l|c|c|c|} \hline decay mode & no \(\pi^{0}\) subclusters & 1 \(\pi^{0}\) subcluster & \(\geq 2\)\(\pi^{0}\) subclusters \\ \hline all \(\tau\rightarrow\mathrm{had}\nu\) & 32\% & 35\% & 33\% \\ \hline \hline \(\tau\rightarrow\pi\nu\) & 65\% & 20\% & 15\% \\ \hline \(\tau\rightarrow\rho\nu\) & 15\% & 50\% & 35\% \\ \hline \(\tau\to a_{1}(\to 2\pi^{0}\pi)\nu\) & 9\% & 34\% & 57\% \\ \hline \end{tabular}
\end{table}
Table 3: Single prong candidates: fractions with zero, one and two or more reconstructed \(\pi^{0}\) subclusters.

#### 3.2.1 Combined veto on electron tracks

An efficient rejection of tracks originating from isolated electrons is important for rejecting backgrounds for example from \(W\to e\nu\) and \(Z\to ee\) events. One possibility would be to reject tracks that have been identified as good electron candidates by the standard electron reconstruction algorithm. With the so called tight selection this algorithm is found to reject \(\sim 85\%\) of all electrons from \(W\to e\nu\) events with a loss of efficiency for true hadronic \(\tau\) decays with \(p_{T}^{\rm track}>9\) GeV of less than 1%.

To achieve a more stringent selection, a dedicated algorithm to veto electrons has been developed aiming at a higher rejection rate while, at the same time, retaining a high fraction of hadronic \(\tau\) decays. It is based on the following variables:

* The energy deposited in the hadronic part of the calorimeter (\(E^{\rm HCAL}\)).
* The energy not associated with a charged track in the strip compartment of the electromagnetic part of the calorimeter (\(E_{\rm max}^{\rm strip}\)).
* The ratio in the transverse plane of the associated energy in the electromagnetic calorimeter and the track momentum (\(E_{T}/p_{T}\)).

Figure 8: The energy response obtained for the visible energy from \(\tau\to\rho\nu\) events using candidates with one \(\pi^{0}\) subcluster (left). The invariant mass of the visible decay products for hadronic single-prong \(\tau\to\rho\nu\), \(\tau\to a_{1}(\to 2\pi^{0}\pi)\nu\), and \(\tau\to\pi\nu\) decays using candidates from \(W\to\tau\nu\) events with at least one \(\pi^{0}\) subcluster reconstructed (right).

Figure 9: The efficiency of the electron veto algorithm for \(W\to\tau\nu\) (rectangles) and \(W\to e\nu\) (triangles) events as a function of \(|\eta|\) and \(\rm p_{T}\) of the leading track.

* The ratio of the number of high threshold to low threshold hits (including outliers) in the TRT (\(\mathrm{N_{HT}/N_{LT}}\)).

The first two variables are used to divide tracks into categories in which discrimination is provided by fixed cuts on the remaining two variables.

The algorithm yields a rejection factor of 60 against electrons from \(W\to e\nu\) events at the expense of losing 5% of the signal from \(W\to\tau\nu\) events. The efficiency of the algorithm 7) as a function of \(|\eta|\) and \(p_{T}\) is shown in Fig. 9 and its performance is summarized in Table 4. For completeness results from the standard electron reconstruction algorithm are also shown. The dedicated electron-veto described here gives much better efficiency for rejecting isolated electrons from W decay than the standard electron reconstruction algorithm for comparable loss in accepting true hadronic \(\tau\) decays.

Footnote 7): For hadronic decays of \(\tau\) leptons the efficiency is defined w.r.t. the reconstructed \(\tau_{had}\) candidates and for electrons w.r.t. to all electrons inside \(|\eta|\leq 2.5\) with \(p_{T}>9\) GeV.

## 4 Offline algorithms for \(\tau\) reconstruction

Two complementary algorithms for the reconstruction of hadronic \(\tau\) decays have been implemented in the ATLAS offline reconstruction software. Each algorithm is discussed separately below and their performance is compared.

### The calorimeter-based algorithm

In this approach [17], hadronically decaying \(\tau\) candidates are reconstructed using calorimeter clusters as seeds. They are obtained from a sliding window clustering algorithm applied to so called calorimeter towers which are formed from cells of all calorimeter layers on a grid of size \(\Delta\eta\times\Delta\phi=0.1\times 2\pi/64\). The energy and position are calculated from the clusters, while all cells with the full granularity of the

\begin{table}
\begin{tabular}{|l|c|c|c|} \hline  & Reconstructed as & Reconstructed as & Overall \\ Candidates & single-prong & three-prong & \\ \hline \hline Electron-veto algorithm & & & \\ \(\tau\) from \(W\to\tau\nu\) (vs reconstructed \(\tau_{had}\)) & 94.1\% & 96.2\% & 94.9\% \\ Electron from \(W\to e\nu\) (vs true e) & 1.5\% & \(<0.1\%\) & 1.6\% \\ \hline \hline Standard algorithm (tight selection) & & & \\ \(\tau\) from \(W\to\tau\nu\) (vs reconstructed \(\tau_{had}\)) & 99.9\% & 99.9\% & 99.9\% \\ Electron from \(W\to e\nu\) (vs true e) & 15.6\% & 0.4\% & 16.4\% \\ \hline \hline Standard algorithm (medium selection) & & & \\ \(\tau\) from \(W\to\tau\nu\) (vs reconstructed \(\tau_{had}\)) & 90.6\% & 95.1\% & 92.1\% \\ Electron from \(W\to e\nu\) (vs true e) & 4.2\% & 0.2\% & 4.6\% \\ \hline \hline \end{tabular}
\end{table}
Table 4: Efficiency for hadronically decaying \(\tau\) leptons and true electrons from \(W\to\tau\nu\) for passing the electron veto algorithm. The numbers given are normalized to true electrons with \(p_{T}>9\) GeV and \(|\eta|<2.5\) (vs. true e) and to reconstructed one-prong or three-prong candidates with the leading track being matched to a \(\pi\) from \(W\to\tau\nu\) events (vs. reconstructed \(\tau_{had}\)). The probability that an electron from \(W\to e\nu\) events with \(p_{T}>9\) GeV and \(|\eta|<2.5\) is reconstructed as one-prong (three-prong) candidate is \(\sim 70\%\) (\(\sim 0.7\%\)). In addition the performance of the standard algorithm for electron reconstruction [16] is shown. The statistical uncertainty on the numbers presented here is at the level of \(0.1-0.5\%\).

corresponding calorimeters are used to calculate the quantities involved in \(\tau\) identification as described in the following. Only clusters with a transverse energy \(E_{T}>15\) GeV are used. The probability for a true \(\tau\) to be reconstructed as a cluster increases from 20% to 68% over the visible \(\tau\) transverse energy range from 15 to 20 GeV and saturates at 98% for \(E_{T}>30\) GeV.

All cells within \(\Delta R<0.4\) around the barycenter of the cluster are then calibrated with an H1-style calibration [18]. The cell weights are a function of the cell energy density, \(\eta\) and the calorimeter region. These weights have been optimized for jets [18] and only approximately for hadronic \(\tau\) decays. The mean and sigma of a Gaussian fit to the ratio of the reconstructed and the generated energy of the visible \(\tau\) decay products, \(E_{T}^{\tau-vis}\), in the range from 0.8 to 1.2 is shown in Fig. 10 as a function of \(E_{T}^{\tau-vis}\) and \(\eta\). The resolution is of the order of 10% and an offset in the range from +5 to -7% is observed in the \(\tau\) energy range from 20 to 50 GeV, while at larger energies the offset is of the order of -3 to -5%.

Several quantities that exploit the \(\tau\) lepton properties have been combined in a likelihood function to discriminate hadronic \(\tau\) decays from fake candidates originating from QCD jets. These quantities are described in the following:

* **The electromagnetic radius \(R_{em}\)**: To exploit the smaller transverse shower profile in \(\tau\) decays, the electromagnetic radius \(R_{em}\) is used, defined as \[R_{\rm em}=\frac{\sum_{i=1}^{n}E_{T,i}\sqrt{\left(\eta_{i}-\eta_{\rm cluster }\right)^{2}+\left(\phi_{i}-\phi_{\rm cluster}\right)^{2}}}{\sum_{i=1}^{n}E_{ T,i}},\] (1) where \(i\) runs over all cell in the electromagnetic calorimeter in a cluster with \(\Delta R<0.4\). The quantities \(\eta_{i}\), \(\phi_{i}\), and \(E_{T,i}\) denote their position and transverse energy in cell \(i\). Cells may have different sizes depending on the layer and their \(\eta\) value. The size varies from \(\Delta\eta\times\Delta\phi=0.003\times 0.1\) in the \(\eta\)-strip region of the barrel to \(0.025\times 0.025\) for the second calorimeter layer. This leads to a dependence of the performance on \(\eta\). This variable shows good discrimination power at low \(E_{T}\) but becomes less effective at higher \(E_{T}\).
* **Isolation in the calorimeter**:

Figure 10: The ratio of the reconstructed (\(E_{T}\)) and the true (\(E_{T}^{\tau-vis}\)) transverse energy of the hadronic \(\tau\) decay products is shown as a function of the visible true transverse energy \(E_{T}^{\tau,\,\rm vis}\) (left), calculated in \(|\eta|<2.5\) and \(|\eta|\) (right) for taus from \(Z\to\tau\tau\) (triangles) and \(A\to\tau\tau\) with \(m_{A}=800\) GeV (squares) decays. The ordinate value is the mean and the error bars correspond to the sigma of the Gaussian fit performed in the range \(0.8<E_{T}/E_{T}^{\tau,\,\rm vis}<1.2\). The results are obtained after applying the loose likelihood selection, see below.

Clusters built from hadronic \(\tau\) decays are well collimated and therefore rather tight isolation criteria can be used. Here a ring of \(0.1<\Delta R<0.2\) was chosen as the isolation region and the quantity \[\Delta E_{\rm T}^{12}=\frac{\sum_{i}E_{T,i}}{\sum_{j}E_{T,j}},\] (2) is calculated, where the indices \(i\) and \(j\) run over all electromagnetic calorimeter cells in a cone around the cluster axis with \(0.1<\Delta R<0.2\) and \(\Delta R<0.4\), respectively, and \(E_{T,i}\) and \(E_{T,j}\) denote the transverse cell energies. Like \(R_{\rm em}\), the \(\Delta E_{T}^{12}\) distribution shows an \(E_{T}\) dependence and becomes narrower with increasing \(E_{T}\). This variable also depends on the event type and is expected to be less effective for events with higher hadronic activity, like e.g. \(t\bar{t}\) events.
* **Charge of the \(\tau\) candidate**: The charge of a \(\tau\) candidate is defined as the sum over the charge(s) of the associated track(s). The misidentification of the charge on the level of a few percent shows almost no \(E_{T}\) dependence.
* **Number of associated tracks**: The number of tracks, \(N_{tr}\), associated with a given cluster within \(\Delta R<0.3\). The tracks are required to have \(p_{T}>2\) GeV and no specific requirements on the quality of the track reconstruction is made. A significant fraction of events with zero, two, and even four tracks is observed for true hadronic \(\tau\) decays.
* **Number of hits in the \(\eta\) strip layer**: The number of hits in \(\eta\) direction in the finely segmented strip detector, \(N_{strip}\), in the first layer of the electromagnetic barrel calorimeter is also used in the likelihood discrimination. Cells in the \(\eta\) strip layer within \(\Delta R<0.4\) around the cluster axis are counted as hits if the energy deposited exceeds 200 MeV. In contrast to jets, a significant fraction of \(\tau\) leptons deposit nearly no energy in the \(\eta\) strip layer (\(\tau\rightarrow\pi\nu\) decays) and the number of corresponding hits is small.
* **Transverse energy width in the \(\eta\) strip layer** The transverse energy width \(\Delta\eta\) is defined as \[\Delta\eta=\sqrt{\frac{\sum_{i=1}^{n}E_{Ti}^{\rm strip}\left(\eta_{i}-\eta_{ \rm cluster}\right)2}{\sum_{i=1}^{n}E_{Ti}^{\rm strip}}}.\] (3) where the sum runs over all strip cells in a cone with \(\Delta R<0.4\) around the cluster axis and \(E_{Ti}^{\rm strip}\) is the corresponding strip transverse energy. Like \(R_{\rm em}\) it is a powerful discriminator at low \(E_{T}\) but loses discrimination power with increasing \(E_{T}\) for higher collimated high \(E_{T}\) jets.
* **Lifetime signed pseudo impact parameter significance**: At present only a 2-dimensional impact parameter, also called the pseudo impact parameter, is used. It is defined as the distance from the beam axis to the point of closest approach of the track in the plane perpendicular to the beam axis. From this information and from the jet axis, a quantity denoted as lifetime signed pseudo impact parameter significance, defined as \({\rm sig}_{d_{0}}=d_{0}/\sigma_{d_{0}}^{2}\) where \(\sigma\) is the impact parameter resolution, is calculated.

* \(E_{T}\) **over \(p_{T}\) of the leading track: \(E_{T}/p_{T1}\)** : For \(\tau\) decays a large fraction of the energy is expected to be carried by the leading track and the ratio of the cluster energy \(E_{T}\) to the momentum of the leading track \(p_{T1}\) is expected to be large, close to 1. This provides another discrimination against QCD jets, which are expected to have a more uniform distribution of \(p_{T}\) among the tracks. They are also expected to have more additional neutral particles. Values above one are also expected from \(\tau\) decay modes involving additional \(\pi^{0}\)s and for three-prong decays. The \(E_{T}\) dependence is rather modest for \(\tau\) decays but more pronounced for QCD jets, which tend to become more signal like with higher \(E_{T}\).

In Fig. 11 the distributions of a few discriminating variables are shown for signal and backgrounds for transverse cluster energies \(E_{T}\) in the range between 40 and 60 GeV and for candidates with 1 or 3 tracks.

For the calorimeter-based algorithm the \(\tau\) identification is based on a one-dimensional likelihood ratio constructed from three discrete variables (\(N_{\rm tr}\), \(N_{\rm strip}\) and the charge of the \(\tau\) lepton) and five continuous variables (\(R_{\rm em}\), \(\Delta E_{T}^{12}\), \(\Delta\eta\), \({\rm sig}_{d_{0}}\), and \(E_{T}/p_{T,1}\)). For the discrete variables the ratios are directly taken from the reference histograms. For the continuous variables fits of appropriate functions to each variable for all \(E_{T}\) bins have been performed. The distribution of the likelihood for taus and jets are shown in Fig. 12. Despite any limitation from using only one-dimensional distributions it shows a good separation power.

It should be noted that the \(\tau\) identification efficiency chosen to keep enough signal events and to achieve the necessary rejection against background depends on the physics channel. Despite the use of \(E_{T}\) bins the likelihood discrimination shows a residual \(E_{T}\) dependence. Therefore, a fixed cut on the likelihood value neither will result in a generally flat efficiency, nor will it be optimal.

Figure 11: The distributions of a few discriminating variables (electromagnetic radius, energy isolation, transverse energy width in the \(\eta\) strip layer and \(E_{T}\) over \(p_{T1}\) of the leading track) used in the calorimeter-based tau identification for true tau decays and jets with visible transverse cluster energies \(E_{T}\) in the range from 40 to 60 GeV and track multiplicities between 1 and 3.

### The track-based algorithm

In this approach [19], the visible part of the hadronically decaying \(\tau\) lepton is seen as a very well collimated object consisting of charged and neutral pions, with the charged component being the leading one, _i.e._ reproducing well the direction of the visible decay products and having significant transverse momentum. This assumption is followed by the requirement of a low multiplicity of tracks reconstructed in the region considered the core of the \(\tau_{had}\) candidate, and the requirement of only minimal energy deposit in the isolation region around the core. The energy-scale of the object and the calorimetric variables used in the identification are built following this picture. For most of the analyses only one-track and three-track candidates should be used. Including candidates with two tracks helps to recover a large fraction of lost three-prong candidates, however it also significantly increases the background from QCD events, in particular for \(\tau\) leptons with visible transverse momentum below \(30\GeV\). Candidates with track multiplicities larger than three should be used for monitoring the level of fake candidates only.

The reconstruction step consists of identifying and qualifying a leading hadronic track8) which becomes a seed for building the \(\tau\) candidate. Then up to six additional tracks are allowed in the core region. The \((\eta,\,\phi)\) position of the candidate is taken from the direction of the track at the vertex or the track-\(p_{T}\) weighted bary-center in the case of multi-track candidates and the energy of the candidate is calculated from the energy flow method. In addition charge \(\pm 1\) or \(0\) is required in the case of multi-prong candidates. The identification step consists of calculating calorimetric and tracking quantities and then providing a decision either based on selection with cuts or a discriminating variable based on multi-variate techniques.

Footnote 8: The threshold \(p_{T}>9\GeV\) on the leading track was used for results presented here, while it was lowered to \(6\GeV\) in the more recent software releases.

#### 4.2.1 The energy - flow approach

The energy scale of the hadronic \(\tau_{had}\) candidate is defined using an energy flow algorithm. The energy deposit in cells is divided into categories.

* The pure electromagnetic energy, \(E_{T}^{\rm emcl}\):

Figure 12: Left: The log likelihood (LLH) distribution for \(\tau\) leptons (solid) and jets from QCD production (dashed). The likelihood is applied after a preselection on the number of associated tracks, i.e. requiring \(1\leq N_{tr}\leq 3\). (Candidates with LLH \(<-10\) had variables outside the boundaries of histograms used when obtaining the PDFs for the likelihood calculation). Right: Efficiency for \(\tau\) leptons and rejection against jets for different \(E_{T}\) ranges, achieved with the likelihood selection.

The energy is seeded by an isolated electromagnetic cluster which is isolated from the good quality tracks and which has no substantial hadronic leakage. The energy is collected in a narrow window around the seed. Only presampler, strip and middle layers are used.
* The charged electromagnetic energy, \(E_{T}^{\rm chrgEM}\), \(E_{T}^{\rm chrgHAD}\): The energy is seeded by the impact point of the track(s) in each layer and the energy is collected in a narrow window around it.
* The neutral electromagnetic energy, \(E_{T}^{\rm neuEM}\): The energy is seeded by the \((\eta,\phi)\) of the track at the vertex and in each layer the closest cell is searched for. The energy is collected from not yet used cells in a cone of \(\Delta R=0.2\) with respect to the cell closest to the impact point. Only presampler, strip and middle layers are used.

In the energy-flow approach the charged energy deposits \(E_{T}^{\rm chrgEM}+E_{T}^{\rm chrgHAD}\) are replaced by the track(s) momenta (no hadronic neutrals) in order to define the energy scale of the \(\tau_{had}\). The contribution from \(\pi^{0}\)'s is included in \(E_{T}^{\rm emcl}\) and \(E_{T}^{\rm neuEM}\); the effects of \(\pi^{0}\) and \(\pi^{\pm}\) depositing energy in the same calorimeter cells or charged energy leakage outside a narrow cone around the track are corrected by adding two terms: \(\sum\)res\(E_{T}^{\rm chrgEM}\) and res\(E_{T}^{\rm neuEM}\). The complete definition for the energy scale \(E_{T}^{\rm effow}\) reads as follows:

\[E_{T}^{\rm effow}=E_{T}^{\rm emcl}+E_{T}^{\rm neuEM}+\sum p_{T}^{\rm track}+ \sum\)res\(E_{T}^{\rm chrgEMtrk}+\mbox{res}E_{T}^{\rm neuEM}. \tag{4}\]

The fractional energy response, calculated as \((E_{rec}-E_{truth})/E_{truth}\), for one and three prong candidates is shown in Fig. 13.

The evident advantage from using the above approach for defining the energy scale comes from the fact that while performing well for true hadronic decays of \(\tau\) leptons, it significantly underestimates the nominal energy of fake \(\tau_{had}\)s from jets. This effect is rather obvious since a cone of \(\Delta R=0.2\) is too narrow to efficiently collect the energy of a QCD jet (particularly with low transverse momentum) and also since a large fraction of the neutral hadronic component is largely omitted in the definition itself (as the energy deposit in the hadronic calorimeter does not contribute to the energy calculations). This leads to a faster falling background spectrum as a function of \(E_{T}\) compared to that using calibrated calorimetric clusters as implemented in the calorimeter-based algorithm (Section 4.1). This method leads however to more non-Gaussian tails in the fractional energy response than the more conventional energy estimates from calorimetry only.

Figure 13: The fractional energy response for single-prong (left) and three-prong (right) true \(\tau_{had}\) candidates reconstructed with the track-based algorithm. Events from a \(W\to\tau\nu\) sample are shown.

#### 4.2.2 Identification with calorimetric and tracking variables

Several calorimetric and tracking variables are used to discriminate a narrow, low track multiplicity \(\tau_{had}\) cluster from a hadronic cluster originating from quarks or gluons. If not stated otherwise, the calorimetric and tracking identification quantities are calculated from cells/tracks within a core cone of \(\Delta R=0.2\) around the seed. The isolation criteria used here are checked in an isolation cone \(\Delta R=0.2-0.4\). Please note, that although some definitions are very similar for the calorimeter-based and track-based algorithms, in case of the latter the narrower core cone is often used for the calculation of calorimetric quantities and a more explicit distinction between core and isolation cone is made.

Not all discriminating quantities discussed in Section 3 have been already implemented in the identification procedure. In particular transverse impact parameter, transverse flight path and categorizing single-prong candidates using \(\pi^{0}\) subclusters have been added only in the current releases of the reconstruction software. Therefore they are not used for the results presented below.

* **Tracking quantities*
* The variance \(W_{\rm tracks}^{\tau}\) (for multi-prong candidates only), defined as \[W_{\rm tracks}^{\tau}=\frac{\sum(\Delta\eta^{\tau,\,{\rm track}})^{2}\cdot{p_{T }}^{\rm track}}{\sum{p_{T}}^{\rm track}}-\frac{(\sum\Delta\eta^{\tau,\,{\rm track }}\cdot{p_{T}}^{\rm track})^{2}}{(\sum{p_{T}}^{\rm track})^{2}}.\] (5)
* The invariant mass of the tracks system (for multi-track candidates), \(m_{trk3p}\),
* The number of tracks in the isolation cone.
* **Calorimetric quantities*
* The electromagnetic radius of the \(\tau_{had}\) candidate, \(R_{\rm em}^{\tau}\), as defined in Eq. (1) for the calorimeter-based algorithm, but calculated from cells around the seed belonging to the first three samplings of the electromagnetic calorimeter only (presampler, strips and middle layer).
* The number of \(\eta\) strips, \(N_{\rm strips}^{\tau}\), with energy deposits above a certain threshold.
* The width of the energy deposit in the strips, as defined in Eq. (3) for the calorimeter based algorithm but calculated in the core cone only.
* The fraction of the transverse energy, \({\rm frac}{E_{T}}^{R12}\), deposited in a cone of radius \(0.1<\Delta R<0.2\) with respect to the total energy in a cone of \(\Delta R=0.2\). Cells belonging to all layers of the calorimeter are used: \[{\rm frac}{E_{T}}^{R12}=\frac{\sum{E_{T}^{\rm cell}}(R^{\tau,\,{\rm cell}}<0.2 )-\sum{E_{T}^{\rm cell}}(R^{\tau,\,{\rm cell}}<0.1)}{\sum{E_{T}^{\rm cell}}(R^ {\tau,\,{\rm cell}}<0.2)}.\] (6)
* The transverse energy, \(E_{T}^{\rm core}\), at the EM scale deposited inside the core cone.
* The transverse energy, \(E_{T}^{\rm isol}\) and \(E_{T}^{\rm isolHAD}\), at the EM scale, deposited inside the isolation cone.
* **Tracking and calorimetric quantities*
* The ratio of transverse energy deposited in the hadronic calorimeter in the core region (at the EM scale), \(E_{T}^{\rm chrgHAD}\), with respect to the sum of the transverse momenta of the tracks.
* The visible mass \(m_{vis}^{eflow}\) calculated from cells used for the energy-flow calculation and tracks. In case of multi-prong candidates, where this mass is smaller than that calculated from the four-momenta of the tracks, the invariant mass of the track system is taken instead.
Figure 14: The distributions for signal and backgrounds for the visible mass \(m_{vis}^{effow}\) and ratio of the transverse energy in the isolation and core region \(E_{T}^{isol}/E_{T}^{core}\) for single-prong candidates, and variance \(W_{\rm tracks}^{\tau}\) and invariant mass of the track system \(m^{trk3p}\) for three-prong candidates. Distributions are shown for the candidates in the transverse energy range \(E_{T}=20-40\) GeV.

In Fig. 14 as an example the distributions for signal and backgrounds for the \(m_{vis}^{efflow}\), the ratio \(E_{T}^{isol}/E_{T}^{core}\) for single-prong candidates, the variance \(W_{\rm tracks}^{\tau}\) and the invariant mass \(m_{trk3p}\) for three-prong candidates are shown. Note that the \(m_{vis}^{efflow}\) distribution shows a double peak structure coming from \(\tau\rightarrow\pi^{\pm}\nu\) and \(\tau\rightarrow\rho(a1)\nu\) decays. The separation for candidates with and without \(\pi^{0}\) clusters was not done for the distribution shown.

#### 4.2.3 Overall efficiency and rejection

The identification step is done by calculating discriminants using basic cut methods, cut methods optimized by the TMVA package [20], multi-variate analyses based on neural network technique, and from PDRS discrimination [21].

The rejection power expected from the identification step only is quite modest, given that a quite good rejection is already achieved in the reconstruction step. The overall performance is summarized in Table 5. For an efficiency of about 30% with respect to all hadronic decays in the energy range \(10-30\) GeV, rejection rates of 200/360 for one-prong/three-prong hadronic \(\tau\) decays can be achieved with the cut based selection and of 500/700 with multi-variate selection techniques.

### Comparison of the two algorithms

Figure 15 shows the expected performance of the two algorithms, illustrated as curves describing the jet rejection versus the efficiency, separately for one and three-prong hadronic \(\tau\)-decays and for different ranges of the visible transverse energy. The jet rejections are computed with respect to jets reconstructed from true particles in the Monte Carlo. The rejections obtained are between a factor of two and ten higher for one-prong decays than for three-prong decays, depending on the algorithm and on the transverse energy range considered. For an efficiency of 30% for one-prong decays, the rejection against jets is typically between 500 and 5000, as illustrated more quantitatively and as a function of the visible transverse energy in Table 6.

Figure 16 shows the normalized track-multiplicity spectra for hadronic \(\tau\) candidates with visible transverse energies above 20 GeV, from \(Z\rightarrow\tau\tau\) decays and from jets, as reconstructed by the track-based algorithm. The distributions are shown after the reconstruction step, after a cut-based identification algorithm and finally after applying a neural network discrimination. The track multiplicity in the jet sample is quite different from that in the signal sample, independently from the cuts applied.

\begin{table}
\begin{tabular}{|c||c|c|c|c|c|} \hline \hline Selection & Efficiency & Rejection & Rejection & Rejection & Rejection \\  & & cuts & TMVA cuts & NN & PDRS \\ \hline \hline  & \multicolumn{5}{c|}{\(E_{T}=10\)-30 GeV} \\ \hline \hline one-prong & 0.33 & 225 \(\pm\) 10 & 435 \(\pm\) 30 & 510 \(\pm\) 40 & 460 \(\pm\) 40 \\ three-prong & 0.28 & 360 \(\pm\) 25 & 470 \(\pm\) 40 & 740 \(\pm\) 70 & 670 \(\pm\) 60 \\ \hline \hline  & \multicolumn{5}{c|}{\(E_{T}=30\)-60 GeV} \\ \hline \hline one-prong & 0.42 & 140 \(\pm\) 10 & 170 \(\pm\) 10 & 440 \(\pm\) 40 & 320 \(\pm\) 30 \\ three-prong & 0.45 & 60 \(\pm\) 2 & 9 0 \(\pm\) 10 & 160 \(\pm\) 10 & 130 \(\pm\) 10 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Efficiencies and rejection rates for different discrimination techniques for the track-based algorithm for fixed efficiencies. The efficiencies are normalized to all hadronic \(\tau\) decays. The rejection rates are calculated with respect to jets reconstructed from true particles in the Monte Carlo. Events from \(Z\rightarrow\tau\tau\) signal samples and QCD dijets were used. The errors given are statistical only.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline Algorithm & \(E_{T}=\) 10-30 GeV & \(E_{T}=\) 30-60 GeV & \(E_{T}=\) 60-100 GeV & \(E_{T}>\) 100 GeV \\ \hline Track-based & 1p: 740 \(\pm\) 70 & 1p: 1030 \(\pm\) 160 & & \\ (neural network) & 3p: 590 \(\pm\) 50 & 3p: 590 \(\pm\) 70 & & \\ \hline Calo-based & & 1p: 1130 \(\pm\) 50 & 1p: 2240 \(\pm\) 140 & 1p: 4370 \(\pm\) 280 \\ (likelihood) & & 3p: 187 \(\pm\) 3 & 3p: 310 \(\pm\) 7 & 3p: 423 \(\pm\) 8 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Rejection against jets from Monte Carlo true particles for a 30% efficiency and separately for the one-prong (1p) and three-prong (3p) candidates. The efficiencies are normalized to true hadronic \(\tau\) decays. For the signal \(Z\to\tau\tau\) events and events from \(bbH,H\to\tau\tau\) with \(m_{H}=800\) GeV were used; for the background QCD dijet-samples were used. The errors given are statistical only.

Figure 16: Track multiplicity distributions obtained for hadronic \(\tau\) decays with a visible transverse energy above 20 GeV and below 60 GeV using the track-based \(\tau\) identification algorithm. The distributions are shown after reconstruction, after cut-based identification and finally after applying the neural network (NN) discrimination technique for an efficiency of 30% for the signal (left) and the background (right).

Figure 15: Expected performance for the track-based algorithm with a neural-network selection (left) and the calorimeter-based algorithm with the likelihood selection (right). The rejection rates against jets from Monte-Calo particles as a function of the efficiency for hadronic \(\tau\) decays for various ranges of the visible transverse energy are shown. For signal events \(Z\to\tau\tau\) and \(bbH,H\to\tau\tau\) with \(m_{H}=800\) GeV were used, for the background QCD dijet samples were used.

At the same time, Figure 16 indicates that the purity of one-prong and three-prong \(\tau_{had}\) candidates improves in the signal sample since the expected fractions of single versus three prongs are reproduced. For one-prong (three-prong) candidates, the purity improves from 87% (74%) after reconstruction to 91% (86%) after cut-based identification and to 92% (93%) after applying the neural-network discrimination technique.

Figure 16 also shows that using candidates with track multiplicities above three to normalize the QCD background will allow a reasonably precise calibration of the performance using real data, provided the rejection against QCD jets is proven to be sufficient to extract a clean signal in the one-prong and three-prong categories. The sensitivity of such a method can be enhanced by also studying the track multiplicity outside the narrow cone used for \(\tau\)-identification and combining this information with that presented in Fig. 16.

The corresponding spectra for the calorimeter-based algorithm are shown in Figure 17 after reconstruction and after applying the likelihood discriminant. The optimization of the likelihood results in a lower efficiency for accepting three-prong decays which biases the track multiplicity spectra. One should note that candidates with 1-3 tracks are accepted as good \(\tau_{had}\) candidates.

The application of these \(\tau\) identification algorithms to extract \(\tau\) signatures from physics processes and to reject the large backgrounds from QCD processes is discussed in Section 6.

## 5 Fake-rates from QCD di-jet samples

This study demonstrates a simple and generic method to determine the \(\tau_{had}\) fake rate from jets in early data. Since fake rates are expected to be in the range of \(10^{-3}\) to few \(10^{-2}\) for low \(p_{\mathrm{T}}\)\(\tau\) leptons, and since the expected rate of QCD jets far exceeds the rate of hadronically decaying \(\tau\) leptons, a precise measurement of fake rates is expected to be crucial for many analyses, and also for a further optimization of the \(\tau_{had}\) identification algorithms. In the following, the method and the results are described and statistical and systematic uncertainties are discussed.

The method proposed here uses a very clean sample of QCD jets, with no significant contamination from true \(\tau\) leptons. This is achieved by selecting dijet events with two jets having similar \(p_{\mathrm{T}}\) and being back-to-back in \(\phi\) (see Fig. 18). One of the two jets is randomly chosen as the so-called 'tag jet', for which a cut on the number of tracks (\(n_{\mathrm{Tk}}\geq 4\) for \(p_{\mathrm{T}}\leq 50\) GeV \(+\) 1 track for each additional 50 GeV interval in \(p_{\mathrm{T}}\)) ensures that it is not a true hadronic \(\tau_{had}\) decay. If this cut is fulfilled, the other jet,

Figure 17: Track multiplicity distributions obtained for hadronic \(\tau_{had}\)-decays with visible transverse energy above 20 GeV and below 60 GeV using the calorimeter-based \(\tau\) identification. The distributions are shown after reconstruction and after applying the likelihood discrimination technique (medium selection) for the signal (left) and the background (right).

called 'probe jet', can be used to measure the fake rate from QCD jets 9). This is performed both for the calorimeter-based and the track-based \(\tau_{had}\) reconstruction algorithm, with identification according to the medium likelihood selection and cut discriminant, respectively. Note also that, in order to avoid a direct dependence on the trigger, the probe jet should be required to not have caused the event to be triggered.

Footnote 9): The fake rate is determined as the number of probe jets identified as \(\tau_{had}\) divided by the number of probe jets.

This method, which achieves low statistical uncertainties even for small datasets, only relies on the dijet and tag jet selection to acquire a clean QCD jet sample and it does not depend, to first order, on the number of true \(\tau\) leptons present in the sample nor on the \(\tau_{had}\) efficiencies. Also, the selection can be easily adapted to select probe jets in an environment similar to the one of any given physics analysis using \(\tau_{had}\) candidates.

To perform these studies, Monte Carlo dijet samples (generated in various \(p_{\mathrm{T}}\) ranges) and samples containing true \(\tau\) leptons (\(Z\to\tau\tau\), \(W\to\tau\nu\)) were used. Proper weighting of the samples, including trigger prescales for running at \(\mathcal{L}=10^{31}\,\mathrm{cm}^{-2}\mathrm{s}^{-1}\), has been applied. To cross-check the method, it has been verified that there is very good agreement between the values obtained with all selected jets and those coming from jets matched to Monte Carlo particles jets only, which indicates a very high jet purity.

The numerical results of the fake rate determination using the available Monte Carlo statistics for the two algorithms can be found in Table 7. Systematic uncertainties (discussed below) are not included. Note that the uncertainty in the range \(40<p_{\mathrm{T}}<80\;\mathrm{GeV}\), for both algorithms using available Monte Carlo statistics, is dominated by one dijet event (with large weight) in one of the Monte Carlo samples. More interesting are the expected statistical uncertainties in data, which are at the percent or sub-percent level for \(100\;\mathrm{pb}^{-1}\), and even for \(10\;\mathrm{pb}^{-1}\) of integrated luminosity. This demonstrates the relevance of this method for very early data.

Given the statistical precision of the fake rate results, this measurement of the systematics of other measurements is going to be limited by its own systematic uncertainties. In the following, an outline of the necessary systematic studies is given, including results where possible.

The presence of true hadronically decaying \(\tau\) leptons in the selected Monte Carlo sample is not statistically significant enough to alter the results within their uncertainties. When more statistics are available, tighter cuts on the tag side can be applied in order to remove more efficiently these types of events.

A slight tendency was observed for the jet samples with lower hard scattering transverse momenta, to show higher fake rates. This can be explained by the fact that the jet characteristics depend on the degree of parton showering. Also, jets from gluons are wider and on average have higher tracks multiplicity

Figure 18: Example of selections on a MC dijet sample, generated with \(70\leq p_{\mathrm{T}}\leq 140\;\mathrm{GeV}\). The two jets have to fulfill \(\Delta\phi\geq(\pi-0.3)\) in order to be back to back in \(\phi\) (left) and have similar \(p_{\mathrm{T}}\) values (right).

than jets from quarks. Then, the fake rate of gluon-jets should be smaller than that of quark-jets. Data triggered with the jet-triggers, that has more gluon-jets than quark-jets, and with single photon triggers, where the quark-jets very likely will be dominant, can be used to understand this effect. However, this type of systematic uncertainty will be small as long as the distributions of observable quantities (such as the number of tracks and the jet isolation) of the probe jets studied for the fake rate is comparable with the properties of the jets faking hadronically decaying \(\tau\) leptons in the physics analysis.

In case there is a physical correlation between the properties of the tag and the probe jet, the selection of the tag jet would directly influence the properties of the probe jet, and hence distort the results. As an example of a possible observable correlation, the number of tracks per jet was studied and it has been found that the correlations were in the sub-percent range. Hence it is concluded that given the current knowledge from Monte Carlo, this source of uncertainty can be neglected. For data, this can be revisited.

## 6 Tau leptons in Standard Model processes

The goals for early \(\tau\) physics in ATLAS include acquiring a sample of \(\tau\) leptons from data with a purity as high possible so that the \(\tau_{had}\) identification efficiency can be measured and the simulation can be tuned. Collecting data with an integrated luminosity of 100 \(\mathrm{pb}^{-1}\) at an instantaneous luminosity of 10\({}^{31}\)cm\({}^{-2}\)s\({}^{-1}\) will provide a unique opportunity to access and understand statistically significant \(\tau\) samples from Standard Model processes at relatively low transverse momenta. Processes, like the production of W and Z bosons and top quark pairs with their huge cross section will lead to samples of a few hundred to a few thousand identified hadronic \(\tau\) decays. Hadronically decaying \(\tau\) leptons will then become a well understood probe for discovery physics like searches for Higgs bosons, SUSY, or unexpected phenomena. Below we present feasibility studies for analyses which can be envisaged with an integrated luminosity of 100 \(\mathrm{pb}^{-1}\).

### The \(W\to\tau\nu\) inclusive production

The \(W\to\tau\nu\) signal will be produced with \(\sigma\times BR=1.7\cdot 10^{4}\) pb, and will be dominated by events with low \(p_{T}\) of the W-boson resulting in soft \(\tau\) leptons with low missing transverse energy. The expected cross-section of the dominant background from hadronic jets is \(\sim 10^{10}\) pb (calculated for hard-scattering \(p_{T}^{hard}>8\) GeV), about 6 orders of magnitude larger than the signal production.

The analysis is very sensitive to the performance of the hadronic \(\tau\)-trigger [22]. These events will have to be triggered with a \(\tau\)+\(E_{T}^{miss}\) trigger, with a configuration adequate to fit into the allowed budget for trigger rates. Given the fact that the physics motivation is to get signal events with \(\tau_{had}\) candidates at low transverse momenta, the present base-line configuration for this analysis is to use \(\tau\)20i+EFxE3010,

\begin{table}
\begin{tabular}{|l|c|c||c|c|} \hline  & \multicolumn{2}{c||}{Calorimeter-based algorithm} & \multicolumn{2}{c|}{Track-based algorithm} \\ \(p_{T}\) range & MC stat. & Expected stat. error & MC stat. & Expected stat. error \\ (GeV) & (\%) & for 100 \(\mathrm{pb}^{-1}\) (\%) & (\%) & for 100 \(\mathrm{pb}^{-1}\) (\%) \\ \hline
15-40 & 2.3 \(\pm\) 0.3 & \(\pm\) 0.02 & 2.5\(\pm\)0.5 & \(\pm\) 0.02 \\
40-80 & 5.2 \(\pm\) 2.2 & \(\pm\) 0.01 & 6.7\(\pm\)2.2 & \(\pm\) 0.01 \\
80-120 & 0.5 \(\pm\) 0.2 & \(\pm\) 0.001 & 1.8\(\pm\)0.6 & \(\pm\) 0.002 \\
120-160 & 0.2 \(\pm\) 0.2 & \(\pm\) 0.002 & 1.4\(\pm\)0.6 & \(\pm\) 0.004 \\ \hline \end{tabular}
\end{table}
Table 7: The \(\tau_{had}\) fake rate from QCD jets and its statistical uncertainty for the available Monte Carlo statistics and for expected 100\(\mathrm{pb}^{-1}\) of data in bins of \(p_{T}\) for both \(\tau_{had}\) reconstruction algorithms.

with the \(E_{T}^{miss}\) trigger applied only at the Event Filter level. The present trigger optimization gives an overall \(\sim 70\%\) trigger efficiency with respect to off-line analysis.

Footnote 10: The \(E_{T}^{miss}\) trigger efficiency is defined as the sum of the \(E_{T}^{miss}\) and \(E_{T}^{miss}\) events, and the sum of the \(E_{T}^{miss}\) events is defined as the sum of the \(E_{T}^{miss}\) events.

The signal will be extracted requiring one identified hadronic \(\tau\) decay with transverse energy \(E_{T}=20-60\) GeV and observing the characteristic track multiplicity spectrum of identified hadronic \(\tau\) decays. In the present study the track-based algorithm was used with the medium identification, corresponding to rejection of 700-1000 for the single- and 600 for the three-prong \(\tau\) selection against jets and 30% efficiency for true hadronic \(\tau_{had}\) decays (see Table 6). The overwhelming background from QCD events will be further suppressed by vetoing events with an additional isolated electrons or muons and by increasing the threshold on \(E_{T}^{miss}\). An additional handle is to select only events with the topological configuration of the \(\tau_{had}\), \(E_{T}^{miss}\) or additional jets optimal for suppressing events with large fake \(E_{T}^{miss}\), _i.e._ excluding those where the \(E_{T}^{miss}\) direction is close to the direction of the identified \(\tau_{had}\) or an additional jets (see Ref. [23]).

The QCD background has been estimated with a mixture of full and fast simulation, taking into account the necessary corrections for the different slopes in the \(E_{T}^{miss}\) distribution in the full and fast simulations. It should be noted also that predictions for this overwhelming background are subject to large uncertainties.

An important background is also expected from \(W\to e\nu\) events, where an electron passes the hadronic \(\tau\)-trigger selection criteria. This channel, with an initial production cross-section of the same order as the signal, but contributing almost exclusively to the single-prong mode, will exceed the signal rates by some factor, before a dedicated electron veto is applied to the single-prong candidates. With the expected performance of such an algorithm, as discussed in Section 3.2.1, this background can be efficiently suppressed, also providing a control channel for the topology of the hadronic part of the \(W\to\tau\nu\) events passing the trigger and offline selections. Backgrounds from \(Z\to\tau\tau\), \(t\bar{t}\), \(Z\to ee\), \(W\to\mu\nu\) events were also considered and it was estimated that they will be suppressed with the offline selection below a few percent of the signal.

Table 8 summarises the expected event yield at the various stages of the selection. With an \(E_{T}^{miss}\) threshold of 50 GeV, the expected signal-to-background ratio is 1:1 and about 3240 signal events would be observed. Increasing the threshold to 60 GeV would reduce the number of accepted signal events to 1550 but increase the signal-to-background ratio to 3:1. Figure 19 shows the expected track multiplicity spectrum after the final selection. The optimisation of this selection can be performed using control samples, i.e. \(W\to e\nu\) events extracted from the same filter stream, hence modeling of the W-recoil part of the event will be possible directly from the data. The final optimisation of the chosen efficiency/rejection and offline threshold on \(E_{T}^{miss}\) will have to be tuned with data, given the large uncertainties on Monte Carlo predictions for the background from hadronic jets. The control on the QCD background normalization will be possible with fake \(\tau_{had}\) with track multiplicity above 3, i.e in the signal-free region.

### The \(Z\to\tau\tau\) inclusive production

The inclusive \(Z\to\tau\tau\) process will provide a ten times lower rate compared to \(W\to\tau\nu\), but will have more robust prospects for analysis. It will be possible to cross-check channels with \(e\)\(\tau_{had}\) and \(\mu\)\(\tau_{had}\) final states to control the background, comparing the number of events observed in the same-sign and opposite-sign samples. Moreover, events will be primarily triggered with lepton triggers providing an unbiased sample of hadronic \(\tau\) decays which could also serve to understand efficiencies of the hadronic \(\tau\)-trigger. The measured cross-section for the \(Z\to\tau\tau\) process will be an excellent check on the \(\tau\) identification efficiencies, while the lepton identification and trigger efficiencies will be measured first from \(Z\to\ell\ell\) channels. A measurement of the visible mass of the \(\ell\)\(\tau_{had}\) system at low background levels will have sensitivity to the energy scale of the reconstructed \(\tau_{had}\)s.

\begin{table}
\begin{tabular}{|c||c|c|c|c|c|} \hline \hline Selection & \(W\rightarrow\tau\nu\) & \(W\to e\nu\) & \(W\rightarrow\mu\nu\) & QCD dijet & \(t\bar{t}\), \(Z\to ee\), \(Z\rightarrow\tau\tau\) \\ \hline \hline Trigger \(\tau 20i\)+EFxE30 & 8.8\(\cdot 10^{4}\) & 6.1\(\cdot 10^{5}\) & 3.2\(\cdot 10^{4}\) & 4.8\(\cdot 10^{5}\) & 3.0\(\cdot 10^{5}\) \\ \hline \hline Identified \(\tau+E_{T}^{miss}>\) 30 GeV & 2.0\(\cdot 10^{4}\) & 2600 & 200 & 3.0 \(\cdot 10^{6}\) & 1600 \\ \hline \(E_{T}^{miss}>\) 50 GeV & 4200 & 530 & 90 & 5.0\(\cdot 10^{4}\) & 550 \\ \hline Veto fake \(E_{T}^{miss}\) topology & 3600 & 500 & 80 & 1.8\(\cdot 10^{4}\) & 150 \\ \hline Require jet \(p_{T}>\) 15 GeV & 3240 & 450 & 60 & 3200 & 80 \\ \hline \hline Increase to \(E_{T}^{miss}>\) 60 GeV & 1550 & 150 & 25 & 500 & 30 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Expected number of events in 100 pb\({}^{-1}\) of data for signal and background after subsequent steps of the selection. The track-based algorithm has been used for \(\tau_{had}\) reconstruction. The QCD background has been estimated combining fast and full simulation. Given are the expected number of events of track multiplicity one to three, i.e. contributing to signal region only.

Figure 19: The track multiplicity spectrum of accepted \(\tau_{had}\) candidates after selection as described in the text with thresholds respectively \(E_{T}^{miss}>\) 50 GeV (left) and \(E_{T}^{miss}>\) 60 GeV (right). The expected event numbers are given for an integrated luminosity of 100 pb\({}^{-1}\).

The analysis presented here is designed to select in the first 100 pb\({}^{-1}\) of data a sufficient number of \(Z\to\tau\tau\to\ell\nu\nu\)\(\tau_{had}\nu\) events with very low background, which then can be used to determine the \(\tau_{had}\) energy scale from the reconstructed \(\ell\tau_{had}\) visible mass and to determine the \(E_{T}^{miss}\) scale [23] from the reconstructed complete invariant mass of the \(\tau\tau\) pair (including neutrinos). Events, which have been selected by the single electron or single muon trigger stream are analysed and as a first step an isolated lepton (electron or muon) with \(p_{T}^{\ell}\,>\,15\) GeV is required. Then, the set of basic selection cuts is applied. It requires a missing transverse energy \(E_{T}^{miss}>20\) GeV (to suppress \(Z\to\ell\ell\) and QCD backgrounds), transverse mass of the lepton and \(E_{T}^{miss}\) system \(m_{T}^{\ell,\,E_{T}^{miss}}<30\) GeV (against \(W\to\ell\nu\) background), total transverse energy deposited in the calorimeter \(\Sigma E_{T}^{calo}<400\) GeV (against \(t\bar{t}\) and QCD backgrounds) and finally no identified b-jet (against \(t\bar{t}\) and QCD backgrounds). In the next step, events with an identified \(\tau_{had}\) with \(p_{T}>15\) GeV are selected. The track multiplicity of identified \(\tau_{had}\) is required to be one or three. In addition the angular separation between the isolated lepton and \(\tau\) is imposed, requiring \(\Delta\phi(\ell,\tau_{had})\) to be in the ranges between 1.0 - 3.1 or 3.2-5.3.

The analysis was performed using \(\tau_{had}\) reconstructed with the calorimeter-based algorithm and the identification with the likelihood discriminant. The thresholds on the likelihood discriminant were optimized for this analysis and correspond to an overall efficiency of \(\sim 35\%\) with respect to all hadronic \(\tau\) decays. The QCD background has been estimated with a mixture of full and fast simulation which assumes uncorrelated probabilities for a jet to produce an isolated lepton candidate (predominantly leptons from heavy flavor decays with a small contribution from fakes in the electron case) and for the second jet to produce a fake \(\tau_{had}\) candidate.

Table 9 gives the expected number of signal and background events passing the selection criteria for a data sample of 100 pb\({}^{-1}\). About 520 signal events are expected in the visible mass \(m_{\ell\tau_{had}}\) window between \(37-75\) GeV. The expected background levels are 10% from \(W\to\ell\nu\) events and about 5% background from QCD events. The reconstructed visible mass of the \(\ell\tau_{had}\) pair is shown in Figure 20 for opposite-sign events.

This selection for \(Z\to\tau\tau\) events will provide access to signal-suppressed and signal-enriched samples. The same-sign events (e \(\tau_{had}\) and \(\mu\)\(\tau_{had}\)) will be essentially signal-free. This will allow a study of \(\tau_{had}\) identification and mistagging efficiencies. The mistagging efficiency will be estimated from the ratio of accepted to all candidates in different categories (one-prong with and without \(\pi^{0}\) subclusters, multi-prong). Then, this estimate can be used to predict the background component in opposite-signevents and to tune the Monte Carlo predictions for the identification variables. It will allow a confirmation of the overall consistency and an estimate of the relative error on the background predictions in the signal enriched sample. Finally, a measurement of the cross-section for \(Z\to\tau\tau\) events relative to the \(Z\to ee,\mu\mu\) channels will provide a cross-checks on the associated efficiencies.

Once the lepton energy scale is determined with the very first data, the selected \(Z\to\tau\tau\) events can be used to determine the \(\tau_{had}\) energy scale in-situ. Subtracting the estimated background from opposite-sign events, as measured with the same-sign events, will allow for better estimates on the energy scale from the shape of the distribution of the visible mass. In Fig. 20 the sensitivity of the measured visible \(Z\) boson mass, as obtained from the reconstructed \(\tau\) pairs, on the absolute \(\tau\) energy scale is shown, assuming only signal events.The statistics correspond to 100 pb\({}^{-1}\) of data. Taking into account only the statistical uncertainties, the \(\tau_{had}\) energy scale could be determined with a precision of \(\sim 3\%\).

### The \(\tau\) leptons from \(t\bar{t}\) production

With a cross-section of 833 pb [24], about 16500 events are expected in 100 pb\({}^{-1}\) with a W boson decaying into a \(\tau\) lepton. Due to the increased center of mass energy available at the LHC the cross section for \(t\bar{t}\) production increases by nearly two orders of magnitude over what is available at the Tevatron. The \(t\bar{t}\) channel is discussed here as an additional source for \(\tau\) leptons from the SM processes, supplementing samples expected from \(W\to\tau\nu\) and \(Z\to\tau\tau\) process.

The decay chain \(t\bar{t}\to W(qq^{\prime})W(\tau_{had}\nu)b\bar{b}\) requires events triggered using \(\tau+E_{T}^{miss}\) triggers, \(\tau\) triggers and multi-jets triggers. In the latter case this will lead to an unbiased sample of \(\tau_{had}\) candidates. The event is required to have at least two light quark jets, two \(b\)-tagged jets, and an identified hadronic \(\tau\) decay. If the event has more than two light quark jets, the pair with the invariant mass closest to the nominal mass of the \(W\) bosons is chosen which is then combined with the closest b jet to constitute the hadronically decaying top quark. With 100 pb\({}^{-1}\) of data about 300 \(t\bar{t}\to W(qq^{\prime})W(\tau_{had}\nu)b\bar{b}\) signal events with S:B of 20:1 are expected. These events can be used to study the \(\tau_{had}\) reconstruction and identification performance and to commission the \(\tau\) trigger. The \(p_{T}\) range of identified \(\tau\) leptons will be complementary to that available from the inclusive W and Z boson production. A more detailed description of the analysis is included in Ref. [25].

The decay chain \(t\bar{t}\to W(e\nu_{e},\mu\nu_{\mu})W(\tau_{had},\nu_{\tau})b\bar{b}\) is also interesting for both its physics potential and the possibility of using this channel to understand \(\tau_{had}\) identification. These events will be triggered with single lepton triggers and the main background will come primarily from \(W(\to\ell\nu)+\)jets, single top production and from \(Z(\to\tau\tau)+\)jets production. The analysis requires an isolated lepton and identified

\begin{table}
\begin{tabular}{|c||c||c|c|c|c|} \hline \hline Selection & \(Z\to\tau\tau\) & \(W\to\ell\nu\) & QCD dijet & \(t\bar{t}\) & \(Z\to\ell\ell\) \\ \hline \hline Isolated lepton & 1.5\(\cdot\)10\({}^{4}\) & 16.7\(\cdot\)10\({}^{5}\) & 1.1\(\cdot\)10\({}^{7}\) & 2.6\(\cdot\)10\({}^{4}\) & 2.2\(\cdot\)10\({}^{5}\) \\ \hline \(E_{T}^{miss}>20\) GeV & 4750 & 14.3\(\cdot\)10\({}^{5}\) & 3.2\(\cdot\)10\({}^{5}\) & 2.4\(\cdot\)10\({}^{4}\) & 1.0\(\cdot\)10\({}^{4}\) \\ \hline \(m_{T}^{\ell,E_{T}^{miss}}<30GeV\) & 3200 & 2.6\(\cdot\)10\({}^{4}\) & 1.8\(\cdot\)10\({}^{5}\) & 3650 & 3200 \\ \hline \(\Sigma E_{T}<400\) GeV & 3000 & 2.4\(\cdot\)10\({}^{4}\) & 1.7\(\cdot\)10\({}^{5}\) & 1280 & 2800 \\ \hline b-jet veto & 2780 & 2.4\(\cdot\)10\({}^{4}\) & 2.7\(\cdot\)10\({}^{4}\) & 135 & 2600 \\ \hline \hline \(\tau_{had}\)-id\(+\Delta\phi(\ell\tau_{had})\) cuts & 630\(\pm\)30 & 210 \(\pm\)10 & 74\(\pm\)11 & 10\(\pm\)2 & 30\(\pm\)5 \\ \hline \hline OS events, \(m^{\ell,\tau_{had}}=37\)-75 GeV & 520\(\pm\)30 & 45 \(\pm\)5 & 29\(\pm\)5 & \(<\) 5 & 10 \(\pm\)5 \\ \hline \hline \end{tabular}
\end{table}
Table 9: Expected number of events in 100 pb\({}^{-1}\) of data for signal and background after reconstruction of the \(\tau\) candidate with the calorimeter-based algorithm and after application of the selection cuts for the \(Z\to\tau\tau\) channel. The QCD background has been estimated combining fast and full simulation.

\(\tau_{had}\). To suppress backgrounds from W\(+\)jets and Z\(+\)jets events it requires two additional high \(E_{T}\) jets, significant energy deposition in the calorimeter \(\Sigma E_{T}>250\) GeV and \(E_{T}^{miss}>25\) GeV. Additional background suppression can be achieved by requiring that one or two jets are b-tagged. Table 10 summarizes cut flow of the analysis.

In the first 100 pb\({}^{-1}\) of data, \(54\pm 4\) signal events in the \(e\tau_{had}\) channel are expected, with a signal-to-background ratio (S:B) 1:10. The use of b-tagging rejects considerably the dominant \(W+3\) jets background (see Fig. 21). If at least one tight b-tag jet is required the expected number of signal events decreases to \(28\pm 3\) with S:B improving to 1:1. When requiring a jet in the event that passes the tight b tagging criteria, the dominant source of background is still \(W(\rightarrow\ell\nu)+\)jets, however the composition of the background changes and single top production starts contributing significantly, with quark or gluon jets faking \(\tau_{had}\) and true b-jets from b-quark fragmentation.

\begin{table}
\begin{tabular}{|c||c||c|c|c|} \hline \hline Selection & \(t\bar{t}(\ell,\tau_{had})\) & \(W\rightarrow\ell\nu+3jets\) & single t & Z\(\rightarrow\ell\ell+2\) jets \\ \hline \hline Isolated lepton \(p_{T}>20\) GeV & 1300 & \(3.9\cdot 10^{5}\) & 4300 & 630 \\ \hline Identified \(\tau_{had}\)\(p_{T}>15\) GeV & 190 & 22000 & 210 & 120 \\ \hline
1st jet \(E_{T}>50\) GeV, 2nd jet \(E_{T}>30\) GeV & 170 & 4000 & 170 & 35 \\ \hline \(E_{T}^{miss}>25\) GeV & 150 & 3400 & 150 & 15 \\ \hline \(\Sigma E_{T}>250\) GeV & 150 & 1750 & 130 & 10 \\ \hline Opposite-sign events & 130 & 850 & 54 & \(<10\) \\ \hline
1 b-jet tag & 67 & 28 & 20 & \\ \hline \hline \end{tabular}
\end{table}
Table 10: Expected number of events in 100 pb\({}^{-1}\) of data for \(t\bar{t}\to W(\ell\nu)W(\tau_{had},\nu_{\tau})b\bar{b}\) signal and background after subsequent steps in the selection. The track-based algorithm has been used for \(\tau_{had}\) reconstruction.

Figure 21: Combined \(b\)-tagging weights using impact parameter and secondary vertex information for the first two leading \(E_{T}\) jets, both in \(t\bar{t}\to W(e\nu_{e},\mu\nu_{\mu})W(\tau_{had}\nu_{\tau})b\bar{b}\) and \(W+3\)\(jets\) background. The \(e\)\(\tau\) (\(\mu\)\(\tau\)) channel is shown on the left (right). The cut value of 7 on the b-tagging weight is indicated with the arrows. An integrated luminosity of 100 pb\({}^{-1}\) of data is assumed.

Summary

Two complementary algorithms for the identification of hadronic \(\tau\) decays in the ATLAS experiment have been developed. The first one (calorimeter based) is seeded from a reconstructed cluster in the calorimeter, the second one (track based) relies on seeds built from reconstructed tracks in the inner detector. Several discrimination methods have been established, including a simple cut-based selection as well as multivariate selections based on likelihood, neutral network, and probability range search techniques. Rejection factors against jets from QCD processes of a few hundred up to a few thousand can be achieved for a \(\tau\) efficiency of 30% in the \(p_{T}\) range between 10 to 60 GeV. In addition, a dedicated algorithm has been developed to reject electrons that pass the \(\tau\) identification criteria. In the low energy range, rejection factors of the order of 50 and higher against electrons from \(W\) and \(Z\) bosons decays are achieved at the expense of a 5% efficiency loss for hadronic \(\tau\) decays.

It has also been estimated that the expected performance in the ATLAS experiment will be adequate to extract \(\tau\) signals in early LHC data from \(W\rightarrow\tau\nu\) and \(Z\rightarrow\tau\tau\) decays. These signals are important to establish and calibrate the \(\tau\) identification performance with early data. The study of dijet events from QCD processes will allow a determination of \(\tau\) fake rates. It is expected that such rates can be measured with a statistical precision at the percent level or better already with data corresponding to an integrated luminosity of 100 pb\({}^{-1}\).

## 8 Acknowledgments

E. Richter-Was, A. Kaczmarska, Pa. Malecki, and M. Wolter supported in part by the Polish Government grant N202 006434 (years 2008-2011). The work of S.Cabrera has been partially supported by a project of the Generalitat Valenciana (GV): GVPRE/2008/062.

## References

* [1] W-M Yao et al 2006, J. Phys. G: Nucl. Part. Phys. **33** 1.
* [2] T. Sjostrand, S. Mrenna and P. Skands, JHEP05 (2006) 026.
* [3] S. Jadach et al., Comp. Phys. Commun. **76** (1993) 361.
* [4] K. Assamagan and Y. Coadou, _The hadronic tau decay of a heavy charged Higgs in ATLAS_, ATLAS Note, ATL-PHYS-2000-031.
* [5] K. Assamagan and A. Deansdrea, _The hadronic \(\tau\) decays of heavy charged Higgs in models with singlet neutrino in large extra dimensions_, ATLAS Note, ATL-PHYS-2001-019.
* [6] T. Pierzchala, E. Richter-Was, Z. Was and M. Worek, Acta Phys.Polon. **B32** (2001) 1277.
* [7] G. R. Bower, T. Pierzchala, Z. Was and M. Worek, Phys. Lett. **B 543** (2002) 227.
* [8] K. Desch, A. Imhof, Z. Was and M. Worek, Phys.Lett. **B579** (2004) 157.
* [9] ATLAS Collaboration, ATLAS Performance and Physics Technical Design Report, ATLAS TDR 15, CERN/LHCC/99-15, 25 May 1999.
* [10] The ATLAS Collaboration, _The ATLAS Experiment at the CERN Large Hadron Collider_, JINST 3 (2008) S08003.