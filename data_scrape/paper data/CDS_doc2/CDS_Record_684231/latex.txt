Trigger Simulation

### Software

At the present stage of the ATLAS trigger studies the software which will be used at the experiment is not yet available. However, there is a Fortran 77 implementation of the offline reconstruction software called ATRECON [12]. This software has been used mainly for studying the detector configurations and for single particle reconstruction efficiencies. Most of the physics channels have been analyzed with the parameterized reconstruction software ATLFAST [13]. For the event filter, no reconstruction software exists. It is foreseen that the event filter will run a lightweight version of the offline reconstruction software. This assures the consistency of the event selection process between the online and the offline world and eases the migration of algorithms between the offline reconstruction and the event filter. For these studies the offline reconstruction software ATRECON1 is used as event filter software.

Footnote 1: All studies are done with the SRT/CVS version 1.2.0 on the ATLAS Linux machines. Standard optimization (-O2) was used during the compilation.

For the simulation of the LVL1 and LVL2 triggers, a stand-alone Fortran software called ATRIG [10] is available. This software has been used for LVL2 trigger studies. It fully implements the LVL1 and LVL2 algorithms for electron and photon identification [1]. In order to study the full trigger chain, ATRIG had to be combined with the offline reconstruction software. It runs on the same data as ATRECON and provides the global LVL1 and LVL2 accepts/rejects as well as the information which trigger menu items were selected. This information is written into the combined physics ntuple (CBNT) introduced for the Physics TDR [1]. ATRECON still runs over all events regardless of the previous selections. Therefore, it is easy to study the differences in efficiency and trigger rate reduction between LVL2 and the EF.

ATRECON has several parameters to configure the reconstruction. In this study it first searches clusters in the electro-magnetic calorimeter with more than a certain transverse energy threshold, called \(E_{T}^{\rm min}\). In the combined version of ATRIG/ATRECON, this step can also be omitted. In this case, the LVL2 information is used to identify a cluster. After a cluster is found, some properties are calculated. The most important are the lateral isolation and the leakage into the hadron calorimeter. The shape of the shower is analyzed to discriminate \(\tau\)-clusters from electron clusters [1].

In a second step, the pattern recognition and tracking package called xKalman [2] is invoked. It starts with a fast histogramming method using the hits in the TRT and then uses the Kalman filter [2] to track candidates through the SCT and Pixel detectors. This procedure is applied only within a given region around the maximum energy deposition in the electro-magnetic calorimeter. This region is called road and is parameterized by the \(\Delta\eta\!\times\!\Delta\phi\) half sizes at the calorimeter. All tracks above a certain transverse momentum, called \(p_{T}^{\rm min}\), are reconstructed including recovering from bremsstrahlung. The Fortran implementation of xKalman uses a homogeneous magnetic field.

There are also other tracking programs available within ATRECON like iPatRec. In reference [12] a comparison between xKalman and iPatRec is shown. Due to differences in the software version, the machines used, and the parameter settings, a direct comparison between those results and the results presented in this work is not possible.

After a track candidate is found, its position in \(\eta\) and \(\phi\), and its \(p_{T}\) is compared to the corresponding values obtained from the electro-magnetic calorimeter. If these values match within a given precision, the candidate is accepted. This step is called "matching".

The last selection applied is the transition radiation (TR) in the TRT. The straw tubes of the TRT measure beside the position in space, also the transition radiation of fast, charged particles like electrons.

### Design and Low Luminosities

All studies within ATLAS are done at two settings: one at the so-called design luminosity2 of \(10^{34}\,\mathrm{cm}^{-2}\,\mathrm{s}^{-1}\) and at low luminosity of \(10^{33}\,\mathrm{cm}^{-2}\,\mathrm{s}^{-1}\). At low luminosity there is an average of two interactions per bunch crossing. In the simulation only one interaction is considered. At design luminosity an average of 23 interactions is expected. In order to simulate this situation, minimum bias events were added to the event using the pile-up method documented in reference [13]. The number of minimum bias events is selected randomly using a Poisson distribution with an average of 23. In both settings, simulated electronic noise is added to the calorimeter without using a threshold [14].

Footnote 2: In some publications the design luminosity is called high luminosity.

These two luminosities have to be understood as common settings to study the behavior of ATLAS. In the real experiment, the luminosities will change during a fill of the LHC. After a new fill of the LHC, the luminosity will be around the design luminosity and then drop for several hours to or even below the low luminosity setting. This implies, of course, that the different parameter settings used in this study will have to be adopted accordingly.

### Datasets

For the trigger efficiency single electrons with a transverse momentum (\(p_{T}\)) of 20 and 30 GeV covering the rapidity range \(|\eta|<2.4\) corresponding to the sensitive region of the tracker and calorimeter were generated. These electrons were tracked through the ATLAS detector and the detector responses were simulated with GEANT 3.21 [1] using the geometry described in the Technical Design Reports [1, 2]. It is implemented by DICE 98_2 [1].

Table 1 shows the total number of generated electrons available for these studies. It also shows that 47%(57%) of the electrons do not emit any photon with \(p_{T}>500\) keV at design (low) luminosity. 43%(32%) emit one or more hard photons from bremsstrahlung and 10%(11%) of the electrons emit photons undergoing a subsequent pair production within the Inner Detector.

The trigger efficiency is specified as percentage of reconstructed electrons to the total number of generated electrons on the given trigger step.

The electron trigger rate at LHC is by far not dominated by hard electrons. The highest rate comes from misidentified hadronic jets or from non-isolated electrons within a jet. Therefore, a large sample of fully simulated dijet events is used to estimate the trigger rate. In addition to the dijets other processes yielding isolated electrons were simulated according to their expected cross-sections (see table 2).

These dijets were generated with \(|\eta|<2.7\) and \(p_{T}>17\,\mathrm{GeV}\). The dijet sample [10] was generated with LVL1 pre-selection for electromagnetic clusters and includes Standard Model processes with isolated electrons and photons. For the tracking and the detector responses of the dijets the older detector geometry DICE 97_6 was used. In this version, the barrel electro-magnetic calorimeter extends beyond \(|\eta|=1.475\) up to \(|\eta|=1.5\) and is equipped with strips in the first sampling over the whole rapidity range. In addition, there are also strips in the end-cap region \(2.4<|\eta|<2.5\)[11]. In this study, this additional information is not used. The barrel cryostat design changed in DICE 98_2, leading to an increased material distribution in front of the calorimeter (increase of \(0.1-0.25X_{0}\) depending of \(\eta\)) [12].

LVL2 and EF rates were obtained from the dijet samples by multiplying the number of selected dijet events by the conversion factors given in reference [11].

\begin{table}
\begin{tabular}{|l|c|c|} \hline  & Design \(\mathcal{L}\) & Low \(\mathcal{L}\) \\  & \(p_{T}\) = 30 GeV & \(p_{T}\) = 20 GeV \\ \hline \hline No photons & 1230 & 3559 \\ Bremsstrahlung & 1133 & 2031 \\ Pair production & 259 & 660 \\ \hline
**Total** & **2622** & **6250** \\ \hline \end{tabular}
\end{table}
Table 1: Number of generated electrons available for these studies, broken down for electrons not emitting photons with \(p_{T}>500\,\mathrm{keV}\), electrons emitting one or more bremsstrahlung photons, and electrons accompanied by photons undergoing pair production.

\begin{table}
\begin{tabular}{|l|c|c|} \hline  & Design \(\mathcal{L}\) & Low \(\mathcal{L}\) \\  & \(p_{T}>17\,\mathrm{GeV}\) & \(p_{T}>17\,\mathrm{GeV}\) \\ \hline \hline W \(\rightarrow\) e \(\nu\) & 17 & 18 \\ isolated electrons & 159 & 163 \\ \hline Pure hadronic jets & 2898 & 2994 \\ non-isolated electrons and & 14947 & 15386 \\ high-\(p_{T}\) photo conversions & 18021 & **18561** \\ \hline
**Total** & **18021** & **18561** \\ \hline \end{tabular}
\end{table}
Table 2: Fully simulated dijet sample, used for an estimate of the trigger rate. Pure hadronic jets, non-isolated electrons, and high-\(p_{T}\) photo conversions are reducible backgrounds, while the isolated electrons from W \(\rightarrow\) e \(\nu\) and other processes are irreducible.

### Timing of Algorithms

The amount of CPU time needed on the event filter and the trigger rate reduction achievable within the stringed time constraints of a few seconds is crucial for the design of the system. Therefore, it was necessary to measure the algorithm execution times of ATRECON. However, due to the fact that ATRECON is implemented in Fortran while the final software will be implemented in OO/C++, the timing of the algorithms cannot be done in a straightforward manner. For example the data access via common blocks in Fortran is fundamentally different from the access via objects. Therefore, it was decided to measure only the algorithmic parts excluding all data access and data preparation steps. These timings should scale well to the OO/C++ implementation. The timing only takes the CPU time into account, i.e. the pure execution time of the algorithm. The resolution of the timing is 10 ms. The timing measurements of each event are written into the CBNT together with the reconstructed quantities.

The first two trigger levels have not been timed, because those are not relevant in terms of execution time compared to the event filter. Level 2 has an average decision latency of a few ms. Measurements of the level 2 latency can be found in reference [B\({}^{+}\)00a].

Figure 1 shows an example of the timing distribution at design luminosity for the electro-magnetic calorimeter reconstruction and the tracking with xKalman. Due to the fact that the EF will only see events passing the LVL2 selection, only these events are considered for the timing of the electro-magnetic calorimeter. The tracking algorithms used at the EF will only be invoked for events accepted by the calorimeter reconstruction. Therefore, the timing of xKalman includes only these events.

The distributions exhibit a clear maximum at small reconstruction times with long tails to a very high time consumption. In order to quantify the timing distributions, always three timing values will be given: the first one specifies the time needed to reconstruct half of the events passing the previous trigger level, the second 80% and the third 95%. As can be seen from figure 1, the timing distribution for electrons is not much affected by using only those events passing the previous trigger step. However, if all background events would be considered, the timing distributions would exhibit much longer tails. The largest effect is observed for the background events at design luminosity, where for example the time to reconstruct 50% of the events is shifted from 10.0 s using only events passing the electro-magnetic calorimeter selection to 12.1 s for all events.

There will be a maximum time allocated to reconstruct an event at the event filter. When this time is exhausted, the event will be written to mass storage flagged accordingly. This time could for example be fixed so that 95% of the events can be reconstructed online.

All timing measurements were made on the ATLAS Linux batch machines. Each machine is a Siemens Celsius 620 machine with dual 550 MHz pentium III processors3running Linux Red Hat 6.1. These processors are specified to 18.7 SPECint95, which corresponds to about 187 CERN units (CU). However, measurements at CERN resulted in about 110 CU (\(\sim 11\) SPECint95) with more realistic, i.e. lower, optimization settings [Jar]. For comparison, it is noteworthy that the studies shown for example in the Physics TDR [1] were done on HP machines which were measured to have 70 CU.

## 3 Single Electron Trigger

### Baseline Settings

The first step of these studies was to reproduce the electron efficiencies and dijet rejections obtained for the physics TDR [1], especially those of given in reference [11], with the combined ATRIG/ATRECON package. This provided beside the confirmation of these numbers also a detailed timing of the reconstruction algorithms used.

Figure 1: Distributions of algorithm timings at design luminosity. The top row shows the timing distributions for the reconstruction of the electromagnetic calorimeter, the bottom row for the tracking with xKalman. On the left side the time distributions for electrons, on the right side for the background are found. The distributions are shown for all generated events and for those events passing the previous trigger level. Additionally, the reconstruction time for 50%, 80%, and 95% of the events passing the previous trigger level is indicated.

For the reconstruction, the standard settings \(E_{T}^{\rm min}=5\,\)GeV, \(p_{T}^{\rm min}=5\,\)GeV, and a road size of \(\Delta\eta\times\Delta\phi=0.5\times 0.5\) are used. The applied cuts for selecting electrons and rejecting dijets are described in great detail in reference [10]4. These cuts depend on the \(\eta\)-region considered and on the luminosity. They have been re-implemented to be usable in combination with the CBNT.

Footnote 4: However, some cuts were documented wrongly: \(\Delta E^{\rm max2}=E^{\rm max2}/(1+9(5)\cdot 10^{-4})\) should read \(\Delta E^{\rm max2}=E^{\rm max2}/(1+9(5)\cdot 10^{-3})\) for design (low) luminosity. For design luminosity the level 2 cuts for hadronic energy are \(E_{T}\leq 0.9\,51\,\)GeV for an electro-magnetic cluster with \(E_{T}\leq 25\,\)GeV, \(E_{T}\leq 1.6\,\)GeV for an electro-magnetic cluster with \(25\,\)GeV\(\,<E_{T}\leq 60\,\)GeV, and no \(E_{T}\) cut for an electro-magnetic cluster with \(E_{T}>60\,\)GeV. Furthermore, the correct cuts for the shower shapes on the second sampling at design luminosity are \(R_{\eta}^{\rm shape\,e}\geq 0.896\) and \(R_{\eta}^{\rm strip}\geq 0.725\).

Tables 3 and 4 summarize the results obtained for design and low luminosity, respectively. The efficiencies agree within the errors with values given in the note [10]. The jet rejection in that note is higher than the rate reduction presented in this work. In that note only the reducible background was considered, whereas the trigger rate given in this work also includes the irreducible background.

The reconstruction time is dominated by the tracking with xKalman and in the design luminosity case far beyond the time budget for the event filter. Especially the long reconstruction times for a few events are striking. The reconstruction time of the electro-magnetic calorimeter is more uniform and dominated by the cluster finding process.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{2}{|c|}{Single electrons \(p_{T}=30\,\)GeV} & \multicolumn{2}{|c|}{Dijets \(p_{T}>17\,\)GeV} \\ Trigger step & Efficiency & Recon. time (s) & Rate & Recon. time (s) \\  & & 50/80 /95\% & (Hz) & 50/80/95\% \\ \hline \hline LVL1 (EM30I) & 94.5\% & n/a & 21886\(\pm\)415 & n/a \\ \hline LVL2 (e30i) & 81.2\% (86.0\%) & n/a & 433\(\pm\)58 (51\(\pm\)7) & n/a \\ \hline e.m. calorimeter & 79.6\% (98.0\%) & 0.20/0.23/0.27 & 31\(\pm\)50 (1.4\(\pm\)0.2) & 0.25/0.30/0.39 \\ \hline ID (xKalman) & 75.6\% (95.0\%) & 5.1/10.0/23.4 & 149\(\pm\)34 (2.1\(\pm\)0.5) & 10.0/20.0/44.0 \\ \hline Matching & 73.7\% (97.4\%) & n/a & 118\(\pm\)30 (1.3\(\pm\)0.3) & n/a \\ \hline TR & 70.6\% (95.8\%) & n/a & 79\(\pm\)25 (1.5\(\pm\)0.5) & n/a \\ \hline \end{tabular}
\end{table}
Table 3: Efficiencies and rates at different trigger levels for design luminosity. In parenthesis the efficiency and rate reduction compared to the previous step is specified. The efficiencies are accurate to about 2% (absolute value). Only statistical errors are shown. The three times given are needed to reconstruct 50%, 80%, and 95% of the events passing the previous trigger level on the ATLAS Linux batch machines.

### Simple Approaches to Accelerate the Reconstruction

In this section some simple ways to accelerate the reconstruction with ATRECON are discussed. Simple means that there are no modifications to the code, but the parameters for the reconstruction are changed. This investigation of the parameter space should be independent of the actual implementation and will also be valid for the coming OO software.

#### 3.2.1 Road Size

The road size parameterizes the extent of the \(\Delta\eta\!\times\!\Delta\phi\) region in which a track is searched. This region is centered at the highest energy in the electro-magnetic calorimeter within a given cluster. It is rather obvious that for single particles this size can be much smaller than the default \(\Delta\eta\!\times\!\Delta\phi=0.5\times 0.5\) without losing any efficiency. Therefore, the road size was diminished to \(\Delta\eta\!\times\!\Delta\phi\!=\!0.1\times 0.1\) and \(\Delta\eta\!\times\!\Delta\phi=0.1\times 0.2\). The latter setting should include most of the electrons suffering from bremsstrahlung. However, the efficiencies and rates are virtually unchanged also for \(\Delta\eta\!\times\!\Delta\phi\!=\!0.1\times 0.1\). The change of the reconstruction time for xKalman is shown in figure 2. At low luminosity no big differences are seen neither for electrons nor for dijets (bottom row). This is explained by the rather low occupancy of the tracker where most hits within a road belong to the electron track. This changes dramatically at design luminosity where the occupancy is much higher. Therefore the reconstruction time can be significantly reduced by decreasing the road size to \(\Delta\eta\!\times\!\Delta\phi=0.1\times 0.1\).

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{2}{|c|}{Single electrons \(p_{T}=20\,\)GeV} & \multicolumn{2}{|c|}{Dijets \(p_{T}>17\,\)GeV} \\ Trigger step & Efficiency & Recon. time (s) & Rate & Recon. time (s) \\  & & 50/80/95\% & (Hz) & 50/80/95\% \\ \hline \hline LVL1 (EM20I) & 93.2\% & n/a & 5831\(\pm\)71 & n/a \\ \hline LVL2 (e20i) & 82.0\% & n/a & 135\(\pm\)11 & n/a \\  & (88.0\%) & & (43\(\pm\)3) & n/a \\ \hline e.m. calorimeter & 80.2\% & \multirow{2}{*}{0.20/0.21/0.22} & 73\(\pm\)4 & \multirow{2}{*}{0.23/0.26/0.33} \\ \(E_{T}^{\rm min}=5\,\)GeV & (97.8\%) & & (1.8\(\pm\)0.2) & \\ \hline ID (xKalman) & 76.0\% & \multirow{2}{*}{0.01/0.03/0.07} & 49\(\pm\)6 & \multirow{2}{*}{0.3/0.7/1.4} \\ \(p_{T}^{\rm min}=5\,\)GeV & (94.7\%) & & (1.5\(\pm\)0.2) & \\ \hline Matching & 74.8\% & \multirow{2}{*}{n/a} & 35\(\pm\)5 & \multirow{2}{*}{n/a} \\  & (98.4\%) & & (1.4\(\pm\)0.2) & \\ \hline TR & 67.8\% & \multirow{2}{*}{n/a} & 23\(\pm\)4 & \multirow{2}{*}{n/a} \\  & (90.6\%) & & (1.5\(\pm\)0.3) & \\ \hline \end{tabular}
\end{table}
Table 4: Efficiencies and rates at different trigger levels for low luminosity. In parenthesis the efficiency and rate reduction compared to the previous step is specified. The efficiencies are accurate to about 2% (absolute value). Only statistical errors are shown. The three times given are needed to reconstruct 50%, 80%, and 95% of the events passing the previous trigger level on the ATLAS Linux batch machines.

Figure 2: xKalman reconstruction time for different road sizes. Top (bottom) row for design (low) luminosity. On the left hand side for single electrons with \(p_{T}=20(30)\,\mathrm{GeV}\), on the right hand side for dijets. The times given are needed to reconstruct 50%, 80%, and 95% of the events passing the electro-magnetic calorimeter cuts. The corresponding xKalman efficiency, respectively the xKalman trigger rate, is shown as a line with the scale on the right-hand side.

#### 3.2.2 Threshold on Electro-Magnetic Clusters

As shown in figure 3 the reconstruction time for xKalman scales approximately linear with the number of electro-magnetic clusters used as seeds, i.e. the time per seed is roughly constant. A reduction of the number of seeds should therefore decrease the reconstruction time at design luminosity. At low luminosity you rarely find more than the cluster coming from the electron. The simplest way to reduce the number of seeds at design luminosity is to increase the energy threshold defining a cluster. The threshold is specified as minimal \(E_{T}\) deposited in a window of \(5\times 5\) calorimeter cells covering a region of \(\Delta\eta\times\Delta\phi\approx 0.125\times 0.123\).

Figure 4 shows the reconstruction time for xKalman for different settings of \(E_{T}^{\rm min}\) for dijets at design and low luminosity. The tails of the distributions are reduced considerably, while the electron efficiency up to \(E_{T}^{\rm min}=15(10)\) GeV for design (low) luminosity remains unchanged.

#### 3.2.3 Tracking Threshold

Once a road is defined, xKalman looks for all tracks above a certain transverse momentum \(p_{T}\). Figure 5 shows the xKalman reconstruction time for different \(p_{T}\) thresholds. If the baseline \(p_{T}^{\rm min}=5\) GeV is reduced, the reconstruction time is largely increased without any significant gain in efficiency. By increasing the \(p_{T}^{\rm min}\) the reconstruction is not much speeded up. Above a \(p_{T}^{\rm min}\) of 10 GeV the efficiency for single electrons drops.

#### 3.2.4 Optimized Parameter Settings

Tables 5 and 6 summarize the results for electron/jet separation obtained by using the best setting of the parameters discussed in this section, i.e. using a \(p_{T}^{\rm min}=10\) GeV, a road size \(\Delta\eta\times\Delta\phi=0.1\times 0.1\), and an electro-magnetic threshold of \(E_{T}^{\rm min}=15(10)\) GeV for design (low) luminosity.

Figure 3: xKalman reconstruction time as function of the number of electromagnetic clusters used as seeds for the tracking. Left for electrons (\(p_{T}=30\) GeV), right for dijets (\(p_{T}>17\) GeV) at design luminosity which were accepted by electro-magnetic calorimeter cuts.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{2}{|c|}{Single electrons \(p_{T}=30\) GeV} & \multicolumn{2}{|c|}{Dijets \(p_{T}>17\) GeV} \\ \cline{2-5} Trigger step & Efficiency & Recon. time (s) & Rate & Recon. time (s) \\  & & 50/80/95\% & (Hz) & 50/80/95\% \\ \hline \hline LVL1 (E M30I) & 94.5\% & n/a & 21886\(\pm\)415 & n/a \\ \hline LVL2 (e30i) & 81.2\% & n/a & 433\(\pm\)58 & n/a \\  & (86.0\%) & n/a & (51\(\pm\)7) & n/a \\ \hline e.m. calorimeter & 78.8\% & \multirow{2}{*}{0.19/0.20/0.22} & 30\(\pm\)49 & \multirow{2}{*}{0.21/0.23/0.26} \\ \(E_{T}^{\rm min}=1\) 5 GeV & (97.1\%) & & (1.4\(\pm\)0.2) & \\ \hline ID (xKalman ) & 74.5\% & \multirow{2}{*}{0.8/1.1/1.5} & 142\(\pm\)33 & \multirow{2}{*}{1.0/1.6/3.4} \\ \(p_{T}^{\rm min}=5\) GeV & (94.5\%) & & (2.2\(\pm\)0.5) & \\ \hline \multirow{2}{*}{Matching} & 73.0\% & \multirow{2}{*}{n/a} & 11\(\pm\)30 & \multirow{2}{*}{n/a} \\  & (98.0\%) & & (1.2\(\pm\)0.3) & \\ \hline \multirow{2}{*}{TR} & 69.9\% & \multirow{2}{*}{n/a} & 79\(\pm\)25 & \multirow{2}{*}{n/a} \\  & (95.9\%) & & (1.5\(\pm\)0.5) & \\ \hline \end{tabular}
\end{table}
Table 5: Efficiencies and rates at design luminosity with parameters optimized for faster reconstruction. In parenthesis the efficiency and rate reduction compared to the previous step is specified. The efficiencies are accurate to about 2% (absolute value). Only statistical errors are shown. The three times given are needed to reconstruct 50%, 80%, and 95% of the events passing the previous trigger level on the ATLAS Linux batch machines.

Figure 4: xKalman reconstruction time as function of the electro-magnetic calorimeter threshold for dijets (\(p_{T}>17\) GeV) at design (low) luminosity is shown on the left (right). The time needed to reconstruct 50%, 80%, and 95% of all events passing the electro-magnetic calorimeter cuts is shown. At low luminosity the statistic of events with a higher threshold than 10 GeV is very low. Therefore the reconstruction time does not drop monotonously. The total reconstruction efficiency for electrons with \(p_{T}=30(20)\) GeV is shown as a line with the scale on the right-hand side.

Figure 5: xKalman reconstruction time for dijets (\(p_{T}>17\) GeV) as function of the minimal \(p_{T}\) required for reconstructed tracks. Top for design, bottom for low luminosity. The time needed to reconstruct 50%, 80%, and 95% of all events passing the electro-magnetic calorimeter cuts is shown. The xKalman efficiency for single electrons with \(p_{T}=30(20)\) GeV is shown as a line with the scale on the right-hand side.

The efficiencies for single electrons and the trigger rates are unchanged compared to the baseline settings. In the following only the reconstruction time for dijets, i.e. for the background, is discussed, because this will dominate the total time spent at the event filter.

The reconstruction of the electro-magnetic calorimeter is not speeded up, because the reconstruction time is dominated by the cluster search, which is independent of the number of clusters, i.e. of the threshold \(E_{T}^{\mathrm{min}}\). The higher threshold leads to less clusters found, which is expressed in the shorter tails of the distributions, i.e. it takes less time to reconstruct 95% of the events.

Due to changes of the parameters, the tracking with x Kalman is much more accelerated. It has to search tracks for less clusters within a smaller road and only tracks with higher transverse momentum \(p_{T}\) are considered. This reduces the median tracking time by a factor of 10(3) for design (low) luminosity. Additionally, the time required to reconstruct 95% of the events passing the electro-magnetic calorimeter cuts is diminished by a factor 13(3).

### Using LVL2 Information on the Event Filter

In the previous section, the event filter reconstructed an event passing LVL2 without using any information gained on lower trigger levels. For example it will search the full electro-magnetic calorimeter for clusters, whereas the LVL2 trigger knows the location of electro-magnetic clusters triggering LVL1 and confirms these clusters with the full granularity. Therefore the cluster searching process on the event filter can be omitted. Only the cluster energy, isolation and other properties will be

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline  & \multicolumn{2}{|c|}{Single electrons \(p_{T}=20\,\mathrm{GeV}\)} & \multicolumn{2}{|c|}{Dijets \(p_{T}>17\,\mathrm{GeV}\)} \\ Trigger step & Efficiency & Recon. time (s) & Rate & Recon. time (s) \\  & & 50/80/95\% & (Hz) & 50/80/95\% \\ \hline \hline LVL1 (EM20I) & 93.2\% & n/a & 5831\(\pm\)71 & n/a \\ \hline LVL2 (e20i) & 82.0\% & n/a & 135\(\pm\)11 & n/a \\  & (88.0\%) & n/a & (43\(\pm\)3) & n/a \\ \hline e.m. calorimeter & 79.8\% & \multirow{2}{*}{0.20/0.21/0.22} & 73\(\pm\)8 & \multirow{2}{*}{0.21/0.24/0.28} \\ \(E_{T}^{\mathrm{min}}=10\,\mathrm{GeV}\) & (97.2\%) & & (1.9\(\pm\)0.2) & \\ \hline ID (xKalman) & 74.5\% & \multirow{2}{*}{0.01/0.03/0.05} & 46\(\pm\)6 & \multirow{2}{*}{0.1/0.2/0.5} \\ \(p_{T}^{\mathrm{min}}=10\,\mathrm{GeV}\) & (93.4\%) & & (1.6\(\pm\)0.2) & \\ \hline Matching & 73.4\% & \multirow{2}{*}{n/a} & 35\(\pm\)5 & \multirow{2}{*}{n/a} \\  & (98.5\%) & & (1.3\(\pm\)0.2) & \\ \hline TR & 66.4\% & \multirow{2}{*}{n/a} & 24\(\pm\)5 & \multirow{2}{*}{n/a} \\  & (90.5\%) & & (1.5\(\pm\)0.3) & \\ \hline \end{tabular}
\end{table}
Table 6: Efficiencies and rates at low luminosity with parameters optimized for faster reconstruction. In parenthesis the efficiency and rate reduction compared to the previous step is specified. The efficiencies are accurate to about 2% (absolute value). Only statistical errors are shown. The three times given are needed to reconstruct 50%, 80%, and 95% of the events passing the previous trigger level on the ATLAS Linux batch machines.

recalculated with much more accurate calibration values than available on LVL2. Additionally, the tracking will use only the clusters involved in the trigger, i.e. in the case of the single electron trigger only one cluster is considered.

Table 7 shows the comparison between the stand-alone cluster search of the event filter and the cluster information from LVL2. The parameter settings for the event filter are in both cases the same and correspond to those discussed in section 3.2.4. The efficiencies and rate reduction of both cluster finding algorithms are very similar. The time saved by omitting the electro-magnetic cluster search on the event filter is small, but the long times to reconstruct 95% of the events with xKalman are reduced considerably.

### Reconstruction Efficiency

As mentioned in section 2.3, the electrons might emit bremsstrahlung and some of the bremsstrahlung photons undergo pair production. Figure 6 shows the reconstruction efficiencies at the individual trigger levels for the different cases. As expected, the electrons not emitting any photons with \(p_{T}>500\,\mathrm{keV}\) have the best efficiency, while some of the electrons emitting hard photons are lost when track reconstruction5 at LVL2 and at the EF is done. As long as only the calorimeter information is used (LVL1 and EF calo), no huge differences are seen between the different particle samples.

Footnote 5: The track reconstruction includes here also the matching of the track to the electro-magnetic calorimeter cluster at LVL2 and at the EF. The transition radiation (TR) is used at the event filter, too.

### Trigger Rates

The total rate of accepted events after the event filter is aimed to be about \(100\,\mathrm{Hz}\). Otherwise the storage and offline processing of the events will need too much re

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|} \hline \multicolumn{2}{|c|}{Setting} & \multicolumn{2}{c|}{e.m. calorimeter} & \multicolumn{2}{c|}{ID (xKalman)} \\ \multicolumn{2}{|c|}{} & \multicolumn{2}{c|}{\(E_{T}^{\mathrm{min}}=10\,\mathrm{GeV}\)} & \multicolumn{2}{c|}{\(p_{T}^{\mathrm{min}}=10\,\mathrm{GeV}\)} \\ \cline{2-7} \(\mathcal{L}\) & Cluster & Electrons (s) & Dijets (s) & Electrons (s) & Dijets (s) \\ \hline \hline \multirow{2}{*}{Design} & EF & 0.19/0.20/0.22 & 0.21/0.23/0.26 & 0.8/ 1.1 /1.5 & 1.0/ 1.6/ 3.4 \\ \cline{2-7}  & LVL2 & 0.17/0.19/0.21 & 0.18/0.19/0.20 & 0.8/ 1.1 /1.4 & 0.8/ 1.2/ 1.6 \\ \hline \multirow{2}{*}{Low} & EF & 0.20/0.21/0.22 & 0.21/0.24/0.28 & 0.01/0.03/0.05 & 0.1/ 0.2/ 0.5 \\ \cline{2-7}  & LVL2 & 0.17/0.18/0.20 & 0.18/0.19/0.21 & 0.02/0.03/0.05 & 0.08/0.13/0.21 \\ \hline \end{tabular}
\end{table}
Table 7: Comparison between the reconstruction speed at the event filter, using the clusters found by the EF or clusters provided by LVL2. Single electrons with \(p_{T}=30(20)\,\mathrm{GeV}\) and dijets with \(p_{T}>17\,\mathrm{GeV}\) at design (low) luminosity are shown. The three times given are needed to reconstruct 50%, 80%, and 95% of the events passing level 2 on the ATLAS Linux batch machines. The reconstruction parameters used at the event filter correspond to the optimized setting shown in section 3.2.4.

Figure 6: Reconstruction efficiency for different particle samples shown in table 1. Top for design luminosity, bottom for low luminosity.

sources without a great gain in expected physics understanding. As can be seen from tables 5 and 6, already the single electron trigger will use 80%(25%) of the total bandwidth at design (low) luminosity.

Table 8 shows the trigger rates after the event filter (including TR) for design and low luminosity separated into reducible and irreducible processes. At low luminosity, both rates are comparable, whereas at design luminosity the rate of the isolated electrons from \(\mathrm{W}\,\rightarrow\,\mathrm{e}\,\nu\) and other processes dominates. Please note that the reducible rate might be higher in the real world, because we used for these studies the full offline software with a perfectly aligned, calibrated and efficient detector. The easiest way to reduce this rate is to increase the trigger threshold for single object triggers above the nominal value of 30(20) GeV at design (low) luminosity. However, this will imply an additional loss in efficiency for physics signals. In order to avoid this, some less inclusive triggers have to be employed. This will be discussed in the next chapter.

## 4 Trigger for Physics Channels

In the previous section the inclusive single electron trigger was discussed. In section 3.5 we concluded that the rates of this trigger item will use 80%(25%) of the total target trigger rate at design (low) luminosity. This is far too much. The increase of the target trigger rate of 100 Hz seems not to be possible within the resources available for the offline processing and storage. Therefore, the nominal thresholds of 30(20) GeV for single electron triggers at design (low) luminosity have to be raised. This will inevitably lower the efficiency for physics channels like \(\mathrm{W}\,\rightarrow\,\mathrm{e}\,\nu\) or \(\mathrm{Z}\,\rightarrow\,\mathrm{e}\,\mathrm{e}\,\). Both channels are important for checking the Standard Model at the higher energies available at LHC. They might play an important role in finding the Higgs using either the channel \(\mathrm{H}\,\rightarrow\,\mathrm{Z}\,\mathrm{Z}^{*}\,\rightarrow\,4\mathrm{e}\,\) or \(\mathrm{H}\,\rightarrow\,\mathrm{W}\,\mathrm{W}\,\rightarrow\,\mathrm{e}\,\nu\,\mathrm{ e}\,\nu\,\). Additionally, the \(\mathrm{Z}\) decay will be used to calibrate the electro-magnetic calorimeter. In this chapter we will discuss possibilities to save the efficiency for these channels.

\begin{table}
\begin{tabular}{|l|c|c|} \hline  & Design \(\mathcal{L}\) & Low \(\mathcal{L}\) \\ \hline \hline Pure hadronic jets & (7.6\(\pm\)7.6 ) Hz & (4.3\(\pm\)1.9) Hz \\ non-isolated electrons & (15.2\(\pm\)10.7) Hz & (8.5\(\pm\)2.7) Hz \\ \hline Total reducible & (22.8\(\pm\)13.2) Hz & (12.8\(\pm\)3.3) Hz \\ \hline \hline isolated electrons & (22.8\(\pm\)13.2) Hz & (6.8\(\pm\)2.4) Hz \\ W \(\,\rightarrow\,\mathrm{e}\,\nu\) & (22.8\(\pm\)13.2) Hz & (4.3\(\pm\)1.9) Hz \\ \hline Total irreducible & (45.6\(\pm\)18.6) Hz & (11.1\(\pm\)3.1) Hz \\ \hline \end{tabular}
\end{table}
Table 8: Trigger rates after the event filter (including TR) for design and low luminosity.

### W \(\to\) e \(\nu\)

The measurement of the W mass is a very important quantity in the Standard Model for constraining the Higgs mass or to verify the prediction of the Standard Model once the Higgs is found. The W mass is proportional to \(\ln m_{\rm\,H}\). Therefore a very high precision of the W mass is needed to constrain the Higgs mass. In 2005, the uncertainty of the W mass from Tevatron and LEP data will be \(\Delta m_{\,W}\raisebox{-3.698858pt}{~{}\shortstack{$<$ \\ [-0.07cm] $\sim$}}~{}30\,\mathrm{MeV}(0.4\%_{0})\)[11].

At LHC the only accessible channels for determining the W mass are \(\mathrm{W}\,\to\,\)e \(\nu\) and \(\mathrm{W}\,\to\,\)\(\mu\,\nu\). The jets from \(\mathrm{W}\,\to\,\)jet jet are difficult to separate from the QCD background. A possibility would be to use \(\mathrm{t}\,\to\,\)b \(\mathrm{W}\,\to\,\)b jet jet with tagging of the b-jet. However, the energy scale for jets is worse than the electro-magnetic scale. In the process \(\mathrm{W}\,\to\,\)\(\tau\,\nu\) with \(\tau\,\to\,\)\(\nu\) + \(\mathrm{X}\) too many undetected neutrinos are involved. The hadronic decay of the \(\tau\) cannot be used because the hadrons are lost in the QCD background. In order to improve the W mass resolution at LHC with \(\mathrm{W}\,\to\,\)e \(\nu\), a very precise calibration of the electro-magnetic calorimeter and very high statistics are needed.

Additionally, for a Higgs mass of about \(m_{\rm\,H}\approx 170\,\mathrm{GeV}\) the most promising channel is \(\mathrm{H}\,\to\,\)\(\mathrm{W}\,\mathrm{W}\,\to\,\)\(\ell\,\nu\) \(\ell\,\nu\). Therefore a high statistic of W events is desirable in order to find a clear excess of events coming from the Higgs decay.

Due to technical reasons, there are only a few W events from the background simulation available6. Therefore only a very crude estimate of the trigger efficiency can be made: \((27\pm 14)\%\) for the trigger menu items e 20i at low luminosity and \((18\pm 11)\%\) for e 30i at design luminosity. It is interesting to note that about 50% of the W events are discarded by LV L1. If a threshold of 35 GeV is chosen the efficiency drops to \((6\pm 6)\%\) (\((11\pm 8)\%\)) for design (low) luminosity.

Footnote 6: Only electrons from the W-decay with \(p_{\rm T}>17\,\mathrm{GeV}\) and \(|\eta|<2.7\) were considered.

Fortunately, there is another way to reduce the rate and still keep all W events. At the event filter the exclusive trigger item e 30i+xE at design and e 20i+xE at low luminosity can be introduced. Figure 7 shows the event filter rate as function of the

Figure 7: Event filter trigger rate as function of an additional \(E_{\rm T}^{\rm miss}\) cut. Left for design luminosity (e 30i+xE), right for low luminosity (e 20i+xE). The errors shown are statistical uncertainties\(E_{T}^{\rm miss}\) threshold. Up to a threshold of 25(15) GeV at design (low) luminosity no W events are lost, whereas the rate is reduced by a factor of 1.7 (2.5).

Please note that there are only very few events left. Therefore, these numbers might give an indication, but are far from solid.

### Z \(\rightarrow\) e e

The study of Z \(\rightarrow\) e e events has a twofold application in ATLAS. The measurement of the Z forward/backward asymmetry can provide a high precision measurement of the Weinberg angle due to the very large statistics available in ATLAS. In addition to the measurement of the Weinberg angle, the study of Z \(\rightarrow\) e e events can be used to provide a high statistics and clean monitoring and calibration of the electromagnetic energy scale for electrons in an energy range important for other precision measurements, such as the W mass and the discovery of the Higgs.

Table 9 shows the efficiency for selecting Z \(\rightarrow\) e e. For this channel, the single electron trigger items e30i (e20i) as well as the double object trigger items e20i\(\times\) 2 (e15i\(\times\)2) are used at design (low) luminosity. The efficiency for this channel is about 90% at both luminosities. The trigger rate is somewhat enlarged for the LVL1 and LVL2 trigger compared to the single electron trigger (cf. tables 5 and 6). The event filter rate is not affected.

If only the double object trigger were employed, the efficiency would drop to about 45%, because the second electron is produced with \(|\eta|>2.4\) and cannot be detected by the electro-magnetic calorimeter. An algorithm to find far-forward electrons is missing. Given the high occupancy in the far-forward region, it is questionable if such an algorithm will be fast enough to run on the event filter.

\begin{table}
\begin{tabular}{|l|c|c|c|c|} \hline \multirow{2}{*}{Trigger step} & \multicolumn{2}{c|}{Design \(\mathcal{L}\)} & \multicolumn{2}{c|}{Low \(\mathcal{L}\)} \\  & Efficiency & Rate (Hz) & Efficiency & Rate (Hz) \\ \hline \hline LVL1 & 97.7\% & 22822\(\pm\)424 & 99.2\% & 5846\(\pm\)71 \\ \hline LVL2 & 94.3\% & 448\(\pm\)59 & 97.3\% & 136\(\pm\)11 \\  & (96.5\%) & (51\(\pm\)7) & (98.1\%) & (43\(\pm\)3) \\ \hline e.m. calorimeter & 93.7\% & 307\(\pm\)49 & 96.6\% & 73\(\pm\)8 \\ \(E_{T}^{\rm min}=10\) GeV & (99.4\%) & (1.5\(\pm\)0.2) & (99.3\%) & (1.8\(\pm\)0.2) \\ \hline ID (xKalman) & 92.0\% & 142\(\pm\)33 & 94.8\% & 47\(\pm\)6 \\ \(p_{T}^{\rm min}=10\) GeV & (98.2\%) & (2.2\(\pm\)0.5) & (98.2\%) & (1.6\(\pm\)0.2) \\ \hline Matching & 90.8\% & 118\(\pm\)30 & 93.7\% & 36\(\pm\)6 \\  & (98.8\%) & (1.2\(\pm\)0.3) & (98.8\%) & (1.3\(\pm\)0.2) \\ \hline TR & 88.5\% & 79\(\pm\)25 & 90.0\% & 24\(\pm\)5 \\  & (97.5\%) & (1.5\(\pm\)0.3) & (96.1\%) & (1.5\(\pm\)0.3) \\ \hline \end{tabular}
\end{table}
Table 9: Z \(\rightarrow\) e e efficiencies and trigger rates at design (low) luminosity for the trigger items e30i (e20i) and e20i\(\times\)2 (e15i\(\times\)2). In parenthesis the efficiency and rate reduction compared to the previous step is specified. The efficiencies are accurate to about \(\pm\)8%(\(\pm\)2%) (absolute value). Only statistical errors are shown.

### H \(\rightarrow\) Z Z\({}^{*}\)\(\rightarrow\) 4 e

One of the most important physics benchmark channels for the LHC is H \(\rightarrow\) Z Z\({}^{*}\)\(\rightarrow\) 4 e. This channel is the most promising discovery channel for the Higgs boson over a wide Higgs mass range [12].

The trigger efficiency for this channel for \(m_{\mbox{\small\,H}}\,=130\) GeV and 170 GeV at low luminosity is shown in table 10. Both single- and double-object trigger items e20i and e15i\(\times\)2 were allowed. The trigger rates are the same as given in table 9.

If only the double object trigger item e15i\(\times\)2 is allowed, the total efficiency drops to 81.2% for \(m_{\mbox{\small\,H}}\,=130\) GeV. For \(m_{\mbox{\small\,H}}\,=170\) GeV the efficiency is unchanged.

## 5 Conclusions and Outlook

In this study a detailed timing of offline algorithms similar to those employed in the online event selection done at the event filter is presented. The stringent time constraints of a few seconds for the processing of an event at the event filter can be met with simple reconfigurations of the reconstruction package ATRECON while retaining the overall trigger efficiency of about 70%(66)% for single electrons with \(p_{T}=30(20)\) GeV at design (low) luminosity.

It is shown that the single (inclusive) electron trigger on its own contributes 80%(25%) of the target trigger rate of 100 Hz at design (low) luminosity. 65%(50%) of this rate is due to irreducible background events like W \(\rightarrow\) e \(\nu\) or isolated electrons from other processes. Additionally, the reducible rate will be higher in the real world, because a perfectly aligned, calibrated and efficient detector was used for these studies.

The trigger rate coming from the single electron trigger item e30i (e20i) at design (low) luminosity is of big concern. Therefore, it will be inevitable to raise the momentum threshold for hard-\(p_{T}\) electrons and to pre-scale the lower threshold trigger items in order to reduce the trigger rate. Fortunately, there are possibilities to save the trigger efficiency for interesting physics channels like W \(\rightarrow\) e \(\nu\), Z \(\rightarrow\) e e, and H \(\rightarrow\) 4 e. By employing an additional cut on the missing transverse energy

\begin{table}
\begin{tabular}{|l|c c|c c|} \hline Trigger step & \multicolumn{2}{c|}{130 GeV} & \multicolumn{2}{c|}{170 GeV} \\ \hline \hline LVL1 & 98.8\% & & 99.0\% & \\ \hline LVL2 & 97.2\% & (98.5\%) & 98.2\% & (99.2\%) \\ \hline e.m. calorimeter & 97.2\% & (99.9\%) & 98.2\% & (100.0\%) \\ \hline ID (xKalman) & 96.6\% & (99.5\%) & 98.0\% & (99.8\%) \\ \hline Matching & 96.5\% & (99.8\%) & 97.7\% & (99.7\%) \\ \hline TR & 95.2\% & (98.6\%) & 97.1\% & (99.4\%) \\ \hline \end{tabular}
\end{table}
Table 10: H \(\rightarrow\) Z Z\({}^{*}\)\(\rightarrow\) 4 e  efficiencies for two different Higgs masses \(m_{\mbox{\small\,H}}\,=130\) GeV and 170 GeV at low luminosity. Both single- and double-object trigger items e20i and e15i\(\times\)2 were allowed. In parenthesis the efficiency compared to the previous step is specified. The efficiencies are accurate to about \(\pm 2\%\) (absolute value). Only statistical errors are shown.

\(E_{T}^{\rm miss}\), the W efficiency can be retained while reducing the trigger rate by a factor of about two. Using the double object trigger items e20i\(\times\)2 (e15i\(\times\)2), the reduction of the trigger efficiency for Z and Higgs events can be moderated.

The physics impact of a raised threshold for high-\(p_{T}\) electrons has to be studied further by optimizing the selection criteria over the full trigger chain. Additional background simulations will be necessary to provide better trigger rate estimates. The boundary between level 2 and the event filter has to be optimized in such a way that the overall efficiency and background rate reduction can be as high as possible within the stringent limitations of an online system. This boundary will always be floating as the increased understanding of the detector and physics will ask for new algorithms on different trigger steps. Some studies in this direction have been done [B\({}^{+}\)00a], but the old framework of ATRIG/ATRECON cannot give a final answer.

Future studies should not only address the algorithm performance in terms of physics performance and execution time, but also take memory requirements and data access schemes into account. Only this more complete view will provide the necessary information to give an estimate of the computing power needed for the event filter, and also for the offline computing. It is obvious that the old framework of ATRECON and ATRIG cannot answer these questions. Therefore, it is important to redo the studies presented in this work as soon as the trigger and reconstruction within the new ATHENA framework will be operational.

## References

* [A\({}^{+}\)95] Andrei Artamonov et al., _DICE-95_, ATLAS Internal Note ATL-SOFT-95-014, 1995.
* [App93] Application Software Group, _Geant -- detector description and simulation tool_, CERN Program Library Long Writeup W5013, 1993.
* [ATL96] ATLAS Collaboration, _ATLAS: calorimeter performance technical design report_, CERN/LHCC/96-040; ATLAS-TDR-1, 1996.
* [ATL97] ATLAS Collaboration, _ATLAS: inner detector technical design report, 1_, CERN/LHCC/97-016; ATLAS-TDR-4, 1997.
* [ATL99a] ATLAS Collaboration, _ATLAS Detector and Physics Performance: Technical Design Report, 1_, CERN/LHCC/99-014; ATLAS-TDR-14, 1999.
* [ATL99b] ATLAS Collaboration, _ATLAS Detector and Physics Performance: Technical Design Report, 2_, CERN/LHCC/99-015; ATLAS-TDR-15, 1999.
* [ATL00] ATLAS HLT/DAQ/DCS Group, _ATLAS High-Level Triggers, DAQ and DCS: Technical Proposal_, CERN/LHCC/2000-017, 2000.
* [B\({}^{+}\)94] John Baines et al., _ATRIG 1.00 ATLAS Trigger Simulation User Guide, Revision 0.00_, ATLAS Internal Note ATL-SOFT-94-017, 1994.

* [B\({}^{+}\)00a] John Baines et al., _First study of the LVL2-EF boundary in the high-\(p_{T}\) e/\(\gamma\) High-Level Trigger_, ATLAS Internal Note ATL-DAQ-2000-045, 2000.
* [B\({}^{+}\)00b] John Baines et al., _Identification of high-\(p_{T}\) electrons by the Second Level Trigger of ATLAS_, ATLAS Internal Note ATL-DAQ-2000-003, 2000.
* [BQ90] P. Billoir and S. Qian, _Simultaneous Pattern Recognition and Track Fitting by the Kalman Filtering Method_, Nuclear Instruments and Methods in Physics Research **A294** (1990), 219-228.
* [D\({}^{+}\)97] Andrea Dell'Acqua et al., _1997 ATLAS Jet Production_, ATLAS Internal Note ATL-PHYS-97-102, 1997.
* [Gav97] Igor Gavrilenko, _Description of Global Pattern Recognition Program (xKalman)_, ATLAS Internal Note ATL-INDET-97-165, 1997.
* Summer Student Lectures_, [http://webcast.cern.ch/Projects/WebLectureArchive/gianottic](http://webcast.cern.ch/Projects/WebLectureArchive/gianottic), 5-6 Aug 1999.
* [Jar] Sverre Jarp, _private communication_.
* [MRW00] Remigius K. Mommsen, Alina Radu, and Monika Wielers, _Performance Studies for Electron and Photon Selection at the Event Filter_, ATLAS Internal Note ATL-DAQ-2000-007, 2000.
* [Off94] Offline Software group, _DRAFT ATLAS ATRECON manual (Version 0.015)_, ATLAS Internal Note ATL-SOFT-94-015, 1994.
* [Pra99] Pascal Pralavorio, _Electron/Jet Separation with the ATLAS detector_, ATLAS Internal Note ATL-PHYS-99-015, 1999.
* [RWFP98] Elzbieta Richter-Was, Daniel Froidevaux, and Luc Poggioli, _ATLFAST 2.0: a fast simulation package for ATLAS_, ATLAS Internal Note ATL-PHYS-98-131, 1998.
* [Sim98] Stefan Simion, _Pile-up Simulation for ATLAS Calorimeters_, [http://home.cern.ch/s/simions/www/pileup/pileup.ps](http://home.cern.ch/s/simions/www/pileup/pileup.ps), 19 Jun 1998.
* [Wie98] Monika Wielers, _Procedure to add Pileup in the Inner Detectors and the Calorimeters at design Luminosity_, [http://home.cern.ch/w/wielers/www/pileup.ps.gz](http://home.cern.ch/w/wielers/www/pileup.ps.gz), 2 Dec 1998.
* [Wie99] Monika Wielers, _Photon Identification with the ATLAS Detector_, ATLAS Internal Note ATL-PHYS-99-016, 1999.