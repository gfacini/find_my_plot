**LHC experimental sensitivity to \(CP\) violating \(gt\bar{t}\) couplings**

Jorgen Sjolin

Stockholm University1

Footnote 1: Email: sjolin@physto.se

The level of \(CP\) violation in top quark events induced by the Standard Model is known to be beyond the experimental sensitivity by many orders of magnitude. However, within the language of effective theories, it is plausible that new \(CP\) violating physics could reveal itself as additional non renormalizable terms in the Lagrangian. Since these should respect the symmetries of the low energy gauge interaction, violate \(CP\) and generate the correct event topology, the set of allowed terms is highly restricted. This analysis gives an estimation of the ATLAS sensitivity to the lowest order effective \(CP\) violating \(gt\bar{t}\) interaction term beyond the Standard Model.

###### Contents

* 1 Introduction
* 2 Effective theory
* 3 Event generation
	* 3.1 Feynman rules
	* 3.2 Amplitudes
	* 3.3 Signal and background samples
* 4 Observables for \(CP\) violation
	* 4.1 Optimal observables
	* 4.2 Non optimal observables
	* 4.3 Standard Model contamination
* 5 Detector simulation
* 6 Analysis
	* 6.1 Dileptons
	* 6.2 Single lepton + jets
	* 6.3 Results
* 7 Conclusions
* A An Exact solution to dilepton events
* B A 3C fit to single lepton + jets events
* B.1 Performance

Introduction

The search for and understanding of \(CP\) violation has played a central role in physics ever since it first discovery [1]. More and more experimental evidence strongly favors [2, 3] that the main source is due to the complex phase in the CKM matrix [4] that mixes the quark mass eigenstates in charged electro-weak currents. Within the 4-dimensional renormalizable Standard Model there is no room for any other mechanism to introduce \(CP\) violation, except for the famous topological strong \(CP\) phase [5] which must be extremely small due to the absence of an electric dipole moment of the neutron [6].

However, we know that the Standard Model cannot be a complete theory. And as the new run of the Tevatron and the emerging LHC experiments begin to probe the physics in the TeV range we anticipate indications of new physics. Many consistent candidates for an extension of the Standard Model contain new sources of \(CP\) violation, i.e. multiple Higgs doublet models [7] and low energy supersymmetry [8] where indeed the large top mass could imply yet undetected but sizable \(CP\) violating effects. An extremely powerful tool to extract the core physical properties, while at the same time hide our lack of information concerning the details of the underlying theory, is that of effective theories [9]. Given the focus of this paper on \(CP\) violation in \(t\overline{t}\) events the new highly restricted set of effective terms in the Lagrangian should respect the gauge invariant symmetries of the low energy theory, violate \(CP\) and generate the correct event topology. In this analysis the topology is that of the LHC, i.e. \(pp\to t\overline{t}+X\).

The topic of new \(CP\) violating sources in \(t\overline{t}\) events has been a very active area in phenomenological studies. Good reviews can for example be found in references [10, 11]. This analysis will concentrate more on experimental issues which have not been explored in the same detail.

## 2 Effective theory

In order to be as model independent as possible the choice was made to use the effective theory approach to the problem of modeling \(CP\) violation in \(t\overline{t}\) production at the Lagrangian level (see e.g. [12, 13]). This means that we assume that there is a new high energy physics scale (\(\Lambda\)) which introduce new degrees of freedom that have been integrated out in the low energy effective Lagrangian. There are three operators at leading order of mass dimension six that are relevant for the LHC environment. They are however, after applying the SM equations of motion, all equivalent up to four-point fermion vertices [14] which can be safely neglected, particularly since the gluon fusion production is dominant. The operator is

\[{\cal O}_{tG}=\bar{q}_{L}\sigma^{\mu\nu}t_{\ R}\tilde{\Phi}G^{a}_{\mu\nu}T^{a} \tag{1}\]

in the common SM notation, i.e. \(q_{L}\) is the left-handed \(SU(2)\) doublet containg the third family left-handed quarks \(t_{L}\) and \(b_{L}\), \(t_{R}\) is the right-handed \(SU(2)\) singlet, \(\Phi\) is the Higgs field where \(\tilde{\Phi}=i\sigma_{2}\Phi^{*}\), \(G^{a}_{\mu\nu}\) is the gluon field tensor, and \(T^{a}\) are the \(SU(3)\) generators. With this operator a real-valued effective Lagrangian term of mass dimension four can be constructed

\[{\cal L}_{6} = \frac{1}{M^{2}}(\alpha_{tG}{\cal O}_{tG}+\alpha_{tG}^{*}{\cal O}_{ tG}^{\dagger}) \tag{2}\] \[= \frac{v}{\sqrt{2}M^{2}}\vec{t}\sigma^{\mu\nu}\{\Re\alpha_{tG}(P_{R }+P_{L})+i\Im\alpha_{tG}(P_{R}-P_{L})\}tG_{\mu\nu}^{a}T^{a} \tag{3}\]

where \(M\) is an arbitrary mass scale (here \(M\) is set to \(m_{t}\)) and \(\alpha_{tG}\) is the coupling constant, the helicity projection operators are \(P_{R,L}=\frac{1\pm\tau_{s}}{2}\), and \(v\) is the Higgs vacuum expectation value after electro-weak symmetry breaking. This is dynamically equivalent to the mass dimension five Lagrangian [15]

\[{\cal L}_{5}=-\frac{C_{5}}{2}\vec{t}\sigma^{\mu\nu}tG_{\mu\nu}^{a}T^{a}-i\frac {D_{5}}{2}\vec{t}\sigma^{\mu\nu}\gamma_{5}tG_{\mu\nu}^{a}T^{a} \tag{4}\]

where \(C_{5}\) is the chromo-magnetic dipole moment (CMDM) and \(D_{5}\) is the chromo-electric dipole moment (CEDM). CEDM is \(CP\)-odd and hence the leading order contribution for the parametrization of \(CP\) violation, while CMDM is \(CP\)-even and does not violate \(CP.\) The relations between the constants in \({\cal L}_{6}\) and \({\cal L}_{5}\) are

\[C_{5}=-\frac{\sqrt{2}v}{M^{2}}\Re\alpha_{tG}\ \mbox{and}\ D_{5}=-\frac{\sqrt{ 2}v}{M^{2}}\Im\alpha_{tG} \tag{5}\]

The couplings \(C_{5}\) and \(D_{5}\) are not dimensionless. A practical definition of dimensionless couplings of order one (\(c_{t}\),\(d_{5}\)) are

\[C_{5}=g_{s}\frac{c_{t}}{m_{t}}\ \mbox{and}\ D_{5}=g_{s}\frac{d_{t}}{m_{t}} \tag{6}\]

where \(g_{s}\) is the strong coupling constant.

Since the terms in \({\cal L}_{6}\) are not renormalizable there exists a triviality limit from the unitarity of the \(S\)-matrix. The unitarity constraint has been estimated in reference [16] to be

\[|\Re\alpha_{tG}|\simeq\frac{m_{t}^{2}\sqrt{\pi}}{v\,\Lambda\sqrt{1+\frac{2}{ 3}\alpha_{s}}},\ \ \ \ \mbox{for}\ \Lambda\,<10\ \mbox{TeV}.\]

If we assume that \(|Re(\alpha_{tG})|\simeq|Im(\alpha_{tG})|\) and set the scale of new physics at \(\Lambda=2\) TeV we find2

Footnote 2: According to reference [16] there is a unique definition of the unitarity constraint if we use \(M\) instead of \(\Lambda\) as the mass scale in \({\cal L}_{6}.\)

\[d_{t}<{\cal O}(1).\]

This means that if there is new physics at \(2\) TeV, the model \({\cal L}_{6}\) will provide a reasonable effective description for \(d_{t}\) below this number.

Event generation

The \(CP\) violating signal is generated by a dedicated Monte Carlo event generator TOPSPIN [17] that incorporates the full matrix elements. The use of complete matrix elements is very important since the \(CP\) violation is mediated by the \(t\overline{t}\) spin correlations. The matrix elements are calculated by the HELAS [18] library with modified \(CP\) violating vertices. The fragmentation of the hard process is handled by PYTHIA [19]. The output agrees with the calculations in reference [15] and COMPHEP [20] that only takes \({\cal L}_{5}\) as input in the generation of the cross-section calculations. The details of the event generation are explained in reference [17].

### Feynman rules

To calculate the new matrix elements for the Monte Carlo generator the first thing to do is to extract the Feynman rules. The Lagrangian \({\cal L}_{5}\) generates two additional Feynman rules apart from the Standard Model. They can be read off directly from the Lagrangian and are

\(V_{1}=-ig_{s}\sigma^{\mu\nu}(\frac{ic_{t}}{m_{t}}-\frac{d_{t}}{m_{t}}\gamma_{5} )q_{\nu}T^{a}\)

\(V_{2}=g_{s}^{2}\sigma^{\mu\nu}(\frac{ic_{t}}{m_{t}}-\frac{d_{t}}{m_{t}}\gamma_ {5})f^{abc}T^{c}\)

The vertex \(V_{1}\) modifies the original \(gt\overline{t}\) vertex and the vertex \(V_{2}\) is a new 4-point vertex not present in the Standard Model. \(f^{abc}\) are the \(SU(3)\) structure constants. Please note that this definition of \(V_{2}\) requires strictly real and constant couplings. The imaginary part of the couplings must be zero below the \(t\overline{t}\) production threshold, hence non zero complex couplings imply \(q^{2}\) dependence and higher orders in the mass dimensions. The extra Lorentz structures needed for a constant imaginary part above the threshold are given in reference [10] but are not included here.

### Amplitudes

The dominant production mode at LHC is \(gg\) fusion (90%), hence \(q\overline{q}\) is not considered. The cleanest final state topology is the semi-leptonic decay of both \(t\) and \(\vec{t}\) resulting in a final state with two oppositely charged leptons, from here on referred to as the dilepton final state. However, the bulk of the total observable and most useful events are those with one \(t\) decaying semi-leptonically and the other one going to hadrons, these types of events are in the rest of the text referred to as lepton + jets. The Standard Model \(t\overline{t}\) diagrams with purely semi-leptonic decays are shown in Figure 1. When \({\cal L}_{5}\) is added there is one more diagram that includes \(V_{2}.\) There are 200 additional Standard Model diagrams that contribute to this final state, which in principle are needed in order to maintain complete gauge invariance. However, due to the narrow widths of the resonances their contribution to the total cross-section was found to be negligible and consequently they are not included in the final analysis due to the extra CPU power requirements.

### Signal and background samples

The total cross-section for \(t\overline{t}\) production at the LHC is estimated to be 833 pb (685 pb) [21]. The numbers within parenthesis are from PYTHIA 6.157 with CTEQ 5M structure functions taken from PDFLIB [22]. Rescaling is needed in order for the leading order MC to match the next leading order calculations. For an expected initial luminosity of 10 fb\({}^{-1}\) per year, this translates into 8.3 million events per year. The two classes of events that are useful in the analysis are dileptons and lepton + jets. The \(W\) branching ratio into each lepton is 10.7%. Since the tau events are not useful due to the extra neutrino, only muons and electrons are used leading to

Figure 1: The four types of diagrams included in the calculation of \(|{\cal M}|^{2},\) here shown for the lepton + jets decay topology. Dotted vertices represents the anomalous couplings. The lower diagram includes the additional four-point vertex \(V_{2}\) that is not present in the Standard Model.

a dilepton sample of 380000 events per year. The hadronic fraction of the \(W\) is 67.8% which gives a total lepton + jets sample of 2.4 million events per year. The purely hadronic sample is not considered since it is very hard to separate from the background.

The main background for dileptons is \(Z\) + jet, where the \(Z\) decays into taus (740 pb, jet \(p_{t}\) > 20 GeV). For lepton + jets the main background is \(W\) + jet (14800 pb, jet \(p_{t}\) > 20 GeV) where the \(W\) decays into leptons.

## 4 Observables for \(Cp\) violation

If the \(d_{t}\) parameter is small, typically 0.1 or less, then the term linear in \(d_{t}\) will be the dominating \(CP\) violating term in the differential cross-section. This has the consequence that the total cross-section is not affected by \(d_{t}\) since the spin average is zero, and the main observable effect will be the in the asymmetries sensitive to \(CP\) violation. There are higher order terms in the cross-section e.g. \(\Delta\sigma(d_{t}^{2})\). But since \(d_{t}\) is assumed to be small the higher order terms will be suppressed in \(CP\)-even observables like the \(p_{t}\) spectrum.

### Optimal observables

Assume that the cross-section \(\sigma\) has a small perturbation controlled by the parameter \(\lambda\). Then \(\sigma\) can be expanded in terms of \(\lambda\)

\[\sigma\simeq\sigma_{0}+\lambda\sigma_{\lambda},\]

where \(\lambda\) could be for example the CEDM parameter \(d_{t}\). The question is how to measure \(\lambda\) in an optimal manner? Under the conditions described above there exists an optimal observable \(f\) for \(\lambda\) given by

\[f=\frac{\sigma_{\lambda}}{\sigma_{0}},\]

such that the statistical fluctuations are minimized [23]. Note that \(f\) inherits the symmetry from the perturbation introduced in the Lagrangian. Unfortunately the optimal observable \(f\) may not be optimal in a global sense when instrumental effects are considered. Some information may not be available or very poorly reconstructed. But even worse, since \(f\) can be quite complicated it can be sensitive to systematic effects that become the dominant error source for large statistical sample. However, the optimal observable always remains very useful as a benchmark for other simpler observables.

Since it not possible to perform true time reversal to the event, the normal equivalence between \(CP\) and \(T\) due to the \(CPT\) theorem cannot be applied in any useful way to the observables. However one can still define a quantity called naive time reversal (\(T_{N}\)). \(T_{N}\) implies reversal of momentum and spin but not interchanging initial and final states. The \(CP\)-odd observables fall into two categories, those which are odd and those which are even under \(T_{N}\). \(T_{N}\)-odd observables probe the real part of \(\lambda\), do not require any strong (absorptive) phase in the final state, but need at least four measured 4-vectors and must be proportional to the Levi-Civita tensor. \(T_{N}\)-even observables on the other hand only require two measured quantities, require a strong phase and probe the imaginary part of \(\lambda\).

### Non optimal observables

Given the resolving power of the optimal observable it makes sense to look for simpler and more robust ones that are competitive. Naive and robust observables have been evaluated in numerous articles [24, 25]. The most competitive are 5-10 times less effective than the optimal ones. For dilepton events the two strongest found in the literature are

\[f_{2}(l^{+},l^{-},b,\vec{b})=\frac{\epsilon_{\mu\nu\sigma\rho}p_{l^{+}p_{l}^{ \prime}-p_{b}^{\prime}p_{b}^{\prime}}}{(p_{l^{+}}\cdot p_{l}-p_{b}\cdot p_{\vec {b}})^{1/2}}\ (T_{N}\mbox{-odd})\]

\[A_{1}=\frac{E_{t}(l^{+})-E_{t}(l^{-})}{E_{t}(l^{+})+E_{t}(l^{-})}\ (T_{N}\mbox{- even})\]

For lepton + jets events, one of the leptons is replaced by the d-type jet from the \(W\) decay. In the analysis several other asymmetries have also been investigated

\[T_{2}=(\vec{p}_{b}-\vec{p}_{\vec{b}})\cdot(\vec{p}_{l^{+}}\times\vec{p}_{l}-)\]

\[Q_{2}=(\vec{p}_{b}-\vec{p}_{\vec{b}})\cdot(\vec{p}_{l^{+}}\times\vec{p}_{l}-)\]

All momenta are given in the laboratory frame except for \(Q_{2}\) where the top momenta are in the parton c.m.s. and the leptons are in the top rest frame. Note that only \(f_{2}\) has the property of being Lorentz invariant.

### Standard Model contamination

Since the \(pp\) initial state is not a \(CP\) eigenstate the signal will eventually at some level receive contamination from \(CP\)-even contributions. It is easy to show that for initial gluons and Lorentz invariant observables like \(f_{2}\) there are no contributions at tree level. Also \(T_{N}\)-odd observables require an absorptive phase in order to receive contributions from \(CP\)-even processes. The situation is worse for the observable \(A_{1}\). Here a contribution from the process \(q\vec{q}\to Z\to t\vec{b}\) is present already at the tree level. In reference [25] it is shown that this background is at least 2 orders of magnitude smaller than the signal.

## 5 Detector simulation

The response of the ATLAS detector [26] is simulated by the fast simulation package ATLFAST [27]. This essentially accounts for resolution smearing of detected object according to the expected performance and cutting outside the detector acceptance.

The calorimeters are simulated by summing and smearing all particles except muons and neutrinos within \(0.1\times 0.1\) in \(\eta\) and \(\phi\), where \(\eta\) is the pseudo rapidity and \(\phi\) is the azimuthal angle. The default ATLFAST jet algorithm is used to reconstruct the jets within a 0.4 cone. Leptons are required to be isolated from the jets. The b-tagging efficiency is set 70%, with rejection parametrization taken from ATLFAST-B. High efficiency is very important and rejection factors of \({\cal O}(10)\) is sufficient to clean up the event against combinatorial background.

## 6 Analysis

In the analysis the choice has been made to only look for the real part of the \(d_{t}\) parameter. This has the consequence that only \(T_{N}\)-odd asymmetries are relevant. There are several reasons for the choice of a real \(d_{t}\). As an example one can look at reference [7]. It is a good first guess that the parameter \(d_{t}\) could be approximated with a real valued constant. Secondly, an imaginary part must be \(q^{2}\) dependent since \(d_{t}\) must be strictly real below the threshold for the production of on-shell t-quarks. The modeling of \(q^{2}\) dependence only implies a few extra Lorentz structures in the 4-point vertex \(V_{2}\), see e.g. [10], but the choice was not to include them in the MC vertex functions. A real \(d_{t}\) is also in the spirit of effective theories where the unknown degrees of freedom are not produced on-shell.

The \(CP\) violation is manifest in the spin correlation between the two t-quarks which is evident from the explicit matrix elements in [24]. The strongest naive asymmetry found that utilizes this fact is \(f_{2}\). Due to the nature of the weak interaction, the spin of the t-quark is reflected in the decay products. The strongest spin analyzers are the charged leptons or, in the case of hadronic \(W\) decays, the d-quarks [28]. The complication is that the flavor and charge of the b-quarks, and d-quarks in hadronic decay, have to be assigned. The strategy chosen here is to let the event kinematics in combination with the b-tagging capability solve the jet flavor and charge assignment. This technique works for both the dilepton and lepton + jets topologies. Another argument for a full event reconstruction is that the use of the t-quark momentum instead the b-quark momentum in the \(f_{2}\) asymmetry improves the sensitivity, at least at the parton level.

In the analysis jets are used in the reconstruction of the \(W\) and top masses. Since parton and jet momenta are not the same, an energy dependent rescaling is performed in order to reconstruct the correct average mass. The jet calibration information for the rescaling is taken from the \(t\bar{t}\) sample but with strict isolation criteria. The effect of the rescaling is shown in figure 2. The rescaling is only used in the reconstruction of the event, i.e. all cuts are unaffected.

### Dileptons

A typical tree level diagram for a dilepton event is shown in Figure 4. The two leptons make the signal clean and easy to trigger on. Also the two b-quarks are relatively hard. The difficulty lies in the two neutrinos. All moment a in the event 

### Single lepton + jets

A typical diagram for a lepton + jets event including initial and final state radiation is shown in Figure 4. The average jet multiplicity is 6 jets, hence the problem of flavor and charge assignment with high efficiency is highly non trivial. An efficient tool for the selection of the jet candidates is to use the 6 most energetic jets. This not only vastly reduces the computational requirements, but also increases the total number of correct assignments. The analysis proceeds as follows

1. Events are selected which have one isolated lepton whose transverse momentum (\(p_{t}\)) is greater than 20 GeV, 2 jets with \(p_{t}>30\) GeV (2 most energetic) and 2 additional jets with \(p_{t}>15\) GeV.
2. All combinations of the 6 most energetic jets which reconstruct the \(W(t)\) masses within 40 (60) GeV are fitted with a 3C fit (see Appendix B) to the event hypothesis and the two combinations with the lowest \(\chi^{2}\) are kept unless the d-type jet is taken to be the least energetic jet of the two.

The number of events that survives the cuts are shown in Table 2.

The \(f_{2}\) asymmetry requires the identification of the d-type quark which is not separable from the u-type quark on an event to event basis in the \(W\) decay. Fortunately, since the d-quark is a much stronger (100%) spin analyzer than the u-quark (-31%), there is a net asymmetry just by averaging over the two configurations. There is further a possibility to account for the jet flavor on a statistical basis due to the fact that in 61% of the cases the d-quark is the least energetic jet in top rest frame. Consequently one can search for an improved significance by giving a higher weight to the least energetic jet.

Figure 4: S-channel part of a typical dilepton (left) and lepton + jets (right) final state event including examples of initial and final state radiation.

### Results

The aim is to have maximal sensitivity to \(CP\) violation. In the analysis chain there are several factors that have a significant impact on the final performance. To begin with, among the evaluated asymmetries \(f_{2}(t)\) is clearly the most sensitive observable at the parton level. However, once the effects of the detector and the reconstruction are included \(f_{2}(b)\) is actually equally good or even better. The distributions of \(f_{2}(t)\) and \(f_{2}(b)\) are shown in Figure 6. The second issue is how to extract the asymmetry in the best possible way. A high quality fit to the distribution is given by a double Gaussian with common mean which is superimposed in Figure 6. When the error of the fit (E1) is compared to the error of the mean taken just from the histogram (E2) one finds, somewhat surprisingly, that the fit yields no improvement to the significance. The significance is defined here as the mean divided by the one sigma error. Maybe less surprising is that the robustness of the E2 estimation is superior compared to E1. Also in favor of E2 is that it requires no a priori estimation of the shape of the distribution. One way to further improve the robustness of the measurement that is proposed by W. Bernreuther et al [29] is to do a counting experiment of the difference between the number of positive and negative asymmetries. Clearly that does not take full advantage of the available information and on average half of the significance is lost. The summary of the strength in significance for the different asymmetries is shown in Table 3.

The significance for a non zero \(f_{2}\) asymmetry and hence the ability to detect a non zero \(CP\) violating effect given a fixed number of events at different values of

Figure 6: The asymmetry \(f_{2}\) fitted to a double Gaussian with common mean using dilepton events. In the left plot the parton level distribution of \(f_{2}(t)\) is shown. The quality of the fit is good but there is no improvement compared to the significance given by the mean and RMS from the histogram. On the right the distribution of \(f_{2}(b)\) after detector simulation is shown. The dip in the peak is due to the \(p_{t}\) cuts.

\(c_{t}\) and \(d_{t}\) are shown in table 4. The control samples from PYTHIA and TOPSPIN at the point (0,0) yield no signal as expected. As the \(CP\) violating parameter \(d_{t}\) is turned on its effect on the asymmetry observable \(f_{2}\) is quite evident. We see that the sample with the best reach is lepton + jets assuming the least energetic jet as the d-jet. We also note a very interesting effect of the \(CP\)-even parameter \(c_{t}\): at the point (-0.6,0.2) the sensitivity to \(d_{t}\) is lost! This point will however not be undetected since the total cross-section is huge in this case. One can also look at \(CP\)-even observables like the \(p_{t}\) spectrum to rule out this point, see Figure 7. In is also interesting to mention the point (-0.2,0.2) which has no effect on the total cross-section. Here the \(f_{2}\) asymmetry is not significantly effected.

To conclude the analysis the systematic effect of a 1% error in the jet energy scale has been evaluated. The fact the observable is a distribution asymmetry makes the end result quite robust. For example the error in the jet energy scale does not introduce any fake asymmetries, but it has an influence on the efficiency of the reconstruction. Up to 25% reduction in the significance was seen in the dilepton sample. For lepton + jets which uses the constrained fit the reduction was only 5% even though it has one more jet in the final state.

## 7 Conclusions

The large sample of \(t\bar{t}\) events soon available in ATLAS has been simulated and analyzed in the context of sensitivity to new \(CP\) violating sources in the \(gt\bar{t}\) production vertex. Using the effective theory approach the level of \(CP\) violation is parametrized in terms of the chromo-electric dipole moment. The 5\(\sigma\) reach in sensitivity for the real part of the CEDM parameter3\(D_{5}\) after one year at low luminosity is estimated to be

Footnote 3: \(d_{t}=0.1\) implies \(D_{5}=\frac{d_{t}}{m_{t}}\times\mbox{GeV}^{-1}g_{s}=\frac{0.1}{175}\times 1 97\times 10^{-14}\mbox{cm}g_{s}=1.1\times 10^{-17}\mbox{cm}g_{s}\).

\begin{table}
\begin{tabular}{l r r r r r} \hline Data & \(A_{1}\) & \(T_{2}\) & \(Q_{2}\) & \(f_{2}\,(b)\) & \(f_{2}\,(t)\) \\ \hline Parton (mean) & 0.0 & 9.5 & 13 & 16 & 22 \\ Parton (count) & & 6.7 & 8.3 & 7.6 & 11 \\ Detector(mean) & 0.2 & 5.1 & 4.2 & 6.7(9.6) & 5.9 \\ Detector(count) & & 2.3 & 2.1 & 3.2 & 2.9 \\ \hline \end{tabular}
\end{table}
Table 3: Significance for different asymmetries in the case of 1M lepton + jets events with \(d_{t}=0.2\). The (mean) refers to significance = mean/(RMS\(\sqrt{\mbox{events}}\)) and (count) refers to the significance given by the difference in the number of positive and negative asymmetry values. The number within parenthesis is when only the least energetic jet in the top rest frame is used for the d-quark. The \(T_{N}\)-even asymmetry \(A_{1}\) is unaffected since \(d_{t}\) has no imaginary part.

[MISSING_PAGE_FAIL:16]

The samples of dileptons and lepton + jets are independently capable of achieving this sensitivity. The condition is however that the CMDM parameter \(c_{t}\) is small. An example of an independent and efficient handle on the \(c_{t}\) parameter is the lepton \(p_{t}\) spectrum. The current experimental limit on \(D_{5}\) is from the top pair production at the Tevatron. The limit is according to reference [15]

\[D_{5}<{\cal O}(100)\times 10^{-18}{\rm cm}g_{s}.\]

It is also interesting to compare the ATLAS result with the limit from an explicit model calculation. For example, reference [7] estimates \(D_{5}\simeq 0.1\times 10^{-18}{\rm cm}g_{s}\) in the case of multiple Higgs doublet models.

## Acknowledgments

This work has been performed within the ATLAS Collaboration, and I thank collaboration members for helpful discussions. I have made use of the physics analysis framework and tools which are the result of collaboration-wide efforts. I would also like to thank Per Osland, Wafaa Kater, P.N. Pandita and Bohdan Grzadkovski for many interesting discussions on \(CP\) violation. Part of this work was supported by the NorFa Nordic LHC Network and The Royal Academy of Sciences.

Figure 7: Transverse lepton momentum spectra. The tail of the spectrum is very sensitive to \(CP\)-even effects in the \(gt\overline{t}\) vertex. The (-0.6,0.2) point of no sensitivity for \(CP\) violation can clearly be ruled out by this simple measurement. Also the small effects of quadratic \(d_{t}\) terms in (0,0.2) is seen.

An Exact solution to dilepton events

The dilepton final state has two unknown neutrino momenta. This problem is stated already in [7] and has a twofold or fourfold ambiguity due to the fact that the solution is given by a quartic equation. The hand written exact analytical solution is straight forward from the constraints

\[f_{1} = (p_{\nu}+p_{e}\,^{+})^{2}-m_{W}^{2}=0 \tag{7}\] \[f_{2} = (p_{\nu}+p_{e}\,-)^{2}-m_{W}^{2}=0\] (8) \[f_{3} = (p_{\nu}+p_{e}\,+p_{b})^{2}-m_{t}^{2}=0\] (9) \[f_{4} = (p_{\nu}+p_{e}\,-+p_{b})^{2}-m_{t}^{2}=0\] (10) \[f_{5} = p_{\nu_{x}}-E_{T}{}_{x}=0\] (11) \[f_{6} = p_{\nu_{y}}-E_{T}{}_{y}=0 \tag{12}\]

though it covers six pages of calculations. Given a solver for quartic equations the final code is hundred lines of Fortran. Both the analytical solution and the code is available from the author by request. Yet another compact solution can be found in Appendix B in [11].

Since on an event to event basis the \(E_{T}\) and the resonance masses are not well known, the problem is ill conditioned. If real solutions are not found, the one with the smallest imaginary part was chosen. This was found to be somewhat wore robust then the point where the quartic equation is closest to zero.

## Appendix B A 3C fit to single lepton + jets events

The event \(t\bar{t}\to\mbox{lepton + jets}\) can be fully reconstructed with a 3C constrained fit. The constraints are

\[f_{1} = (p_{\nu}+p_{e})^{2}-m_{W}^{2}=0 \tag{13}\] \[f_{2} = (p_{d}+p_{u})^{2}-m_{W}^{2}=0\] (14) \[f_{3} = (p_{\nu}+p_{e}+p_{b})^{2}-m_{t}^{2}=0\] (15) \[f_{4} = (p_{d}+p_{u}+p_{\bar{b}})^{2}-m_{t}^{2}=0\] (16) \[f_{5} = p_{\nu_{x}}-E_{T}{}_{x}=0\] (17) \[f_{6} = p_{\nu_{y}}-E_{T}{}_{y}=0 \tag{18}\]

The variables are split into \(\mbox{unknown}(\xi)\), \(\mbox{measured}\,(y)\) and improved measured \((\eta)\) quantities

\[\xi = \{\vec{p}_{\nu}\} \tag{19}\] \[y = \{\vec{p}_{e},\vec{p}_{d},\vec{p}_{b},\vec{p}_{b},\vec{p}_{u},m_{ W_{1}},m_{W_{2}},m_{t_{1}},m_{t_{2}},\vec{E}_{T}\} \tag{20}\]

All particles except \(b\)-quarks, \(t\)-quarks and \(W\)'s are assumed to be massless. Please note that the resonance masses are formulated as measured quantities with associated errors. The solution to the general non linear constrained least-squares problem follows that of [30] and is formulated as

\[\min\chi^{2}(\eta,\xi,\lambda) = (y-\eta)^{T}V^{-1}(y)(y-\eta)+2\lambda^{T}f(\eta,\xi) \tag{21}\]

where V(y) is the covariance matrix with values taken from [26] and \(\lambda\) are the Lagrangian multipliers. The derivatives of \(\chi^{2}(\eta,\xi,\lambda)\) are set to zero and \(f(\eta,\xi)\) is Taylor expanded. The method then iterates from the starting guess \(\eta=y\) and \(\xi=\{\vec{F}_{T},\vec{p}_{\nu_{z}}\}\) until either a convergent or divergent behavior is found. The starting guess \(\vec{p}_{\nu_{z}}\) is solved from the constraints \(f_{i}\). Convergence is defined as \(\big{|}\chi_{n+1}^{2}-\chi_{n}^{2}\big{|}<0.5\), \(\sum_{i}|f_{i}|<0.1\) and iterations\(<30\). Each iteration is solved in steps

\[\xi^{n+1} = \xi^{n}-V(\xi)F_{\xi}^{T}S^{-1}r \tag{22}\] \[\lambda^{n+1} = S^{-1}\left[r+F_{\xi}(\xi^{n+1}-\xi^{n})\right]\] (23) \[\eta^{n+1} = y-VF_{\eta}^{T}\lambda^{n+1} \tag{24}\]

where

\[r = f^{n}+F_{\eta}^{n}(y-\eta^{n}\,)\quad(1\times\,6) \tag{25}\] \[S = F_{\eta}^{n}V(y)(F_{\eta}^{T})^{n}\quad\,(6\times\,6)\] (26) \[V(\xi) = (F_{\xi}^{T}S^{-1}F_{\xi})^{-1}\quad\,(3\times\,3)\] (27) \[(F_{\eta})_{ij} = \frac{\partial f_{i}}{\partial\eta_{j}}\quad(21\times\,6)\] (28) \[(F_{\xi})_{ij} = \frac{\partial f_{i}}{\partial\xi_{j}}\quad(3\times\,6) \tag{29}\]

The matrix equation is solved with the Fortran matrix routines in CERNLIB [31] using double precision. For numerical stability all \(f_{i}\) had to be rescaled, i.e. \(f_{i}^{t}=0.01\,f_{i}\). Also in (22) the matrices should be evaluated before applied to the vector \(r\).

### Performance

In order to verify the method a set of potentially good candidate events were pre-selected. All momenta were required to be isolated such that a cone of radii 0.4 could be applied to all particles without overlap. Also the default acceptance of the ATLAS detector was applied. The errors on \(\mbox{$\,\hbox to 0.0pt{\kern 2.5pt/}\kern-0.5pt{\lower 2.5pt\hbox{$ \sim$}}\,$}T\) were cut at 5 GeV, the same cut was applied to the resonance masses. All these cuts were made at the parton level of the MC generator [19]. The events were then passed through fast detector simulation for proper smearing. No initial or final state radiation were enabled, not even fragmentation of the quarks. This provided a good set of true parton level information and the corresponding measured quantities. The unmeasured z-component of the neutrino momentum before and after the fit is shown in Figure 8. The corresponding \(\chi^{2}\) probability is shown in Figure 9.

The main limitation of the fit is that all the constraints are based on quantities that are more or less non Gaussian. The \(\mbox{$\,\hbox to 0.0pt{\kern 2.5pt/}\kern-0.5pt{\lower 2.5pt\hbox{$ \sim$}}\,$}T\) has large tails and the resonance masses are distributed according to Breit-WiegnerFigure 9: \(\chi^{2}\) probability distribution for the 3C fit using preselected high quality events. Errors according to design specifications and PDG [32].

## References

* [1] J. H. Christenson, J. W. Cronin, V. L. Fitch and R. Turlay, Phys. Rev. Lett. **13**, 138 (1964).
* [2] B. Aubert et al. [Babar Collaboration], Phys. Rev. Lett. **87**, 091801 (2001).,
* [3] K. Abe et al. [Belle Collaboration], Phys. Rev. Lett. **87**, 091802 (2001).
* [4] M. Kobayashi, and T. Maskawa, Prog. Theor. Phys. **49** 652 (1973).
* [5] G. 't Hooft, Phys. Rev. Lett. **37** (1976) 8.
* [6] V. Baluni, Phys. Rev. D **19** (1979) 2227.
* [7] A. Soni and R. M. Xu, Phys. Rev. Lett. **69** (1992) 33.
* [8] C. R. Schmidt, Phys. Lett. B **293** (1992) 111.
* [9] J. Wudka, A short course in effective Lagrangians, hep-ph/00022180.
* [10] D. Atwood et al, \(CP\) violation in Top Physics, hep-ph/0006032
* [11] Phys. Rev. D **58** (1998) 114002.
* [12] Jin Min Yang and Bing-Lin Young, Phys. Rev. D **56** (1997) 467.
* [13] Jin Min Yang and Bing-Lin Young, Phys. Rev. D **56** (1997) 5907.
* [14] B. Grzadkowski, Talk at the Fourth Nordic LHC Physics Workshop, Stockholm 22-24 November 2001.
* [15] P. Haberl, O. Nachtmann and A. Wilch, Phys. Rev. D **53** (1996) 4875.
* [16] G. J. Gounaris, D. T. Papadamou and F. M. Renard, Z. Phys. C **76** (1997) 333
* [17] J. Sjolin, TOPSPIN, ATL-PHYS-2002-011.
* [18] H. Murayama, I. Watanabe and K. Hagiwara, KEK-91-11.
* [19] T. Sjostrand, PYTHIA 5.7 and JETSET 7.4, Computer Physics Common. **82**, 1994. Program version 6.157.
* [20] A. Pukhov _et al._, arXiv:hep-ph/9908288.
* [21] R. Bonciani et al, NLL Resummation of the Heavy-Quark Hadroproduction Cross-Section, Nucl.Phys. **B529** (1998) 424-450.
* [22] H. Plothow-Besch, PDFLIB 8.04, CERN-ETT/TT
* [23] D. Atwood, A. Aeppli and A. Soni, Phys. Rev. Lett. **69** (1992) 2754.

* [24] D. Atwood et al, Phys. Rev. D **45** (1992) 2405.
* [25] W. Bernreuther and A. Brandenburg, Phys. Rev. D **49** (1994) 4481.
* [26] ATLAS Detector and Physics Performance TDR, CERN/LHCC/99-14.
* [27] E. Richter-Was, D. Froidevaux, L. Poggioli, ATL-PHYS-98-131 (1998).
* [28] G. Mahlon and S. Parke, Phys. Rev. D **53** (1996) 4886. Nucl. Instrum. Meth. A **389** (1997) 299.
* [29] W. Bernreuther et al, hep-ph/9812387.
* [30] A. G. Frodesen et al., Probability and Statistics in Particle Physics, ISBN 82-00-01906-3.
* [31] CERNLIB, CERN Program Library, [http://cern.ch/cernlib](http://cern.ch/cernlib).
* [32] D. E. Groom et al., The European Physical Journal **C15** (2000).