# Formulae for Estimating Significance

The ATLAS Collaboration

###### Abstract

This note compares several methods for estimating significance of an observation of a number of events given a predicted rate with some uncertainty. A recommendation is made for the nominal formula to use in the absence of any strong justification for choosing an alternative.

26th September 2020

## 1 Introduction

The need for a simple formula for calculating the significance of an event count with respect to a prediction - with or without uncertainty - is anticipated in a number of areas of physics analysis:

* Data-vs-prediction plots are sometimes augmented with auxiliary significance plots to show the bin-by-bin significance.
* Event selections may be optimized with respect to an expected significance, where the mean event count is assumed to be \(\langle n\rangle=s+b\) and where \(s\) is the mean expected signal count and \(b\) is the mean expected background count, possibly with an uncertainty \(\sigma\); hence \(\langle n\rangle=b\) for the background-only hypothesis.

A recommendation for calculating the significance for the background-only hypothesis is first presented in section 2. Following a definition of significance from \(p\)-values in section 3, section 4 surveys a few methods to calculate the significance for the background-only hypothesis, and compares results for various choices of \(n\), \(b\) and \(\sigma\). The recommended formula is selected in section 5 by comparing results with significances obtained from toy data. Low \(n\) count cases are studied in section 6.

## 2 Recommendation

The recommended formula to use for estimating significance \(Z\) of observing \(n\) events given a prediction of \(b\pm\sigma\) events is:

\[Z=\begin{cases}+\sqrt{2\left(n\ln\left[\frac{n(b+\sigma^{2})}{b^{2}+n\sigma^{ 2}}\right]-\frac{b^{2}}{\sigma^{2}}\ln\left[1+\frac{\sigma^{2}(n-b)}{b(b+ \sigma^{2})}\right]\right)}&\text{if $n\geqslant b$}\\ -\sqrt{2\left(n\ln\left[\frac{n(b+\sigma^{2})}{b^{2}+n\sigma^{2}}\right]- \frac{b^{2}}{\sigma^{2}}\ln\left[1+\frac{\sigma^{2}(n-b)}{b(b+\sigma^{2})} \right]\right)}&\text{if $n<b$.}\end{cases} \tag{1}\]

In the case of \(n\geqslant b\), this formula corresponds to equation 25 in [1]. In the case of vanishing uncertainty (\(\sigma=0\)) this formula reduces to:

\[Z=\begin{cases}+\sqrt{2\left(n\ln\left[\frac{n}{b}\right]-(n-b)\right)}& \text{if $n\geqslant b$}\\ -\sqrt{2\left(n\ln\left[\frac{n}{b}\right]-(n-b)\right)}&\text{if $n<b$.}\end{cases} \tag{2}\]

The origin of this formula is discussed section 4, and is consistent with a Poisson-counting likelihood where the background rate nuisance parameter is constrained by an auxiliary Poisson measurement. The formula derives from use of the asymptotic formulae for the distributions of profile likelihood test statistics. It reproduces well the significance calculated through a toy (frequentist) approach for a corresponding model, as shown in Fig. 6. Similarly to the use of these asymptotic formulae for the derivation of limits, this formula is found to slightly overestimate the magnitude of the true significance in the case of very low event counts (fewer than 2 events), as seen in Fig. 7.

Code implementations of the recommended formula and other formulae studied in this note is publicly available from details given in appendix C.

## 3 Defining significances from p-values

Consider the observation of \(n\) events with the probability \(P(n)\) such that \(\sum_{n=0}^{\infty}P(n)=1\). The background-only hypothesis predicts the expected number of events to be \(b=\langle n\rangle\). Compared to a prediction, the \(p\)-value \(p_{e}\) suitable for an excess and the \(p\)-value \(p_{d}\) suitable for a deficit are given by

\[p_{e}(n) =\sum_{j=n}^{\infty}P(j) \text{($p$-value suitable for excess)} \tag{3}\] \[p_{d}(n) =\sum_{j=0}^{n}P(j)=1-\sum_{j=n+1}^{\infty}P(j). \text{($p$-value suitable for deficit)} \tag{4}\]

Note that \(p_{e}(n)+p_{d}(n)=1+P(n)>1\).

The related significances are obtained as usual by specifying the corresponding number of standard deviations in a one-tailed test of a Gaussian variate. In order to obtain a negative significance for a large deficit, we choose

\[Z_{d} =\Phi^{-1}(p_{d}) Z_{e} =\Phi^{-1}(1-p_{e})\, \tag{5}\]

where

\[\Phi(Z)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{Z}dt\ e^{-t^{2}/2}. \tag{6}\]

We therefore have \(p_{e}=1/2\iff Z_{e}=0\), and \(p_{d}=1/2\iff Z_{d}=0\).

In the limit of large \(n\), or when the \(p\)-value is defined using an asymptotic test statistic, \(p_{e}(n)+p_{d}(n)=1\) and therefore \(Z_{e}\) and \(Z_{d}\) are the same, and \(\langle n\rangle\) is equal to the median of \(n\), \(\text{Med}(n)\). In such cases, including the significance formula recommended in this note, we have the intuitive outcome that \(Z>0\) for \(n>b\) and \(Z<0\) for \(n<b\). The rest of this section is therefore not relevant for this recommendation.

But in general, for display purposes, a prescription is necessary in order to define the significance \(Z\) in terms of \(Z_{e}\) and \(Z_{d}\). Strictly speaking \(p_{e}\) and \(p_{d}\), and hence \(Z_{e}\) and \(Z_{d}\), cannot be defined at the same time as they belong to different classes of outcomes. But for display purposes, it is desirable in practice to have one significance \(Z\) encapsulating the significance of an event count given a background estimate and its uncertainty, such that \(Z\) is negative for a deficit and positive for an excess - this is what is usually needed when plotting the bin-by-bin significance of a data-vs-prediction histogram.

### Significance prescriptions

The median of \(n\), \(\text{Med}(n)\), is defined [2][3] as the least integer \(n\) such that \(\sum_{j=0}^{n}P(j)\geqslant\frac{1}{2}\). From equations 3 and 4, we therefore obtain1

Footnote 1: We are assuming that \(P(n)\) does not have any interval of \(n\) for which \(P(n)=0\) such that \(P(n)>0\) on both sides of the interval.

\[p_{e}\ (\text{Med}(n))>\frac{1}{2}\quad\text{and}\quad p_{d}\ (\text{Med}(n)) \geqslant\frac{1}{2} \tag{7}\]and the special cases \(p_{e}(n)=\frac{1}{2}\implies n=\operatorname{Med}(n)+1\) and \(p_{d}(n)=\frac{1}{2}\implies n=\operatorname{Med}(n)\). When \(\operatorname{Med}(n)\) is sufficiently different from \(\langle n\rangle\), cases may occur for which \(Z<0\) for \(n>b\) or \(Z>0\) for \(n<b\). Since the expressions "excess" and "deficit" refer to comparing \(n\) to \(\langle n\rangle\) instead of to \(\operatorname{Med}(n)\), one can have \(Z<0\) for an "excess" or \(Z>0\) for a "deficit"; such cases are counter-intuitive but expected since the median should really be considered in defining excess or deficit in the context of a significance. Following equation 7, it is therefore desirable to define \(Z\) in terms of \(Z_{e}\) and \(Z_{d}\) such that

\[Z=0\ \iff\ b\text{ such that }n=\operatorname{Med}(n)\ \text{ or }\ p_{e}(n)=\frac{1}{2}\ \text{ or }\ p_{d}(n)=\frac{1}{2}. \tag{8}\]

Note that the term \(p_{d}(n)=1/2\) is redundant since it is included in the term \(n=\operatorname{Med}(n)\) by virtue of the median definition.

Three different prescriptions are described here, with our recommendation being to use Prescription 3 for display purposes where a prescription is necessary.

**Prescription 1**

\[Z=\begin{cases}Z_{e}&\text{if }n\geqslant b\\ Z_{d}&\text{if }n<b\.\end{cases} \tag{9}\]

Since this prescription ignores \(\operatorname{Med}(n)\), the condition 8 is not satisfied. Cases do occur where \(Z<0\) for \(n>b\) or where \(Z>0\) for \(n<b\). The behaviour of this prescription as a function of \(b\) is illustrated in Fig. 1 as a blue line. Note that in general with this prescription \(Z\) is a discontinuous function of \(b\) at \(b=n\); furthermore the discontinuity is such that \(Z\)_increases_ as \(b\) increases.

**Prescription 2**

\[Z=\begin{cases}Z_{e}&\text{if }n\geqslant b\text{ and }Z_{e}>0\\ Z_{d}&\text{if }n<b\text{ and }Z_{d}<0\\ 0&\text{otherwise.}\end{cases} \tag{10}\]

This is the prescription proposed for display purposes in [4] section 2.4. With this prescription, in some cases \(Z\) is a discontinuous function of \(b\) at \(b=n\); such a case is illustrated in Fig. 1 (green line). By definition, cases where \(Z<0\) for \(n>b\) or where \(Z>0\) for \(n<b\) cannot occur. Since this prescription ignores \(\operatorname{Med}(n)\), the condition 8 is not satisfied.

**Prescription 3**

\[Z=\begin{cases}Z_{e}&\text{if }Z_{e}>0\text{ and }Z_{d}>0\\ Z_{d}&\text{if }Z_{e}<0\text{ and }Z_{d}<0\\ 0&\text{otherwise.}\end{cases} \tag{11}\]

Since \(p_{e}\geqslant 1-p_{d}\), we have \(Z_{e}\leqslant Z_{d}\). Therefore with this prescription \(Z\) is always a continuous function of \(b\) for all \(n\). From equation 7, Prescription 3 ensures that the condition 8 is fulfilled, by definition. Cases do occur where \(Z<0\) for \(n>b\) or where \(Z>0\) for \(n<b\), but as previously noted this is not an issue. An example of a case where \(Z>0\) for \(n<b\) is illustrated in Fig. 1 (magenta line). This counter-intuitive result is due to the fact that the observed number of events \(n=12\) is not included in the range of \(b\) values for which \(\operatorname{Med}(n)=n=12\). In Fig. 1 \(\operatorname{Med}(n)\) is shown in orange with the values given on the right vertical axis; note that \(\text{Med}(n)=n=12\implies Z=0\) for Prescription 3. For the Poisson-Gamma model this occurs when \(\sigma\geqslant\sqrt{b}\) (see section 4.8 and appendix B), while this never occurs for the Poisson model without uncertainty (see section 4.3).

Note that for scenarios where \(n>b\implies Z_{e}>0\) and \(n<b\implies Z_{d}<0\) Prescription 3 is identical to Prescription 2. In these cases the range of \(b\) values for which \(\text{Med}(n)=n\) includes the observed number of events \(n\). Fig. 1 illustrates an unusual case where all three prescriptions behave differently.

### Significance distributions

When the \(p\)-value is continuous between 0 and 1, as is the case in the limit of large \(n\) or when the \(p\)-value is defined using an asymptotic test statistic, equations 5 and 6 ensure that as \(n\) fluctuates the significance will follow a Gaussian distribution of 0 mean and unit standard deviation, \(N(0,1)\). In this case, as already mentioned, \(Z_{e}\) and \(Z_{d}\) are the same and the significance prescription is irrelevant.

When the \(p\)-value is a discrete variable, as is the case in general when observing a number of events \(n\), the significance distribution will depart from \(N(0,1)\), for any prescription. In this case, the choice of the prescription will affect the signifiance distribution, but without affecting which prescription is to be favoured.

Examples of significance distributions are given in appendix A.

Figure 1: Significance as a function of the expected background \(b=\langle n\rangle\) for a Poisson-Gamma Bayesian treatment (see section 4.8) for the case of an observed number of events of \(n=12\) with a \(50\%\) relative uncertainty on \(b\). The behaviour of the three prescriptions for converting \(Z_{e}\) and \(Z_{d}\) into a final significance value \(Z\) are shown. \(\text{Med}(n)\) is shown in orange with the values given on the right vertical axis. Prescription 3 is the only prescription that has \(Z=0\) when \(n=\text{Med}(n)\) (equation 8) _and_\(Z>0\) when \(n>\text{Med}(n)\), which occurs for \(b\lesssim 12.7\).

## 4 Comparison of different formulae

Where necessary, figures in this section will use Prescription 3 for the definition of significance \(Z\) in terms of \(Z_{d}\) and \(Z_{e}\).

### Gaussian approximation without uncertainty

Equation 12 comes from using the Gaussian approximation for the Poisson distribution of \(n\) events given a background rate of \(b\). Under this approximation, the significance is simply given as:

\[Z=\frac{n-b}{\sqrt{b}}. \tag{12}\]

This formula cannot account for uncertainty of the background rate \(b\). The behaviour of this formula as a function of \(b\) for four different choices of \(n\) is shown in orange in Figs. 2 and 3, and onwards.

### Gaussian approximation with uncertainty

A simplistic way to introduce uncertainty into this approximation is to assume that the background distribution is approximated by the combination of a Gaussian with mean \(b\) and variance \(b\), and another Gaussian with mean \(0\) and variance \(\sigma^{2}\). Conceptually, you might say that the background event count would be a random variable that is the sum of two random variables drawn from these Gaussians. This new variable will be Gaussian distributed with mean \(b\) and variance of \(b+\sigma^{2}\), leading to the following formula for the significance:

\[Z=\frac{n-b}{\sqrt{b+\sigma^{2}}}. \tag{13}\]

This formula is shown in yellow in Figs. 2 and 3, and onwards.

### Poisson model without uncertainty

Consider the observation of \(n\) events given a prediction of exactly \(b=\langle n\rangle\) events, with the probability of observing \(n\) events given by the Poisson distribution

\[P(n|b)=\frac{b^{n}}{n!}e^{-b}. \tag{14}\]

\(p\)-values suitable for excess or deficit are respectively given by

\[p_{e}(n|b) =\sum_{j=n}^{\infty}P(j|b)=F_{\chi^{2}}(2b,2n)\, \tag{15}\] \[p_{d}(n|b) =\sum_{j=0}^{n}P(j|b)=1-\sum_{j=n+1}^{\infty}P(j|b)=1-F_{\chi^{2} }(2b,2(n+1))\, \tag{16}\]where \(F_{\chi^{2}}\) is the cumulative chi-square distribution (see page 167 of [5]). The significance of the observed \(n\) is obtained as described in section 3. Figs. 2 and 3 illustrate a few cases (in blue) for this formula. As for the Gaussian approximation formula, this expression for significance does not account for uncertainty on \(b\). With the bounds on \(\mathrm{Med}(n)\) given [2] by \(b-\ln 2\leqslant\mathrm{Med}(n)<b+1/3\), the range of \(b\) such that \(\mathrm{Med}(n)=n\) is \(n-1/3<b\leqslant n+\ln 2\). Therefore the range of \(b\) values such that \(\mathrm{Med}(n)=n\) always includes the observed \(n\), ensuring that the significance Prescriptions 2 and 3 are equivalent.

The \(p\)-values calculation can be reformulated using a likelihood ratio. Consider the likelihood function \(L(s)=P(n|s+b)\) where \(s+b\) is the prediction of the number of signal plus background events. The case \(s=0\) corresponds to the background-only hypothesis. The likelihood is maximized for \(\hat{s}=n-b\), and the likelihood ratio \(0\leqslant\lambda(s)\equiv L(s)/L(\hat{s})\leqslant 1\) becomes \(\lambda(0)=(b/n)^{n}e^{(n-b)}\) for the background-only hypothesis. We then consider the uncapped test statistic

\[q_{\circ}=\begin{cases}-2\ln\lambda(0)&\hat{s}\geqslant 0\\ +2\ln\lambda(0)&\hat{s}<0\end{cases}. \tag{17}\]

The \(p\)-value for the background-only hypothesis suitable for an excess (deficit) is the probability that \(q_{\circ}\) is greater or equal than (is less or equal than) the observed \(q_{\circ}\). Since \(q_{\circ}\) increases with \(n\), the \(p\)-values are equivalent to the ones obtained in equations 15 and 16.

For a sufficiently large \(n\), Wilks' theorem can be used. This gives

\[Z=\begin{cases}+\sqrt{-2\ln\lambda(0)}&n\geqslant b\\ -\sqrt{-2\ln\lambda(0)}&n<b\end{cases}, \tag{18}\]

which results in equation 2, the zero-uncertainty case of the formula that is described in section 4.4. This asymptotic result can be written as

\[Z=\frac{n-b}{\sqrt{b}}\left[1+O\left(\frac{n-b}{b}\right)\right]\;, \tag{19}\]

and reduces to the Gaussian approximation for \(\left|\frac{n-b}{b}\right|\ll 1\).

### Poisson-Poisson model with asymptotic formulae

This formula comes from applying the likelihood ratio treatment described in the previous section to a likelihood function corresponding to a product of Poisson distributions. The motivation for this likelihood is that the nuisance parameter representing the true-but-unknown background rate \(b\) is constrained by an auxiliary measurement \(m\). While in many real-life cases no such auxiliary measurement is made, uncertainties are usually incorporated into LHC statistical analyses in this fashion. The transfer-factor \(\tau\) relating the event rates in the two regions is a function of the background \(b\) and its uncertainty \(\sigma\) through \(\tau=b/\sigma^{2}\) (see equation 8 in [1]) and the full likelihood is expressed as:

\[L(s)=P(n|s+b)P(m|\tau b). \tag{20}\]

For the purpose of computing significance, the _"observed"_ value of \(m\) is taken to be \(\tau b\). Note that this is not required to be an integer, and so the second Poisson distribution given here is actually the continuation of the discrete case, implemented using gamma functions.2 The likelihood is maximized for \(\hat{s}=n-m/\tau\), \(\hat{b}=m/\tau\). For the background-only hypothesis, the maximum likelihood is for \(\hat{\hat{b}}=(n+m)/(1+\tau)\). The profile likelihood ratio \(0\leqslant\lambda(s,b)\equiv L(s,b)/L(\hat{s},\hat{b})\leqslant 1\) becomes for the background-only hypothesis

Footnote 2: This is, in fact, exactly how ROOT’s TMath::Poisson method is implemented.

\[\lambda(0)\equiv\frac{L(0,\hat{\hat{b}})}{L(\hat{s},\hat{b})}=\left(\frac{n+m}{ 1+\tau}\right)^{n+m}\frac{\tau^{m}}{n^{n}m^{m}}. \tag{21}\]

Using the uncapped test statistic of equation 17 and Wilk's approximation for the test statistic distribution yields

\[Z=\begin{cases}+\sqrt{-2\ln\lambda(0)}&\tau n\geqslant m\\ -\sqrt{-2\ln\lambda(0)}&\tau n<m\,\end{cases} \tag{22}\]

which, setting \(m=\tau b\), yields equation 1, repeated here:

\[Z=\begin{cases}+\sqrt{2\left(n\ln\left[\frac{n(b+\sigma^{2})}{b^{2}+n\sigma^{ 2}}\right]-\frac{b^{2}}{\sigma^{2}}\ln\left[1+\frac{\sigma^{2}(n-b)}{b(b+ \sigma^{2})}\right]\right)}&\text{if $n\geqslant b$}\\ -\sqrt{2\left(n\ln\left[\frac{n(b+\sigma^{2})}{b^{2}+n\sigma^{2}}\right]- \frac{b^{2}}{\sigma^{2}}\ln\left[1+\frac{\sigma^{2}(n-b)}{b(b+\sigma^{2})} \right]\right)}&\text{if $n<b$.}\end{cases} \tag{23}\]

This formula is shown in red in Figs. 2 and 3, and onwards. In the case of \(n\geqslant b\), this formula corresponds to equation 25 in [1].

### Poisson-Gaussian model with asymptotic formulae

An alternative to the formula given in the previous section comes from repeating the likelihood ratio treatment to a model consisting of a Poisson and a Gaussian, i.e.:

\[L(s)=P(n|s+b)G(m|b,\sigma), \tag{24}\]

where \(G\) is the Gaussian formula and \(m\) is taken to be equal to the nominal prediction for \(b\). The resulting expression for \(Z\) is given by:

\[Z=\begin{cases}+\sqrt{2\left(n\ln\left[\frac{n}{\hat{b}}\right]+\hat{\hat{b}} -n+\frac{(b-\hat{\hat{b}})^{2}}{2\sigma^{2}}\right)}&\text{if $n\geqslant b$}\\ -\sqrt{2\left(n\ln\left[\frac{n}{\hat{b}}\right]+\hat{\hat{b}}-n+\frac{(b- \hat{\hat{b}})^{2}}{2\sigma^{2}}\right)}&\text{if $n<b$,}\end{cases} \tag{25}\]

where the conditional maximum likelihood estimate of \(b\) is given by:

\[\hat{\hat{b}}=\frac{1}{2}\left(b-\sigma^{2}+\sqrt{(b-\sigma^{2})^{2}+4n\sigma ^{2}}\right). \tag{26}\]The formula yields similar results to the formula of the previous section, but can exhibit non-negligible differences in extreme cases. Under situations where the background estimate is strongly believed to be Gaussian rather than Poisson constrained, this particular formula may be preferable to the one given in the previous section.

Examples of this formula as a function of the background \(b\) are shown in green in Figs. 4 and 5.

### Poisson-Binomial model

Another formula can be obtained by starting from the Poisson-Poisson model but converting this into a model consisting of a Poisson and a Binominal. Under this scenario, \(n+m\) (the total number of "events") is a fixed quantity (i.e. \(m\) and \(n\) do not fluctuate independently). Further discussion of this model can be found in [1]. This type of model is not consistent with the usual type of model built for LHC statistical analysis, but is included here because the RooStats software provides a built-in method for computing the significance for such a model: RooStats::NumberCountingUtils::BinomialObsZ.

Figure 2: Different formulae for significance, shown as a function of the expected background \(b=\langle n\rangle\), for different choices of the number of observed events \(n\) and the relative uncertainty on the background \(\sigma/b\). The Gaussian approximation (orange) and Poisson (blue) formulae do not depend on the relative uncertainty. Where necessary, Prescription 3 from section 3 has been used.

The implementation of the Poisson-Binomial model in RooStats yields the \(p\)-value \(p_{e}\) as described in section 3:

\[p_{e}(n,m|b,\sigma)=\sum_{i=n}^{n+m}B\left(i|n+m;\rho=\frac{\sigma^{2}}{\sigma^{2 }+b}\right)=I_{\frac{\sigma^{2}}{\sigma^{2}+b}}\left(n,1+\frac{b^{2}}{\sigma^{2 }}\right)\,, \tag{27}\]

where \(B\) is the binomial distribution for an observation of \(i\) passing events from a sample of \(n+m\) events, assuming a pass rate of \(\rho\), and where \(I\) is the regularized incomplete beta function

\[I_{x}(a,b)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\int_{0}^{x}dt\,t^{a-1}(1-t) ^{b-1}\,, \tag{28}\]

with \(I_{1}(a,b)=1\). The significance obtained from this model is shown in grey in Figs. 4 and 5 (on the left-side of each plot of Fig. 4 the grey line is obscured by the black line, and on the right-side of each plot of Fig. 5 the grey squares are obscured by black squares, where black corresponds to the formula described by the following section). For reasons discussed in the next section, this function should not be used directly as an expression for significances of deficits.

Figure 3: Different formulae for significance, shown as a function of the number of observed events \(n\), for different choices of the expected background \(b=\langle n\rangle\) and its relative uncertainty \(\sigma/b\). The Gaussian approximation (orange) and Poisson (blue) formulae do not depend on the relative uncertainty. Where necessary, Prescription 3 from section 3 has been used.

### Modified Poisson-Binomial model

The modification introduced in this section is to correctly compute \(p_{d}\) as:

\[p_{d}(n,m|b,\sigma)=1-\sum_{i=n+1}^{n+m}B\left(i|n+m;\rho=\frac{ \sigma^{2}}{\sigma^{2}+b}\right)=1-I_{\frac{\sigma^{2}}{\sigma^{2}+b}}\left(n+1,\frac{b^{2}}{\sigma^{2}}\right)\,, \tag{29}\]

and, using this \(p_{d}\) and \(p_{e}\) from equation 27, a significance can be obtained from one of the prescriptions described in section 3. The behaviour of this formula, using the recommended Prescription 3, is shown in black in Figs. 4 and 5. Since \(p_{d}\) is identical to that of the Poisson-Gamma mixture (section 4.8), the black line or squares are covered by magenta line or squares. An improved behaviour is recovered with this modification, although the absolute significances estimated with this formula, as will be seen later, are underestimates of the true significance. Note that the upper limit of the sum in equation 29 depends on \(n\), yielding an increase of \(\text{Med}(n)\) with \(n\) for fixed \(b\) and \(\sigma\). As seen in Fig. 5, this results in more than one \(n\) for which \(Z=0\) for fixed \(b\) and \(\sigma\). For all other formulae \(\text{Med}(n)\) depends only on \(b\) and possibly \(\sigma\), so that at most only one \(n\) value can produce \(Z=0\).

### Poisson-Gamma mixture Bayesian formula

This final formula for significance is described in [4] and is based on a model consisting of a Poisson distribution for which the mean is assumed to be drawn from a Gamma distribution of mean \(b\) and variance \(\sigma^{2}\). The Poisson mean is marginalized over to obtain the Poisson-Gamma mixture, also known as negative binomial distribution, here parametrized in terms of \(b\) and \(\sigma\):

\[P(n|b,\sigma) =\int_{0}^{\infty}dx\;P(n|x)\;\text{Gamma}(x|\alpha,\beta)=\int_ {0}^{\infty}dx\;\left(\frac{x^{n}}{n!}e^{-x}\right)\left(\frac{\beta^{\alpha} }{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}\right) \tag{30}\] \[=\frac{\Gamma(n+\alpha)}{\Gamma(\alpha)n!}\frac{\beta^{\alpha}}{ (1+\beta)^{n+\alpha}}\,, \tag{31}\]

where

\[\alpha=\frac{b^{2}}{\sigma^{2}}\qquad\qquad\beta=\frac{b}{\sigma^{2}}\qquad \qquad\alpha,\,\beta,b,\sigma>0 \tag{32}\]

The resulting distribution has a mean of \(\alpha/\beta=b\) as desired, and a variance of \(\sigma^{2}+b\).

The cumulative distribution function of the negative binomial distribution can be expressed in terms of the regularized incomplete beta function given in equation 28. This yields

\[p_{e}(n) =\sum_{j=n}^{\infty}P(j|b,\sigma)=I_{\frac{\sigma^{2}}{\sigma^{2 }+b}}\left(n,\frac{b^{2}}{\sigma^{2}}\right) \tag{33}\] \[p_{d}(n) =\sum_{j=0}^{n}P(j|b,\sigma)=1-\sum_{j=n+1}^{\infty}P(j|b,\sigma) =1-I_{\frac{\sigma^{2}}{\sigma^{2}+b}}\left(n+1,\frac{b^{2}}{\sigma^{2}} \right)\,. \tag{34}\]As mentionned in [4], in practice one considers the sums with a finite number of terms (\(1-p_{e}\) or \(p_{d}\)) while taking advantage of the recurrence relation of the \(\Gamma\) function:

\[P(n|b,\sigma) =\frac{n-1+\alpha}{n(1+\beta)}P(n-1|b,\sigma) n\geqslant 1 \tag{35}\] \[P(0|b,\sigma) =\frac{\beta^{\alpha}}{(1+\beta)^{\alpha}}\,. \tag{36}\]

The behaviour of this formula is shown in magenta in Figs. 4 and 5. Note that \(p_{d}\) is identical to that of the modified binomial-Poisson model of the previous section, and hence so is the significance result for \(Z<0\).

From bounds on the median of the negative binomial distribution [3], it can be shown (see appendix B) that only for the condition \(\sigma\geqslant\sqrt{b}\) is the observed \(n\) not included in the range of \(b\) such that \(\text{Med}(n)=n\). Therefore for this condition Prescription 2 and Prescription 3 differ.

Figure 4: All the different formulae for significance covered in this note, as functions of the expected background \(b=\langle n\rangle\), for different choices of observed number of events \(n\) and background relative uncertainty \(\sigma/b\). Where necessary, Prescription 3 from section 3 has been used.

Figure 5: All the different formulae for significance covered in this note, as functions of the observed number of events \(n\), for different choices of the expected background \(b=\langle n\rangle\) and its relative uncertainty \(\sigma/b\). Where necessary, Prescription 3 from section 3 has been used.

## 5 Comparing the formulae with significance from toys

To test which of the formulae covered in section 4 best estimates the significance of an observation of \(n\) events under a prediction of \(b\pm\sigma\) background rate, toy data were generated from a model that describes this hypothesis. Two different models were studied: a Poisson-Poisson model (see section 4.4) and a Poisson-Gaussian model (see section 4.5). For each toy the uncapped profile likelihood ratio test statistic is computed. The tail integral of the distribution of this test statistic is used to give a toy-based significance. All toys are generated with the auxiliary measurements fluctuated about the conditional maximum likelihood estimator \(\hat{\hat{b}}\) (the _profile construction_).

In the Poisson-Poisson case, the auxiliary measurement \(m\) is allowed to take on non-integer values, which is consistent with the behaviour of models constructed through the HistFactory model-building tool [6] where a Poisson constraint term is used for a nuisance parameter. The likelihood ratio test statistic is always computed with the corresponding likelihood formula for the model that the toys were generated from.

The results of the toys are shown by the red (Poisson-Poisson) and green (Poisson-Gaussian) points in Fig. 6. The red and green curves correspondingly follow these points better than the other curves. This motivates the choice of the Poisson-Poisson formula as the preferred expression for calculating significance, and should be adequate for most scenarios. If it is known that the dominant uncertainty on the background is mainly Gaussian constrained then the Poisson-Gaussian formula can be used as an alternative, but in all but the most extreme cases (see section 6) it will give very similar results to Poisson-Poisson.

Figure 6: All the different formulae for significance covered in this note, as functions of the expected background \(b=\langle n\rangle\), for different choices of observed number of events \(n\) and background relative uncertainty \(\sigma/b\). Where necessary, Prescription 3 from section 3 has been used. The solid red and green points correspond to significances calculated from toys generated under the Poisson-Poisson and Poisson-Gaussian models respectively, using the uncapped profile likelihood test statistic.

## 6 Studies of low event count limiting case

In the extreme case of very low event counts (\(n=0\) and \(n=1\)) it is found that the recommended formulae for significance no longer match the significance obtained from toys. This is not in itself a surprising result, given that the recommended formulae are derived under the Wilk's approximation for the test statistic distribution, which is only valid in the large sample limit. As is seen in Fig. 7, the recommended formulae can slightly overestimate the magnitude of the significance when compared to significance from toys, however none of the other formulae agree well with the result from toys either. It is important to be aware of this behaviour of the formulae in these extreme cases but it should not be seen as a deterrent for their general usage. Fig. 8 shows \(\Delta Z=Z_{\rm rec}-Z_{\rm toys}\) where \(Z_{\rm rec}\) is the recommended significance given by equation 1 and \(Z_{\rm toys}\) is obtained from Poisson-Poisson model toys (see section 5) for two cases of \(\sigma/b\) and for the number of observed events \(n\) equal to 0, 1, 2 and 3.

It is possible to use numerical methods (summations) to obtain a function for significance that agrees with these toys, however the need for such accuracy is unlikely to arise in the use cases envisioned in section 1.

Figure 7: All the different formulae for significance covered in this note, as functions of the expected background \(b=\langle n\rangle\), for the number of observed events \(n\) equal to 0 (top row), 1 (middle row), and 2 (bottom row), and background relative uncertainty \(\sigma/b\) equal to 10% (left) and 50% (right). Where necessary, Prescription 3 from section 3 has been used. The solid red and green points correspond to significances calculated from toys generated under the Poisson-Poisson and Poisson-Gaussian models respectively, using the uncapped profile likelihood test statistic. On the left figures, the Poisson-Poisson results are hidden behind the Poisson-Gaussian results.

Figure 8: Difference between the recommended significance (equation 1) and the significance obtained from Poisson-Poisson model toys (see section 5) as a function of the expected background \(b=\langle n\rangle\) for a relative uncertainty on \(b\) of 10% (top) and 50% (bottom). Results are shown for the number of observed events \(n\) equal to 0, 1, 2 and 3.

## 7 Conclusion

We surveyed various formulae for estimating the significance of \(n\) events for the background-only hypothesis prediction of \(b=\langle n\rangle\), itself possibly with an estimated error of \(\sigma\). The main goal was to provide a practical recommendation to be used, for example, in displaying bin-by-bin significances in comparing data and prediction, where significances can be positive or negative to usually indicate excess or deficit respectively. The performances of the significance formulae were assessed by comparing their predictions with the results of randomly generated toy data. The final recommendation, which offered the best overall performance, is given in equation 1 and is consistent with a Poisson-counting likelihood where the background nuisance parameter is constrained by an auxiliary Poisson measurement. This formula is found to slightly overestimate the magnitude of the true significance in the extreme case of very low event count (\(n=0\) and \(n=1\)), but we feel this should not be seen as a deterrent for its general usage.

## References

* [1] R. D. Cousins, J. T. Linnemann and J. Tucker, _Evaluation of three methods for calculating statistical significance when incorporating a systematic uncertainty into a test of the background-only hypothesis for a Poisson process_, Nuclear Instruments and Methods in Physics Research A **595** (2008) 480, eprint: physics/0702156 (cit. on pp. 2, 7-9).
* [2] K. Choi, _On the medians of gamma distributions and an equation of Ramanujan_, Proc. Amer. Math. Soc. **121** (1994) 245 (cit. on pp. 3, 7).
* [3] R. van de Ven and N. Weber, _Bounds for the Median of the Negative Binomial Distribution_, Metrica **40** (1993) 185 (cit. on pp. 3, 12, 23).
* [4] G. Choudalakis and D. Casadei, _Plotting the Differences Between Data and Expectation_, Eur. Phys. J. Plus **127** (2012) 25, arXiv: 1111.2062 [physics.data-an] (cit. on pp. 4, 11, 12).
* [5] N. L. Johnson, A. W. Kemp and S. Kotz, _Univariate Discrete Distributions_, 3rd edition, John Wiley & Sons Inc., 2005 (cit. on p. 7).
* [6] K. Cranmer, G. Lewis, L. Moneta, A. Shibata and W. Verkerke, _HistFactory: A tool for creating statistical models for use with RooFit and RooStats_, tech. rep. CERN-OPEN-2012-016, New York U., 2012, url: [https://cds.cern.ch/record/1456844](https://cds.cern.ch/record/1456844) (cit. on p. 14).